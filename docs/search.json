[
  {
    "objectID": "03-contmarked.html",
    "href": "03-contmarked.html",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\ntheme_set(theme_bw())\n\n\n\n\nspe = readRDS(\"../data/spe.rds\")\n\n#subset the data to only look at sample ID 0.01\nsub = spe[, spe$sample_id == 0.01]\n#sub = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"Astrocyte\", \"Pericytes\")]\n(pp = .ppp(sub, marks = \"cluster_id\"))\n\nMarked planar point pattern: 6111 points\nmarks are of storage type  'character'\nwindow: rectangle = [1222.5635, 3012.4248] x [-3993.535, -2202.755] units\n\n#subset the data to only look at sample ID 0.01\nsub_2CT = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"Astrocyte\", \"Inhibitory\")]\n#sub = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"Astrocyte\", \"Pericytes\")]\n(pp_2CT = .ppp(sub_2CT, marks = \"cluster_id\"))\n\nMarked planar point pattern: 2611 points\nmarks are of storage type  'character'\nwindow: rectangle = [1222.5635, 3012.4248] x [-3990.104, -2204.671] units\n\n#split the multitype point process into several single type processes\n#fist, set the marks of the point process to be factors\nmarks(pp) = factor(marks(pp))\nppls = split(pp)\n\n\nplot(ppls)"
  },
  {
    "objectID": "03-contmarked.html#session-info",
    "href": "03-contmarked.html#session-info",
    "title": "",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] SpatialExperiment_1.8.0     SingleCellExperiment_1.20.0\n [3] SummarizedExperiment_1.28.0 Biobase_2.58.0             \n [5] GenomicRanges_1.50.1        GenomeInfoDb_1.34.3        \n [7] IRanges_2.32.0              S4Vectors_0.36.0           \n [9] BiocGenerics_0.44.0         MatrixGenerics_1.10.0      \n[11] matrixStats_0.63.0          spatstat.core_2.4-4        \n[13] rpart_4.1.19                nlme_3.1-160               \n[15] spatstat.random_3.0-1       spatstat.geom_3.0-3        \n[17] spatstat.data_3.0-0        \n\nloaded via a namespace (and not attached):\n [1] locfit_1.5-9.6            Rcpp_1.0.9               \n [3] lattice_0.20-45           deldir_1.0-6             \n [5] digest_0.6.30             evaluate_0.18            \n [7] tensor_1.5                sparseMatrixStats_1.10.0 \n [9] zlibbioc_1.44.0           rlang_1.0.6              \n[11] rstudioapi_0.14           magick_2.7.3             \n[13] R.oo_1.25.0               R.utils_2.12.2           \n[15] Matrix_1.5-3              goftest_1.2-3            \n[17] rmarkdown_2.18            splines_4.2.1            \n[19] BiocParallel_1.32.3       stringr_1.4.1            \n[21] htmlwidgets_1.5.4         beachmat_2.14.0          \n[23] RCurl_1.98-1.9            polyclip_1.10-4          \n[25] DelayedArray_0.24.0       HDF5Array_1.26.0         \n[27] compiler_4.2.1            xfun_0.35                \n[29] DropletUtils_1.18.1       mgcv_1.8-41              \n[31] htmltools_0.5.3           GenomeInfoDbData_1.2.9   \n[33] edgeR_3.40.0              codetools_0.2-18         \n[35] bitops_1.0-7              rhdf5filters_1.10.0      \n[37] R.methodsS3_1.8.2         grid_4.2.1               \n[39] jsonlite_1.8.3            magrittr_2.0.3           \n[41] dqrng_0.3.0               scuttle_1.8.1            \n[43] cli_3.4.1                 stringi_1.7.8            \n[45] XVector_0.38.0            limma_3.54.0             \n[47] DelayedMatrixStats_1.20.0 spatstat.utils_3.0-1     \n[49] rjson_0.2.21              Rhdf5lib_1.20.0          \n[51] tools_4.2.1               abind_1.4-5              \n[53] parallel_4.2.1            fastmap_1.1.0            \n[55] yaml_2.3.6                spatstat.sparse_3.0-0    \n[57] rhdf5_2.42.0              knitr_1.41"
  },
  {
    "objectID": "04-bothmarked.html",
    "href": "04-bothmarked.html",
    "title": "",
    "section": "",
    "text": "source(\"utils.R\")\n\n\n\n\n\nspe <- readRDS(\"../data/spe.rds\")"
  },
  {
    "objectID": "04-bothmarked.html#session-info",
    "href": "04-bothmarked.html#session-info",
    "title": "",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] SpatialExperiment_1.8.0     SingleCellExperiment_1.20.0\n [3] SummarizedExperiment_1.28.0 Biobase_2.58.0             \n [5] GenomicRanges_1.50.1        GenomeInfoDb_1.34.3        \n [7] IRanges_2.32.0              S4Vectors_0.36.0           \n [9] BiocGenerics_0.44.0         MatrixGenerics_1.10.0      \n[11] matrixStats_0.63.0          spatstat.core_2.4-4        \n[13] rpart_4.1.19                nlme_3.1-160               \n[15] spatstat.random_3.0-1       spatstat.geom_3.0-3        \n[17] spatstat.data_3.0-0        \n\nloaded via a namespace (and not attached):\n [1] locfit_1.5-9.6            Rcpp_1.0.9               \n [3] lattice_0.20-45           deldir_1.0-6             \n [5] digest_0.6.30             evaluate_0.18            \n [7] tensor_1.5                sparseMatrixStats_1.10.0 \n [9] zlibbioc_1.44.0           rlang_1.0.6              \n[11] rstudioapi_0.14           magick_2.7.3             \n[13] R.oo_1.25.0               R.utils_2.12.2           \n[15] Matrix_1.5-3              goftest_1.2-3            \n[17] rmarkdown_2.18            splines_4.2.1            \n[19] BiocParallel_1.32.3       stringr_1.4.1            \n[21] htmlwidgets_1.5.4         beachmat_2.14.0          \n[23] RCurl_1.98-1.9            polyclip_1.10-4          \n[25] DelayedArray_0.24.0       HDF5Array_1.26.0         \n[27] compiler_4.2.1            xfun_0.35                \n[29] DropletUtils_1.18.1       mgcv_1.8-41              \n[31] htmltools_0.5.3           GenomeInfoDbData_1.2.9   \n[33] edgeR_3.40.0              codetools_0.2-18         \n[35] bitops_1.0-7              rhdf5filters_1.10.0      \n[37] R.methodsS3_1.8.2         grid_4.2.1               \n[39] jsonlite_1.8.3            magrittr_2.0.3           \n[41] dqrng_0.3.0               scuttle_1.8.1            \n[43] cli_3.4.1                 stringi_1.7.8            \n[45] XVector_0.38.0            limma_3.54.0             \n[47] DelayedMatrixStats_1.20.0 spatstat.utils_3.0-1     \n[49] rjson_0.2.21              Rhdf5lib_1.20.0          \n[51] tools_4.2.1               abind_1.4-5              \n[53] parallel_4.2.1            fastmap_1.1.0            \n[55] yaml_2.3.6                spatstat.sparse_3.0-0    \n[57] rhdf5_2.42.0              knitr_1.41"
  },
  {
    "objectID": "02-discmarked.html",
    "href": "02-discmarked.html",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\nlibrary(spatstat)\nlibrary(seg)\nlibrary(stats)\nlibrary(RANN)\nlibrary(ggplot2)\nlibrary(spatstat.geom)\n\n\n\n\n\nspe &lt;- readRDS(\"../data/spe.rds\")"
  },
  {
    "objectID": "02-discmarked.html#session-info",
    "href": "02-discmarked.html#session-info",
    "title": "Preamble",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices datasets  utils     methods  \n[8] base     \n\nother attached packages:\n [1] dixon_0.0-8                    splancs_2.01-44               \n [3] spdep_1.2-8                    sf_1.0-14                     \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.9.4                  SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] reshape2_1.4.4                 patchwork_1.1.3               \n[15] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[17] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[19] dbplyr_2.3.4                   RANN_2.6.1                    \n[21] seg_0.5-7                      sp_2.1-1                      \n[23] rlang_1.1.1                    ggplot2_3.4.4                 \n[25] dplyr_1.1.3                    mixR_0.2.0                    \n[27] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[29] spatstat.model_3.2-6           rpart_4.1.19                  \n[31] spatstat.explore_3.2-3         nlme_3.1-162                  \n[33] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[35] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[37] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[39] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[41] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[43] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[45] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] splines_4.3.1                 later_1.3.1                  \n  [3] bitops_1.0-7                  filelock_1.0.2               \n  [5] tibble_3.2.1                  R.oo_1.25.0                  \n  [7] polyclip_1.10-6               XML_3.99-0.14                \n  [9] lifecycle_1.0.3               edgeR_3.42.4                 \n [11] lattice_0.21-8                crosstalk_1.2.0              \n [13] magrittr_2.0.3                limma_3.56.2                 \n [15] rmarkdown_2.25                yaml_2.3.7                   \n [17] metapod_1.7.0                 httpuv_1.6.11                \n [19] spatstat.sparse_3.0-2         RColorBrewer_1.1-3           \n [21] DBI_1.1.3                     abind_1.4-5                  \n [23] zlibbioc_1.46.0               purrr_1.0.2                  \n [25] R.utils_2.12.2                RCurl_1.98-1.12              \n [27] rappdirs_0.3.3                GenomeInfoDbData_1.2.10      \n [29] ggrepel_0.9.4                 irlba_2.3.5.1                \n [31] spatstat.utils_3.0-3          terra_1.7-55                 \n [33] units_0.8-4                   goftest_1.2-3                \n [35] RSpectra_0.16-1               dqrng_0.3.1                  \n [37] DelayedMatrixStats_1.22.6     codetools_0.2-19             \n [39] DropletUtils_1.20.0           DelayedArray_0.26.7          \n [41] tidyselect_1.2.0              raster_3.6-26                \n [43] viridis_0.6.4                 ScaledMatrix_1.8.1           \n [45] base64enc_0.1-3               jsonlite_1.8.7               \n [47] BiocNeighbors_1.18.0          e1071_1.7-13                 \n [49] ellipsis_0.3.2                tools_4.3.1                  \n [51] ggnewscale_0.4.9              Rcpp_1.0.11                  \n [53] glue_1.6.2                    gridExtra_2.3                \n [55] xfun_0.40                     mgcv_1.8-42                  \n [57] HDF5Array_1.28.1              withr_2.5.1                  \n [59] BiocManager_1.30.22           fastmap_1.1.1                \n [61] boot_1.3-28.1                 rhdf5filters_1.12.1          \n [63] bluster_1.10.0                fansi_1.0.5                  \n [65] rsvd_1.0.5                    digest_0.6.33                \n [67] R6_2.5.1                      mime_0.12                    \n [69] colorspace_2.1-0              wk_0.8.0                     \n [71] tensor_1.5                    dichromat_2.0-0.1            \n [73] RSQLite_2.3.1                 R.methodsS3_1.8.2            \n [75] utf8_1.2.3                    generics_0.1.3               \n [77] renv_1.0.3                    class_7.3-22                 \n [79] httr_1.4.7                    htmlwidgets_1.6.2            \n [81] S4Arrays_1.0.6                tmaptools_3.1-1              \n [83] pkgconfig_2.0.3               scico_1.5.0                  \n [85] gtable_0.3.4                  blob_1.2.4                   \n [87] XVector_0.40.0                htmltools_0.5.6.1            \n [89] fftwtools_0.9-11              scales_1.2.1                 \n [91] png_0.1-8                     knitr_1.44                   \n [93] rstudioapi_0.15.0             rjson_0.2.21                 \n [95] curl_5.1.0                    proxy_0.4-27                 \n [97] cachem_1.0.8                  rhdf5_2.44.0                 \n [99] stringr_1.5.0                 BiocVersion_3.17.1           \n[101] KernSmooth_2.23-21            vipor_0.4.5                  \n[103] parallel_4.3.1                AnnotationDbi_1.62.2         \n[105] leafsync_0.1.0                s2_1.1.4                     \n[107] pillar_1.9.0                  grid_4.3.1                   \n[109] vctrs_0.6.4                   promises_1.2.1               \n[111] BiocSingular_1.16.0           beachmat_2.16.0              \n[113] xtable_1.8-4                  cluster_2.1.4                \n[115] beeswarm_0.4.0                evaluate_0.22                \n[117] magick_2.8.0                  cli_3.6.1                    \n[119] locfit_1.5-9.8                compiler_4.3.1               \n[121] crayon_1.5.2                  classInt_0.4-10              \n[123] ggbeeswarm_0.7.2              plyr_1.8.9                   \n[125] stringi_1.7.12                stars_0.6-4                  \n[127] viridisLite_0.4.2             deldir_1.0-9                 \n[129] BiocParallel_1.34.2           munsell_0.5.0                \n[131] Biostrings_2.68.1             leaflet_2.2.0                \n[133] Matrix_1.5-4.1                leafem_0.2.3                 \n[135] sparseMatrixStats_1.12.2      bit64_4.0.5                  \n[137] Rhdf5lib_1.22.1               statmod_1.5.0                \n[139] KEGGREST_1.40.1               shiny_1.7.5.1                \n[141] interactiveDisplayBase_1.38.0 igraph_1.5.1                 \n[143] memoise_2.0.1                 lwgeom_0.2-13                \n[145] bit_4.0.5"
  },
  {
    "objectID": "00-setup.html",
    "href": "00-setup.html",
    "title": "Preamble",
    "section": "",
    "text": "Show the code\nlibrary(ggplot2)\nlibrary(RColorBrewer)\nlibrary(ExperimentHub)\nlibrary(SpatialExperiment)\nlibrary(STexampleData)\n©2024 The pasta authors. Content is published under Creative Commons CC-BY-4.0 License for the text and GPL-3 License for any code."
  },
  {
    "objectID": "00-setup.html#save-data",
    "href": "00-setup.html#save-data",
    "title": "Preamble",
    "section": "Save data",
    "text": "Save data\n\n\nShow the code\nsaveRDS(spe, \"../data/spe.rds\")\nsaveRDS(spe_vis, \"../data/spe_spot.rds\")"
  },
  {
    "objectID": "00-setup.html#session-info",
    "href": "00-setup.html#session-info",
    "title": "Preamble",
    "section": "Session info",
    "text": "Session info\n\n\nShow the code\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] MerfishData_1.2.0           EBImage_4.42.0             \n [3] STexampleData_1.8.0         SpatialExperiment_1.10.0   \n [5] SingleCellExperiment_1.22.0 SummarizedExperiment_1.30.2\n [7] Biobase_2.60.0              GenomicRanges_1.52.1       \n [9] GenomeInfoDb_1.36.4         IRanges_2.34.1             \n[11] S4Vectors_0.38.2            MatrixGenerics_1.12.3      \n[13] matrixStats_1.0.0           ExperimentHub_2.8.1        \n[15] AnnotationHub_3.8.0         BiocFileCache_2.8.0        \n[17] dbplyr_2.3.4                BiocGenerics_0.46.0        \n[19] RColorBrewer_1.1-3          ggplot2_3.5.1              \n\nloaded via a namespace (and not attached):\n [1] DBI_1.1.3                     bitops_1.0-7                 \n [3] rlang_1.1.1                   magrittr_2.0.3               \n [5] compiler_4.3.1                RSQLite_2.3.1                \n [7] DelayedMatrixStats_1.22.6     fftwtools_0.9-11             \n [9] png_0.1-8                     vctrs_0.6.4                  \n[11] pkgconfig_2.0.3               crayon_1.5.2                 \n[13] fastmap_1.1.1                 magick_2.8.0                 \n[15] XVector_0.40.0                ellipsis_0.3.2               \n[17] labeling_0.4.3                scuttle_1.10.3               \n[19] utf8_1.2.3                    promises_1.2.1               \n[21] rmarkdown_2.25                purrr_1.0.2                  \n[23] bit_4.0.5                     xfun_0.40                    \n[25] beachmat_2.16.0               zlibbioc_1.46.0              \n[27] cachem_1.0.8                  jsonlite_1.8.7               \n[29] blob_1.2.4                    later_1.3.1                  \n[31] rhdf5filters_1.12.1           DelayedArray_0.26.7          \n[33] Rhdf5lib_1.22.1               BiocParallel_1.34.2          \n[35] interactiveDisplayBase_1.38.0 jpeg_0.1-10                  \n[37] tiff_0.1-11                   parallel_4.3.1               \n[39] R6_2.5.1                      limma_3.56.2                 \n[41] Rcpp_1.0.11                   knitr_1.44                   \n[43] R.utils_2.12.2                httpuv_1.6.11                \n[45] Matrix_1.5-4.1                tidyselect_1.2.0             \n[47] rstudioapi_0.15.0             abind_1.4-5                  \n[49] yaml_2.3.7                    codetools_0.2-19             \n[51] curl_5.1.0                    lattice_0.21-8               \n[53] tibble_3.2.1                  shiny_1.7.5.1                \n[55] withr_2.5.1                   KEGGREST_1.40.1              \n[57] evaluate_0.22                 Biostrings_2.68.1            \n[59] pillar_1.9.0                  BiocManager_1.30.22          \n[61] filelock_1.0.2                generics_0.1.3               \n[63] RCurl_1.98-1.12               BiocVersion_3.17.1           \n[65] sparseMatrixStats_1.12.2      munsell_0.5.0                \n[67] scales_1.3.0                  xtable_1.8-4                 \n[69] glue_1.6.2                    tools_4.3.1                  \n[71] locfit_1.5-9.8                rhdf5_2.44.0                 \n[73] grid_4.3.1                    edgeR_3.42.4                 \n[75] DropletUtils_1.20.0           AnnotationDbi_1.62.2         \n[77] colorspace_2.1-0              GenomeInfoDbData_1.2.10      \n[79] HDF5Array_1.28.1              cli_3.6.1                    \n[81] rappdirs_0.3.3                fansi_1.0.5                  \n[83] S4Arrays_1.0.6                dplyr_1.1.3                  \n[85] gtable_0.3.4                  R.methodsS3_1.8.2            \n[87] digest_0.6.33                 dqrng_0.3.1                  \n[89] farver_2.1.1                  rjson_0.2.21                 \n[91] htmlwidgets_1.6.2             memoise_2.0.1                \n[93] htmltools_0.5.6.1             R.oo_1.25.0                  \n[95] lifecycle_1.0.3               httr_1.4.7                   \n[97] mime_0.12                     bit64_4.0.5"
  },
  {
    "objectID": "01-unmarked.html",
    "href": "01-unmarked.html",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\n\n\n\n\n\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#subset the data to only look at sample ID 0.01\nsub &lt;- spe[, spe$sample_id == 0.01]\n(pp &lt;- .ppp(sub, marks = \"cluster_id\"))\n\nMarked planar point pattern: 6111 points\nmarks are of storage type  'character'\nwindow: rectangle = [1222.5635, 3012.4248] x [-3993.535, -2202.755] units\n\n#split the multitype point process into several single type processes\n#first, set the marks of the point process to be factors\nmarks(pp) &lt;- factor(marks(pp))\nppls &lt;- split(pp)\n\nIf not otherwise indicated, all information was taken from Baddeley et al. - Spatial Point Patterns.\n\n#Plot the entire point process where the marks are overlayed\nplot(unmark(pp), main = 'Point Pattern Unmarked')\n\n\n\n#Plot the marks separately \nplot(ppls, main = 'Point Pattern Marks Separated')\n\n\n\n\n\n\n\n\n\n\n\n\nComplete spatial randomness (CSR) is the null model of point patterns, being the result of a poisson process. A completely random process is characterised by two properties\n\n\nHomogeneity means that the expected number of points falling into a given region \\(B\\) is proportional to its area \\(|B|\\) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) is the intensity of the process, so the average number of points in a unit area.\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|\n\\label{eq:expected_number_points}\n\\]\n\n\n\nIndependence means that in two regions \\(A\\) and \\(B\\) the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are two independent random variables. That means the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). The number of points follow a poisson distribution:\n\\[\n\\mathbb{P}[N=k] = e^{-\\mu}\\frac{\\mu^k}{k!}\\\\\n\\label{eq:poisson_process}\n\\]\n\n\n\n\nA poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density \\(\\lambda(u)\\) is a function of spatial location \\(u\\). The expected number of points falling into a region \\(B\\) is\n\\[\n\\mu = \\int_{B} \\lambda(u)du\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\n\nA point process is called isotropic, if its statistical properties are invariant to rotations. A CSR process is both stationary and isotropic.\n\n\n\n“A point process is called stationary if, when we view the process through a window \\(W\\), its statistical properties do not depend on the location of the window in two-dimensional space.”\n\n\nIt is important to note that the inhomogeneous metrics do not apply to every spatially inhomogeneous point process. They only apply to point processes which are correlation stationary. A point pattern is correlation stationary if the metric only depends on the relative position in subpatterns of the point process, which means that estimates of the inhomogeneous metric should be similar in different subquadrats of the point pattern.\n\n\n\n\nThe inhomogeneous K-function further assumes that while the intensity is spatially varying, the scale of the interaction remains constant. This is equivalent to the assumption that in small subregions the process is stationary and isotropic, but the rescaling factor can vary across the total process. In this case the locally scaled version of the K-function is applicable.\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimatied functions between the quadrats. It has to be noted that this test highly depends on the arbitrarydefinition of the quadrats.\n\nselection &lt;- c('OD Mature')\npp_sel &lt;-  subset(pp, marks %in% selection, drop = TRUE)\n\n\nodrho &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\nodlambda &lt;- predict(odrho)\n\nod4 &lt;- quantess(unmark(pp_sel), \"x\", 2)\nod42 &lt;- nestsplit(pp_sel, od4, ny=3)\n\nplot(od42)\n\n\n\nod42$inten &lt;- factor(as.integer(od42$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n\nres.scaled &lt;- studpermu.test(od42, pts ~ inten, summaryfunction=Kscaled,\n               minpoints = 10)\n\nres.inhom &lt;- studpermu.test(od42, pts~ inten, summaryfunction=Kinhom,\n               lambda=odlambda, minpoints = 10)\n\n#p-value of the local-scaling test\nres.scaled$p.value\n\n[1] 0.001\n\n#p-value of the inhomogeneity test\nres.inhom$p.value\n\n[1] 0.415\n\n\nAlternatively, we can inspect deviations against the hypothesis that the points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types. Source\n#TODO: We should maybe move this to after the intensity part\n\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp, marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\nf0 &lt;- pValuesHotspot(pp_sel)\n\n# Plot significant p-values\nplot(f0$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\nIntensity is the expected density of points per unit area, as seen above. It can be interpreted as the rate of occurrence or the abundance of events recorded. The intensity itself is called a first moment property - being related to the expected number of points.\n\n\nThe intensity can be estimated regardless of the type of the point pattern. In order to do so, we sum the individual intensities of the marks\n\nintensityPointProcess&lt;- function(pp,mark){\n  if(mark == TRUE){\n    return(intensity(pp))\n  }\n  else{\n    return(sum(intensity(pp)))\n  }\n}\n\nintensityPointProcess(pp,mark=FALSE)\n\n[1] 0.001906561\n\n\nelse we can look at each mark individually\n\nintensityPointProcess(pp,mark=TRUE)\n\n   Ambiguous    Astrocyte  Endothelial    Ependymal   Excitatory   Inhibitory \n2.411670e-04 2.015445e-04 1.463225e-04 8.361288e-05 3.681463e-04 6.130571e-04 \n   Microglia  OD Immature    OD Mature    Pericytes \n3.026287e-05 6.239767e-05 1.425787e-04 1.747135e-05 \n\n\n\n\n\nIn quadrat counting all the points falling into a given quadrat are counted. This gives an overview on the characterstics of the point pattern, such as correlation stationarity.\n\nQ5 &lt;- quadratcount(pp, nx=5, ny=5)\nplot(unmark(pp), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\n\n\n\nThe quadrat counts can be tested against regularity. This can happen again in the unmarked pattern or in the separated types. This tells us if the counts of the points are distributed evenly across the quadrats.\n\nquadratTestPointProcess &lt;- function(pp, mark){\n  if(mark==TRUE){\n    return(lapply(split(pp), quadrat.test, 5, alternative=\"regular\", method=\"MonteCarlo\"))\n  }\n  else{\n    return(quadrat.test(unmark(pp), 5, alternative=\"regular\", method=\"MonteCarlo\"))\n  }\n}\nquadratTestPointProcess(pp, mark=FALSE)\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  unmark(pp)\nX2 = 245.95, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 5 by 5 grid of tiles\n\n\n\n\n\nIn kernel estimation we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There are different types of kernel estimators (see Baddeley). A popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth.\n\nDens &lt;- density(pp)\nplot(Dens, main = 'Kernel Density')\n\n\n\n\n\n\n\n\n\nWhether or not a point process is completely spatially random depends on two characeteristics. The points have to be distributed homogeneously and they have to be independent of each other (see definitions above). There are different ways to test for CSR which are summarised in the wrapper below.\n\n#PRE: takes a point process and the indication, which test for CSR should be performed and potentially a covariate\n#POST: returns if a point process or its individual point process marks are CSR or not.\n#TODO: Change maybe to a switch statment in terms of computing time; Change lapply to mclapply later on\n#TODO: There is a conceptual mistake - we pull out marks and test them against a markov simulation. It should rather be to test against all the other cells\ntestingCSR &lt;- function(\n    pp,\n    method = c('quadrat','cdf','bermans','clark-evans','hopkins-skellam'),\n    mark = FALSE,\n    covariate = NULL,\n    test = c('ks', 'cvm', 'ad'),\n    verbose = FALSE\n){\n  #perform a quadrattest for individual marks or for the entire pointprocess\n  if(method == 'quadrat'){\n    if(mark == TRUE){\n      test.result &lt;- lapply(split(pp), quadrat.test, 5, method=\"MonteCarlo\")\n    }\n    else{\n      test.result &lt;- quadrat.test(unmark(pp), 5, method=\"MonteCarlo\")\n    }\n   }\n  #perform a cdftest for individual marks or for the entire pointprocess given a covariate\n  else if(method == 'cdf' && !is.null(covariate)){\n    if(mark == TRUE){\n      test.result &lt;- lapply(split(pp), cdf.test, covariate, test=test)\n    }\n    else{\n      test.result &lt;- cdf.test(unmark(pp), covariate, test=test)\n    }\n  }\n  #perform a bermans test for individual marks or for the entire pointprocess\n  else if(method == 'bermans' && !is.null(covariate)){\n     if(mark == TRUE){\n      test.result &lt;- lapply(split(pp), berman.test, covariate, test='Z1')\n    }\n    else{\n      test.result &lt;- berman.test(unmark(pp), covariate, test='Z1')\n    } \n  }\n  #perform a clark evans test for individual marks or for the entire pointprocess\n  else if(method == 'clark-evans'){\n     if(mark == TRUE){\n      test.result &lt;- lapply(split(pp), clarkevans.test)\n    }\n    else{\n      test.result &lt;- clarkevans.test(unmark(pp))\n    } \n  }\n  #perform a hopkins-skellam test for individual marks or for the entire pointprocess\n  else if(method == 'hopkins-skellam'){\n     if(mark == TRUE){\n      test.result &lt;- lapply(split(pp), hopskel.test)\n    }\n    else{\n      test.result &lt;- hopskel.test(unmark(pp))\n    } \n  }\n  #base case of the \"switch\" statement\n  else{\n    print(\"ERROR: non-specified arguments or methods\")\n    return(NULL)\n  }\n  \n  #summarise the results as a mask of booleans to indicate which structures are \n  #random and which are not\n  if(mark==TRUE){\n    p.value.mask &lt;- lapply(test.result, function(x) x$p.value&gt;0.05)\n  }\n  else{\n    p.value.mask &lt;- test.result$p.value&gt;0.05\n  }\n  #return the values of the test calculations, either just the boolean if \n  #CSR or not or the entire test statistics\n  if(verbose == TRUE){\n    return(test.result)\n  }\n  else{\n    return(p.value.mask)\n  }\n}\nresult &lt;- testingCSR(pp,method='clark-evans',mark=TRUE, verbose=FALSE)\n\ntestingCSR(ppls$Ependymal, method='clark-evans')\n\n[1] FALSE\n\ntestingCSR(ppls$`OD Mature`, method='clark-evans')\n\n[1] FALSE\n\ntestingCSR(ppls$Microglia, method='clark-evans')\n\n[1] FALSE\n\n\n\n\n\n\nCorrelation or more generally covariance is called a second order quantity and measures dependence between data points. This is a very useful concept, allowing for the assessment of correlation between points.\n\n\n\n\n\nIn the framework of correlation analysis we often look at distances \\(d_{ij} = ||x_i-x_j||\\) of all ordered points. It is a natural idea to look at the summary of these distances \\(d_{ij}\\), e.g. a histogram. The histogram of this point process is a difficult statistic, as it depends on the observation window \\(W\\), thus the histogram can change significantly with a changing window \\(W\\). Therefore, we look at the empirical distribution function of the distances \\(d_{ij}\\) that are smaller or equal than a radius \\(r\\)\n\\[\n\\hat{H}(r) = \\frac{1}{n(n-1)}\\sum_{i=1}^n \\sum_{j=1\\\\j\\neq i}^n \\{d_{ij}\\leq r\\}\n\\]\nThe contribution of each point \\(x_i\\) to the sum above is\n\\[\nt_i(r) = \\sum_{j \\neq i} \\mathbb{1} \\{d_{ij}\\leq r\\}\n\\]\nthis number \\(t_i(r)\\) is the number of points that fall within a radius \\(r\\) centered at \\(x_i\\). It follows then:\n\\[\n\\hat{H}(r) = \\frac{1}{n(n-1)}\\sum_{i=1}^n t_i(r) = \\frac{1}{n-1} \\bar{t}(r)\n\\]\nHere, we see what we actually want to measure is “the average number of r-neighbours of a typical random point”. This number is still dependent on the size of the observation window so we want to standardise is by the number of points and \\(|W|\\) the window size. Then we obtain the empirical Ripley’s \\(K\\) function\n\\[\n\\hat{K}(r) = \\frac{|W|}{n(n-1)}\\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n\\{d_{ij}\\leq r\\}\n\\]\nThe standardisation makes it possible to compare point patterns with different observation windows and with different numbers of points. Using the empirical \\(K\\) function assumes though tha the point process has homogeneous intensity.\n\n\n\ninstead of the summary of pairwise distances, we are interested in the point process. In order to do so, we have to think about the expected number of \\(r\\)-neighbours given a point \\(X\\) at a location \\(u\\) divided by its intensity \\(\\lambda\\)\nThis means\n\\[\nK(r) = \\frac{1}{\\lambda} \\mathbb{E} [t(u,r,X)|u \\in X]\n\\]\nwhere\n\\[\nt(u,r,X) = \\sum_{j=1}^{n(X)} \\mathbb{1} \\{0&lt;||u-x_j||\\leq r\\}\n\\]\nThis definition of the true \\(K\\) function is only valid if the point process is stationary. For a homogeneous poisson process we obtain\n\\[\nK_{pois}(r) = \\pi r^2\n\\]\n\n\n\nEdge effects describe the phenomenon that we never observe the entire point process but only a part of it within a window \\(W\\). This means that parts of the point process at the border might not be observed and the value of the statistic biased along the edges.\nThere are many corrections for edge effects. They are briefly listed here\n\n\nIn border correction the summation of data points is restricted to \\(x_i\\) for which \\(b(x_i,r)\\) is completely in the window \\(W\\).\n\n\n\nWe can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.\n\n\n\nA stationary point process \\(X\\) is invariant to translations. So the entire point process can be shifted by a vector \\(s\\) to be at the position \\(X+s\\).\n\n\n\n\n\nThe \\(K\\)-function can be centered which is then called the \\(L\\)-function. The \\(L\\)-function is a variance-stabilising version of the \\(K\\)-function (see spicyR for reference).\n\\[\nL(r) = \\sqrt{\\frac{K(r)}{\\pi}}\n\\]\n\n\n\nWe have seen above, that the \\(K\\)-function is cumulative in nature. Meaning that the contributions of all distances smaller equal to \\(r\\) are counted. An alternative is to take the derivative of the \\(K\\)-function in order to obtain contributions of distances between points equal to \\(r\\).\n\\[\ng(r) = \\frac{K'(r)}{2\\pi r}\n\\]\n“\\(g(r)\\) is the probability of observing a pair of point of the process separated by a distance \\(r\\), divided by the corresponding probability for a Poisson process.”\n\n\nThe pair correlation function can be estimated via kernel smoothing. In very large datasets the pair correlation function can be approximated using histogram-based methods.\n\\[\n\\hat{g}(r) = \\frac{|W|}{2 \\pi r n (n-1)} \\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n \\kappa_h(r-d_{ij})e_{ij}(r)\n\\]\nwhere \\(\\kappa\\) is the smoothing kernel. \\(\\kappa_h(x)\\) is a rescaled version of the template kernel \\(\\kappa\\)\n\\[\n\\kappa_h(x) = \\frac{1}{h}\\kappa\\left(\\frac{x}{h}\\right)\n\\]\nIn the above, \\(\\kappa\\) can be any probability density “over the real line with mean 0”. Usually, the Epanechinikov kernel is used as smoothing kernel with half-width \\(w\\).\n\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricResBoot &lt;- function(ppls, celltype, fun){\n  metric.res &lt;- lohboot(ppls[[celltype]], fun = fun)\n  metric.res$type &lt;- celltype\n  return(metric.res)\n}\n#PRE: celltypes, function to calculation and edge correction method\n#POST: dataframe of \nmetricResBootToDF &lt;- function(celltype_ls, ppls, fun, edgecorr){\n  res_ls &lt;- lapply(celltype_ls, metricResBoot, fun = fun, ppls = ppls)\n  #stick all values into a dataframe\n  res_df &lt;- c()\n  for(i in 1:length(celltype_ls))res_df &lt;- rbind(res_df, res_ls[[i]])\n  return(res_df)\n}\n\n#PRE: Celltypes of interest, function to analyse, edge correction to perform\n#POST: plot of the metric\nplotMetric &lt;- function(celltype_ls, ppls, fun, edgecorr){\n  res_df &lt;- metricResBootToDF(celltype_ls, ppls, fun, edgecorr)\n  #plot the curve\n  p &lt;- ggplot(res_df, aes(x=r, y=res_df[[edgecorr]], col= type))+\n    geom_line()+\n    geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)+\n    ggtitle(paste0(fun, '-function'))+\n    geom_line(aes(x=r,y=theo, color = 'Poisson'),linetype = \"dashed\")+\n    ylab(edgecorr) +\n    scale_color_manual(name='Point Processes',\n                     breaks=c('Ependymal', 'Microglia', 'OD Mature', 'Poisson'),\n                     values=c('Ependymal'='red', 'Microglia'='dark green', 'OD Mature'='blue', 'Poisson'='black'))+\n    theme_light()\n  return(p)\n}\n\ncelltype_ls &lt;- c(\"Ependymal\", \"OD Mature\", \"Microglia\")\np_K &lt;- plotMetric(celltype_ls, ppls, 'Kest', 'iso')\n\np_L &lt;- plotMetric(celltype_ls, ppls, 'Lest', 'iso')\n\np_g &lt;- plotMetric(celltype_ls, ppls, 'pcf', 'border')\n\n\np_K/p_L/p_g\n\n\n\n\n\n\n\n\n\n\nIn the case that a spatial pattern is known or suspected to be inhomogeneous, we have to take this into account for our analysis. Biological samples display inhomogeneity very often, therefore this analysis is preferred over the homogeneous alternatives. Inhomogeneous alternatives can be calculated via:\n\\[\nK_{inhom}(r) = \\mathbb{E} \\left[\\sum_{x_j \\in X} \\frac{1}{\\lambda(x_j)}\\mathbb{1}\\{0&lt;||u-x_j||\\leq r\\}|u \\in X\\right]\n\\]\nThis theoretical quantity can be approximated with estimators such as\n\\[\n\\hat{K}_{inhom}(r) = \\frac{1}{D^p|W|}\\sum_i\\sum_{j \\neq i} \\frac{\\mathbb{1}\\{||u-x_j||\\leq r\\}}{\\hat{\\lambda}(x_j)\\hat{\\lambda}(x_i)}e(x_j,x_i;r)\n\\]\nwhere \\(e(u,v;r)\\) is an edge correction weight, \\(\\hat{\\lambda}(u)\\) is an estimator of the intensity of \\(u\\) and \\(D^p\\) is the pth power of\n\\[\nD = \\frac{1}{|W|}\\sum_i \\frac{1}{\\hat{\\lambda}(x_i)}\n\\]\n\np_K &lt;- plotMetric(celltype_ls, ppls, 'Kinhom', 'iso')\n\np_L &lt;- plotMetric(celltype_ls, ppls, 'Linhom', 'iso')\n\np_g &lt;- plotMetric(celltype_ls, ppls, 'pcfinhom', 'border')\n\n\np_K/p_L/p_g\n\n\n\n\nThe inhomogeneous \\(K\\)-function tells us that the microglia cells follow a Poisson process (dashed line) closely and can therefore be assumed to be randomly distributed and not clustered. Ependymal cells show a high degree of clustering at a low radius \\(r\\). OD mature cells are in the middle, showing a lower degree of clustering at lower values of \\(r\\).\nThe \\(L\\)-function is a variance stabilised (source spicyR) version of the \\(K\\)-function. Thus, the information is complementary to the above. Microglia cells are along the dashed poisson line, indicating no clustering of microglia cells. Ependymal cells are highly clustered at low values of \\(r\\), whereas OD mature show intermediate clustering at lower values of \\(r\\).\nThe pair correlation function is the derivative of the \\(K\\)-function. Therefore, it is not a sum of the points in the circle with radius \\(r\\) but rather the individual points on the radius \\(r + h\\) where \\(h\\) is very small. The pcf plot gives similar information as before: Microglia cells are around the dashed poisson line. OD Mature cells show a rather broad range of correlations between \\(r \\in [20,100]\\). Ependymal cells have a very strong correlation at \\(\\sim r = 25\\).\nWe have to note that inhomogeneity correction assumes that the process is correlation stationary, meaning that the summary statistics are the same in each quadrat. This is clearly violated at least for Ependymal cells and OD mature cells. Therefore, the question remains whether acounting for one issue (homogeneity) via a correction that assumes correlation stationarity does not just exchange one problem for another.\n\n\n\n\n\n\nIn the inhomogeneous \\(K\\) approach above, we assume that the local scale of the point process is not changed. However, the intensity can vary spatially. In a biological sample, this assumption is easily violated, e.g. when a gradient of cells that increases from one side to another. Therefore, we can assume that the process is subdivided in small regions. In these small regions the point process is a scaled version of a template process. This template process has to be both stationary and isotropic. For two locations \\(u\\) and \\(v\\) we would then assume that\n\\[\ng(u,v) = g_1 \\left(\\frac{||u-v||}{s}\\right)\n\\]\nIn this example, \\(g_1\\) is the pair correlation function of the template process and \\(s\\) a scaling factor.\n\n\n\nwould work by taking the derivative of the locally scaled \\(K\\)-function\n\n\n\nAs the \\(L\\) is just a transformation of the \\(K\\)-function, the same local scaling can apply to the \\(L\\)-function\n\n### need to redefine the metric function, because bootstrap is not available for locally scaled functions ###\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricRes &lt;- function(ppls, celltype, fun){\n  metric.res &lt;- do.call(fun, args = list(X=ppls[[celltype]]))\n  metric.res$type &lt;- celltype\n  return(metric.res)\n}\n\n#PRE: celltypes, function to calculation and edge correction method\n#POST: dataframe of \nmetricResToDF &lt;- function(celltype_ls, ppls, fun, edgecorr){\n  res_ls &lt;- lapply(celltype_ls, metricRes, fun = fun, ppls = ppls)\n  #stick all values into a dataframe\n  res_df &lt;- c()\n  for(i in 1:length(celltype_ls))res_df &lt;- rbind(res_df, res_ls[[i]])\n  return(res_df)\n}\n### need to redefine the plotting function, because bootstrap is not available for locally scaled functions ###\n#PRE: Celltypes of interest, function to analyse, edge correction to perform\n#POST: plot of the metric\nplotScaledMetric &lt;- function(celltype_ls, ppls, fun, edgecorr){\n  res_df &lt;- metricResToDF(celltype_ls, ppls, fun, edgecorr)\n  #plot the curve\n  p &lt;- ggplot(res_df, aes(x=r, y=res_df[[edgecorr]], col= type))+\n    geom_line(size=1)+\n    ggtitle(paste0(fun, '-function'))+\n    geom_line(aes(x=r,y=theo, color = 'Poisson'),linetype = \"dashed\", size=1)+\n    ylab(edgecorr) +\n    scale_color_manual(name='Point Processes',\n                     breaks=c('Ependymal', 'Microglia', 'OD Mature', 'Poisson'),\n                     values=c('Ependymal'='red', 'Microglia'='dark green', 'OD Mature'='blue', 'Poisson'='black'))+\n    theme_light()\n  return(p)\n}\n\np_K &lt;- plotScaledMetric(celltype_ls, ppls, 'Kscaled', 'iso')\n\np_L &lt;- plotScaledMetric(celltype_ls, ppls, 'Lscaled', 'iso')\n\n\np_K/p_L\n\n\n\n\nThe interpretation of the locally scaled \\(L\\)-function is similar to the interpreation of the inhomogeneous \\(L\\)-function. The correlation is strongest for Ependymal cells, followed by OD mature cells. Microglia cells are again close to the random poisson process. Note that here, the curves of the Ependymal and OD mature cells stay always above the dashed poisson line, unlike in the inhomogeneous version.\nGiven that our biological samples are both inhomogeneous and locally scaled by eye (can be tested as seen above), the locally scaled \\(L\\)-function seems a good variant for assessing correlation.\n\n\n\nThe \\(K\\) and \\(L\\)-functions above are summary statistics over the entire pattern. However, if we know that there are different regions in our point pattern, we might want to know the individual contributions of these patterns. This gives then e.g. \\(n\\) (for all points) local \\(K\\),\\(L\\) or pair correlation-functions. Baddeley et. al. propose to compare these \\(n\\) functions with e.g. functional principal component analysis. We will show here the example of the LISA version of the \\(L\\) function.\n\n\n\n\nL_odmature_lisa &lt;- localL(ppls$`OD Mature`)\n# plot(L_odmature_lisa, main = 'local L functions OD Mature', legend=FALSE)\n\ndf &lt;- as.data.frame(L_odmature_lisa)\n\ndfm &lt;- reshape2::melt(df, \"r\")\n\nget_sel &lt;- dfm %&gt;% filter(r &gt; 200.1358 & r &lt; 200.1360, variable != \"theo\") %&gt;%\n  mutate(sel = value) %&gt;% select(variable, sel)\n\ndfm &lt;- dfm %&gt;% left_join(get_sel)\n\np &lt;- ggplot(dfm, aes(x=r, y=value, group=variable, colour=sel)) +\n  geom_line() + \n  scale_color_continuous(type = \"viridis\") +\n  geom_vline(xintercept = 200) +\n  theme(legend.position = \"none\") +\n  theme_light()\n\nppdf &lt;- as.data.frame(pp) %&gt;% filter(marks==\"OD Mature\")\nppdf$sel &lt;- get_sel$sel # assume they are in same order\n\nq &lt;- ggplot(ppdf, aes(x=x, y=y, colour=sel)) + \n  geom_point() +\n  scale_color_continuous(type = \"viridis\") +\n  theme(legend.position = \"none\") +\n  theme_light()\n\n\np|q\n\n\n\n\nIn the case of the OD mature cells we obtain further information with this plot. We note that there are two distinct populations of curves, those that are clearly above the straight poisson line and others that are around/underneath the straight poisson line. This indicates that there are two different kinds of interactions in the OD mature cells. Stronger clustering (the upper part of the plot) and more random parts (lower part).\nThere are inhomogeneous versions of these (e.g. localLinhom). These are not shown here for brevity.\n\n\n\nWe apply functional PCA to retrieve the main trends in these individual curves. The idea of functional PCA is the same as for ordinary PCA just applied to the concept of functions. For the \\(n\\) functions above functional PCA will recover the main trends in the data\n\n#adapted from the fdapace vignette\nfunctional.pca.pp &lt;- function(df){\n  df_fdob &lt;- df %&gt;% as.matrix()\n  #remove theo column - we want only the actual estimations in there without the poisson line theo\n  if('theo' %in% colnames(df)){\n     df_fdob &lt;- df_fdob[,-ncol(df_fdob)]\n  }\n  if('r' %in% colnames(df)){\n     df_fdob &lt;- df_fdob[,-ncol(df_fdob)]\n  }\n  #number of columns\n  N &lt;- ncol(df_fdob)\n  #number of rows\n  M &lt;- nrow(df_fdob)\n  #the x values at which all the curves were evaluated, here called tVec\n  s &lt;- df$r\n  #create the FPCA object\n  fd_obj &lt;- fdapace::MakeFPCAInputs(IDs = rep(1:N, each=M),tVec=rep(s,N), yVec=df_fdob)\n  #check that the FPCA object is valid\n  fdapace::CheckData(fd_obj$Ly, fd_obj$Lt)\n  #run the computation of the FPCA - would work with sparse data.\n  fpca_obj &lt;- fdapace::FPCA(fd_obj$Ly, fd_obj$Lt, list(plot = TRUE, dataType='Dense', kernel='rect'))\n  fdapace::CreatePathPlot(fpca_obj,K = 3, pch = 4,showObs = FALSE, showMean = TRUE)\n}\n\nfunctional.pca.pp(L_odmature_lisa)\n\n\n\n\n\n\n\nHere, we see the functional PCA for the OD mature cells. The Design plot tells us that we have a very dense dataset over the entire support. The mean curve displays the mean trend over all \\(n\\) LISA \\(L\\)-curves (note that this result is similar to the locally scaled \\(L\\)-function). The scree plot indicates that the first eigenfunction explains more than \\(80 \\%\\) of the variance. The eigenfunction curves in the bottom right panel indicate the deviation from the mean curve.\nLooking at the second plot we see the smoothed mean curve and the individual curves that are reconstructed from the first three eigenfunctions. The first eigenfunction from the bottom right panel, \\(\\phi_1\\), is above the mean curve. When we look at the example that is clearly visible. \\(\\phi_2\\) is first above the mean curve and then lower than the mean curve. These curves are visible as well. Lastly, \\(\\phi_3\\) is curves that start low and pick up to be larger than the mean curve in the end. This is visible in e.g. the orange dashed line -&gt; check the source from the Springer book “Functional Data Analysis with R and Matlab”.\n\n\n\n\n\nSo far we have considered first- and second-order summary statistics and local adaptations of these. In the following, we will continue a high-order statistics. In second-order statistics one considers pairs and counts these in the case of the \\(K\\) function. In a third-order setting we would now count triplets of points. A triplet is counted as the normalised expected value of triangles where all edges are smaller than the radius r\n\\[\nT(r) = \\frac{1}{\\lambda^3}\\mathbb{E}\\left[\\sum_{i=1}^n\\sum_{j=1\\\\j\\neq i}^nm(x_i,x_j,u) | u \\in X\\right]\n\\]\nhere m is the maximum side of the triangle\n\\[\nm(a,b,c) = \\max(||a-b||,||a-c||,||b-c||)\n\\]\n\np &lt;- plotScaledMetric(celltype_ls, ppls, 'Tstat', 'trans')\np\n\n\n\n\n\n\n\n\nSo far, most approaches considered intensity and correlation as measures to assess a point pattern. Below, we will look at measures of spacing and shortest-distances to assess spatial arrangements.\nBaddeley et.al. summarises three basic distances to measure\n\npairwise distance: \\(d_{i,j} = ||x_i-x_j||\\)\nnearest-neighbour distances: \\(d_i = \\min_{j \\neq i}d_{ij}\\)\nempty-space distance: \\(d(u) = \\min_j||u-x_j||\\)\n\nThere are test of CSR that are based on spacing -&gt; Clark-Evans test and Hopkins-Skellam Index that are both implemented above in the CSR testing function\n\n\n\nNearest neighbour methods center around the notion of “nearness”. In particular, we introduce nndist from spatstat, a method to calculate the distances until \\(k\\) nearest neighbours are found. This function returns us then \\(k\\) curves for the \\(k\\) neighbour distances. We can for instance collapse this information of the \\(k\\) curves in a mean curve per sample. This information of the mean nearest neighbour distance is summarised as a density.\n\nnndistance &lt;- function(pp, nk){\n  xy &lt;- cbind(pp$x, pp$y)\n  nndistances_k15 &lt;- nndist(xy, k = nk) \n  nndistances_mean &lt;- rowMeans(nndistances_k15)\n  return(nndistances_mean)\n}\n\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricRes_nndist &lt;- function(ppls, celltype, fun){\n  metric.res &lt;- list(res = do.call(fun, args = list(pp=ppls[[celltype]], nk = seq(1:15))))\n  metric.res$type = celltype\n  return(metric.res)\n}\n\n#go through all defined celltypes and calculate the nearest-neighbour distance\nres_ls &lt;- lapply(celltype_ls, metricRes_nndist, fun = nndistance, ppls = ppls)\n#initialise a dataframe for the metric values and the type information\nres_df &lt;- data.frame(metric = numeric(0), type = character(0))\n# Loop through the res_ls list and combine the metric values with their corresponding type - ChatGPT\nfor (i in 1:length(res_ls)) {\n  metric_values &lt;- res_ls[[i]]$res\n  metric_type &lt;- rep(res_ls[[i]]$type, length(metric_values))\n  df &lt;- data.frame(metric = metric_values, type = metric_type)\n  res_df &lt;- rbind(res_df, df)\n}\n#plot the densities\np &lt;- ggplot(res_df, aes(x=metric, col= type))+\n    geom_density(linewidth=1)+\n    scale_x_sqrt() +\n    theme_light() +\n    ggtitle('Sqrt of the Mean Nearest-Neighbour Distance')\np\n\n\n\n\n\nres_df_wider &lt;- res_df %&gt;% group_by(type) %&gt;% mutate(row = row_number()) %&gt;% tidyr::pivot_wider(names_from = type, values_from = metric) %&gt;% select(-row) \n#we have the problem that the number of points is not the same for all celltypes\nfunctional.pca.pp(res_df_wider) \n\nIn the probability-density function of the nearest neighbours the ependymal cells show the shortest nearest-neighbour distances. The OD mature cells have larger nearest neighbour distances and the bimodal distribution indicates a mix of longer and wider distances (which was as well visible in the LISA \\(L\\) function). Microglia cells show the widest distances and the symmetry of the curve indicates similar distances throughout the field of view.\n\n\nOften, we are interested which spatial structures build a spatial unit. One way to answer this question is to use spatially aware clustering. Here we show one very basic approach, DBScan (density-based spatial clustering with applications for noise). DBScan is an algorithm which uses a parameter called minimal Features. If the number of points per cluster is smaller than the minimal number of features, it is either noise or it is merged with another cluster. Another parameter \\(\\epsilon\\) defines the distance at which a point has to lay in order to be part of a cluster. The value of this parameter \\(\\epsilon\\) can be determined by an elbow plot, similar to clustering resolution parameters in other algorithms. from https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/how-density-based-clustering-works.htm\n\npp_df &lt;- as.data.frame(ppls$`OD Mature`)\n#determine the correct epsilon neighbourhood\ndbscan::kNNdistplot(pp_df, k=5)\n\n\n\n\nGiven the kNN distance plot we visually detect the “knee” of the curve to be at an distance \\(\\epsilon\\) of \\(200\\). This value is needed for the computation of DBScan.\n\n#perform DBScan\npp_dbscan &lt;- dbscan::dbscan(pp_df[-3], eps =200, minPts = 5)\nplot(pp_df[-3], col = pp_dbscan$cluster)\n\n\n\n\nWe see that DBScan identifies four clusters. A top cluster in red and two main side clusters in black and green. There is another cluster in blue which is at the top right corner.\nanother lead to follow in detected spatial clusters is scan statistics with the package .\n\n\n\n\n\n\nUnder a stationary spatial point process, the empty-space distance is defined as\n\\[\nd(u,X) = \\min\\{||u-x_i||: x_i \\in X\\}\n\\]\nThe empty space function is then the cumulative distribution function of the empty-space distances defined above\n\\[\nF(r) = \\mathbb{P}\\{d(u,X)\\leq r\\}\n\\]\nThe nearest-neighbour distance is defined as\n\\[\nd_i = \\min_{j\\neq i}||x_j-x_i||\n\\]\nThe nearest-neighbour distance distribution function \\(G(r)\\) is then defined as\n\\[\nG(r) = \\mathbb{P}\\{d(x,X\\backslash u \\leq r |X\\ has\\ a\\ point\\ at\\ u\\}\n\\]\nFor a homogeneous Poisson process, the nearest-neighbour distance distribution is identical to the empty-space function of the same process\n\\[\nG_{pois} \\equiv F_{pois}\n\\]\nFor a general point process the \\(F\\) and \\(G\\) functions are different\n\n\n\n\nThe \\(F\\) and \\(G\\) functions are, like the \\(K\\) function, cumulative. The same disadvantages as with the \\(K\\) function occur here too. Therefore, an analogue to the pair-correlation function would make sense to consider. For practical reasons this is no longer the derivative of the \\(F\\) function but rather a hazard rate.\n\\[\nh(r) = \\frac{f(r)}{1-F(r)}\n\\]\nFor a CSR process, the hazard rate is\n\\[\nh_{pois}(r) = 2 \\pi \\lambda r\n\\]\nHere we use a variance stabilising transformation as suggested by Baddeley et. al. This transformation means that if the process is completely spatial random, the hazard is equal to the intensity \\(\\lambda\\). \n\n\n\nThe concepts of the empty-space function \\(F\\) and the nearest-neighbour function \\(G\\) are somewhat complementary. If one decreases, the other increases. A comparison of these two functions as a measure of CSR is the Hopkins-Skellam test (implemented above).\nAnother approach is the \\(J\\) function.\n\\[\nJ(r) = \\frac{1-G(r)}{1-F(r)}\n\\]\n“For a homogeneous Poisson process, \\(F_{pois} \\equiv G_{pois}\\) such that then \\(J_{pois} \\equiv 1\\). Values \\(J(r) &gt; 1\\) are consistent with a regular pattern, and $J(r) &lt; 1 is consistent with clustering.” (Baddeley et. al.)\n\n### need to redefine the plotting function, because bootstrap is not available for spacing functions ###\n#PRE: Celltypes of interest, function to analyse, edge correction to perform\n#POST: plot of the metric\nplotSpacingMetric &lt;- function(celltype_ls, ppls, fun, x,  edgecorr){\n  res_df &lt;- metricResToDF(celltype_ls, ppls, fun)\n  #plot the curve\n  p &lt;- ggplot(res_df, aes(x=res_df[[x]], y=res_df[[edgecorr]], col= type))+\n    geom_line()+\n    ylab(edgecorr) +\n    xlab(x) +\n    ggtitle(paste0(fun, '-function'))+\n    geom_line(aes(x=res_df[[x]], y=theo), linetype = 'dashed')+\n    theme_light()\n  return(p)\n}\n\np_G &lt;- plotSpacingMetric(celltype_ls, ppls, 'Gest', 'r', 'rs')\n\np_F &lt;- plotSpacingMetric(celltype_ls, ppls, 'Fest', 'r', 'rs')\n\np_J &lt;- plotSpacingMetric(celltype_ls, ppls, 'Jest', 'r', 'rs')\n\n\np_G/p_F/p_J\n\n\n\n\n\n\n\nThere are inhomogeneous variants of the spacing functions explained above\n\np_G &lt;- plotSpacingMetric(celltype_ls, ppls, 'Ginhom', 'r', 'bord')\n\np_F &lt;- plotSpacingMetric(celltype_ls, ppls, 'Finhom', 'r', 'bord')\n\np_J &lt;- plotSpacingMetric(celltype_ls, ppls, 'Jinhom', 'r', 'bord')\n\n\np_G/p_F/p_J\n\n\n\n\nAgain here, comparing the homogeneous versions of the functions with the inhomogeneous ones reveals, that we seem to solve one problem (inhomogeneity) by assuming correlation stationarity. As this is not given, the inhomogeneous versions don’t seem to be accurate. In fact, the homogeneous versions are more easily interpretable than the inhomogeneous alternatives.\n\n\n\nNext to the distance to the nearest-neighbours, we can estimate the orientation of the vector to the nearest-neighbour. This gives an indication of the orientation of the spacing.\n\np &lt;- plotSpacingMetric(celltype_ls, ppls, 'nnorient', 'phi', 'bordm')\np\n\n\n\n\nThe values of \\(\\phi\\) correspond to the orientation of the point pattern. The horizontal axis goes from \\(180\\) to \\(0\\) (left to right) and the vertical from \\(90\\) to \\(270\\) (top to bottom). We can infer that the orientation of the Ependymal nearest-neighbours is along the vertical axis, OD mature cells don’t show a clear pattern and microglial cells a horizontal orientation in their nearest neighbours with a small peak at \\(\\sim 180\\) (orientation to the top).\nThe concept of spacing is not only usable in point pattern analysis but more broadly in any spatial context (e.g. spacing between shapes instead of points).\n\n\n\nThe same consideration about edge effects as for the \\(K\\) functions have to be made for the spacing functions. The uncorrected estimators are negatively biased as estimators for the real spacing functions. The easiest approach is to draw an artificial border and consider nearest neighbours there in. Other approaches are based on sampling. Yet another approach is based on survival analysis. The idea is that a circle of a point to grows homogeneously with increasing radius until it hits the frame of the window and “dies”. This gives survival distributions. This is similar to censored data, where the Kaplan-Meier estimator is the optimal choice."
  },
  {
    "objectID": "01-unmarked.html#session-info",
    "href": "01-unmarked.html#session-info",
    "title": "Preamble",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] stringr_1.5.0                  dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.9.4                  SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-14                     \n[17] reshape2_1.4.4                 patchwork_1.1.3               \n[19] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[21] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[23] dbplyr_2.3.4                   RANN_2.6.1                    \n[25] seg_0.5-7                      sp_2.1-1                      \n[27] rlang_1.1.1                    ggplot2_3.4.4                 \n[29] dplyr_1.1.3                    mixR_0.2.0                    \n[31] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[33] spatstat.model_3.2-6           rpart_4.1.19                  \n[35] spatstat.explore_3.2-3         nlme_3.1-162                  \n[37] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[39] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[41] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[43] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[45] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[47] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[49] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] numDeriv_2016.8-1.1           backports_1.4.1              \n  [7] tools_4.3.1                   utf8_1.2.3                   \n  [9] R6_2.5.1                      HDF5Array_1.28.1             \n [11] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [13] withr_2.5.1                   gridExtra_2.3                \n [15] leaflet_2.2.0                 leafem_0.2.3                 \n [17] cli_3.6.1                     labeling_0.4.3               \n [19] proxy_0.4-27                  dbscan_1.1-11                \n [21] foreign_0.8-84                R.utils_2.12.2               \n [23] dichromat_2.0-0.1             scico_1.5.0                  \n [25] limma_3.56.2                  rstudioapi_0.15.0            \n [27] RSQLite_2.3.1                 generics_0.1.3               \n [29] crosstalk_1.2.0               Matrix_1.5-4.1               \n [31] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [33] abind_1.4-5                   R.methodsS3_1.8.2            \n [35] terra_1.7-55                  lifecycle_1.0.3              \n [37] yaml_2.3.7                    edgeR_3.42.4                 \n [39] rhdf5_2.44.0                  tmaptools_3.1-1              \n [41] grid_4.3.1                    blob_1.2.4                   \n [43] promises_1.2.1                dqrng_0.3.1                  \n [45] crayon_1.5.2                  lattice_0.21-8               \n [47] beachmat_2.16.0               KEGGREST_1.40.1              \n [49] magick_2.8.0                  pillar_1.9.0                 \n [51] knitr_1.44                    metapod_1.7.0                \n [53] rjson_0.2.21                  boot_1.3-28.1                \n [55] codetools_0.2-19              wk_0.8.0                     \n [57] glue_1.6.2                    data.table_1.14.8            \n [59] vctrs_0.6.4                   png_0.1-8                    \n [61] gtable_0.3.4                  cachem_1.0.8                 \n [63] xfun_0.40                     S4Arrays_1.0.6               \n [65] mime_0.12                     DropletUtils_1.20.0          \n [67] pracma_2.4.2                  units_0.8-4                  \n [69] statmod_1.5.0                 bluster_1.10.0               \n [71] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [73] bit64_4.0.5                   filelock_1.0.2               \n [75] irlba_2.3.5.1                 vipor_0.4.5                  \n [77] KernSmooth_2.23-21            Hmisc_5.1-1                  \n [79] colorspace_2.1-0              DBI_1.1.3                    \n [81] nnet_7.3-19                   raster_3.6-26                \n [83] tidyselect_1.2.0              bit_4.0.5                    \n [85] compiler_4.3.1                curl_5.1.0                   \n [87] htmlTable_2.4.1               BiocNeighbors_1.18.0         \n [89] DelayedArray_0.26.7           checkmate_2.2.0              \n [91] scales_1.2.1                  classInt_0.4-10              \n [93] rappdirs_0.3.3                goftest_1.2-3                \n [95] fftwtools_0.9-11              spatstat.utils_3.0-3         \n [97] rmarkdown_2.25                XVector_0.40.0               \n [99] htmltools_0.5.6.1             pkgconfig_2.0.3              \n[101] base64enc_0.1-3               sparseMatrixStats_1.12.2     \n[103] fastmap_1.1.1                 htmlwidgets_1.6.2            \n[105] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n[107] farver_2.1.1                  jsonlite_1.8.7               \n[109] BiocParallel_1.34.2           R.oo_1.25.0                  \n[111] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[113] magrittr_2.0.3                Formula_1.2-5                \n[115] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[117] Rhdf5lib_1.22.1               munsell_0.5.0                \n[119] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[121] viridis_0.6.4                 stringi_1.7.12               \n[123] leafsync_0.1.0                MASS_7.3-60                  \n[125] zlibbioc_1.46.0               plyr_1.8.9                   \n[127] parallel_4.3.1                ggrepel_0.9.4                \n[129] deldir_1.0-9                  Biostrings_2.68.1            \n[131] stars_0.6-4                   splines_4.3.1                \n[133] tensor_1.5                    locfit_1.5-9.8               \n[135] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[137] BiocVersion_3.17.1            XML_3.99-0.14                \n[139] evaluate_0.22                 BiocManager_1.30.22          \n[141] httpuv_1.6.11                 purrr_1.0.2                  \n[143] polyclip_1.10-6               rsvd_1.0.5                   \n[145] lwgeom_0.2-13                 xtable_1.8-4                 \n[147] fdapace_0.5.9                 e1071_1.7-13                 \n[149] RSpectra_0.16-1               later_1.3.1                  \n[151] viridisLite_0.4.2             class_7.3-22                 \n[153] tibble_3.2.1                  memoise_2.0.1                \n[155] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[157] cluster_2.1.4"
  },
  {
    "objectID": "01-unmarked.html#dependencies",
    "href": "01-unmarked.html#dependencies",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")"
  },
  {
    "objectID": "01-unmarked.html#setup",
    "href": "01-unmarked.html#setup",
    "title": "Preamble",
    "section": "",
    "text": "spe &lt;- readRDS(\"../data/spe.rds\")\n\n#subset the data to only look at sample ID 0.01\nsub &lt;- spe[, spe$sample_id == 0.01]\n(pp &lt;- .ppp(sub, marks = \"cluster_id\"))\n\nMarked planar point pattern: 6111 points\nmarks are of storage type  'character'\nwindow: rectangle = [1222.5635, 3012.4248] x [-3993.535, -2202.755] units\n\n#split the multitype point process into several single type processes\n#first, set the marks of the point process to be factors\nmarks(pp) &lt;- factor(marks(pp))\nppls &lt;- split(pp)\n\nIf not otherwise indicated, all information was taken from Baddeley et al. - Spatial Point Patterns.\n\n#Plot the entire point process where the marks are overlayed\nplot(unmark(pp), main = 'Point Pattern Unmarked')\n\n\n\n#Plot the marks separately \nplot(ppls, main = 'Point Pattern Marks Separated')"
  },
  {
    "objectID": "01-unmarked.html#concepts-and-definitions-of-point-processes",
    "href": "01-unmarked.html#concepts-and-definitions-of-point-processes",
    "title": "Preamble",
    "section": "",
    "text": "Complete spatial randomness (CSR) is the null model of point patterns, being the result of a poisson process. A completely random process is characterised by two properties\n\n\nHomogeneity means that the expected number of points falling into a given region \\(B\\) is proportional to its area \\(|B|\\) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) is the intensity of the process, so the average number of points in a unit area.\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|\n\\label{eq:expected_number_points}\n\\]\n\n\n\nIndependence means that in two regions \\(A\\) and \\(B\\) the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are two independent random variables. That means the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). The number of points follow a poisson distribution:\n\\[\n\\mathbb{P}[N=k] = e^{-\\mu}\\frac{\\mu^k}{k!}\\\\\n\\label{eq:poisson_process}\n\\]\n\n\n\n\nA poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density \\(\\lambda(u)\\) is a function of spatial location \\(u\\). The expected number of points falling into a region \\(B\\) is\n\\[\n\\mu = \\int_{B} \\lambda(u)du\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\n\nA point process is called isotropic, if its statistical properties are invariant to rotations. A CSR process is both stationary and isotropic.\n\n\n\n“A point process is called stationary if, when we view the process through a window \\(W\\), its statistical properties do not depend on the location of the window in two-dimensional space.”\n\n\nIt is important to note that the inhomogeneous metrics do not apply to every spatially inhomogeneous point process. They only apply to point processes which are correlation stationary. A point pattern is correlation stationary if the metric only depends on the relative position in subpatterns of the point process, which means that estimates of the inhomogeneous metric should be similar in different subquadrats of the point pattern.\n\n\n\n\nThe inhomogeneous K-function further assumes that while the intensity is spatially varying, the scale of the interaction remains constant. This is equivalent to the assumption that in small subregions the process is stationary and isotropic, but the rescaling factor can vary across the total process. In this case the locally scaled version of the K-function is applicable.\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimatied functions between the quadrats. It has to be noted that this test highly depends on the arbitrarydefinition of the quadrats.\n\nselection &lt;- c('OD Mature')\npp_sel &lt;-  subset(pp, marks %in% selection, drop = TRUE)\n\n\nodrho &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\nodlambda &lt;- predict(odrho)\n\nod4 &lt;- quantess(unmark(pp_sel), \"x\", 2)\nod42 &lt;- nestsplit(pp_sel, od4, ny=3)\n\nplot(od42)\n\n\n\nod42$inten &lt;- factor(as.integer(od42$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n\nres.scaled &lt;- studpermu.test(od42, pts ~ inten, summaryfunction=Kscaled,\n               minpoints = 10)\n\nres.inhom &lt;- studpermu.test(od42, pts~ inten, summaryfunction=Kinhom,\n               lambda=odlambda, minpoints = 10)\n\n#p-value of the local-scaling test\nres.scaled$p.value\n\n[1] 0.001\n\n#p-value of the inhomogeneity test\nres.inhom$p.value\n\n[1] 0.415\n\n\nAlternatively, we can inspect deviations against the hypothesis that the points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types. Source\n#TODO: We should maybe move this to after the intensity part\n\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp, marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\nf0 &lt;- pValuesHotspot(pp_sel)\n\n# Plot significant p-values\nplot(f0$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\nIntensity is the expected density of points per unit area, as seen above. It can be interpreted as the rate of occurrence or the abundance of events recorded. The intensity itself is called a first moment property - being related to the expected number of points.\n\n\nThe intensity can be estimated regardless of the type of the point pattern. In order to do so, we sum the individual intensities of the marks\n\nintensityPointProcess&lt;- function(pp,mark){\n  if(mark == TRUE){\n    return(intensity(pp))\n  }\n  else{\n    return(sum(intensity(pp)))\n  }\n}\n\nintensityPointProcess(pp,mark=FALSE)\n\n[1] 0.001906561\n\n\nelse we can look at each mark individually\n\nintensityPointProcess(pp,mark=TRUE)\n\n   Ambiguous    Astrocyte  Endothelial    Ependymal   Excitatory   Inhibitory \n2.411670e-04 2.015445e-04 1.463225e-04 8.361288e-05 3.681463e-04 6.130571e-04 \n   Microglia  OD Immature    OD Mature    Pericytes \n3.026287e-05 6.239767e-05 1.425787e-04 1.747135e-05 \n\n\n\n\n\nIn quadrat counting all the points falling into a given quadrat are counted. This gives an overview on the characterstics of the point pattern, such as correlation stationarity.\n\nQ5 &lt;- quadratcount(pp, nx=5, ny=5)\nplot(unmark(pp), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\n\n\n\nThe quadrat counts can be tested against regularity. This can happen again in the unmarked pattern or in the separated types. This tells us if the counts of the points are distributed evenly across the quadrats.\n\nquadratTestPointProcess &lt;- function(pp, mark){\n  if(mark==TRUE){\n    return(lapply(split(pp), quadrat.test, 5, alternative=\"regular\", method=\"MonteCarlo\"))\n  }\n  else{\n    return(quadrat.test(unmark(pp), 5, alternative=\"regular\", method=\"MonteCarlo\"))\n  }\n}\nquadratTestPointProcess(pp, mark=FALSE)\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  unmark(pp)\nX2 = 245.95, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 5 by 5 grid of tiles\n\n\n\n\n\nIn kernel estimation we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There are different types of kernel estimators (see Baddeley). A popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth.\n\nDens &lt;- density(pp)\nplot(Dens, main = 'Kernel Density')\n\n\n\n\n\n\n\n\n\nWhether or not a point process is completely spatially random depends on two characeteristics. The points have to be distributed homogeneously and they have to be independent of each other (see definitions above). There are different ways to test for CSR which are summarised in the wrapper below.\n\n#PRE: takes a point process and the indication, which test for CSR should be performed and potentially a covariate\n#POST: returns if a point process or its individual point process marks are CSR or not.\n#TODO: Change maybe to a switch statment in terms of computing time; Change lapply to mclapply later on\n#TODO: There is a conceptual mistake - we pull out marks and test them against a markov simulation. It should rather be to test against all the other cells\ntestingCSR &lt;- function(\n    pp,\n    method = c('quadrat','cdf','bermans','clark-evans','hopkins-skellam'),\n    mark = FALSE,\n    covariate = NULL,\n    test = c('ks', 'cvm', 'ad'),\n    verbose = FALSE\n){\n  #perform a quadrattest for individual marks or for the entire pointprocess\n  if(method == 'quadrat'){\n    if(mark == TRUE){\n      test.result &lt;- lapply(split(pp), quadrat.test, 5, method=\"MonteCarlo\")\n    }\n    else{\n      test.result &lt;- quadrat.test(unmark(pp), 5, method=\"MonteCarlo\")\n    }\n   }\n  #perform a cdftest for individual marks or for the entire pointprocess given a covariate\n  else if(method == 'cdf' && !is.null(covariate)){\n    if(mark == TRUE){\n      test.result &lt;- lapply(split(pp), cdf.test, covariate, test=test)\n    }\n    else{\n      test.result &lt;- cdf.test(unmark(pp), covariate, test=test)\n    }\n  }\n  #perform a bermans test for individual marks or for the entire pointprocess\n  else if(method == 'bermans' && !is.null(covariate)){\n     if(mark == TRUE){\n      test.result &lt;- lapply(split(pp), berman.test, covariate, test='Z1')\n    }\n    else{\n      test.result &lt;- berman.test(unmark(pp), covariate, test='Z1')\n    } \n  }\n  #perform a clark evans test for individual marks or for the entire pointprocess\n  else if(method == 'clark-evans'){\n     if(mark == TRUE){\n      test.result &lt;- lapply(split(pp), clarkevans.test)\n    }\n    else{\n      test.result &lt;- clarkevans.test(unmark(pp))\n    } \n  }\n  #perform a hopkins-skellam test for individual marks or for the entire pointprocess\n  else if(method == 'hopkins-skellam'){\n     if(mark == TRUE){\n      test.result &lt;- lapply(split(pp), hopskel.test)\n    }\n    else{\n      test.result &lt;- hopskel.test(unmark(pp))\n    } \n  }\n  #base case of the \"switch\" statement\n  else{\n    print(\"ERROR: non-specified arguments or methods\")\n    return(NULL)\n  }\n  \n  #summarise the results as a mask of booleans to indicate which structures are \n  #random and which are not\n  if(mark==TRUE){\n    p.value.mask &lt;- lapply(test.result, function(x) x$p.value&gt;0.05)\n  }\n  else{\n    p.value.mask &lt;- test.result$p.value&gt;0.05\n  }\n  #return the values of the test calculations, either just the boolean if \n  #CSR or not or the entire test statistics\n  if(verbose == TRUE){\n    return(test.result)\n  }\n  else{\n    return(p.value.mask)\n  }\n}\nresult &lt;- testingCSR(pp,method='clark-evans',mark=TRUE, verbose=FALSE)\n\ntestingCSR(ppls$Ependymal, method='clark-evans')\n\n[1] FALSE\n\ntestingCSR(ppls$`OD Mature`, method='clark-evans')\n\n[1] FALSE\n\ntestingCSR(ppls$Microglia, method='clark-evans')\n\n[1] FALSE"
  },
  {
    "objectID": "01-unmarked.html#correlation",
    "href": "01-unmarked.html#correlation",
    "title": "Preamble",
    "section": "",
    "text": "Correlation or more generally covariance is called a second order quantity and measures dependence between data points. This is a very useful concept, allowing for the assessment of correlation between points.\n\n\n\n\n\nIn the framework of correlation analysis we often look at distances \\(d_{ij} = ||x_i-x_j||\\) of all ordered points. It is a natural idea to look at the summary of these distances \\(d_{ij}\\), e.g. a histogram. The histogram of this point process is a difficult statistic, as it depends on the observation window \\(W\\), thus the histogram can change significantly with a changing window \\(W\\). Therefore, we look at the empirical distribution function of the distances \\(d_{ij}\\) that are smaller or equal than a radius \\(r\\)\n\\[\n\\hat{H}(r) = \\frac{1}{n(n-1)}\\sum_{i=1}^n \\sum_{j=1\\\\j\\neq i}^n \\{d_{ij}\\leq r\\}\n\\]\nThe contribution of each point \\(x_i\\) to the sum above is\n\\[\nt_i(r) = \\sum_{j \\neq i} \\mathbb{1} \\{d_{ij}\\leq r\\}\n\\]\nthis number \\(t_i(r)\\) is the number of points that fall within a radius \\(r\\) centered at \\(x_i\\). It follows then:\n\\[\n\\hat{H}(r) = \\frac{1}{n(n-1)}\\sum_{i=1}^n t_i(r) = \\frac{1}{n-1} \\bar{t}(r)\n\\]\nHere, we see what we actually want to measure is “the average number of r-neighbours of a typical random point”. This number is still dependent on the size of the observation window so we want to standardise is by the number of points and \\(|W|\\) the window size. Then we obtain the empirical Ripley’s \\(K\\) function\n\\[\n\\hat{K}(r) = \\frac{|W|}{n(n-1)}\\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n\\{d_{ij}\\leq r\\}\n\\]\nThe standardisation makes it possible to compare point patterns with different observation windows and with different numbers of points. Using the empirical \\(K\\) function assumes though tha the point process has homogeneous intensity.\n\n\n\ninstead of the summary of pairwise distances, we are interested in the point process. In order to do so, we have to think about the expected number of \\(r\\)-neighbours given a point \\(X\\) at a location \\(u\\) divided by its intensity \\(\\lambda\\)\nThis means\n\\[\nK(r) = \\frac{1}{\\lambda} \\mathbb{E} [t(u,r,X)|u \\in X]\n\\]\nwhere\n\\[\nt(u,r,X) = \\sum_{j=1}^{n(X)} \\mathbb{1} \\{0&lt;||u-x_j||\\leq r\\}\n\\]\nThis definition of the true \\(K\\) function is only valid if the point process is stationary. For a homogeneous poisson process we obtain\n\\[\nK_{pois}(r) = \\pi r^2\n\\]\n\n\n\nEdge effects describe the phenomenon that we never observe the entire point process but only a part of it within a window \\(W\\). This means that parts of the point process at the border might not be observed and the value of the statistic biased along the edges.\nThere are many corrections for edge effects. They are briefly listed here\n\n\nIn border correction the summation of data points is restricted to \\(x_i\\) for which \\(b(x_i,r)\\) is completely in the window \\(W\\).\n\n\n\nWe can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.\n\n\n\nA stationary point process \\(X\\) is invariant to translations. So the entire point process can be shifted by a vector \\(s\\) to be at the position \\(X+s\\).\n\n\n\n\n\nThe \\(K\\)-function can be centered which is then called the \\(L\\)-function. The \\(L\\)-function is a variance-stabilising version of the \\(K\\)-function (see spicyR for reference).\n\\[\nL(r) = \\sqrt{\\frac{K(r)}{\\pi}}\n\\]\n\n\n\nWe have seen above, that the \\(K\\)-function is cumulative in nature. Meaning that the contributions of all distances smaller equal to \\(r\\) are counted. An alternative is to take the derivative of the \\(K\\)-function in order to obtain contributions of distances between points equal to \\(r\\).\n\\[\ng(r) = \\frac{K'(r)}{2\\pi r}\n\\]\n“\\(g(r)\\) is the probability of observing a pair of point of the process separated by a distance \\(r\\), divided by the corresponding probability for a Poisson process.”\n\n\nThe pair correlation function can be estimated via kernel smoothing. In very large datasets the pair correlation function can be approximated using histogram-based methods.\n\\[\n\\hat{g}(r) = \\frac{|W|}{2 \\pi r n (n-1)} \\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n \\kappa_h(r-d_{ij})e_{ij}(r)\n\\]\nwhere \\(\\kappa\\) is the smoothing kernel. \\(\\kappa_h(x)\\) is a rescaled version of the template kernel \\(\\kappa\\)\n\\[\n\\kappa_h(x) = \\frac{1}{h}\\kappa\\left(\\frac{x}{h}\\right)\n\\]\nIn the above, \\(\\kappa\\) can be any probability density “over the real line with mean 0”. Usually, the Epanechinikov kernel is used as smoothing kernel with half-width \\(w\\).\n\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricResBoot &lt;- function(ppls, celltype, fun){\n  metric.res &lt;- lohboot(ppls[[celltype]], fun = fun)\n  metric.res$type &lt;- celltype\n  return(metric.res)\n}\n#PRE: celltypes, function to calculation and edge correction method\n#POST: dataframe of \nmetricResBootToDF &lt;- function(celltype_ls, ppls, fun, edgecorr){\n  res_ls &lt;- lapply(celltype_ls, metricResBoot, fun = fun, ppls = ppls)\n  #stick all values into a dataframe\n  res_df &lt;- c()\n  for(i in 1:length(celltype_ls))res_df &lt;- rbind(res_df, res_ls[[i]])\n  return(res_df)\n}\n\n#PRE: Celltypes of interest, function to analyse, edge correction to perform\n#POST: plot of the metric\nplotMetric &lt;- function(celltype_ls, ppls, fun, edgecorr){\n  res_df &lt;- metricResBootToDF(celltype_ls, ppls, fun, edgecorr)\n  #plot the curve\n  p &lt;- ggplot(res_df, aes(x=r, y=res_df[[edgecorr]], col= type))+\n    geom_line()+\n    geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)+\n    ggtitle(paste0(fun, '-function'))+\n    geom_line(aes(x=r,y=theo, color = 'Poisson'),linetype = \"dashed\")+\n    ylab(edgecorr) +\n    scale_color_manual(name='Point Processes',\n                     breaks=c('Ependymal', 'Microglia', 'OD Mature', 'Poisson'),\n                     values=c('Ependymal'='red', 'Microglia'='dark green', 'OD Mature'='blue', 'Poisson'='black'))+\n    theme_light()\n  return(p)\n}\n\ncelltype_ls &lt;- c(\"Ependymal\", \"OD Mature\", \"Microglia\")\np_K &lt;- plotMetric(celltype_ls, ppls, 'Kest', 'iso')\n\np_L &lt;- plotMetric(celltype_ls, ppls, 'Lest', 'iso')\n\np_g &lt;- plotMetric(celltype_ls, ppls, 'pcf', 'border')\n\n\np_K/p_L/p_g\n\n\n\n\n\n\n\n\n\n\nIn the case that a spatial pattern is known or suspected to be inhomogeneous, we have to take this into account for our analysis. Biological samples display inhomogeneity very often, therefore this analysis is preferred over the homogeneous alternatives. Inhomogeneous alternatives can be calculated via:\n\\[\nK_{inhom}(r) = \\mathbb{E} \\left[\\sum_{x_j \\in X} \\frac{1}{\\lambda(x_j)}\\mathbb{1}\\{0&lt;||u-x_j||\\leq r\\}|u \\in X\\right]\n\\]\nThis theoretical quantity can be approximated with estimators such as\n\\[\n\\hat{K}_{inhom}(r) = \\frac{1}{D^p|W|}\\sum_i\\sum_{j \\neq i} \\frac{\\mathbb{1}\\{||u-x_j||\\leq r\\}}{\\hat{\\lambda}(x_j)\\hat{\\lambda}(x_i)}e(x_j,x_i;r)\n\\]\nwhere \\(e(u,v;r)\\) is an edge correction weight, \\(\\hat{\\lambda}(u)\\) is an estimator of the intensity of \\(u\\) and \\(D^p\\) is the pth power of\n\\[\nD = \\frac{1}{|W|}\\sum_i \\frac{1}{\\hat{\\lambda}(x_i)}\n\\]\n\np_K &lt;- plotMetric(celltype_ls, ppls, 'Kinhom', 'iso')\n\np_L &lt;- plotMetric(celltype_ls, ppls, 'Linhom', 'iso')\n\np_g &lt;- plotMetric(celltype_ls, ppls, 'pcfinhom', 'border')\n\n\np_K/p_L/p_g\n\n\n\n\nThe inhomogeneous \\(K\\)-function tells us that the microglia cells follow a Poisson process (dashed line) closely and can therefore be assumed to be randomly distributed and not clustered. Ependymal cells show a high degree of clustering at a low radius \\(r\\). OD mature cells are in the middle, showing a lower degree of clustering at lower values of \\(r\\).\nThe \\(L\\)-function is a variance stabilised (source spicyR) version of the \\(K\\)-function. Thus, the information is complementary to the above. Microglia cells are along the dashed poisson line, indicating no clustering of microglia cells. Ependymal cells are highly clustered at low values of \\(r\\), whereas OD mature show intermediate clustering at lower values of \\(r\\).\nThe pair correlation function is the derivative of the \\(K\\)-function. Therefore, it is not a sum of the points in the circle with radius \\(r\\) but rather the individual points on the radius \\(r + h\\) where \\(h\\) is very small. The pcf plot gives similar information as before: Microglia cells are around the dashed poisson line. OD Mature cells show a rather broad range of correlations between \\(r \\in [20,100]\\). Ependymal cells have a very strong correlation at \\(\\sim r = 25\\).\nWe have to note that inhomogeneity correction assumes that the process is correlation stationary, meaning that the summary statistics are the same in each quadrat. This is clearly violated at least for Ependymal cells and OD mature cells. Therefore, the question remains whether acounting for one issue (homogeneity) via a correction that assumes correlation stationarity does not just exchange one problem for another.\n\n\n\n\n\n\nIn the inhomogeneous \\(K\\) approach above, we assume that the local scale of the point process is not changed. However, the intensity can vary spatially. In a biological sample, this assumption is easily violated, e.g. when a gradient of cells that increases from one side to another. Therefore, we can assume that the process is subdivided in small regions. In these small regions the point process is a scaled version of a template process. This template process has to be both stationary and isotropic. For two locations \\(u\\) and \\(v\\) we would then assume that\n\\[\ng(u,v) = g_1 \\left(\\frac{||u-v||}{s}\\right)\n\\]\nIn this example, \\(g_1\\) is the pair correlation function of the template process and \\(s\\) a scaling factor.\n\n\n\nwould work by taking the derivative of the locally scaled \\(K\\)-function\n\n\n\nAs the \\(L\\) is just a transformation of the \\(K\\)-function, the same local scaling can apply to the \\(L\\)-function\n\n### need to redefine the metric function, because bootstrap is not available for locally scaled functions ###\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricRes &lt;- function(ppls, celltype, fun){\n  metric.res &lt;- do.call(fun, args = list(X=ppls[[celltype]]))\n  metric.res$type &lt;- celltype\n  return(metric.res)\n}\n\n#PRE: celltypes, function to calculation and edge correction method\n#POST: dataframe of \nmetricResToDF &lt;- function(celltype_ls, ppls, fun, edgecorr){\n  res_ls &lt;- lapply(celltype_ls, metricRes, fun = fun, ppls = ppls)\n  #stick all values into a dataframe\n  res_df &lt;- c()\n  for(i in 1:length(celltype_ls))res_df &lt;- rbind(res_df, res_ls[[i]])\n  return(res_df)\n}\n### need to redefine the plotting function, because bootstrap is not available for locally scaled functions ###\n#PRE: Celltypes of interest, function to analyse, edge correction to perform\n#POST: plot of the metric\nplotScaledMetric &lt;- function(celltype_ls, ppls, fun, edgecorr){\n  res_df &lt;- metricResToDF(celltype_ls, ppls, fun, edgecorr)\n  #plot the curve\n  p &lt;- ggplot(res_df, aes(x=r, y=res_df[[edgecorr]], col= type))+\n    geom_line(size=1)+\n    ggtitle(paste0(fun, '-function'))+\n    geom_line(aes(x=r,y=theo, color = 'Poisson'),linetype = \"dashed\", size=1)+\n    ylab(edgecorr) +\n    scale_color_manual(name='Point Processes',\n                     breaks=c('Ependymal', 'Microglia', 'OD Mature', 'Poisson'),\n                     values=c('Ependymal'='red', 'Microglia'='dark green', 'OD Mature'='blue', 'Poisson'='black'))+\n    theme_light()\n  return(p)\n}\n\np_K &lt;- plotScaledMetric(celltype_ls, ppls, 'Kscaled', 'iso')\n\np_L &lt;- plotScaledMetric(celltype_ls, ppls, 'Lscaled', 'iso')\n\n\np_K/p_L\n\n\n\n\nThe interpretation of the locally scaled \\(L\\)-function is similar to the interpreation of the inhomogeneous \\(L\\)-function. The correlation is strongest for Ependymal cells, followed by OD mature cells. Microglia cells are again close to the random poisson process. Note that here, the curves of the Ependymal and OD mature cells stay always above the dashed poisson line, unlike in the inhomogeneous version.\nGiven that our biological samples are both inhomogeneous and locally scaled by eye (can be tested as seen above), the locally scaled \\(L\\)-function seems a good variant for assessing correlation.\n\n\n\nThe \\(K\\) and \\(L\\)-functions above are summary statistics over the entire pattern. However, if we know that there are different regions in our point pattern, we might want to know the individual contributions of these patterns. This gives then e.g. \\(n\\) (for all points) local \\(K\\),\\(L\\) or pair correlation-functions. Baddeley et. al. propose to compare these \\(n\\) functions with e.g. functional principal component analysis. We will show here the example of the LISA version of the \\(L\\) function.\n\n\n\n\nL_odmature_lisa &lt;- localL(ppls$`OD Mature`)\n# plot(L_odmature_lisa, main = 'local L functions OD Mature', legend=FALSE)\n\ndf &lt;- as.data.frame(L_odmature_lisa)\n\ndfm &lt;- reshape2::melt(df, \"r\")\n\nget_sel &lt;- dfm %&gt;% filter(r &gt; 200.1358 & r &lt; 200.1360, variable != \"theo\") %&gt;%\n  mutate(sel = value) %&gt;% select(variable, sel)\n\ndfm &lt;- dfm %&gt;% left_join(get_sel)\n\np &lt;- ggplot(dfm, aes(x=r, y=value, group=variable, colour=sel)) +\n  geom_line() + \n  scale_color_continuous(type = \"viridis\") +\n  geom_vline(xintercept = 200) +\n  theme(legend.position = \"none\") +\n  theme_light()\n\nppdf &lt;- as.data.frame(pp) %&gt;% filter(marks==\"OD Mature\")\nppdf$sel &lt;- get_sel$sel # assume they are in same order\n\nq &lt;- ggplot(ppdf, aes(x=x, y=y, colour=sel)) + \n  geom_point() +\n  scale_color_continuous(type = \"viridis\") +\n  theme(legend.position = \"none\") +\n  theme_light()\n\n\np|q\n\n\n\n\nIn the case of the OD mature cells we obtain further information with this plot. We note that there are two distinct populations of curves, those that are clearly above the straight poisson line and others that are around/underneath the straight poisson line. This indicates that there are two different kinds of interactions in the OD mature cells. Stronger clustering (the upper part of the plot) and more random parts (lower part).\nThere are inhomogeneous versions of these (e.g. localLinhom). These are not shown here for brevity.\n\n\n\nWe apply functional PCA to retrieve the main trends in these individual curves. The idea of functional PCA is the same as for ordinary PCA just applied to the concept of functions. For the \\(n\\) functions above functional PCA will recover the main trends in the data\n\n#adapted from the fdapace vignette\nfunctional.pca.pp &lt;- function(df){\n  df_fdob &lt;- df %&gt;% as.matrix()\n  #remove theo column - we want only the actual estimations in there without the poisson line theo\n  if('theo' %in% colnames(df)){\n     df_fdob &lt;- df_fdob[,-ncol(df_fdob)]\n  }\n  if('r' %in% colnames(df)){\n     df_fdob &lt;- df_fdob[,-ncol(df_fdob)]\n  }\n  #number of columns\n  N &lt;- ncol(df_fdob)\n  #number of rows\n  M &lt;- nrow(df_fdob)\n  #the x values at which all the curves were evaluated, here called tVec\n  s &lt;- df$r\n  #create the FPCA object\n  fd_obj &lt;- fdapace::MakeFPCAInputs(IDs = rep(1:N, each=M),tVec=rep(s,N), yVec=df_fdob)\n  #check that the FPCA object is valid\n  fdapace::CheckData(fd_obj$Ly, fd_obj$Lt)\n  #run the computation of the FPCA - would work with sparse data.\n  fpca_obj &lt;- fdapace::FPCA(fd_obj$Ly, fd_obj$Lt, list(plot = TRUE, dataType='Dense', kernel='rect'))\n  fdapace::CreatePathPlot(fpca_obj,K = 3, pch = 4,showObs = FALSE, showMean = TRUE)\n}\n\nfunctional.pca.pp(L_odmature_lisa)\n\n\n\n\n\n\n\nHere, we see the functional PCA for the OD mature cells. The Design plot tells us that we have a very dense dataset over the entire support. The mean curve displays the mean trend over all \\(n\\) LISA \\(L\\)-curves (note that this result is similar to the locally scaled \\(L\\)-function). The scree plot indicates that the first eigenfunction explains more than \\(80 \\%\\) of the variance. The eigenfunction curves in the bottom right panel indicate the deviation from the mean curve.\nLooking at the second plot we see the smoothed mean curve and the individual curves that are reconstructed from the first three eigenfunctions. The first eigenfunction from the bottom right panel, \\(\\phi_1\\), is above the mean curve. When we look at the example that is clearly visible. \\(\\phi_2\\) is first above the mean curve and then lower than the mean curve. These curves are visible as well. Lastly, \\(\\phi_3\\) is curves that start low and pick up to be larger than the mean curve in the end. This is visible in e.g. the orange dashed line -&gt; check the source from the Springer book “Functional Data Analysis with R and Matlab”.\n\n\n\n\n\nSo far we have considered first- and second-order summary statistics and local adaptations of these. In the following, we will continue a high-order statistics. In second-order statistics one considers pairs and counts these in the case of the \\(K\\) function. In a third-order setting we would now count triplets of points. A triplet is counted as the normalised expected value of triangles where all edges are smaller than the radius r\n\\[\nT(r) = \\frac{1}{\\lambda^3}\\mathbb{E}\\left[\\sum_{i=1}^n\\sum_{j=1\\\\j\\neq i}^nm(x_i,x_j,u) | u \\in X\\right]\n\\]\nhere m is the maximum side of the triangle\n\\[\nm(a,b,c) = \\max(||a-b||,||a-c||,||b-c||)\n\\]\n\np &lt;- plotScaledMetric(celltype_ls, ppls, 'Tstat', 'trans')\np"
  },
  {
    "objectID": "01-unmarked.html#spacing",
    "href": "01-unmarked.html#spacing",
    "title": "Preamble",
    "section": "",
    "text": "So far, most approaches considered intensity and correlation as measures to assess a point pattern. Below, we will look at measures of spacing and shortest-distances to assess spatial arrangements.\nBaddeley et.al. summarises three basic distances to measure\n\npairwise distance: \\(d_{i,j} = ||x_i-x_j||\\)\nnearest-neighbour distances: \\(d_i = \\min_{j \\neq i}d_{ij}\\)\nempty-space distance: \\(d(u) = \\min_j||u-x_j||\\)\n\nThere are test of CSR that are based on spacing -&gt; Clark-Evans test and Hopkins-Skellam Index that are both implemented above in the CSR testing function\n\n\n\nNearest neighbour methods center around the notion of “nearness”. In particular, we introduce nndist from spatstat, a method to calculate the distances until \\(k\\) nearest neighbours are found. This function returns us then \\(k\\) curves for the \\(k\\) neighbour distances. We can for instance collapse this information of the \\(k\\) curves in a mean curve per sample. This information of the mean nearest neighbour distance is summarised as a density.\n\nnndistance &lt;- function(pp, nk){\n  xy &lt;- cbind(pp$x, pp$y)\n  nndistances_k15 &lt;- nndist(xy, k = nk) \n  nndistances_mean &lt;- rowMeans(nndistances_k15)\n  return(nndistances_mean)\n}\n\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricRes_nndist &lt;- function(ppls, celltype, fun){\n  metric.res &lt;- list(res = do.call(fun, args = list(pp=ppls[[celltype]], nk = seq(1:15))))\n  metric.res$type = celltype\n  return(metric.res)\n}\n\n#go through all defined celltypes and calculate the nearest-neighbour distance\nres_ls &lt;- lapply(celltype_ls, metricRes_nndist, fun = nndistance, ppls = ppls)\n#initialise a dataframe for the metric values and the type information\nres_df &lt;- data.frame(metric = numeric(0), type = character(0))\n# Loop through the res_ls list and combine the metric values with their corresponding type - ChatGPT\nfor (i in 1:length(res_ls)) {\n  metric_values &lt;- res_ls[[i]]$res\n  metric_type &lt;- rep(res_ls[[i]]$type, length(metric_values))\n  df &lt;- data.frame(metric = metric_values, type = metric_type)\n  res_df &lt;- rbind(res_df, df)\n}\n#plot the densities\np &lt;- ggplot(res_df, aes(x=metric, col= type))+\n    geom_density(linewidth=1)+\n    scale_x_sqrt() +\n    theme_light() +\n    ggtitle('Sqrt of the Mean Nearest-Neighbour Distance')\np\n\n\n\n\n\nres_df_wider &lt;- res_df %&gt;% group_by(type) %&gt;% mutate(row = row_number()) %&gt;% tidyr::pivot_wider(names_from = type, values_from = metric) %&gt;% select(-row) \n#we have the problem that the number of points is not the same for all celltypes\nfunctional.pca.pp(res_df_wider) \n\nIn the probability-density function of the nearest neighbours the ependymal cells show the shortest nearest-neighbour distances. The OD mature cells have larger nearest neighbour distances and the bimodal distribution indicates a mix of longer and wider distances (which was as well visible in the LISA \\(L\\) function). Microglia cells show the widest distances and the symmetry of the curve indicates similar distances throughout the field of view.\n\n\nOften, we are interested which spatial structures build a spatial unit. One way to answer this question is to use spatially aware clustering. Here we show one very basic approach, DBScan (density-based spatial clustering with applications for noise). DBScan is an algorithm which uses a parameter called minimal Features. If the number of points per cluster is smaller than the minimal number of features, it is either noise or it is merged with another cluster. Another parameter \\(\\epsilon\\) defines the distance at which a point has to lay in order to be part of a cluster. The value of this parameter \\(\\epsilon\\) can be determined by an elbow plot, similar to clustering resolution parameters in other algorithms. from https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/how-density-based-clustering-works.htm\n\npp_df &lt;- as.data.frame(ppls$`OD Mature`)\n#determine the correct epsilon neighbourhood\ndbscan::kNNdistplot(pp_df, k=5)\n\n\n\n\nGiven the kNN distance plot we visually detect the “knee” of the curve to be at an distance \\(\\epsilon\\) of \\(200\\). This value is needed for the computation of DBScan.\n\n#perform DBScan\npp_dbscan &lt;- dbscan::dbscan(pp_df[-3], eps =200, minPts = 5)\nplot(pp_df[-3], col = pp_dbscan$cluster)\n\n\n\n\nWe see that DBScan identifies four clusters. A top cluster in red and two main side clusters in black and green. There is another cluster in blue which is at the top right corner.\nanother lead to follow in detected spatial clusters is scan statistics with the package .\n\n\n\n\n\n\nUnder a stationary spatial point process, the empty-space distance is defined as\n\\[\nd(u,X) = \\min\\{||u-x_i||: x_i \\in X\\}\n\\]\nThe empty space function is then the cumulative distribution function of the empty-space distances defined above\n\\[\nF(r) = \\mathbb{P}\\{d(u,X)\\leq r\\}\n\\]\nThe nearest-neighbour distance is defined as\n\\[\nd_i = \\min_{j\\neq i}||x_j-x_i||\n\\]\nThe nearest-neighbour distance distribution function \\(G(r)\\) is then defined as\n\\[\nG(r) = \\mathbb{P}\\{d(x,X\\backslash u \\leq r |X\\ has\\ a\\ point\\ at\\ u\\}\n\\]\nFor a homogeneous Poisson process, the nearest-neighbour distance distribution is identical to the empty-space function of the same process\n\\[\nG_{pois} \\equiv F_{pois}\n\\]\nFor a general point process the \\(F\\) and \\(G\\) functions are different\n\n\n\n\nThe \\(F\\) and \\(G\\) functions are, like the \\(K\\) function, cumulative. The same disadvantages as with the \\(K\\) function occur here too. Therefore, an analogue to the pair-correlation function would make sense to consider. For practical reasons this is no longer the derivative of the \\(F\\) function but rather a hazard rate.\n\\[\nh(r) = \\frac{f(r)}{1-F(r)}\n\\]\nFor a CSR process, the hazard rate is\n\\[\nh_{pois}(r) = 2 \\pi \\lambda r\n\\]\nHere we use a variance stabilising transformation as suggested by Baddeley et. al. This transformation means that if the process is completely spatial random, the hazard is equal to the intensity \\(\\lambda\\). \n\n\n\nThe concepts of the empty-space function \\(F\\) and the nearest-neighbour function \\(G\\) are somewhat complementary. If one decreases, the other increases. A comparison of these two functions as a measure of CSR is the Hopkins-Skellam test (implemented above).\nAnother approach is the \\(J\\) function.\n\\[\nJ(r) = \\frac{1-G(r)}{1-F(r)}\n\\]\n“For a homogeneous Poisson process, \\(F_{pois} \\equiv G_{pois}\\) such that then \\(J_{pois} \\equiv 1\\). Values \\(J(r) &gt; 1\\) are consistent with a regular pattern, and $J(r) &lt; 1 is consistent with clustering.” (Baddeley et. al.)\n\n### need to redefine the plotting function, because bootstrap is not available for spacing functions ###\n#PRE: Celltypes of interest, function to analyse, edge correction to perform\n#POST: plot of the metric\nplotSpacingMetric &lt;- function(celltype_ls, ppls, fun, x,  edgecorr){\n  res_df &lt;- metricResToDF(celltype_ls, ppls, fun)\n  #plot the curve\n  p &lt;- ggplot(res_df, aes(x=res_df[[x]], y=res_df[[edgecorr]], col= type))+\n    geom_line()+\n    ylab(edgecorr) +\n    xlab(x) +\n    ggtitle(paste0(fun, '-function'))+\n    geom_line(aes(x=res_df[[x]], y=theo), linetype = 'dashed')+\n    theme_light()\n  return(p)\n}\n\np_G &lt;- plotSpacingMetric(celltype_ls, ppls, 'Gest', 'r', 'rs')\n\np_F &lt;- plotSpacingMetric(celltype_ls, ppls, 'Fest', 'r', 'rs')\n\np_J &lt;- plotSpacingMetric(celltype_ls, ppls, 'Jest', 'r', 'rs')\n\n\np_G/p_F/p_J\n\n\n\n\n\n\n\nThere are inhomogeneous variants of the spacing functions explained above\n\np_G &lt;- plotSpacingMetric(celltype_ls, ppls, 'Ginhom', 'r', 'bord')\n\np_F &lt;- plotSpacingMetric(celltype_ls, ppls, 'Finhom', 'r', 'bord')\n\np_J &lt;- plotSpacingMetric(celltype_ls, ppls, 'Jinhom', 'r', 'bord')\n\n\np_G/p_F/p_J\n\n\n\n\nAgain here, comparing the homogeneous versions of the functions with the inhomogeneous ones reveals, that we seem to solve one problem (inhomogeneity) by assuming correlation stationarity. As this is not given, the inhomogeneous versions don’t seem to be accurate. In fact, the homogeneous versions are more easily interpretable than the inhomogeneous alternatives.\n\n\n\nNext to the distance to the nearest-neighbours, we can estimate the orientation of the vector to the nearest-neighbour. This gives an indication of the orientation of the spacing.\n\np &lt;- plotSpacingMetric(celltype_ls, ppls, 'nnorient', 'phi', 'bordm')\np\n\n\n\n\nThe values of \\(\\phi\\) correspond to the orientation of the point pattern. The horizontal axis goes from \\(180\\) to \\(0\\) (left to right) and the vertical from \\(90\\) to \\(270\\) (top to bottom). We can infer that the orientation of the Ependymal nearest-neighbours is along the vertical axis, OD mature cells don’t show a clear pattern and microglial cells a horizontal orientation in their nearest neighbours with a small peak at \\(\\sim 180\\) (orientation to the top).\nThe concept of spacing is not only usable in point pattern analysis but more broadly in any spatial context (e.g. spacing between shapes instead of points).\n\n\n\nThe same consideration about edge effects as for the \\(K\\) functions have to be made for the spacing functions. The uncorrected estimators are negatively biased as estimators for the real spacing functions. The easiest approach is to draw an artificial border and consider nearest neighbours there in. Other approaches are based on sampling. Yet another approach is based on survival analysis. The idea is that a circle of a point to grows homogeneously with increasing radius until it hits the frame of the window and “dies”. This gives survival distributions. This is similar to censored data, where the Kaplan-Meier estimator is the optimal choice."
  },
  {
    "objectID": "05-spotbased.html",
    "href": "05-spotbased.html",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\ntheme_set(theme_light())\n\n\n\n\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, namels Mdkand Ncl[7]."
  },
  {
    "objectID": "05-spotbased.html#dependencies",
    "href": "05-spotbased.html#dependencies",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\ntheme_set(theme_light())"
  },
  {
    "objectID": "05-spotbased.html#setup-and-preprocessing",
    "href": "05-spotbased.html#setup-and-preprocessing",
    "title": "Preamble",
    "section": "",
    "text": "# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, namels Mdkand Ncl[7]."
  },
  {
    "objectID": "05-spotbased.html#regular-lattice-data",
    "href": "05-spotbased.html#regular-lattice-data",
    "title": "Preamble",
    "section": "",
    "text": "Spot based data is collected along a regular spaced grid where all sample areas have the same size. Such a grid is also called a regular lattice. In more rigorous terms the data \\(Y\\) is the product of a random process but the sampling locations are fixed along a lattice \\(D\\). The lattice \\(D\\) does not have to regular but in the scope of spot based data it is. The main difference of this type of data in comparison to point patterns is, that the locations of the data are then not results of a stochastic process but rather due to a defined sampling strategy [1].\nThe lattice is composed of individual spatial units\n\\[\nD = \\{A_1, A_2,...,A_n\\}\n\\] where these units are not supposed to overlap\n\\[\nA_i \\cap A_j = \\emptyset \\forall i \\neq j\n\\]\nThe data is then a random variable of the spatial unit along the lattice\n\\[\nY_i = Y(A_i)\n\\]\n–&gt; need to find the papers mentioned here!!\nA lot of lattice data analysis technique build on the concept of neighbours. Therefore, the spatial relationship has to be modelled with e.g. a spatial weigth matrix \\(W\\). There are a lot of ways to define a spatial weigth matrix \\(W\\). An intuitive way is from Cliff and Ord (1981) and Upton and Fingleton (1985). Here, the units that are adjacent are specified with a one and the ones that are not adjacent with a zero (inary coniguity matrix) [1].\n\\[\nw_{ij} = \\begin{cases}\n1 \\text{ if } A_i \\text{ and } A_j \\text{ are adjacent}\\\\\n0 \\text{ otw}\n\\end{cases}\n\\]\nother options to specify the weight matrix \\(W\\) are mentioned in [1]."
  },
  {
    "objectID": "05-spotbased.html#global-measures-for-univariate-data",
    "href": "05-spotbased.html#global-measures-for-univariate-data",
    "title": "Preamble",
    "section": "Global Measures for Univariate Data",
    "text": "Global Measures for Univariate Data\nGlobal measures are values across an entire field of view. This gives e.g. one number per field of view.\nA common analysis to do with lattice data (and point pattern data) is to check for spatial correlation. This is a second-order property of the form (Getis 1991)\n\\[\n\\sum_i \\sum_j = w_{ij}U_{ij}\n\\]\nwhere \\(w_{ij}\\) is the weight matrix and \\(U_{ij}\\) a dissimilarity measure. [1]\n\nGlobal Moran’s I coefficient\nA common dissimilarity measure is Morans \\(I\\). It is defined by [1]\n\\[\nI = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(y_i - \\hat{y})(y_j - \\hat{y})}{\\sum_i (y_i - \\hat{y})^2}\n\\]\nUnder the null \\(I\\) takes the value \\(-1/(n-1)\\) in expectation. This value is close to \\(0\\) for large \\(n\\). A value higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation. Negative values indicate negative auto-correlation, but this is not so easy to interpret [1]. The implementation below is a Monte Carlo simulation approach to define a null distribution to test against.\n\nImplementation using VOYAGER\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n# plotSpatialFeature(sfe_tissue, features = \"nCounts\", \n#                    colGeometryName = \"spotPoly\",\n#                    annotGeometryName = \"myofiber_simplified\", \n#                    aes_use = \"color\", linewidth = 0.5, fill = NA,\n#                    annot_aes = list(fill = \"area\"))\n\nsfe_tissue &lt;-  colDataUnivariate(sfe_tissue, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"visium\", nsim = 1000,\n                                type = \"moran.mc\")\n\nres &lt;- colFeatureData(sfe_tissue)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$moran.mc_statistic_Vis5A\n#p-value\nres$moran.mc_p.value_Vis5A\n\nplotMoranMC(sfe_tissue, c(\"nCounts\", \"nGenes\"))\n\n\n\nImplementation using spdep\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe_tissue, \"visium\")\n\nsfe_tissue[rowData(sfe_tissue)[,'symbol'] == 'Myh2',]\n\nclass: SpatialFeatureExperiment \ndim: 1 932 \nmetadata(0):\nassays(2): counts logcounts\nrownames(1): ENSMUSG00000033196\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(932): AAACATTTCCCGGATT AAACCTAAGCAGCCGG ... TTGTGTTTCCCGAAAG\n  TTGTTGTGTGTCAAGA\ncolData names(13): barcode col ... in_tissue sizeFactor\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: col: visium\n\nspdep::moran.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe_tissue$nGenes  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 19.758, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.3840275174     -0.0010741139      0.0003798881 \n\nspdep::moran.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe_tissue$nCounts  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 27.181, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.5287046946     -0.0010741139      0.0003798881 \n\n\nThe number of genes per spot shows a Moran’s \\(I\\) of \\(\\sim 0.38\\) which indicates auto-correlation. The number of counts per spot shows a Moran’s \\(I\\) of \\(\\sim 0.53\\).\n\n\n\nGlobal Geary’s C coefficient\nAnother measure of spatial auto-correlation is Geary’s \\(C\\). It is very closely related to Moran’s \\(I\\). Geary’s \\(C\\) is defined by:\n\\[\nC = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(y_i-y_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(y_i-\\bar{y})^2}\n\\]\nThe interpretation is inveresely to Moran’s \\(I\\). A value less than \\(1\\) indicates positive auto-correlation, a value more than \\(1\\) negative auto-correlation. (https://pachterlab.github.io/voyager/articles/visium_10x.html)\nThe testing works similarly to Moran’s \\(I\\), just the objective function changes in the Monte Carlo estimation\n\nImplementation using VOYAGER\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\nsfe_tissue &lt;-  colDataUnivariate(sfe_tissue, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"visium\", nsim = 1000,\n                                type = \"geary.mc\")\n\nres &lt;- colFeatureData(sfe_tissue)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$geary.mc_statistic_Vis5A\n\n[1] 0.4748925 0.6057966\n\n#p-value\nres$geary.mc_p.value_Vis5A\n\n[1] 0.000999001 0.000999001\n\n\n\n\nImplementation using spdep\n\nspdep::geary.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe_tissue$nGenes \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 19.996, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     0.6057966472      1.0000000000      0.0003886284 \n\nspdep::geary.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe_tissue$nCounts \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 26.729, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     0.4748924980      1.0000000000      0.0003859596 \n\n\nThe Geary’s \\(C\\) statistic gives a value of \\(0.47\\) for the number of counts and \\(0.61\\) for the number of genes. The interpretation is that both features show positive auto correlation.\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/gean.12164\n\n\n\nGlobal Getis-Ord \\(G\\) statistic\nThe global \\(G\\) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in teh dataset. Formally that is,\n\\[\nG(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j}, \\text{s.t } j \\neq i\n\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather considering both approaches.\n–&gt; weights should be binarised for this test - how to do this?\n\nspdep::globalG.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods)\n\n\n    Getis-Ord global G statistic\n\ndata:  sfe_tissue$nGenes \nweights: weights_neighbourhoods \n\nstandard deviate = 20.757, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.185181e-03       1.074114e-03       2.863192e-11 \n\nspdep::globalG.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods)\n\n\n    Getis-Ord global G statistic\n\ndata:  sfe_tissue$nCounts \nweights: weights_neighbourhoods \n\nstandard deviate = 27.797, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.361423e-03       1.074114e-03       1.068346e-10 \n\n\n[5]"
  },
  {
    "objectID": "05-spotbased.html#local-measures-for-univariate-data",
    "href": "05-spotbased.html#local-measures-for-univariate-data",
    "title": "Preamble",
    "section": "Local Measures for Univariate Data",
    "text": "Local Measures for Univariate Data\n\nLocal Moran’s I coefficient\nOften a global measure is not enough. One number determining e.g. the spatial autocorrelation over an entire tissue slice might not be reflective of tissue heterogeneity. Therefore, local indicators of spatial associations have been developed [2]. For each sampling location we calculate as follows (https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1538-4632.1995.tb00338.x) (formula from ?localmoran)\n\\[\nI_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\n\\]\nSince we are calculating several local statistics potentially from the same observations, problems of multiple testing arise. We correct for this issue with standard adjustments, such as Benjamini Hochberg correction (https://rss.onlinelibrary.wiley.com/doi/10.1111/j.2517-6161.1995.tb02031.x). The problem of false positives due to multiple testing is discussed in great detail in [2].\nImplementation with spdep\n\n#calculate local Moran's I and then correct for multiple testing using Benjamini-Hochberg correction if you want to plot p-values\nlocalplot &lt;- function(sfe, var, fun, plotvar, weights_neighbourhoods){\n  loc &lt;- do.call(fun, args = list(x=sfe[[var]], listw = weights_neighbourhoods))\n  #why so ever, 'localG' has a different return structure than 'localmoran'. Thus, this conditional with different indexing\n  if(fun %in% c('localG')){\n    loc &lt;- attr(loc, 'internals')\n    #extract the effect size\n    locEffect &lt;- loc[,1]\n    #extract the p-value and adjust for multiple testing\n    p.val.adj &lt;- loc[,5] |&gt; p.adjust(\"BH\")\n  }\n  else if(fun == 'localC_perm'){\n    p.val.adj &lt;- attr(loc, 'pseudo-p')[,'Pr(z != E(Ci))']\n    locEffect &lt;- loc\n  }\n  else if (fun == 'LOSH'){\n    locEffect &lt;- loc[,1]\n    p.val.adj &lt;- c()\n  }\n  else{\n    #extract the effect size\n    locEffect &lt;- loc[,1]\n    #extract the p-value and adjust for multiple testing\n    p.val.adj &lt;- loc[,5] |&gt; p.adjust(\"BH\")\n  }\n  \n  #convert into a plain sf object for plotting\n  sf &lt;- colGeometries(sfe)$spotPoly\n  \n  sf$locEffect &lt;- locEffect\n  sf$p.val.adj &lt;- p.val.adj\n  \n  return(tm_shape(sf) + tm_fill(col = plotvar))\n}\n\np &lt;- localplot(sfe_tissue, 'nCounts', fun = 'localmoran', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\nq &lt;- localplot(sfe_tissue, 'nGenes', fun = 'localmoran', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\n\ntmap_arrange(p,q)\n\n\n\n\n\nImplementation with Voyager\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localmoran\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localmoran\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\nLocal Geary’s C coefficient\nGeary’s C can be calculated for local interactions as well.\n\\[\nC_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2\n\\]\nThe interpretation is the same as for local Moran’s \\(I\\) [6].\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'localC_perm', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'localC_perm', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\n\ntmap_arrange(p,q)\n\n\n\n\n\nImplementation with Voyager\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localC_perm\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localC_perm\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\nLocal Getis-Ord \\(G_i\\) coefficient\nThe local Getis-Ord \\(G_i\\) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\).\n\\[\nG_i(d) = \\frac{\\sum_{j=1}^n w_{ij}(d)x_j}{\\sum_{j=1}^n x_j}, \\text{s.t } j \\neq i\n\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\) which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term. Importantly, \\(G_i(d)\\) is scale-invariant but not location-invariant. That means, the subdivision into the \\(n\\) subregions matterns for the computation of the local statistic [5].\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'localG', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'localG', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\n\ntmap_arrange(p,q)\n\n\n\n\n\nImplementation with Voyager\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\nLocal Spatial Heteroscedasticity (LOSH)\nThe univariate methods described above assume homoscedastic variance so that the variance is uniform over the sampling area [4]. In the context of tumour-immune infiltration we could have regions where the mean infiltration is the same but the variability depends on the specific pathology. Therefore, a new statistic was introduced, local spatial heteroscedasticity (LOSH). The aim of LOSH is similar to the local \\(G\\) statistic, where we compared means, to now compare variances. The aim is to compare homogeienity and heterogeneity of groups in space. This statistic is especially interesting in combination with the local \\(G\\) statistic, giving an overview on the mean-variance relationship of the sample [4].\nLOSH is defined formally as follows:\n\\[\nH_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\n\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_j(d), j\\in N(i,d)\\) are the local residuals [4].\nOrd and Getis provide a very nice table for the interpretation of the mean and variance relationship provided by \\(G_i\\) and \\(H_i\\).\n–&gt; insert table\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'LOSH', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'LOSH', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\n\ntmap_arrange(p,q)"
  },
  {
    "objectID": "05-spotbased.html#measures-for-bi--and-multivariate-data",
    "href": "05-spotbased.html#measures-for-bi--and-multivariate-data",
    "title": "Preamble",
    "section": "",
    "text": "So far, we have considered methods for univariate data, so where we looked at the change of one variable in several contexts. Spatial methods for bi- and multivariate data exist as well and will be discussed in the following.\n\n\nThe implementation in the package spdep is as follows:\n\\[\nL(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}}\n\\] (https://r-spatial.github.io/spdep/reference/lee.htmlls)\nLee’s \\(L\\) is a bivariate measure that combines non-spatial Pearson Correlation with spatial autocorrelation via Moran’s \\(I\\) [3]. Instead of looking at the auto-correlation of one signle variable we can now assess the spatial dependence of two variables.\n\nloc &lt;- lee(x = sfe_tissue$nCounts, y = sfe_tissue$nGenes, n = length(sfe_tissue$nCounts), listw = weights_neighbourhoods)\n\n#convert into a plain sf object for plotting\nsf &lt;- colGeometries(sfe_tissue)$spotPoly\n\nsf$locEffect &lt;- loc$localL\n\ntm_shape(sf) + tm_fill(col = 'locEffect')  \n\n\n\n\n\n\n\nsfe_tissue &lt;- runBivariate(sfe_tissue, \"locallee\", swap_rownames = \"symbol\",\n                           feature1 = c('nGenes', 'nCounts'))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)"
  },
  {
    "objectID": "05-spotbased.html#voyager",
    "href": "05-spotbased.html#voyager",
    "title": "Preamble",
    "section": "VOYAGER",
    "text": "VOYAGER\nThere is a very nice resource explaining in detail the available methods for lattice data (amongst others) (https://pachterlab.github.io/voyager/index.html). We will summarise complement these approaches in this chapter"
  },
  {
    "objectID": "05-spotbased.html#sources",
    "href": "05-spotbased.html#sources",
    "title": "Preamble",
    "section": "Sources",
    "text": "Sources\n[1] Zuur, A. F., Ieno, E. N., Smith, G. M., Saveliev, A. A., Mukharamova, S. S., & Zuur, A. F. (2007). Analysis and modelling of lattice data. Analysing Ecological Data, 321-339.\n[2] Pebesma, E., & Bivand, R. (2023). Spatial data science: With applications in R. CRC Press.\n[3] Lee, S. I. (2001). Developing a bivariate spatial association measure: an integration of Pearson’s r and Moran’s I. Journal of geographical systems, 3, 369-385.\n[4] Ord, J. K., & Getis, A. (2012). Local spatial heteroscedasticity (LOSH). The Annals of Regional Science, 48, 529-539.\n[5] Getis, A., & Ord, J. K. (1992). The analysis of spatial association by use of distance statistics. Geographical analysis, 24(3), 189-206.\n[6] Anselin, L. (1995). Local indicators of spatial association—LISA. Geographical analysis, 27(2), 93-115.\n[7] McKellar, D. W., Walter, L. D., Song, L. T., Mantri, M., Wang, M. F., De Vlaminck, I., & Cosgrove, B. D. (2021). Large-scale integration of single-cell transcriptomic data captures transitional progenitor states in mouse skeletal muscle regeneration. Communications biology, 4(1), 1280. ## Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices datasets  utils     methods  \n[8] base     \n\nother attached packages:\n [1] stringr_1.5.0                  dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.10.3                 SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-14                     \n[17] reshape2_1.4.4                 patchwork_1.1.3               \n[19] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[21] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[23] dbplyr_2.3.4                   RANN_2.6.1                    \n[25] seg_0.5-7                      sp_2.1-1                      \n[27] rlang_1.1.1                    ggplot2_3.4.4                 \n[29] dplyr_1.1.3                    mixR_0.2.0                    \n[31] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[33] spatstat.model_3.2-6           rpart_4.1.19                  \n[35] spatstat.explore_3.2-3         nlme_3.1-162                  \n[37] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[39] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[41] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[43] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[45] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[47] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[49] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     proxy_0.4-27                 \n [17] dbscan_1.1-11                 R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.2.1                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] spatstat.utils_3.0-3          rmarkdown_2.25               \n [87] XVector_0.40.0                htmltools_0.5.6.1            \n [89] pkgconfig_2.0.3               base64enc_0.1-3              \n [91] sparseMatrixStats_1.12.2      fastmap_1.1.1                \n [93] htmlwidgets_1.6.2             shiny_1.7.5.1                \n [95] DelayedMatrixStats_1.22.6     jsonlite_1.8.7               \n [97] BiocParallel_1.34.2           R.oo_1.25.0                  \n [99] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[101] magrittr_2.0.3                GenomeInfoDbData_1.2.10      \n[103] s2_1.1.4                      Rhdf5lib_1.22.1              \n[105] munsell_0.5.0                 Rcpp_1.0.11                  \n[107] ggnewscale_0.4.9              viridis_0.6.4                \n[109] stringi_1.7.12                leafsync_0.1.0               \n[111] zlibbioc_1.46.0               plyr_1.8.9                   \n[113] parallel_4.3.1                ggrepel_0.9.4                \n[115] deldir_1.0-9                  Biostrings_2.68.1            \n[117] stars_0.6-4                   splines_4.3.1                \n[119] tensor_1.5                    locfit_1.5-9.8               \n[121] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[123] BiocVersion_3.17.1            XML_3.99-0.14                \n[125] evaluate_0.22                 renv_1.0.3                   \n[127] BiocManager_1.30.22           httpuv_1.6.11                \n[129] purrr_1.0.2                   polyclip_1.10-6              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4"
  },
  {
    "objectID": "05-spotbased.html#session-info",
    "href": "05-spotbased.html#session-info",
    "title": "Preamble",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices datasets  utils     methods  \n[8] base     \n\nother attached packages:\n [1] spdep_1.2-8                    sf_1.0-14                     \n [3] spData_2.3.0                   tmap_3.3-4                    \n [5] scater_1.28.0                  scran_1.28.2                  \n [7] scuttle_1.9.4                  SFEData_1.2.0                 \n [9] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[11] reshape2_1.4.4                 patchwork_1.1.3               \n[13] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[15] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[17] dbplyr_2.3.4                   RANN_2.6.1                    \n[19] seg_0.5-7                      sp_2.1-1                      \n[21] rlang_1.1.1                    ggplot2_3.4.4                 \n[23] dplyr_1.1.3                    mixR_0.2.0                    \n[25] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[27] spatstat.model_3.2-6           rpart_4.1.19                  \n[29] spatstat.explore_3.2-3         nlme_3.1-162                  \n[31] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[33] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[35] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[37] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[39] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[41] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[43] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] splines_4.3.1                 later_1.3.1                  \n  [3] bitops_1.0-7                  filelock_1.0.2               \n  [5] tibble_3.2.1                  R.oo_1.25.0                  \n  [7] polyclip_1.10-6               XML_3.99-0.14                \n  [9] lifecycle_1.0.3               edgeR_3.42.4                 \n [11] lattice_0.21-8                crosstalk_1.2.0              \n [13] magrittr_2.0.3                limma_3.56.2                 \n [15] rmarkdown_2.25                yaml_2.3.7                   \n [17] metapod_1.7.0                 httpuv_1.6.11                \n [19] spatstat.sparse_3.0-2         RColorBrewer_1.1-3           \n [21] DBI_1.1.3                     abind_1.4-5                  \n [23] zlibbioc_1.46.0               purrr_1.0.2                  \n [25] R.utils_2.12.2                RCurl_1.98-1.12              \n [27] rappdirs_0.3.3                GenomeInfoDbData_1.2.10      \n [29] ggrepel_0.9.4                 irlba_2.3.5.1                \n [31] spatstat.utils_3.0-3          terra_1.7-55                 \n [33] units_0.8-4                   goftest_1.2-3                \n [35] RSpectra_0.16-1               dqrng_0.3.1                  \n [37] DelayedMatrixStats_1.22.6     codetools_0.2-19             \n [39] DropletUtils_1.20.0           DelayedArray_0.26.7          \n [41] tidyselect_1.2.0              raster_3.6-26                \n [43] viridis_0.6.4                 ScaledMatrix_1.8.1           \n [45] base64enc_0.1-3               jsonlite_1.8.7               \n [47] BiocNeighbors_1.18.0          e1071_1.7-13                 \n [49] ellipsis_0.3.2                dbscan_1.1-11                \n [51] tools_4.3.1                   ggnewscale_0.4.9             \n [53] Rcpp_1.0.11                   glue_1.6.2                   \n [55] gridExtra_2.3                 xfun_0.40                    \n [57] mgcv_1.8-42                   HDF5Array_1.28.1             \n [59] withr_2.5.1                   BiocManager_1.30.22          \n [61] fastmap_1.1.1                 boot_1.3-28.1                \n [63] rhdf5filters_1.12.1           bluster_1.10.0               \n [65] fansi_1.0.5                   rsvd_1.0.5                   \n [67] digest_0.6.33                 R6_2.5.1                     \n [69] mime_0.12                     colorspace_2.1-0             \n [71] wk_0.8.0                      tensor_1.5                   \n [73] dichromat_2.0-0.1             RSQLite_2.3.1                \n [75] R.methodsS3_1.8.2             utf8_1.2.3                   \n [77] generics_0.1.3                renv_1.0.3                   \n [79] class_7.3-22                  httr_1.4.7                   \n [81] htmlwidgets_1.6.2             S4Arrays_1.0.6               \n [83] tmaptools_3.1-1               pkgconfig_2.0.3              \n [85] scico_1.5.0                   gtable_0.3.4                 \n [87] blob_1.2.4                    XVector_0.40.0               \n [89] htmltools_0.5.6.1             scales_1.2.1                 \n [91] png_0.1-8                     splancs_2.01-44              \n [93] knitr_1.44                    rstudioapi_0.15.0            \n [95] rjson_0.2.21                  curl_5.1.0                   \n [97] proxy_0.4-27                  cachem_1.0.8                 \n [99] rhdf5_2.44.0                  stringr_1.5.0                \n[101] BiocVersion_3.17.1            KernSmooth_2.23-21           \n[103] vipor_0.4.5                   parallel_4.3.1               \n[105] AnnotationDbi_1.62.2          leafsync_0.1.0               \n[107] s2_1.1.4                      pillar_1.9.0                 \n[109] grid_4.3.1                    vctrs_0.6.4                  \n[111] promises_1.2.1                BiocSingular_1.16.0          \n[113] beachmat_2.16.0               xtable_1.8-4                 \n[115] cluster_2.1.4                 beeswarm_0.4.0               \n[117] evaluate_0.22                 magick_2.8.0                 \n[119] cli_3.6.1                     locfit_1.5-9.8               \n[121] compiler_4.3.1                crayon_1.5.2                 \n[123] classInt_0.4-10               ggbeeswarm_0.7.2             \n[125] plyr_1.8.9                    stringi_1.7.12               \n[127] stars_0.6-4                   viridisLite_0.4.2            \n[129] deldir_1.0-9                  BiocParallel_1.34.2          \n[131] munsell_0.5.0                 Biostrings_2.68.1            \n[133] leaflet_2.2.0                 Matrix_1.5-4.1               \n[135] leafem_0.2.3                  sparseMatrixStats_1.12.2     \n[137] bit64_4.0.5                   Rhdf5lib_1.22.1              \n[139] statmod_1.5.0                 KEGGREST_1.40.1              \n[141] shiny_1.7.5.1                 interactiveDisplayBase_1.38.0\n[143] igraph_1.5.1                  memoise_2.0.1                \n[145] lwgeom_0.2-13                 bit_4.0.5"
  },
  {
    "objectID": "02-discmarked.html#dependencies",
    "href": "02-discmarked.html#dependencies",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\nlibrary(spatstat)\nlibrary(seg)\nlibrary(stats)\nlibrary(RANN)\nlibrary(ggplot2)\nlibrary(spatstat.geom)"
  },
  {
    "objectID": "02-discmarked.html#setup",
    "href": "02-discmarked.html#setup",
    "title": "Preamble",
    "section": "",
    "text": "spe &lt;- readRDS(\"../data/spe.rds\")"
  },
  {
    "objectID": "02-discmarked.html#distances-and-nearest-neighbors",
    "href": "02-discmarked.html#distances-and-nearest-neighbors",
    "title": "Preamble",
    "section": "Distances and nearest neighbors",
    "text": "Distances and nearest neighbors\nInvestigating the nearest neighbor distance between point for all combinations of marks can be done as follows:\n\nd &lt;- nndist(pp_sel,by = marks(pp_sel))\na &lt;- aggregate(d,by = list(from=marks(pp_sel)),min)\na\n\n       from Ependymal Microglia OD Mature\n1 Ependymal  3.225180  8.176169 12.959456\n2 Microglia  8.176169 16.443565  6.215464\n3 OD Mature 12.959456  6.215464  6.428006"
  },
  {
    "objectID": "02-discmarked.html#nearest-neighbor-correlations",
    "href": "02-discmarked.html#nearest-neighbor-correlations",
    "title": "Preamble",
    "section": "Nearest neighbor correlations",
    "text": "Nearest neighbor correlations\nA overall correlation between marks can be calculated with nncorr. It returns two values: unnormalised, which is the probability that a point and its nearest neighbor have the same type and normalised, which divides the unnormalised probability by the probability of random labeling. So a value close to 1 indicates random labeling. A value much larger than 1 means neighboring point are often of the same type.\n\nnncorr(pp_sel)\n\nunnormalised   normalised \n   0.8081321    1.8823711 \n\n\n\nAnother possibility is to work with nearest neighborhood contingency tables to do statistical tests using the dixon function from the R package dixon. It allows to calculate the statistic “segregation of species” S which indicates either random labeling (if S=0), attraction (if S&lt;0) or seggregation (if S&gt;0).\n\nif(require(dixon)){\n  out &lt;- dixon::dixon(as.data.frame(pp_sel))\n  out$tablaZ\n}\n\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\n\n       From        To     Obs.Count     Exp. Count    S      Z    p-val.Z\n1 Ependymal Ependymal           262          87.16  1.96  20.04    0.0000\n2 Ependymal Microglia             3          31.66 -1.07  -5.66    0.0000\n3 Ependymal OD Mature             3         149.18 -2.04 -16.87    0.0000\n4 Microglia Ependymal             9          31.66 -0.68  -4.92    0.0000\n5 Microglia Microglia            21          11.34  0.32   2.50    0.0124\n6 Microglia OD Mature            67          53.99  0.25   2.60    0.0094\n7 OD Mature Ependymal             8         149.18 -1.43 -14.26    0.0000\n8 OD Mature Microglia            69          53.99  0.12   2.35    0.0190\n9 OD Mature OD Mature           380         253.83  0.60  11.43    0.0000\n    p-val.Nobs\n1         0.01\n2         0.01\n3         0.01\n4         0.01\n5         0.06\n6         0.01\n7         0.01\n8         0.02\n9         0.01"
  },
  {
    "objectID": "02-discmarked.html#summary-functions-for-pairs-of-types",
    "href": "02-discmarked.html#summary-functions-for-pairs-of-types",
    "title": "Preamble",
    "section": "Summary functions for pairs of types",
    "text": "Summary functions for pairs of types\n\n\n\n\n\nSimilar to the simple case without marks it is possible do estimate summary functions. More specifically the summary functions between different marks can be calculated.\nThese summary functions assume that the multitype process is stationary which might not be an appropriate assumption in spatial omcis data.\n\nCross K-function\n\nKall &lt;- alltypes(rescale(pp_sel), Kcross)\nplot(Kall)\n\n\n\n\nThe diagonal shows the K-function for the different marks, with indication of Poisson or non-Poisson point processes. Off-diagonal panels give indication of independence of points when the number of points follows the expected K-function and does not imply that the points are Poisson\n\n\nCross L-function:\nSimiliar to the the K-function, the cross L-function can be defined for all pairs of points.\n\nlc &lt;- alltypes(pp_sel, Lcross)\nplot(lc, .-r~r)\n\n\n\n\n\nlce &lt;- alltypes(pp_sel, Lcross, envelope = TRUE, nsim=9)\nplot(lce, .-r~r)\n\n\n\n\n\nTODO: not sure why the off-diagonal are not perfectly symmetric\n\n\n\nCross pair-correlation function\n\npcfc &lt;- alltypes(pp_sel, pcfcross)\nplot(pcfc)\n\n\n\n\n\n\nMark connection function\nThe mark connection function is essentially the cross pair-correlation function divided by the unmarked pair-correlation function. It can be interpreted as the conditional probability that two points a distance r apart have labels of type 1 and of type 2, given the presence of those points.\n\nmc &lt;- alltypes(pp_sel, markconnect)\nplot(mc)\n\n\n\n\nThe dashed lines indicate expected values under random labeling, revealing that nearby points are more likely to have different types than expected by chance. This positive association between different cell types does not necessarily imply dependence, as it could be influenced by a negative association between cells of the same type.\n\n\nCross F-function (empty space function)\nThe cross F-function is the cumulative distribution function of the distance from a location to the nearest point of the same type. Assumes that the process is stationary.\n\nfc &lt;- alltypes(pp_sel, Fest)\nplot(fc)\n\n\n\n\n\n\nCross G-function (Nearest-neighbor function)\nThe cross G-function is the cumulative distribution function of the distance from a location to the nearest point of another type. If the points are independent of each other the G and F function are identical. Assumes that the process is stationary.\n\ngc &lt;- alltypes(pp_sel, Gcross)\nplot(gc)\n\n\n\n\n\n\nCross J-function\nThe value of 1 is consistent with CSR and independence between different points.\n\njc &lt;- alltypes(pp_sel, Jcross)\nplot(jc)\n\n\n\n\n\n\nDot functions\nFor each K-, G- and J- function there also exist dot functions which is measuring distances from points of one type to points of any type.\n\njd &lt;- alltypes(pp_sel, Jdot)\nplot(jd)"
  },
  {
    "objectID": "02-discmarked.html#summary-function-within-and-between-types",
    "href": "02-discmarked.html#summary-function-within-and-between-types",
    "title": "Preamble",
    "section": "Summary function within and between types",
    "text": "Summary function within and between types\n\nMark equality function\nThe Mark or Type Equality function for a stationary multitype point process measures the correlation between types of two points separated by distance r. If k &lt; 1, points at distance r are less likely than expected to be of the same type. If &gt; 1, they are more likely to be of the same type.\n\nme &lt;- markcorr(pp_sel)\nplot(me)\n\n\n\n\n\n\nI-function\n\nic &lt;- Iest(pp_sel)\nplot(ic)"
  },
  {
    "objectID": "02-discmarked.html#summary-functions-for-non-stationary-processes",
    "href": "02-discmarked.html#summary-functions-for-non-stationary-processes",
    "title": "Preamble",
    "section": "Summary functions for non stationary processes",
    "text": "Summary functions for non stationary processes\nThe cross and dot functions described above assume a underlying stationary point process. If this assumption is not given, the interpretation of the result might be incorrect.\nThe inhomogeneous equivalents of the described functions require the different intensities as inputs in spatstat. If they are not given the intensities are estimated using kernel smoothing.\n\nInhomogeneous L-function\n\nlci &lt;- alltypes(pp_sel, Lcross.inhom)\nplot(lci, .-r~r)"
  },
  {
    "objectID": "02-discmarked.html#testing-the-indepenence-of-components-assumption",
    "href": "02-discmarked.html#testing-the-indepenence-of-components-assumption",
    "title": "Preamble",
    "section": "Testing the indepenence of components assumption",
    "text": "Testing the indepenence of components assumption\nThe i to j functions are useful to test the independence of different subprocesses. If the processes of type i and j are independent then \\(K_{ij} = \\pi r^2, G_{ij}(r) = F_{j}(r), J_{ij}(r) \\equiv 1\\).\n\npp_scaled &lt;- rescale(pp_sel)\n\nE1 &lt;- envelope(pp_scaled, Kcross, nsim=10, i=\"OD Mature\", j=\"Ependymal\", simulate=expression(rshift(pp_scaled, radius=150)))\n\nGenerating 10 simulations by evaluating expression  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\nE2 &lt;- envelope(pp_scaled, Gcross, nsim=10, i=\"OD Mature\", j=\"Ependymal\", simulate=expression(rshift(pp_scaled, radius=150)))\n\nGenerating 10 simulations by evaluating expression  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\nE3 &lt;- envelope(pp_scaled, Jcross, nsim=10, i=\"OD Mature\", j=\"Ependymal\", simulate=expression(rshift(pp_scaled, radius=150)))\n\nGenerating 10 simulations by evaluating expression  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\npar(mfrow = c(3,1))\nplot(E1)\nplot(E2)\nplot(E3)\n\n\n\n\nAlternatively, randomization tests can be used in which simulated patterns from the dataset are generated and randomly split into subpatterns. These are then compared to the null hypothesis in which all subpatterns should be statistically equivalent to the original. However, this approach assumes stationarity and there is no methods to handle edge effects appearing from random shifts when splitting."
  },
  {
    "objectID": "02-discmarked.html#testing-random-labelling",
    "href": "02-discmarked.html#testing-random-labelling",
    "title": "Preamble",
    "section": "Testing random labelling",
    "text": "Testing random labelling\nRandom labelling test is most logical when the marks represents its status, which is not most appropriate assumption when considering cell types. Test for random labelling can be done using permuation test, in which the labels are randomly permuted. Random labelling can be assumed if the permuted datasets are statistically equivalent to the original dataset."
  },
  {
    "objectID": "03-contmarked.html#dependencies",
    "href": "03-contmarked.html#dependencies",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\nlibrary(rgeoda)\nlibrary(spatstat)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(parallel)\nlibrary(ggplot2)\n# spatial correlogram\nlibrary(ncf)"
  },
  {
    "objectID": "03-contmarked.html#setup",
    "href": "03-contmarked.html#setup",
    "title": "Preamble",
    "section": "",
    "text": "spe = readRDS(\"../data/spe.rds\")\n\n#subset the data to only look at sample ID 0.01\nsub = spe[, spe$sample_id == 0.01]\n#sub = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"Astrocyte\", \"Pericytes\")]\n(pp = .ppp(sub, marks = \"cluster_id\"))\n\nMarked planar point pattern: 6111 points\nmarks are of storage type  'character'\nwindow: rectangle = [1222.5635, 3012.4248] x [-3993.535, -2202.755] units\n\n#subset the data to only look at sample ID 0.01\nsub_2CT = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"Astrocyte\", \"Inhibitory\")]\n#sub = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"Astrocyte\", \"Pericytes\")]\n(pp_2CT = .ppp(sub_2CT, marks = \"cluster_id\"))\n\nMarked planar point pattern: 2611 points\nmarks are of storage type  'character'\nwindow: rectangle = [1222.5635, 3012.4248] x [-3990.104, -2204.671] units\n\n#split the multitype point process into several single type processes\n#fist, set the marks of the point process to be factors\nmarks(pp) = factor(marks(pp))\nppls = split(pp)\n\n\nplot(ppls)"
  },
  {
    "objectID": "03-contmarked.html#summary-functions",
    "href": "03-contmarked.html#summary-functions",
    "title": "Preamble",
    "section": "Summary functions",
    "text": "Summary functions\nAs in the discrete case the summary functions assume that the point process is stationary.\n\nMark correlation function\nThe mark correlation function measures the dependence between the marks at two points at distance \\(r\\). It is not a correlation in the classical sense, since it can take any nonegative value. The value of 1 indicates no correlation between the marks. The generalized mark correlation function is given by\n\\[ k_f(r) = \\frac{\\mathbb{E}[f(m(u)m(v))]}{\\mathbb{E}[f(M,M')]}\\] where \\(f(m_1,m_2)\\) is a test function with two arguments that represent the marks and returns a non-negative value. For continuous non-negative marks the choice of \\(f\\) is by default \\(f(m_1,m_2)= m_1 m_2\\). \\(M, M′\\) represent independent, identically distributed random points with same distribution as the mark of a randomly chosen point. This denominator is chosen such that random marks have a mark correlation of 1.\n\nplot(markcorr(pp))\n\n\n\n\nWe can compare the mark correlation function to a pointwise simulation envelope in which we generate 5 simulations of random labeling.\n\nppEsr1 &lt;- subset(pp, select = 'Esr1')\nmarkcorr.Esr1 &lt;- envelope(ppEsr1, markcorr, nsim=10)\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\nplot(markcorr.Esr1)\n\n\n\n\nThe plot indicates that the mark correlation function is significantly different from the random case. The positive association of expression of the Esr1 gene declines with distance. This is consistent with clustering we saw in the residual plot above."
  },
  {
    "objectID": "03-contmarked.html#bivariate-global-morans-i",
    "href": "03-contmarked.html#bivariate-global-morans-i",
    "title": "Preamble",
    "section": "Bivariate Global Moran’s I",
    "text": "Bivariate Global Moran’s I\nGlobal morans’I concept is equal to local but one can plot continuous variable on x axis and spatial lag on y axis and the slope is equal to morans I value. With 4 quadrants that allow us to understand the global picture of spatial correlation**\nWhile the local one gives us information about more local environments\n\\(B\\)\nConcept -&gt; Moran’s I is a correlation coefficient that measures the overall spatial autocorrelation of a dataset.\n-&gt; Moran’s I values ranging from –1 to 1.\n\n-1 is + perfect clustering of dissimilar values (perfect dispersion)\n0 is no autocorrelation (perfect randomness)\n1 indicates perfect clustering (opposite of perfect dispersion)\n\n-&gt; Moran’s I output cannot be taken directly for interpretation. It is an inferential statistic, and one has to determine statistical significance by using hypothesis test, calculating z-score and its associated p-value.\n\nThe null hypothesis for the test is that the data is randomly distributed.\nThe alternative hypothesis is that the data is more spatially clustered than you would expect by chance alone. 2 scenarios:\n\nPositive z-score: data is spatially clustered in some way.\nNegative z-score: data is clustered in a competitive way. For example, high values may be repelling high values or negative values may be repelling negative values in a competitive way.\n\n\nCalculations\n-&gt; Calculations for Moran’s I are based on a weighted matrix, with units i and j. Similarities between units is calculated as the product of the differences between yi and yj with the overall mean.\n\\[\nsimilarity = (y_i - \\overline{y}) * (y_j - \\overline{y})\n\\\\where \\ \\overline{y} = \\sum_{i = 1}^{n} y_i / n\n\\]\n-&gt; Moran’s statistic is calculated using the basic form, which is divided by s (sample variance)\n\\[\nI = \\frac{\\sum_{i} \\sum_{j} (y_i - \\overline{y}) * (y_j - \\overline{y}) }{\\sum_{i} \\sum_{j} w_{ij}} * \\frac{1}{S²}\n\\\\S² = \\frac{\\sum_{(y_i - \\overline{y})²}}{n}\n\\]\nwij as the elements of the spatial weights matrix\nN is the number of observations\n-&gt; The distribution of the statistic under the null can be derived using either an assumption of normality or so-called randomization. While the analytical derivations provide easy way to interpret the mean and the variance of the statistic under the null hypothesis, inference based on them employs an approximation to a standard normal distribution, which may be inappropriate when the underlying assumptions are not satisfied.\n-&gt; An alternative to the analytical derivation is a computation approach based on permutation. This calculates a reference distribution for the statistic under the null hypothesis of spatial randomnes by randomly permuting the observed values over the locations. The statistic is computed for each of these randomly reshuffled data sets, which yields a reference distribution.\n-&gt; The reference distribution is used to calculate so-called pseudo p-value as follows:\n\\[\np=\\frac{R + 1}{M + 1}\n\\]\nWhere R is the number of times the computed Moran’s I from the spatial random datasets is equal to or more extreme than the observed statistic. M equals the number of permutations.\nGenerate spatial weights (The weight matrix is often row-standardized - all the wieghts in a row sum to 1)\n\nContiguity Based Weights: queen_weights(), rook_weights()\nDistance Based Weights: distance_weights()\nK-Nearest Neighbor Weights: knn_weights()\nKernel Weights: distance_weights() and knn_weights() with kernel parameters\n\n\nMorans’I scatter plot\n-&gt; Plot with the spatially lagged variable on the y-axis and the original variable on the x-axis. The slope of the linear fit to the scatter plot equals Moran’s I value.\n-&gt; An important aspect of the visualization in the Moran scatter plot is the classification of the nature of spatial autocorrelation into four categories. Since the plot is centered on the mean (of zero), all points to the right of the mean have zi&gt;0 and all points to the left have zi&lt;0 .We refer to these values respectively as high and low, in the limited sense of higher or lower than average. Similarly, we can classify the values for the spatial lag above and below the mean as high and low.\n-&gt; as such, we have 4 quadrants: + (&gt;0 &gt;0 -&gt; High-high) | (&lt;0 &lt;0 -&gt; Low-low) Correspond to positive spatial correlation (Similar values at the neighborhood locations) + (&lt;0 &gt;0 -&gt; Low-high) | (&gt;0 &lt;0 -&gt; High-low) Correspond to negative spatial correlation (Dissimilar values at the neighborhood locations)\n-&gt; Spatial lag is calculated on standardized values of the variable of interest and thus, the plot is in x axis (standardized values of variable of interest) and y axis (spatial lag)\n-&gt; A spatial lag of a specified variable is computed by taking the weighted average of neighboring polygons, as specified in the weights matrix. For example: a census tract with three neighboring tracts that have 10%, 15%, and 20% black population would have a spatial lag of 15%; that is, [(10%+15%+20%)/3]. The row-standardized spatial weights matrix is used in the calculation of the spatial lag.\nCalculate spatial lag\n\nsptl_lag = spatial_lag(knn_weights_sfObj, sfObj[\"mark\"])\n\nsptl_lag %&gt;% as.vector() %&gt;% unlist %&gt;% hist\n\nI am not sure how to represent non-numerical variables for the morans plot"
  },
  {
    "objectID": "03-contmarked.html#local-morans-i",
    "href": "03-contmarked.html#local-morans-i",
    "title": "Preamble",
    "section": "Local Moran’s I",
    "text": "Local Moran’s I\n-&gt; With row-standardized weights, the sum of all weights:\n\\[\nS_0 = \\sum_{i}\\sum_{j}w_{ij}\n\\] equals the number of observations, n. As a result, Moran’s statistic simplifies to: \\[\nI = \\frac{\\sum_{i}\\sum_{j} w_{ij} z_iz_j}{\\sum_{i}z²}\n\\] where z is the deviations from the mean. This can be simplified to: \\[\nI_i = c.z_i \\sum_{j} w_{ij}z_j\n\\] since the dominator of previous equation is constant, it is replaced by c for simplicity…\nThe equation represents product of the value at location i with its spatial lag, the weighted sum of the values at neighboring locations. A little bit of algebra shows that the sum of the local statistics is proportional to the global Moran’s I, or, alternatively, that the global Moran’s I corresponds with the average of the local statistics\n-&gt; Significance can be based on an analytical approximation, but, as argued in Anselin (1995), this is not very reliable in practice. A preferred approach consists of a conditional permutation method. This is similar to the permutation approach mentioned above, except that the value of each zi is held fixed at its location i. The remaining n-1 z-values are then randomly permuted to yield a reference distribution for the local statistic (one for each location).\n\n# convert ppp object to sf object\nsfObj = st_as_sf(pp)\n\n# Remove 1st row -&gt; window info (otherwise crash)\nsfObj = sfObj[-1,]\n\n# change name of 1st column\ncolnames(sfObj)[1] = c(\"mark\")\n\n# convert marks to factors\nsfObj$mark = as.factor(sfObj$mark)\n\n# calculate weights based on knn -&gt; others algos can be used\nknn_weights_sfObj = knn_weights(sfObj, k = sqrt(dim(sfObj)[1]) %&gt;% floor) # \n\nMoran’s test\n\nlisa = local_moran(knn_weights_sfObj, sfObj[\"mark\"], cpu_threads = parallel::detectCores() * 0.75)\n\n#lisa_clusters(): Get the local cluster indicators returned from LISA computation.\n#lisa_colors(): Get the cluster colors of LISA computation.\n#lisa_labels(): Get the cluster labels of LISA computation.\n#lisa_values(): Get the local spatial autocorrelation values returned from LISA computation.\n#lisa_num_nbrs(): Get the number of neighbors of every observations in LISA computation.\n#lisa_pvalues(): Get the local pseudo-p values of significance returned from LISA computation.\n#lisa_fdr(): Get the False Discovery Rate (FDR) in LISA.\n#lisa_bo(): Get the False Discovery Rate (FDR) in LISA.\n\nGet the False Discovery Rate value based on current pseudo-p values:\n\nfdr = lisa_fdr(lisa, 0.05)\nfdr\n\n[1] 8.181967e-06\n\n\nThen, one can set 0.05 as the cutoff p-value to filter the cluster results:\n\n#lisa_clust = lisa_clusters(lisa, cutoff = fdr)\nlisa_clust = lisa_clusters(lisa, cutoff = 0.05)\ntable(lisa_clust)\n\nlisa_clust\n   0    1    2    3    4 \n1897  610 2345  928  331 \n\n#0 Not significant\n#1 High-High\n#2 Low-Low\n#3 High-Low\n#4 Low-High\n#5 Undefined\n#6 Isolated\n\nplot lisa output (clusters of correlation)\n\nlisa_pvalues = lisa_pvalues(lisa)\nlisa_colors = lisa_colors(lisa)\n#change white to blue for the non significant\nlisa_colors[1] = \"#47E5DA\"\nlisa_labels = lisa_labels(lisa)\n\nplot(st_geometry(sfObj), \n     col=sapply(lisa_clust, function(x){return(lisa_colors[[x+1]])}), \n     border = \"#333333\", lwd=0.2)\n\ntitle(main = \"Local Moran Map\")\nlegend('bottomleft', legend = lisa_labels, fill = lisa_colors, border = \"#eeeeee\")\n\n\n\np_labels = c(\"Not significant\", \"p &lt;= 0.05\", \"p &lt;= 0.01\", \"p &lt;= 0.001\")\np_colors = c(\"#47E5DA\", \"#7C47E5\", \"#479BE5\", \"#F34A4A\")\nplot(st_geometry(sfObj), \n     col=sapply(lisa_pvalues, function(x){\n       if (x &lt;= 0.001) return(p_colors[4])\n       else if (x &lt;= 0.01) return(p_colors[3])\n       else if (x &lt;= 0.05) return (p_colors[2])\n       else return(p_colors[1])\n       }), \n     border = \"#333333\", lwd=0.2)\ntitle(main = \"Local Moran Map\")\nlegend('bottomleft', legend = p_labels, fill = p_colors, border = \"#eeeeee\")"
  },
  {
    "objectID": "03-contmarked.html#only-2-ct-castrocyte-inhibitory",
    "href": "03-contmarked.html#only-2-ct-castrocyte-inhibitory",
    "title": "Preamble",
    "section": "Only 2 CT c(“Astrocyte”, “Inhibitory”)",
    "text": "Only 2 CT c(“Astrocyte”, “Inhibitory”)\n\n# convert ppp object to sf object\nsfObj_2CT = st_as_sf(pp_2CT)\n\n# Remove 1st row -&gt; window info (otherwise crash)\nsfObj_2CT = sfObj_2CT[-1,]\n\n# change name of 1st column\ncolnames(sfObj_2CT)[1] = c(\"mark\")\n\n# convert marks to factors\nsfObj_2CT$mark = as.factor(sfObj_2CT$mark)\n\n# weights\nknn_weights_sfObj_2CT = knn_weights(sfObj_2CT, k = sqrt(dim(sfObj_2CT)[1]) %&gt;% floor) # \n\nMoran’s test\n\nlisa_2CT = local_moran(knn_weights_sfObj_2CT, sfObj_2CT[\"mark\"], cpu_threads = parallel::detectCores() * 0.75)\n\nplot lisa_2CT output\n\nlisa_2CT_clust = lisa_clusters(lisa, cutoff = FALSE)\nlisa_2CT_pvalues = lisa_pvalues(lisa_2CT)\nlisa_2CT_colors = lisa_colors(lisa_2CT)\n#change white to blue for the non significant\nlisa_2CT_colors[1] = \"#47E5DA\"\nlisa_2CT_labels = lisa_labels(lisa_2CT)\n\nplot(st_geometry(sfObj_2CT), \n     col=sapply(lisa_2CT_clust, function(x){return(lisa_colors[[x+1]])}), \n     border = \"#333333\", lwd=0.2)\n\ntitle(main = \"Local Moran Map\")\nlegend('bottomleft', legend = lisa_2CT_labels, fill = lisa_2CT_colors, border = \"#eeeeee\")\n\n\n\np_labels = c(\"Not significant\", \"p &lt;= 0.05\", \"p &lt;= 0.01\", \"p &lt;= 0.001\")\np_colors = c(\"#47E5DA\", \"#7C47E5\", \"#479BE5\", \"#F34A4A\")\nplot(st_geometry(sfObj_2CT), \n     col=sapply(lisa_2CT_pvalues, function(x){\n       if (x &lt;= 0.001) return(p_colors[4])\n       else if (x &lt;= 0.01) return(p_colors[3])\n       else if (x &lt;= 0.05) return (p_colors[2])\n       else return(p_colors[1])\n       }), \n     border = \"#333333\", lwd=0.2)\ntitle(main = \"Local Moran Map\")\nlegend('bottomleft', legend = p_labels, fill = p_colors, border = \"#eeeeee\")"
  },
  {
    "objectID": "03-contmarked.html#multivariate-local-geary-test",
    "href": "03-contmarked.html#multivariate-local-geary-test",
    "title": "Preamble",
    "section": "Multivariate Local Geary test",
    "text": "Multivariate Local Geary test\n-&gt; Geary’s C is inversely related to Moran’s I, but it is not identical. Moran’s I is a measure of global spatial autocorrelation, while Geary’s C is more sensitive to local spatial autocorrelation.\n\\[\nC = \\frac{(N = 1) \\sum_{i}  \\sum_{j} w_{ij} (x_i - x_j)²} {2W \\sum_{i} (x_i - \\overline{x})²}\n\\]\nWhere N is the number of spatial units indexed by i and j. \\(x\\) is the variable of interest, \\(\\overline{x}\\) is the mean of \\(x\\) \\(Wij\\) is a matrix of spatial weights with zeroes on the diagonal\n-&gt; The value of Geary’s C lies between 0 and some unspecified value greater than 1. + Values significantly lower than 1 demonstrate increasing positive spatial autocorrelation, + Values significantly higher than 1 illustrate increasing negative spatial autocorrelation.\n\nlisa_geary = local_multigeary(knn_weights_sfObj, sfObj[\"mark\"])\n\nlisa_pvalues = lisa_pvalues(lisa_geary)\n#change white to blue for the non significant\nlisa_labels = lisa_labels(lisa_geary)\n\nplot(st_geometry(sfObj), \n     col=sapply(lisa_clust, function(x){return(lisa_2CT_colors[[x+1]])}), \n     border = \"#333333\", lwd=0.2)\n\ntitle(main = \"Multivariate Local Geary\")\nlegend('bottomleft', legend = lisa_labels, fill = lisa_2CT_colors, border = \"#eeeeee\")\n\n\n\np_labels = c(\"Not significant\", \"p &lt;= 0.05\", \"p &lt;= 0.01\", \"p &lt;= 0.001\")\np_colors = c(\"#47E5DA\", \"#7C47E5\", \"#479BE5\", \"#F34A4A\")\nplot(st_geometry(sfObj), \n     col=sapply(lisa_pvalues, function(x){\n       if (x &lt;= 0.001) return(p_colors[4])\n       else if (x &lt;= 0.01) return(p_colors[3])\n       else if (x &lt;= 0.05) return (p_colors[2])\n       else return(p_colors[1])\n       }), \n     border = \"#333333\", lwd=0.2)\ntitle(main = \"Multivariate Local Geary\")\nlegend('bottomleft', legend = p_labels, fill = p_colors, border = \"#eeeeee\")"
  },
  {
    "objectID": "03-contmarked.html#spatial-correlogram",
    "href": "03-contmarked.html#spatial-correlogram",
    "title": "Preamble",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\n-&gt; A non-parametric spatial correlogram is an alternative measure of global spatial autocorrelation that does not rely on the specification of a spatial weights matrix. Instead, a local regression is fit to the covariances or correlations computed for all pairs of observations as a function of the distance between them.\n-&gt; If data is univariate, the spatial dependence is measured by Moran’s I. If it is multivariate, it is measure by the centered Mantel statistics. The latter is used to calculate correlations between corresponding positions of 2 (dis)similarity or distance matrices.\n-&gt; With standardized variables z, this boils down to a local regression:\n\\[\nz_i.z_j = f(d_{ij}) + \\mu\n\\]\nwhere \\(dij\\) is the distance between a pair of locations i-j \\(\\mu\\) is an error term \\(f\\) is the non-parametric function to be determined from the data (typically LOWESS or kernel regression)"
  },
  {
    "objectID": "03-contmarked.html#spatial-correlogram-plot",
    "href": "03-contmarked.html#spatial-correlogram-plot",
    "title": "Preamble",
    "section": "Spatial correlogram plot",
    "text": "Spatial correlogram plot\n-&gt; The plot depicts how the spatial autocorrelation changes with distance. + The intersection between correlogram and the red line is the turning point from autocorrelation to spatial randomness\n\n## Adapted function from their github\nplot.correlog = function(x, ...) {\n##############################################################################\n# this is the generic plot function for correlog objects\n# significant values are represented by filled circles\n##############################################################################\n  args.default = list(xlab = \"distance (mean-of-class)\", ylab = \"correlation\", \n                       main = \"Correlogram\")\n  args.input = list(...)\n  args = c(args.default[!names(args.default) %in% names(args.input)], args.input)\n  loess = loess(x$correlation ~ x$mean.of.class)\n  do.call(plot, c(list(x = x$mean.of.class, y = x$correlation), args))\n  \n  lines(x$mean.of.class, x$correlation)\n  lines(x$mean.of.class,  predict(loess), col = \"blue\",lwd = 3)\n  abline(h=0, col = \"red\")\n  if (!is.null(x$p)) {\n      points(x$mean.of.class[x$p &lt; 0.025], x$correlation[x$p &lt; 0.025], pch = 21, \n             bg = \"black\")\n  }\n}\n\n\nAstrocyte and Inhibitory (Little correlation)\n\n#subset the data to only look at sample ID 0.01\nsub_2CT = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"Astrocyte\",\"Inhibitory\")]\n#sub = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"Astrocyte\", \"Pericytes\")]\n(pp_2CT = .ppp(sub_2CT, marks = \"cluster_id\"))\n\nMarked planar point pattern: 2611 points\nmarks are of storage type  'character'\nwindow: rectangle = [1222.5635, 3012.4248] x [-3990.104, -2204.671] units\n\n\n\nsptl_correlogram = correlog(x = pp_2CT$x, y = pp_2CT$y, z = ifelse(pp_2CT$marks == \"Astrocyte\", 0 , 1), increment = 10, resamp = 50)\n\n\n#' {correlation}{the value for the Moran (or Mantel) similarity.}\n#' {mean.of.class}{the actual average of the distances within each distance class.}\n#' {nlok}{the number of pairs within each distance class.}\n#' {x.intercept}{the interpolate x.intercept of Epperson (1993).}\n#' {p}{the permutation p-value for each distance-class.}\n#' {corr0}{If a cross-correlogram is calculated, corr0 gives the empirical within-patch cross-correlation.}\n\nplot.correlog(sptl_correlogram) \n\n\n\n\n\n\nOD Mature and Excitatory (Bigger correlation)\n\n#subset the data to only look at sample ID 0.01\nsub_2CT = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"OD Mature\",\"Excitatory\")]\n#sub = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"Astrocyte\", \"Pericytes\")]\n(pp_2CT = .ppp(sub_2CT, marks = \"cluster_id\"))\n\nMarked planar point pattern: 1637 points\nmarks are of storage type  'character'\nwindow: rectangle = [1227.0107, 3008.1897] x [-3973.478, -2204.314] units\n\n\n\nsptl_correlogram = correlog(x = pp_2CT$x, y = pp_2CT$y, z = ifelse(pp_2CT$marks == \"OD Mature\", 0 , 1), increment = 10, resamp = 50)\n\n\n#' {correlation}{the value for the Moran (or Mantel) similarity.}\n#' {mean.of.class}{the actual average of the distances within each distance class.}\n#' {nlok}{the number of pairs within each distance class.}\n#' {x.intercept}{the interpolate x.intercept of Epperson (1993).}\n#' {p}{the permutation p-value for each distance-class.}\n#' {corr0}{If a cross-correlogram is calculated, corr0 gives the empirical within-patch cross-correlation.}\n\nplot.correlog(sptl_correlogram)"
  },
  {
    "objectID": "03-contmarked.html#irregular-lattice-and-neighbourhood-matrix",
    "href": "03-contmarked.html#irregular-lattice-and-neighbourhood-matrix",
    "title": "Preamble",
    "section": "Irregular lattice and neighbourhood matrix",
    "text": "Irregular lattice and neighbourhood matrix\nMost analysis techniques rely on the a neighborhood matrix, which is a matrix that indicates which cells are neighbors. In the case of the regular lattice, the calculation of the neighborhood matrix is rather straightforward. In the case of the irregular lattice it can be more complicated as the reconstruction of the cells is often not perfect."
  },
  {
    "objectID": "03-contmarked.html#neighbourhood-matrix",
    "href": "03-contmarked.html#neighbourhood-matrix",
    "title": "Preamble",
    "section": "Neighbourhood matrix",
    "text": "Neighbourhood matrix\n\ncolGraph(sfe, \"knn5\") &lt;- findSpatialNeighbors(sfe, method = \"knearneigh\",\n                                                  dist_type = \"idw\", k = 5, \n                                                  style = \"W\")"
  },
  {
    "objectID": "03-contmarked.html#implementation-using-voyager",
    "href": "03-contmarked.html#implementation-using-voyager",
    "title": "Preamble",
    "section": "Implementation using voyager",
    "text": "Implementation using voyager\n\nfeatures_use &lt;- c(\"nGenes\")\nsfe &lt;- colDataMoransI(sfe, features_use, colGraphName = \"knn5\")\n\ncolFeatureData(sfe)[features_use,]\n\nDataFrame with 1 row and 2 columns\n       moran_sample01 K_sample01\n            &lt;numeric&gt;  &lt;numeric&gt;\nnGenes       0.434643    3.19599\n\nsfe &lt;- colDataUnivariate(sfe, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"knn5\", nsim = 200,\n                                type = \"moran.mc\")\nres &lt;- colFeatureData(sfe)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$moran.mc_statistic_sample01\n\n[1] 0.3866512 0.4346431\n\n#p-value\nres$moran.mc_p.value_sample01\n\n[1] 0.004975124 0.004975124"
  },
  {
    "objectID": "03-contmarked.html#implementation-using-spdep",
    "href": "03-contmarked.html#implementation-using-spdep",
    "title": "Preamble",
    "section": "Implementation using spdep",
    "text": "Implementation using spdep\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe, \"knn5\")\nspdep::moran.test(x = sfe$nGenes, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe$nGenes  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 215.54, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     4.346431e-01     -9.990609e-06      4.066653e-06 \n\nspdep::moran.test(x = sfe$nCounts, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe$nCounts  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 191.74, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     3.866512e-01     -9.990609e-06      4.066653e-06"
  },
  {
    "objectID": "03-contmarked.html#implementation-using-voyager-1",
    "href": "03-contmarked.html#implementation-using-voyager-1",
    "title": "Preamble",
    "section": "Implementation using voyager",
    "text": "Implementation using voyager\n\nfeatures_use &lt;- c(\"nGenes\")\nsfe &lt;- colDataMoransI(sfe, features_use, colGraphName = \"knn5\")\n\ncolFeatureData(sfe)[features_use,]\n\nDataFrame with 1 row and 8 columns\n       moran_sample01 K_sample01 moran.mc_statistic_sample01\n            &lt;numeric&gt;  &lt;numeric&gt;                   &lt;numeric&gt;\nnGenes       0.434643    3.19599                    0.434643\n       moran.mc_parameter_sample01 moran.mc_p.value_sample01\n                         &lt;numeric&gt;                 &lt;numeric&gt;\nnGenes                         201                0.00497512\n       moran.mc_alternative_sample01 moran.mc_method_sample01\n                         &lt;character&gt;              &lt;character&gt;\nnGenes                       greater   Monte-Carlo simulati..\n                      moran.mc_res_sample01\n                                     &lt;list&gt;\nnGenes 0.00138187,0.00307290,0.00365525,...\n\nsfe &lt;- colDataUnivariate(sfe, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"knn5\", nsim = 200,\n                                type = \"geary.mc\")\nres &lt;- colFeatureData(sfe)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$geary.mc_statistic_sample01\n\n[1] 0.5758033 0.5447334\n\n#p-value\nres$geary.mc_p.value_sample01\n\n[1] 0.004975124 0.004975124"
  },
  {
    "objectID": "03-contmarked.html#implementation-using-spdep-1",
    "href": "03-contmarked.html#implementation-using-spdep-1",
    "title": "Preamble",
    "section": "Implementation using spdep",
    "text": "Implementation using spdep\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe, \"knn5\")\nspdep::geary.test(x = sfe$nGenes, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe$nGenes \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 215.64, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     5.447334e-01      1.000000e+00      4.457425e-06 \n\nspdep::geary.test(x = sfe$nCounts, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe$nCounts \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 187.83, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     5.758033e-01      1.000000e+00      5.100209e-06"
  },
  {
    "objectID": "02-between-marks.html#dependencies",
    "href": "02-between-marks.html#dependencies",
    "title": "Discrete Marks",
    "section": "",
    "text": "source(\"utils.R\")"
  },
  {
    "objectID": "02-between-marks.html#setup",
    "href": "02-between-marks.html#setup",
    "title": "Discrete Marks",
    "section": "",
    "text": "spe &lt;- readRDS(\"../data/spe.rds\")"
  },
  {
    "objectID": "02-between-marks.html#spatial-proximity",
    "href": "02-between-marks.html#spatial-proximity",
    "title": "Discrete Marks",
    "section": "Spatial Proximity",
    "text": "Spatial Proximity\nIndex of Spatial Proximity developed by White (1983) [White, M. J. (1983). The measurement of spatial segregation. The American Journal of Sociology, 88, 1008-1018.].\n\nThis numerical value indicates the degree of segregation. A value of 1 indicates evenness in the sample, and values greater than 1.0 indicate clustering. If the index value is smaller than one, it indicates an unusual form of segregation (i.e., some groups are closer to other groups). It compares the average distance between members of one group with that between all individuals, irrespective of group assignment. It may change depend on the definition of distance.\n\n\n# Index of spatial proximity\npaste0('Index of spatial proximity: ',\nisp(pp_sel,\n    data = model.matrix))\n\n[1] \"Index of spatial proximity: 2.94890271873706\""
  },
  {
    "objectID": "02-between-marks.html#distances-and-nearest-neighbors",
    "href": "02-between-marks.html#distances-and-nearest-neighbors",
    "title": "Discrete Marks",
    "section": "Distances and nearest neighbors",
    "text": "Distances and nearest neighbors\nInvestigating the nearest neighbor distance between point for all combinations of marks can be done as follows:\n\nd &lt;- nndist(pp_sel,by = marks(pp_sel))\na &lt;- aggregate(d,by = list(from=marks(pp_sel)),min)\na\n\n       from Ependymal Microglia OD Mature\n1 Ependymal  3.225180  8.176169 12.959456\n2 Microglia  8.176169 16.443565  6.215464\n3 OD Mature 12.959456  6.215464  6.428006"
  },
  {
    "objectID": "02-between-marks.html#nearest-neighbor-correlations",
    "href": "02-between-marks.html#nearest-neighbor-correlations",
    "title": "Discrete Marks",
    "section": "Nearest neighbor correlations",
    "text": "Nearest neighbor correlations\nA overall correlation between marks can be calculated with nncorr. It returns two values: unnormalised, which is the probability that a point and its nearest neighbor have the same type and normalised, which divides the unnormalised probability by the probability of random labeling. So a value close to 1 indicates random labeling. A value much larger than 1 means neighboring point are often of the same type.\n\nnncorr(pp_sel)\n\nunnormalised   normalised \n   0.8081321    1.8823711 \n\n\n\nAnother possibility is to work with nearest neighborhood contingency tables to do statistical tests using the dixon function from the R package dixon. It allows to calculate the statistic “segregation of species” S which indicates either random labeling (if S=0), attraction (if S&lt;0) or seggregation (if S&gt;0).\n\n\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\n\n       From        To     Obs.Count     Exp. Count    S      Z    p-val.Z\n1 Ependymal Ependymal           262          87.16  1.96  20.04    0.0000\n2 Ependymal Microglia             3          31.66 -1.07  -5.66    0.0000\n3 Ependymal OD Mature             3         149.18 -2.04 -16.87    0.0000\n4 Microglia Ependymal             9          31.66 -0.68  -4.92    0.0000\n5 Microglia Microglia            21          11.34  0.32   2.50    0.0124\n6 Microglia OD Mature            67          53.99  0.25   2.60    0.0094\n7 OD Mature Ependymal             8         149.18 -1.43 -14.26    0.0000\n8 OD Mature Microglia            69          53.99  0.12   2.35    0.0190\n9 OD Mature OD Mature           380         253.83  0.60  11.43    0.0000\n    p-val.Nobs\n1         0.01\n2         0.01\n3         0.01\n4         0.01\n5         0.02\n6         0.01\n7         0.01\n8         0.11\n9         0.01"
  },
  {
    "objectID": "02-between-marks.html#summary-functions-for-pairs-of-types",
    "href": "02-between-marks.html#summary-functions-for-pairs-of-types",
    "title": "Discrete Marks",
    "section": "Summary functions for pairs of types",
    "text": "Summary functions for pairs of types\n\n\n\n\n\nSimilar to the simple case without marks it is possible do estimate summary functions. More specifically the summary functions between different marks can be calculated. These summary functions assume that the multitype process is stationary which might not be an appropriate assumption in spatial omcis data, we therefore use inhomogeneous versions of the summary functions.\n\nCross K-function\nThe cross K-function is a summary function that measures the average number of points of type j within a distance r of a point of type i. The formula is given by\n\\[\nK(r) = \\frac{1}{\\lambda_j} \\mathbb{E} [t(u,r,X^{j})|u \\in X^{i}]\n\\]\nwhere \\(X^{i}\\) is the point pattern of type \\(i\\) and \\(t(u,r,X^{j})\\) is the number of points of type \\(j\\) in a circle of radius \\(r\\) around \\(u\\).\nFirst we plot an overview over the cross K function for the different types.\n\nplotCrossAll(pp_sel, \"Kcross.inhom\", \"iso\")\n\n\n\n\nThe diagonal of the cross K-function plot shows the K-function for the different marks (indication of Poisson or non-Poisson point processes). Off-diagonal panels give indication of independence of points when the number of points follows the expected K-function but does not imply that the individual marks follow a Poisson process. If the types are independent they are also uncorrelated.\nIn this overview we can see that there is indication that Microglia and OD Mature cells are independent of each other. The other types seem to be dependent on each other. Let’s focus a bit more on the relationship between Ependymal and the other two cell types. We will also calculate confidence intervals for the different cross K-functions.\nHowever, it is important to remember that the cross K-function assumes that the multitype process is stationary. If this is not the case, there is a risk in misinterpreting the results. The problem is confounding between clustering and inhomogeneity. We have already seen that our dataset most likely does not follow the assumption of stationarity. For this reason we will calculate the inhomogneous cross K-function.\n\n# fig-width: 10\n# fig-height: 10\np_epen_od + p_epend_micro\n\n\n\n\nRemember that the dashed line represents the assumption of a multitype Poisson process. If the line lies above the dotted line there is indication of clustering while if the line is below the dotted line there is indication of repulsion. In the plot above we can see that there is indication of clustering between Ependymal and OD Mature cells while there is indication of repulsion between Ependymal and Microglia cells.\n\n\nCross L-function\nAlternatively the L cross function with similar interpreation can be calculated using the Lcross function.\n\n# fig-width: 10\n# fig-height: 10\np_epen_od + p_epend_micro\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMark connection function\nThe mark connection function is essentially the cross pair-correlation function, i.e. the generalization of the of the pair correlation function to multitpye point processes, divided by the unmarked pair-correlation function. It can be interpreted as the conditional probability that two points a distance r apart have labels of type 1 and of type 2, given the presence of those points.\n\nplotCrossAll(pp_sel, \"markconnect\", \"iso\") + scale_y_continuous(limits = c(0, 1))\n\n\n\n\nThe dashed lines indicate expected values under random labeling. The values measures dependence or association between the different points. Positive values indicate that nearby points are more likely to have different types than expected by chance. This positive association between different cell types does not necessarily imply dependence, as it could be influenced by a negative association between cells of the same type, as it is the case for the Microglia cells.\n\n\nCross F-function (empty space function), cross G-function (Nearest-neighbor function) and cross J-function\nThe cross F-function is the cumulative distribution function of the distance from a location to the nearest point of the same type. For each type \\(i\\) it is defined as\n\\[F_i(r) = \\mathbb{P}\\{d(u,X^{i}\\leq r\\}\\].\nThe cross G-function is the cumulative distribution function of the distance from a location to the nearest point of another type and is defined as\n\\[G_{ij}(r) = \\mathbb{P}\\{d(x,X^{(j)} \\setminus u \\leq r \\mid X^{(i)} \\ \\text{has a point at u})\\].\nIf the points are independent of each other the G and F function are identical. Both assume that the process is stationary.\nThere exists a difference in the interpretation of the theoretical values of the K-cross and the G-cross function. For the K-cross the theoretical value indicates independence between the marks while for the G-cross the theoretical value is consistent with the assumption that the points of type j are Poisson in addition to being independent of the points of type \\(i\\).\nThe cross J-function is defined as\n\\[J_{ij}(r) = \\frac{1-G_{ij}(r)}{1-F_{j}(r)}\\]\nand summarizes the interpoint dependence between type \\(i\\) and \\(j\\). Under the hypothesis of independent components, i.e. that the point processes of each type are independent the G-function is equivalent to the F-function and the J-function is equal to 1.\n\n\n\n\n\n\n\n\n\n\nDot functions\nFor each K-, G- and J- function there also exist dot functions which is measuring distances from points of one type to points of any type. These functions allow us to measure the dependence of one mark with all other marks. For expample, the K-dot function represents the expected number of other point within distance \\(r\\) of a typical point of type \\(i\\).\n\nplotCrossAll(pp_sel, \"Kdot.inhom\", \"iso\")\n\n\n\n\nThe dot functions are useful summary statistic to analyse the dependence of one mark with all other marks."
  },
  {
    "objectID": "02-between-marks.html#summary-function-within-and-between-types",
    "href": "02-between-marks.html#summary-function-within-and-between-types",
    "title": "Discrete Marks",
    "section": "Summary function within and between types",
    "text": "Summary function within and between types\nIn our original dataset we have a large number of different marks. We picked the three OD mature, Ependymal and Microglia for illustrative purposes. An alternative to looking at all cross summary function combinations, it is possible to compare between and within types. An alternative is to compare within and between types.\n\nMark equality function\nThe Mark or Type Equality function for a stationary multitype point process measures the correlation between types of two points separated by distance r. It is the sum of the mark connection function of all pairs of points of the same type.\nIf k &lt; 1, points at distance r are less likely than expected to be of the same type. If &gt; 1, they are more likely to be of the same type. The value 1 indicates a lack of correlation.\n\nplotMarkCorr &lt;- function(pp, edgecorr = \"iso\") {\n    me &lt;- markcorr(pp)\n    ggplot(me, aes(x = r, y = .data[[edgecorr]])) +\n        geom_line(size = 1) +\n        geom_line(aes(x = r, y = theo), linetype = \"dotted\", size = 1) +\n        geom_line() +\n        labs(title = attributes(me)$yexp) +\n        theme_minimal()\n}\n\nplotMarkCorr(pp)\n\n\n\n\nWe can see that in our dataset, it is closer, the more likely it is to find points of the same type."
  },
  {
    "objectID": "02-between-marks.html#testing-random-labelling",
    "href": "02-between-marks.html#testing-random-labelling",
    "title": "Discrete Marks",
    "section": "Testing random labelling",
    "text": "Testing random labelling\nRandom labeling test is most logical when the marks represents its status, which is not most appropriate assumption when considering cell types. Test for random labeling can be done using permutation test, in which the labels are randomly permuted. Random labeling can be assumed if the permuted datasets are statistically equivalent to the original dataset."
  },
  {
    "objectID": "02-between-marks.html#testing-the-indepenence-of-components-assumption",
    "href": "02-between-marks.html#testing-the-indepenence-of-components-assumption",
    "title": "Discrete Marks",
    "section": "Testing the indepenence of components assumption",
    "text": "Testing the indepenence of components assumption\nThe i to j functions are useful to test the independence of different subprocesses. If the processes of type i and j are independent then \\(K_{ij} = \\pi r^2, G_{ij}(r) = F_{j}(r), J_{ij}(r) \\equiv 1\\). Alternatively, randomization tests can be used in which simulated patterns from the dataset are generated and randomly split into subpatterns. These are then compared to the null hypothesis in which all subpatterns should be statistically equivalent to the original. However, this approach assumes stationarity and there is a need to handle edge effects appearing from random shifts when splitting.\n\npEnv\n\n\n\n\n\nplotEnvCross(pp_sel, fun = \"Kcross\", \"Ependymal\", \"OD Mature\", nsim = 39, radius = 150, global = TRUE)\n\nGenerating 78 simulations by evaluating expression (39 to estimate the mean and \n39 to calculate envelopes) ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, \n78.\n\nDone.\n\n\n\n\n\nWe have indication that the indepence of components assumption should not be rejected. Therefore we assume that Ependtymal and OD Mature cells are independent."
  },
  {
    "objectID": "02-between-marks.html#setup-1",
    "href": "02-between-marks.html#setup-1",
    "title": "Discrete Marks",
    "section": "Setup",
    "text": "Setup\n\n#subset the data to only look at sample ID 0.01\nsub = spe[, spe$sample_id == 0.01]\n#sub = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"Astrocyte\", \"Pericytes\")]\n(pp = .ppp(sub, marks = \"cluster_id\"))\n\nMarked planar point pattern: 6111 points\nmarks are of storage type  'character'\nwindow: rectangle = [1222.5635, 3012.4248] x [-3993.535, -2202.755] units\n\n#subset the data to only look at sample ID 0.01\nsub_2CT = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"Astrocyte\", \"Inhibitory\")]\n#sub = spe[, spe$sample_id == 0.01 & spe$cluster_id %in% c(\"Astrocyte\", \"Pericytes\")]\n(pp_2CT = .ppp(sub_2CT, marks = \"cluster_id\"))\n\nMarked planar point pattern: 2611 points\nmarks are of storage type  'character'\nwindow: rectangle = [1222.5635, 3012.4248] x [-3990.104, -2204.671] units\n\n#split the multitype point process into several single type processes\n#fist, set the marks of the point process to be factors\nmarks(pp) = factor(marks(pp))\nppls = split(pp)\n\n\nplot(ppls)"
  },
  {
    "objectID": "02-between-marks.html#summary-functions",
    "href": "02-between-marks.html#summary-functions",
    "title": "Discrete Marks",
    "section": "Summary functions",
    "text": "Summary functions\nAs in the discrete case the summary functions assume that the point process is stationary.\n\nMark correlation function\nThe mark correlation function measures the dependence between the marks at two points at distance \\(r\\). It is not a correlation in the classical sense, since it can take any nonegative value. The value of 1 indicates no correlation between the marks. The generalized mark correlation function is given by\n\\[ k_f(r) = \\frac{\\mathbb{E}[f(m(u)m(v))]}{\\mathbb{E}[f(M,M')]}\\] where \\(f(m_1,m_2)\\) is a test function with two arguments that represent the marks and returns a non-negative value. For continuous non-negative marks the choice of \\(f\\) is by default \\(f(m_1,m_2)= m_1 m_2\\). \\(M, M′\\) represent independent, identically distributed random points with same distribution as the mark of a randomly chosen point. This denominator is chosen such that random marks have a mark correlation of 1.\n\nplot(markcorr(pp))\n\n\n\n\nWe can compare the mark correlation function to a pointwise simulation envelope in which we generate 5 simulations of random labeling.\n\nppEsr1 &lt;- subset(pp, select = 'Esr1')\nmarkcorr.Esr1 &lt;- envelope(ppEsr1, markcorr, nsim=10)\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\nplot(markcorr.Esr1)\n\n\n\n\nThe plot indicates that the mark correlation function is significantly different from the random case. The positive association of expression of the Esr1 gene declines with distance. This is consistent with clustering we saw in the residual plot above."
  },
  {
    "objectID": "02-between-marks.html#irregular-lattice-and-neighbourhood-matrix",
    "href": "02-between-marks.html#irregular-lattice-and-neighbourhood-matrix",
    "title": "Discrete Marks",
    "section": "Irregular lattice and neighbourhood matrix",
    "text": "Irregular lattice and neighbourhood matrix\nMost analysis techniques rely on the a neighborhood matrix, which is a matrix that indicates which cells are neighbors. In the case of the regular lattice, the calculation of the neighborhood matrix is rather straightforward. In the case of the irregular lattice it can be more complicated as the reconstruction of the cells is often not perfect."
  },
  {
    "objectID": "02-between-marks.html#neighbourhood-matrix",
    "href": "02-between-marks.html#neighbourhood-matrix",
    "title": "Discrete Marks",
    "section": "Neighbourhood matrix",
    "text": "Neighbourhood matrix\n\ncolGraph(sfe, \"knn5\") &lt;- findSpatialNeighbors(sfe, method = \"knearneigh\",\n                                                  dist_type = \"idw\", k = 5, \n                                                  style = \"W\")"
  },
  {
    "objectID": "02-between-marks.html#implementation-using-voyager",
    "href": "02-between-marks.html#implementation-using-voyager",
    "title": "Discrete Marks",
    "section": "Implementation using voyager",
    "text": "Implementation using voyager\n\nfeatures_use &lt;- c(\"nGenes\")\nsfe &lt;- colDataMoransI(sfe, features_use, colGraphName = \"knn5\")\n\ncolFeatureData(sfe)[features_use,]\n\nDataFrame with 1 row and 2 columns\n       moran_sample01 K_sample01\n            &lt;numeric&gt;  &lt;numeric&gt;\nnGenes       0.434643    3.19599\n\nsfe &lt;- colDataUnivariate(sfe, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"knn5\", nsim = 200,\n                                type = \"moran.mc\")\nres &lt;- colFeatureData(sfe)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$moran.mc_statistic_sample01\n\n[1] 0.3866558 0.4346428\n\n#p-value\nres$moran.mc_p.value_sample01\n\n[1] 0.004975124 0.004975124"
  },
  {
    "objectID": "02-between-marks.html#implementation-using-spdep",
    "href": "02-between-marks.html#implementation-using-spdep",
    "title": "Discrete Marks",
    "section": "Implementation using spdep",
    "text": "Implementation using spdep\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe, \"knn5\")\nspdep::moran.test(x = sfe$nGenes, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe$nGenes  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 215.54, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     4.346428e-01     -9.990609e-06      4.066635e-06 \n\nspdep::moran.test(x = sfe$nCounts, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe$nCounts  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 191.74, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     3.866558e-01     -9.990609e-06      4.066635e-06"
  },
  {
    "objectID": "02-between-marks.html#implementation-using-voyager-1",
    "href": "02-between-marks.html#implementation-using-voyager-1",
    "title": "Discrete Marks",
    "section": "Implementation using voyager",
    "text": "Implementation using voyager\n\nfeatures_use &lt;- c(\"nGenes\")\nsfe &lt;- colDataMoransI(sfe, features_use, colGraphName = \"knn5\")\n\ncolFeatureData(sfe)[features_use,]\n\nDataFrame with 1 row and 8 columns\n       moran_sample01 K_sample01 moran.mc_statistic_sample01\n            &lt;numeric&gt;  &lt;numeric&gt;                   &lt;numeric&gt;\nnGenes       0.434643    3.19599                    0.434643\n       moran.mc_parameter_sample01 moran.mc_p.value_sample01\n                         &lt;numeric&gt;                 &lt;numeric&gt;\nnGenes                         201                0.00497512\n       moran.mc_alternative_sample01 moran.mc_method_sample01\n                         &lt;character&gt;              &lt;character&gt;\nnGenes                       greater   Monte-Carlo simulati..\n                      moran.mc_res_sample01\n                                     &lt;list&gt;\nnGenes 0.00138126,0.00305603,0.00366659,...\n\nsfe &lt;- colDataUnivariate(sfe, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"knn5\", nsim = 200,\n                                type = \"geary.mc\")\nres &lt;- colFeatureData(sfe)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$geary.mc_statistic_sample01\n\n[1] 0.5758085 0.5447379\n\n#p-value\nres$geary.mc_p.value_sample01\n\n[1] 0.004975124 0.004975124"
  },
  {
    "objectID": "02-between-marks.html#implementation-using-spdep-1",
    "href": "02-between-marks.html#implementation-using-spdep-1",
    "title": "Discrete Marks",
    "section": "Implementation using spdep",
    "text": "Implementation using spdep\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe, \"knn5\")\nspdep::geary.test(x = sfe$nGenes, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe$nGenes \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 215.64, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     5.447379e-01      1.000000e+00      4.457373e-06 \n\nspdep::geary.test(x = sfe$nCounts, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe$nCounts \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 187.83, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     5.758085e-01      1.000000e+00      5.100101e-06"
  },
  {
    "objectID": "02-between-marks.html#session-info",
    "href": "02-between-marks.html#session-info",
    "title": "Discrete Marks",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] stringr_1.5.0                  dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.9.4                  SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-14                     \n[17] reshape2_1.4.4                 patchwork_1.1.3               \n[19] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[21] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[23] dbplyr_2.3.4                   RANN_2.6.1                    \n[25] seg_0.5-7                      sp_2.1-1                      \n[27] rlang_1.1.1                    ggplot2_3.4.4                 \n[29] dplyr_1.1.3                    mixR_0.2.0                    \n[31] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[33] spatstat.model_3.2-6           rpart_4.1.19                  \n[35] spatstat.explore_3.2-3         nlme_3.1-162                  \n[37] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[39] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[41] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[43] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[45] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[47] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[49] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.2.1                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] fftwtools_0.9-11              spatstat.utils_3.0-3         \n [87] rmarkdown_2.25                XVector_0.40.0               \n [89] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [91] base64enc_0.1-3               sparseMatrixStats_1.12.2     \n [93] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [95] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [97] farver_2.1.1                  jsonlite_1.8.7               \n [99] BiocParallel_1.34.2           R.oo_1.25.0                  \n[101] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[103] magrittr_2.0.3                GenomeInfoDbData_1.2.10      \n[105] s2_1.1.4                      Rhdf5lib_1.22.1              \n[107] munsell_0.5.0                 Rcpp_1.0.11                  \n[109] ggnewscale_0.4.9              viridis_0.6.4                \n[111] stringi_1.7.12                leafsync_0.1.0               \n[113] zlibbioc_1.46.0               plyr_1.8.9                   \n[115] parallel_4.3.1                ggrepel_0.9.4                \n[117] deldir_1.0-9                  Biostrings_2.68.1            \n[119] stars_0.6-4                   splines_4.3.1                \n[121] tensor_1.5                    locfit_1.5-9.8               \n[123] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[125] BiocVersion_3.17.1            XML_3.99-0.14                \n[127] evaluate_0.22                 BiocManager_1.30.22          \n[129] httpuv_1.6.11                 purrr_1.0.2                  \n[131] polyclip_1.10-6               rsvd_1.0.5                   \n[133] lwgeom_0.2-13                 xtable_1.8-4                 \n[135] e1071_1.7-13                  RSpectra_0.16-1              \n[137] later_1.3.1                   viridisLite_0.4.2            \n[139] class_7.3-22                  tibble_3.2.1                 \n[141] memoise_2.0.1                 beeswarm_0.4.0               \n[143] AnnotationDbi_1.62.2          cluster_2.1.4"
  },
  {
    "objectID": "01-within-marks.html",
    "href": "01-within-marks.html",
    "title": "Discrete Marks",
    "section": "",
    "text": "Code\nsource(\"utils.R\")\n\n\n\n\n\n\n\nCode\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#subset the data to only look at sample ID 0.01, 0.06 and 0.26\n# list(\"-0.29\", \"0.01\", \"0.06\")\n#zstack_list &lt;- list(\"-0.04\", '-0.09', '-0.14', '-0.19', '-0.24', '-0.29', '0.01', '0.06', '0.11', '0.16', '0.21', \"0.26\")\n\n#define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n\n#define the celltype that you want to compare across the stacks - hereby we assume independence across the z-stacks which is an assumption that can be challenged\ncelltype_ls &lt;- \"OD Mature\"\n\nselectZstacks &lt;- function(zstack, spe){\n  sub &lt;- spe[, spe$sample_id == zstack]\n  pp &lt;- .ppp(sub, marks = \"cluster_id\")\n  return(pp)\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe)\nnames(pp_ls) &lt;- zstack_list\n\n\nThe theory of spatial point patterns is discussed in great detail in (Baddeley, Rubak, and Turner 2015). The book has an accompanying package called spatstat which offers great functionality to the theoretical concepts discribed in the book (Baddeley and Turner 2005). This chapter relies heavily on both publications.\n\n\n\n\n\nIn point pattern analysis we assume that the patterns we observe are a realisation of a stochastic process called a point process. The inferences we make about the point pattern are based on the point process. E.g. the pattern can be said to be created by a poisson point process and thus is evenly distributed in the observation window (Baddeley, Rubak, and Turner 2015, 127).\nWhen considering a pattern with \\(m\\) multiple types, as we do in the (Moffitt et al. 2018) dataset, there are two very closely related concepts. One can view the pattern as a multitype point pattern, where all the points are sampled from the same point process. The other option is to consider the pattern as a multivariate point pattern, where the points come from \\(m\\) distinct point processes. The difference between these two views is that in the multitype framework we assume the points to stem from the same point process and thus depend on each other. In the multivariate framework we assume that the types stem from independent point processes and therefore we can consider dependencies of one type alone. Whether or not the underlying point processes are independent depends on the biological question. If we analyse two celltypes in one slice of a tissue, we should consider them as being sampled from one point process. However, if we consider the distribution of a celltype in two slices of the same tissue we can have grounds to consider the point processes as independent (Baddeley, Rubak, and Turner 2015, 565).\n\n\n\nThe most common set up in point pattern analysis is what we call window sampling. Instead of observing the entire pattern we observe a subset of this pattern in the so called window. In the analysis we try to make inference on the entire point process based on the observed window. An example could be different small microscopy windows through which a big tissue slice is observed. The windows would be samples of the bigger point process. In this case, it would be wrong to assume the window to be the convex hull around the observed points because they are just a sample of the bigger point pattern (Baddeley, Rubak, and Turner 2015, 144–45).\nThere is another concept called the small world model. It assumes that points can only be observed in a finite small world and not beyond these boundaries. When thinking of an entire tissue, this is a very common scenario. Cells can only be observed within the tissue and not beyond. In this case, it would be correct to not assume a rectangular observation window but to use more conservative methods to estimate an unknown sampling window such as the Ripley-Rasson estimate of a spatial domain (Baddeley, Rubak, and Turner 2015, 144–45).\nIn both cases it is important to understand the direction of the bias. If the unknown window is estimated to be smaller than the true window, we underestimate the window. This then again leads to an overestimation of the density of points and to other characteristics of the pattern. Therefore, an underestimation of the window size is more concerning than a slight overestimation (Baddeley, Rubak, and Turner 2015, 144–45).\n\n\nCode\nsetRiprasWindows &lt;- function(pp){\n  Window(pp) &lt;- ripras(pp)\n  marks(pp) &lt;- factor(marks(pp))\n  return(pp)\n}\n#the entire point patterns with the ripras windows\npp &lt;- lapply(pp_ls, setRiprasWindows)\n\nseparateMarks &lt;- function(pp){\n  #split the multitype point process into several single type processes\n  ppls &lt;- split(pp)\n  return (ppls)\n}\n#the point patterns separated by their marks\npp_ls &lt;- lapply(pp, separateMarks)\n\n\n\n\n\nComplete spatial randomness (CSR) is often used as the null model for various point patterns, and is the result of a Poisson process. A completely spatial random process is characterised by two properties, homogeneity and independence, as discussed below (Baddeley, Rubak, and Turner 2015, 132).\n\n\n“Homogeneity […] means that the expected number of points falling in a region B should be proportional to its area |B|” (Baddeley, Rubak, and Turner 2015, 132) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) represents the intensity of the process, i.e., the average number of points in a unit area (Baddeley, Rubak, and Turner 2015, 132–33). :\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|.\n\\label{eq:expected_number_points}\n\\]\n\n\n\nIndependence implies that in two (non-overlapping) regions \\(A\\) and \\(B\\), the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are independent random variables. In other words, the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). In addition, the number of points, \\(N = n(X\\cap B)\\), follows a Poisson distribution:\n\\[\n\\mathbb{P}[N=k] = e^{-\\mu}\\frac{\\mu^k}{k!}\\\\\n\\label{eq:poisson_process}\n\\] where \\(k = \\lambda |B|\\) (Baddeley, Rubak, and Turner 2015, 133).\n\n\n\n\nA Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density, \\(\\lambda(u)\\), sometimes known as the intensity function (see below), is a function of spatial location \\(u\\). In this case, the expected number of points falling into a region \\(B\\), \\(\\mu = n(X\\cap B)\\), is an integration of the intensity function over that region (Baddeley, Rubak, and Turner 2015, 138).\n\\[\n\\mu = \\int_{B} \\lambda(u) du.\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\n\nA point process is called isotropic, if its statistical properties are invariant to rotations; a CSR process is both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 147).\n\n\n\n“A point process is called stationary if, when we view the process through a window W , its statistical properties do not depend on the location of the window in two-dimensional space” (Baddeley, Rubak, and Turner 2015, 146). This is the case for any homogeneous point process, where the statistical properties of the pattern are unchanged given shifting of the observation window. This means it is stationary in all statistical properties; first-order properties (e.g. intensity) and second-order properties (e.g. correlation) (Baddeley, Rubak, and Turner 2015, 218). Not all metrics assume stationarity in its full sense. Inhomogeneous metrics only assume second-order / correlation stationarity. That means while the intensity function can vary spatially (first-order stationarity is not given), the estimates of correlation functions (e.g. the inhomogeneous K-function) should be the same in parts of the window (Baddeley, Rubak, and Turner 2015, 689).\n\n\n\nIf a process is not correlation stationary, so the estimates of the inhomogeneous metric vary between locations, locally-scaled versions of the metric can be applicable. This means in small subregions, the process is still stationary and isotropic, but there is a rescaling factor that can vary across the total process (Baddeley, Rubak, and Turner 2015, 246–47).\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimated functions between the quadrats. It should be noted that this test depends on the arbitrary definition of the quadrats. Given our chosen patterns are not independent but result as marks from an overall point-pattern, the permutation approach is questionable. Furthermore, the outcome of the permutation test depends heavily on the choice of the quadrats. Therefore, the interpretation can be difficult (Baddeley, Rubak, and Turner 2015, 689–93).\n\n\nCode\npermutation_test &lt;- function(pp, mark, split, minpoints) {\n  pp_sel &lt;-  subset(pp, marks %in% mark, drop = TRUE)\n  \n  rho_est &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\n  lambda &lt;- predict(rho_est)\n\n  tesselation &lt;- quantess(unmark(pp_sel), \"x\", 3)\n  tesselation_split &lt;- nestsplit(pp_sel, tesselation, ny=split)\n  \n  plot(tesselation_split, main = mark)\n  \n  tesselation_split$inten &lt;- factor(as.integer(tesselation_split$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n  \n  res.scaled &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kscaled,\n                 minpoints = minpoints)\n  \n  res.inhom &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kinhom,\n                 lambda=lambda, minpoints = minpoints)\n  \n  #p-value of the local-scaling test\n  print(paste0(mark,' local scaling test ', res.scaled$p.value))\n  \n  #p-value of the inhomogeneity test\n  print(paste0(mark,' inhomogeneity test ', res.inhom$p.value))\n}\nlapply(c(\"Microglia\", \"OD Mature\", \"Ependymal\"), function(x) permutation_test(pp[['0.01']], x, split = 3, minpoints = 10))\n\n\nThe p-value of the test for local scaling for microglia cells is \\(&lt;0.05\\) which indicates that the assumption of local scaling is rejected. Therefore, the distribution of microglia cells is not a scaled version of an overall distribution pattern. The p-value of the test for inhomogeneity for both microglia cells is \\(&gt;0.05\\) indicating that the assumption of correlation stationarity is not rejected. In this case we can use the inhomogeneous version of the K-function which assumes correlation stationarity.\nFor ependymal and OD mature cells however, the p-values for both the local scaling test and the inhomogeneity test are \\(&gt;0.05\\) which means that both the correlation stationarity assumption and the local scaling assumption can’t be rejected. [ME: Does this make sense? Or is this just an artifact?]\nAs the interpretation of the permutation test is highly dependent on the quadrats, the results should be interpreted with care. Both inhomogeneous and locally scaled versions of the summary functions have support and both offer interesting insights into the spatial pattern. Therefore, we will compare all versions and show what the choice of metrics means for their interpretation.\n\n\n\nIntensity is the expected density of points per unit area. It can be interpreted as the rate of occurrence or the abundance of events recorded. The intensity represents a first order property because it is related to the expected number of points . More formally the average intensity of a point process is defined as:\n\\[\n\\bar{\\lambda} = \\frac{n(x)}{|W|}\n\\label{eq:average_intensity}\n\\]\nAs this is an average over the entire window, it only really makes sense for a homogeneous point process (Baddeley, Rubak, and Turner 2015, 157–60)\n\n\nFor a homogeneous point process, the intensity can be estimated in a simplistic way: summing the individual intensities of the marks (Baddeley, Rubak, and Turner 2015, 161).\n\n\nCode\nintensityPointProcess &lt;- function(pp,mark) if(mark) intensity(pp) else sum(intensity(pp))\n\nintensityPointProcess(pp_ls[['0.01']], mark = FALSE) %&gt;% round(6)\n\n\n[1] 0.001909\n\n\nOtherwise, we can compute the intensity for each mark individually.\n\n\nCode\nintensityPointProcess(pp_ls[['0.01']], mark = TRUE) %&gt;% round(8)\n\n\n  Ambiguous   Astrocyte Endothelial   Ependymal  Excitatory  Inhibitory \n 0.00024151  0.00020183  0.00014653  0.00008373  0.00036867  0.00061393 \n  Microglia OD Immature   OD Mature   Pericytes \n 0.00003031  0.00006249  0.00014278  0.00001750 \n\n\n\n\n\nIn kernel estimation, we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There are a wide variety of kernel estimators (see (Baddeley, Rubak, and Turner 2015, 168)), but a popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth (Baddeley, Rubak, and Turner 2015, 168).\n\n\nCode\npp_sel &lt;-  subset(pp_ls[['0.01']]$`OD Mature`, drop = TRUE)\nDens &lt;- density(pp_sel, sigma = 100)\nplot(Dens, main = 'Kernel Density (OD Mature cells)')\n\n\n\n\n\n\n\n\nIn quadrat counting, all points falling into a given quadrat are counted. This gives an overview on the characteristics of the point pattern, such as correlation stationarity (Baddeley, Rubak, and Turner 2015, 163).\n\n\nCode\nQ5 &lt;- quadratcount(pp_ls[['0.01']], nx=8, ny=8)\nplot(unmark(pp[['0.01']]), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\nUnder independence assumptions, the quadrat counts can be used for testing homogeneity, i.e., if the points are distributed evenly across the quadrats (Baddeley, Rubak, and Turner 2015, 164–65).\n\n\nCode\nval &lt;- quadrat.test(pp_ls[['0.01']]$`OD Mature`, 5, alternative=\"regular\", method=\"MonteCarlo\")\nval\n\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nX2 = 635.09, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 25 tiles (irregular windows)\n\n\nA p-value of 1 indicates that the null hypothesis of irregularity can not be rejected strongly. Thus, the point pattern of oligodendrocyts is strongly irregular.\nAlternatively, we can inspect departures from the hypothesis that points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types (Buller 2020).\n\n\nCode\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp[['0.01']], marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\n\nWhether or not a point process is completely spatially random (CSR) depends on two characteristics: points need to be distributed homogeneously and they have to be independent of each other (see definitions above). There are various ways to test for CSR, here we show the use-case of the clark-evans test (Baddeley, Rubak, and Turner 2015, 165–66).\n\n\nCode\nclarkevans.test(pp_ls[['0.01']]$`OD Mature`)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nR = 0.77286, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\n\nIn the following document we will often compare the distribution of mature oligodendrocytes (OD mature cells) across different z-slices of the same tissue. We assume these slices to be enough far away to be considered independent. Therefore, we assume that these patterns were generated independently by different point processes. Since we consider the dependence of one mark among itself, we are in a univariate setting per slide. We compare several univariate curves along different z-slices, which is in turn a multivariate comparison (Baddeley, Rubak, and Turner 2015, 565).\nIn our example dataset we analyse the mouse preoptic hypothalamus (Moffitt et al. 2018). This is a tissue of the mouse brain that is cut out of a bigger context. The lower boundary is the end of the tissue whereas the upper three boundaries are a technical boundary. Therefore, our example is a mixture between window sampling and the small world model. In order to decrease the bias of the tissue boarder, we use the Ripley-Rasson estimate of a spatial domain to estimate the sampling window.\n\n\nCode\npar(mfrow=c(1,3))\n#Plot the marks separately \nlapply(zstack_list, function(zstack){\n  plot(pp_ls[[zstack]][[celltype_ls]], main = zstack, legend = FALSE)\n})\n\n\n\n\n\n[[1]]\nSymbol map with constant values\ncols: #000000E4\n\n[[2]]\nSymbol map with constant values\ncols: #000000C2\n\n[[3]]\nSymbol map with constant values\ncols: #0000007B\n\n\nCode\ndev.off()\n\n\nnull device \n          1 \n\n\n\n\n\nCorrelation, or more generally covariance, represents a second-order summary statistic and measures dependence between data points (Baddeley, Rubak, and Turner 2015, 199).\n\n\n\n\nIn the framework of correlation analysis, we often look at distances \\(d_{ij} = ||x_i-x_j||\\) of all points. It is then natural to look at the summary of these distances, \\(d_{ij}\\), e.g. as a histogram. The histogram of this point process depends on the observation window \\(W\\), thus the histogram can change significantly with a different window. Therefore, we look at the empirical distribution function of the distances \\(d_{ij}\\) that are smaller or equal than a radius \\(r\\) (Baddeley, Rubak, and Turner 2015, 203)\nWhat we actually measure here is “the average number of r-neighbours of a typical random point” (Baddeley, Rubak, and Turner 2015, 204). This number is still dependent on the size of the observation window so we can standardise it by the number of points and the window size, \\(|W|\\). We then obtain the empirical Ripley’s \\(K\\) function (Baddeley, Rubak, and Turner 2015, 204):\n\\[\n\\hat{K}(r) = \\frac{|W|}{n(n-1)}\\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n\\{d_{ij}\\leq r\\} e_{ij}(r)\n\\]\nThe standardisation makes it possible to compare point patterns with different observation windows and with different numbers of points. However, using the empirical \\(K\\) function assumes though that the point process has homogeneous intensity, which is often not the case for biological tissue (Baddeley, Rubak, and Turner 2015, 204–5). We will return to this issue below in the Correcting for Inhomogeneity. The term \\(e_{ij}(r)\\) is for edge correction. We will briefly cover this in Edge effects and their corrections for spatial metrics\n\n\n\nEdge effects describe the phenomenon that not the entire point process is observed, but rather only the part within the window \\(W\\). This means the value of various statistics could be biased along the edges (Baddeley, Rubak, and Turner 2015, 213).\nThere are many corrections for edge effects that are briefly listed here (Baddeley, Rubak, and Turner 2015, 214–19):\nBorder correction:\nIn border correction the summation of data points is restricted to \\(x_i\\) for which \\(b(x_i,r)\\) is completely in the window \\(W\\).\nIsotropic correction:\nWe can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.\nTranslation correction:\nA stationary point process \\(X\\) is invariant to translations. So the entire point process can be shifted by a vector \\(s\\) to be at the position \\(X+s\\).\n\n\n\n\nThe \\(K\\)-function can be ``centered’’, which is then called the \\(L\\)-function. The \\(L\\)-function is a variance-stabilising version of the \\(K\\)-function (Canete et al. 2022):\n\\[\nL(r) = \\sqrt{\\frac{K(r)}{\\pi}}.\n\\]\n\n\n\nWe have seen above that the \\(K\\)-function is cumulative. That is, the contributions of all distances smaller equal to \\(r\\) are considered. An alternative is to take the derivative of the \\(K\\)-function in order to obtain contributions of distances between points equal to \\(r\\), according to:\n\\[\ng(r) = \\frac{K'(r)}{2\\pi r},\n\\]\nwhere \\(g(r)\\) is the derivative of the \\(K\\) function (so interactions at exactly \\(r\\)) divided by the probability of a poisson process at this radius (Baddeley, Rubak, and Turner 2015, 225).\n\n\nCode\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricRes &lt;- function(plot_by, pp, celltype, fun, bootstrap, continuous, f){\n  if(continuous){\n    pp &lt;- subset(pp, select = plot_by)\n  }\n  else{\n    pp_sel &lt;- pp[[plot_by]]\n    pp &lt;- subset(pp_sel, marks == celltype)\n  }\n  if(bootstrap){\n    metric.res &lt;- lohboot(pp, fun = fun, f = f)\n  }\n  else{\n    metric.res &lt;- do.call(fun, args = list(X=pp, f=f))\n  }\n  metric.res$type &lt;- celltype\n  metric.res$plot_by &lt;- plot_by\n  return(metric.res)\n}\n\n#PRE: celltypes, function to calculation and edge correction method\n#POST: dataframe of \nmetricResToDF &lt;- function(plot_by, celltype, pp, fun, edgecorr, bootstrap, continuous, f){\n  lapply(plot_by, function(u) {\n    metricRes(u, fun = fun, pp = pp, celltype = celltype, bootstrap, continuous, f)  %&gt;%\n      as.data.frame()\n  }) %&gt;% bind_rows\n}\n\n# [MR: try to write the above a little more compactly]\n\n#PRE: Celltypes of interest, function to analyse, edge correction to perform\n#POST: plot of the metric\nplotMetric &lt;- function(plot_by, pp, celltype = NULL, x, fun, edgecorr, bootstrap = FALSE, continuous = FALSE, f = NULL){\n  #calculate the metric and store as dataframe\n  res_df &lt;- metricResToDF(plot_by, celltype, pp, fun, edgecorr, bootstrap, continuous, f)\n  #plot the curves\n  p &lt;- ggplot(res_df, aes(x=.data[[x]], y=.data[[edgecorr]], col= (plot_by)))+\n      geom_line() +\n      {if(bootstrap)geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)}+\n      ggtitle(paste0(fun, '-function'))+\n      geom_line(aes(x=.data[[x]],y=theo),linetype = \"dashed\")+\n      ylab(edgecorr) +\n      # scale_color_manual(name='Point Processes',\n      #                  breaks=c('-0.29', '0.01',\n      #                           '0.06', 'Poisson'),\n      #                  values=c('-0.29'='red',\n      #                           '0.01'='dark green',\n      #                           '0.06'='blue', 'Poisson'='black'))+\n      theme_light()\n  \n  return(p)\n}\n\np_K &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Kest', 'iso', bootstrap = TRUE)\np_L &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Lest', 'iso', bootstrap = TRUE)\np_g &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'pcf', 'border', bootstrap = TRUE)\n\n\n\n\nCode\np_homo &lt;- wrap_plots(list(p_K,p_L,p_g), guides = 'collect')\np_homo\n\n\n\n\n\nAs we have seen above in the test for homogeneity in oligodendrocytes, the assumptions of homogeneity are not given in our data. Therefore, we will have to use the inhomogeneous alternatives (inhomogeneity correction and local scaling) of the metrics instead.\n\n\n\n\n\nIn the case that a spatial pattern is known or suspected to be inhomogeneous, we have to take this into account in the analysis. Biological point patterns display inhomogeneity very often, therefore this analysis is preferred over the homogeneous alternatives. Inhomogeneous alternatives can be estimated via: \n\\[\n\\hat{K}_{inhom}(r) = \\frac{1}{D^p|W|}\\sum_i\\sum_{j \\neq i} \\frac{\\mathbb{1}\\{||u-x_j||\\leq r\\}}{\\hat{\\lambda}(x_j)\\hat{\\lambda}(x_i)}e(x_j,x_i;r),\n\\]\nwhere \\(e(u,v;r)\\) is an edge correction weight and \\(\\hat{\\lambda}(x_i)\\) is an estimator of the intensity at point \\(x_i\\). The inhomogeneity correction happens via these \\(\\hat{\\lambda}(x_i)\\) per point \\(x_i\\). The estimation of these local intensities can happen in a data-dependent manner via kernel-smoothing. As this is the same data to then calculate the metric on, this can lead to biases. However, in the case where the local intensities are known, the inhomogeneous \\(K\\) function is an unbiased estimator (Baddeley, Rubak, and Turner 2015, 243–44).\n\n\nCode\np_K &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls,'r','Kinhom', 'iso', bootstrap = TRUE)\np_L &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls,'r', 'Linhom', 'iso', bootstrap = TRUE)\np_g &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls,'r', 'pcfinhom', 'border', bootstrap = TRUE)\n\n\n\n\nCode\np_inhomo &lt;- wrap_plots(list(p_K,p_L,p_g), guides = 'collect')\np_inhomo\n\n\n\n\n\nThe inhomogeneous \\(K\\)-function tells us that the microglia cells follow close to a Poisson process (dashed line) closely and can therefore be assumed to be randomly distributed and not clustered. Ependymal cells show a high degree of clustering at a low radius \\(r\\). OD mature cells exhibit a medium level of clustering.\nIn the \\(L\\)-function, the microglia cells are along the dashed Poisson line, indicating no clustering; ependymal cells are highly clustered at low values of \\(r\\), whereas OD mature show intermediate clustering.\nThe pair correlation function is the derivative of the \\(K\\)-function. The pcf plot gives similar information as before: microglia cells are around the dashed Poisson line. OD Mature cells show a rather broad range of correlations between \\(r \\in [20,100]\\). Ependymal cells have a very strong correlation at \\(\\sim r = 25\\).\nInterestingly, the curves for the inhomogeneous functions of ependymal cells and OD mature cells cross the poisson line at \\(r=300\\). This means that the inhomogeneous functions find repulsion of ependymal cells and OD mature cells past a radius of \\(r=300\\).\n\n\n\n\n\n\n\nIn the inhomogeneous \\(K\\)-function approach above, we assume that the intensities can vary locally but the scale of the point process is not changed. This means that while the intensities might vary in the parts of the point pattern, the pattern in one subquadrat is not just a scaled version of another subquadrat. In a biological sample, this assumption is easily violated, e.g. when a gradient of cells increases from one side to another [ME needs a reference]. The correlation structure might scale linearly with the distance (Baddeley, Rubak, and Turner 2015, 246–47) (Prokešová, Hahn, and Jensen 2006).\nTo circumvent this local scaling, we can assume that the process is subdivided into small regions. In these small regions, the point process is a scaled version of a template process. This template process needs to be both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 246–47).\n\n\n\nSince the \\(L\\)-function is simply a transformation of the \\(K\\)-function, the same local scaling framework can be applied to the \\(L\\)-function (Baddeley, Rubak, and Turner 2015, 246–47).\n\n\nCode\np_K &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Kscaled', 'iso', bootstrap = FALSE)\np_L &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Lscaled', 'iso', bootstrap = FALSE)\n#p_g &lt;- plotScaledMetric(zstack_list,celltype_ls, pp_ls, 'pcfscaled', 'iso')$p\n\n\n\n\nCode\np_scaled &lt;- wrap_plots(list(p_K, p_L), guides = 'collect')\np_scaled\n\n\n\n\n\nAs seen by our permutation tests we have grounds to believe that the patterns of ependymal and OD mature cells are locally scaled. Therefore, we will analyse this pattern using a locally scaled K and L function.\nWe see, that again our ependymal cells are very far from the poisson process line, indicating strong clustering among ependymal cells. The OD mature cells range in the middle showing intermediate clustering\n\n\nCode\nwrap_plots(list(p_homo, p_inhomo, p_scaled), nrow = 3, guides = 'collect')\n\n\n\n\n\nIn the section on homogeneity vs. inhomogeneity above we have argued using permutation tests that our pattern is not homogeneous but rather inhomogeneous. In fact, both OD mature cells and ependymal cells even show local scaling in the permutation test. In the plot above we see all variants of the correlation metrics. Given the assumptions of either homogeneity (first row), inhomogeneity (second row) and local scaling (third row) changes the interpretation to some extent.\nDeciding whether a pattern is homogeneous or not is easy and should always be done. In fact, most biological tissue will be inhomogeneous. The kind of inhomogeneity is more difficult to determine. Since the inhomogeneous curves (second row) and the local scaling curves (third row) are very different, it matters a lot to have good grounds to assume one or the other. Given our permutation tests above, we see that most support is found for local scaling metrics.\nAll the variants assume something about the properties of the metrics and given valuable insights. In the choice which metric fits the most, some care has to be taken.\n\n\n\nIt is worth noting that the \\(K\\)- and \\(L\\)-functions described above are summary statistics over the entire pattern (i.e., averaged over all points). However, if we know that there are different regions in our point pattern, an alternative strategy is to compute ``local’’ contributions to these patterns, i.e., local \\(K\\)- ,\\(L\\)- or pair-correlation functions. Baddeley et. al. propose to compare these \\(n\\) functions with so-called functional principal component analysis (see below). We will show here the example of the LISA version of the \\(L\\)-function (Baddeley, Rubak, and Turner 2015, 247–48).\n\n\n\n\nCode\nL_odmature_lisa &lt;- localL(pp_ls[['0.01']]$`OD Mature`)\n\ndf &lt;- as.data.frame(L_odmature_lisa)\ndfm &lt;- reshape2::melt(df, \"r\")\n\nget_sel &lt;- dfm %&gt;% filter(r &gt; 200.5630 & r &lt; 201.4388, variable != \"theo\") %&gt;%\n  mutate(sel = value) %&gt;% select(variable, sel)\n\ndfm &lt;- dfm %&gt;% left_join(get_sel)\n\np &lt;- ggplot(dfm, aes(x=r, y=value, group=variable, colour=sel)) +\n  geom_line() + \n  scale_color_continuous(type = \"viridis\") +\n  geom_vline(xintercept = 200) +\n  theme(legend.position = \"none\") +\n  theme_light()\n\nppdf &lt;- as.data.frame(pp[['0.01']]) %&gt;% filter(marks==\"OD Mature\")\nppdf$sel &lt;- get_sel$sel # assume they are in same order\n\nq &lt;- ggplot(ppdf, aes(x=x, y=y, colour=sel)) + \n  geom_point() +\n  scale_color_continuous(type = \"viridis\") +\n  theme(legend.position = \"none\") +\n  theme_light()\n\n\n\n\nCode\np|q\n\n\n\n\n\nIn the case of the OD mature cells, we obtain further information with this plot. We note that there are two distinct populations of curves: those that are clearly above the mean LISA curve in black and others that are around/underneath. This indicates that there are two different kinds of interactions in the OD mature cells. Stronger clustering and less clustered regions.\nThere are inhomogeneous versions of these (e.g. localLinhom) that are not shown here for brevity.\n\n\n\nWe apply functional PCA to retrieve the main trends in these individual curves. The idea of functional PCA is the same as for ordinary PCA but applied to functional data (i.e., each observation is a function instead of a point). For the \\(n\\) functions above, functional PCA will recover the main trends in the data (Ramsay and Silverman 2005). We use the R package fdapace to perform functional PCA (Zhou et al. 2022).\n\n\nCode\n#adapted from the fdapace vignette\nfunctional.pca.pp &lt;- function(df){\n  df_fdob &lt;- asinh(df %&gt;% as.matrix / 50)  # [MR: should we transform? if so, how?]\n  #df_fdob &lt;- df %&gt;% as.matrix # [MR: should we transform? if so, how?]\n  #remove theo column - we want only the actual estimations in there without the Poisson line theo\n  if('r' %in% colnames(df) || 'theo' %in% colnames(df))\n     df_fdob &lt;- df_fdob[,!colnames(df_fdob) %in% c(\"r\", \"theo\")]\n  if('Ependymal' %in% colnames(df))\n    df_fdob &lt;- df_fdob[,!colnames(df_fdob) %in% c(\"trans\",'iso')]\n\n  #number of columns\n  N &lt;- ncol(df_fdob)\n  #number of rows\n  M &lt;- nrow(df_fdob)\n  #the x values at which all the curves were evaluated, here called tVec\n  s &lt;- df$r\n  #create the FPCA object\n  fd_obj &lt;- fdapace::MakeFPCAInputs(IDs = rep(1:N, each=M),\n                                    tVec=rep(s,N), yVec=df_fdob)\n  print(which( unlist( lapply(fd_obj$Lt, \n                              function(x) length(x) != length(unique(x))))))\n  #check that the FPCA object is valid\n  fdapace::CheckData(fd_obj$Ly, fd_obj$Lt)\n  #run the computation of the FPCA - would work with sparse data.\n  fpca_obj &lt;- fdapace::FPCA(fd_obj$Ly, fd_obj$Lt, \n                            list(plot = TRUE, dataType='Dense', kernel='rect'))\n  fdapace::CreatePathPlot(fpca_obj,K = 3, pch = 4,\n                          showObs = FALSE, showMean = TRUE)\n  return(fpca_obj)\n}\n\nfpca_obj &lt;- functional.pca.pp(L_odmature_lisa)\n\n\n\n\n\n\n\n\nCode\nfpca_pc_df &lt;- as.data.frame(fpca_obj$xiEst) %&gt;% \n  rename(PC1 = V1, PC2 = V2, PC3 = V3)\nfpca_pc_df$sel &lt;- get_sel$sel # assume they are in same order\n\nggplot(fpca_pc_df, aes(x=PC1, y=PC2, col = sel)) + \n  scale_color_continuous(type = \"viridis\") +\n  geom_point() +\n  theme_light() +\n  ggtitle(\"Biplot of the LISA L curves of the OD mature cells\")\n\n\n\n\n\nCode\np1 &lt;- ggplot(ppdf, aes(x=x, y=y, colour = fpca_pc_df$PC1)) + \n  scale_color_continuous(type = \"viridis\") +\n  theme_light() +\n  geom_point()\n\np2 &lt;- ggplot(ppdf, aes(x=x, y=y, colour = fpca_pc_df$PC2)) + \n  scale_color_continuous(type = \"viridis\") +\n  theme_light() +\n  geom_point()\n\np1|p2\n\n\n\n\n\nHere, we see the functional PCA for the OD mature cells. The Design plot tells us that we have a very dense dataset over the entire support [MR: do we need the ‘Design plot’? it doesn’t show much]. The mean curve displays the mean trend over all \\(n\\) LISA \\(L\\)-curves (which is itself similar to the locally-scaled \\(L\\)-function). The scree plot indicates that the first eigenfunction explains more than \\(80 \\%\\) of the variance. The eigenfunction curves in the bottom right panel indicate the deviation from the mean curve.\nLooking at the second plot, we see the smoothed mean curve and the individual curves that are reconstructed from the first three eigenfunctions. The first eigenfunction from the bottom right panel, \\(\\phi_1\\), is above the mean curve, which relates to the population of curves above the mean. \\(\\phi_2\\) is first above the mean curve and then lower than the mean curve. These curves are visible as well. Lastly, \\(\\phi_3\\) is curves that start low and pick up to be larger than the mean curve in the end. This is visible in e.g. the orange dashed line (Ramsay and Silverman 2005).\nThe last plot shows the biplot of the loadings of the functional PCA. Each point is a cell from the OD mature cells with the loadings of the first two principal components plotted. The points are coloured as they were in the plots of the LISA \\(L\\)-curves. The first principal component clearly separates the two populations.\n\n\n\n\n\nSo far we have considered first- and second-order summary statistics and local (or inhomogeneous) adaptations of them. In the second order, one considers (counts of) pairs (e.g., \\(K\\) function). In a third-order setting, we would count triplets of points. A triplet is counted as the normalised expected value of triangles where all edges are smaller than the radius r (Baddeley, Rubak, and Turner 2015, 249).\n\n\n\n\n\nSo far, most approaches considered intensity and correlation as measures to assess a point pattern. Next, we will look at measures of spacing and shortest-distances to assess spatial arrangements (Baddeley, Rubak, and Turner 2015, 255).\nBaddeley et.al. summarises three basic distances to measure:\n\npairwise distance: \\(d_{i,j} = ||x_i-x_j||\\)\nNN distances: \\(d_i = \\min_{j \\neq i}d_{ij}\\)\nempty-space distance: \\(d(u) = \\min_j||u-x_j||\\)\n\nNote also that there are tests of CSR that are based on spacing, including the Clark-Evans and Hopkins-Skellam Index tests that were discussed above ``Testing for CSR’’.\n\n\nNearest neighbour (NN) methods are based on the notion of “nearness”. In particular, we introduce nndist from spatstat, a method to calculate the distances until \\(k\\) NN are found. This function returns a density for each specified \\(k\\) for the \\(k\\) neighbour distances. We can for instance collapse the \\(k\\) curves into a mean curve per point pattern. This information of the mean nearest neighbour distance (MMND) can be summarised as a density. Note, that these distances are “raw” nearest-neighbour distances which are not corrected for edge effects. Edge correction for the nearest neighbour distance (\\(k = 1\\)) is implemented in the function Gest below (Baddeley, Rubak, and Turner 2015, 256) (Baddeley and Turner 2005).\n\n\nCode\nnndistance &lt;- function(pp, nk){\n  xy &lt;- cbind(pp$x, pp$y)\n  nndistances_k15 &lt;- nndist(xy, k = nk) \n  nndistances_mean &lt;- rowMeans(nndistances_k15)\n  return(nndistances_mean)\n}\n\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricRes_nndist &lt;- function(ppls, celltype, fun){\n  metric.res &lt;- list(res = do.call(fun, args = list(pp=ppls[[celltype]], nk = seq(1:15))))\n  metric.res$type = celltype\n  return(metric.res)\n}\n# [MR: again, this function looks again like those before and maybe could be done as an all-in-one wrapper.]\ncelltypes &lt;- c(\"Ependymal\", \"OD Mature\", \"Microglia\")\n#go through all defined celltypes and calculate the nearest-neighbour distance\nres_ls &lt;- lapply(celltypes, metricRes_nndist, fun = nndistance, ppls = pp_ls[['0.01']])\n#initialise a dataframe for the metric values and the type information\nres_df &lt;- data.frame(metric = numeric(0), type = character(0))\n# Loop through the res_ls list and combine the metric values with their corresponding type - ChatGPT\nfor (i in 1:length(res_ls)) {\n  metric_values &lt;- res_ls[[i]]$res\n  metric_type &lt;- rep(res_ls[[i]]$type, length(metric_values))\n  df &lt;- data.frame(metric = metric_values, type = metric_type)\n  res_df &lt;- rbind(res_df, df)\n}\n#plot the densities\np &lt;- ggplot(res_df, aes(x=metric, col= type))+\n    geom_density(linewidth=1)+\n    scale_x_sqrt() +\n    theme_light() +\n    ggtitle('Sqrt of the Mean Nearest-Neighbour Distance')\np\n\n\n\n\n\nIn the MNND empirical distribution, the ependymal cells show the shortest NN distances, a reflection of their clustering. The OD mature cells have larger NN distances as well as a bimodal distribution, indicating a mix of longer and wider distances (as visible in the LISA \\(L\\)-functions). Microglia cells show the widest distances and the symmetry of the curve indicates similar distances throughout the field of view.\n\n\n\n\n\nUnder a stationary spatial point process, the empty-space distance is defined as:\n\\[\nd(u,X) = \\min\\{||u-x_i||: x_i \\in X\\}\n\\]\nNote that this is an edge-corrected distribution function of the nearest-neighbour distance above.\n[MR: what does one do for a non-stationary process?] [ME: that is a very good question, basically all point pattern methods assume stationarity]\nThe empty space function is then the cumulative distribution function of the empty-space distances defined above:\n\\[\nF(r) = \\mathbb{P}\\{d(u,X)\\leq r\\}.\n\\]\nThe NN distance is defined as:\n\\[\nd_i = \\min_{j\\neq i}||x_j-x_i||.\n\\]\nThe NN distance distribution function \\(G(r)\\) is then defined as:\n\\[\nG(r) = \\mathbb{P}\\{d(x,X\\backslash u \\leq r |X\\ has\\ a\\ point\\ at\\ u\\}.\n\\]\nFor a homogeneous Poisson process, the NN distance distribution is identical to the empty-space function of the same process:\n\\[\nG_{pois} \\equiv F_{pois}.\n\\]\nFor a general point process, the \\(F\\) and \\(G\\) functions are different (Baddeley, Rubak, and Turner 2015, 261–64).\n\n\n\n\nThe \\(F\\) and \\(G\\) functions are, like the \\(K\\) function, cumulative. The same disadvantages as with the \\(K\\) function occur here too [MR: what disadvantages? maybe say them explicitly here]. Therefore, an analogue to the pair-correlation function would make sense to consider. For practical reasons, this is no longer the derivative of the \\(F\\) function but rather a hazard rate:\n\\[\nh(r) = \\frac{f(r)}{1-F(r)}.\n\\]\nFor a CSR process, the hazard rate is:\n\\[\nh_{pois}(r) = 2 \\pi \\lambda r\n\\]\n(i.e., linear in \\(r\\)) (Baddeley, Rubak, and Turner 2015, 271–74).\n\n\n\nThe concepts of the empty-space function \\(F\\) and the NN function \\(G\\) are somewhat complementary. If one decreases, the other increases.\nThus, a related approach is the \\(J\\) function:\n\\[\nJ(r) = \\frac{1-G(r)}{1-F(r)}.\n\\]\nFor a CSR process, \\(J_{pois} \\equiv 1\\), whereas values of \\(J(r) &gt; 1\\) are consistent with a regular (e.g., repelling) pattern, and $J(r) &lt; 1 represents a clustered process (Baddeley, Rubak, and Turner 2015, 274–76).\n\n\nCode\np_G &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Gest', 'rs', bootstrap = FALSE)\np_F &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Fest', 'rs', bootstrap = FALSE)\np_J &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Jest', 'rs', bootstrap = FALSE)\n\n\n\n\nCode\nwrap_plots(list(p_G,p_F,p_J), guides = 'collect')\n\n\n\n\n\n\n\n\n[MR: so if there are inhomogeneous versions, should we skip the plots above? Or not, because the inhomogeneous versions are inaccurate because they still assume correlation stationarity. What do we do?!? We need to be careful not to paint overselves into a corner.]\nThere are inhomogeneous variants of the spacing functions explained above\n\n\nCode\np_G &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Ginhom', 'bord')\np_F &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Finhom', 'bord')\np_J &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Jinhom', 'bord')\n\n\n\n\nCode\nwrap_plots(list(p_G,p_F,p_J), guides = 'collect')\n\n\n\n\n\n[ME: add some text to inhomogeneity]\n\n\n\nNext to the NN distance, we can estimate the orientation of the neighbours, which gives an indication of the orientation of the spacing. It works by taking the angle between each point and its \\(k^{th}\\) nearest neighbour. The angle is anticlockwise from the x-axis (Baddeley, Rubak, and Turner 2015, 278–79) (Baddeley and Turner 2005).\n\n\nCode\np &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'phi', 'nnorient', 'bordm', bootstrap = FALSE)\np\n\n\n\n\n\nThe values of \\(\\phi\\) correspond to the orientation of the point pattern. The horizontal axis goes from \\(180\\) to \\(0\\) (left to right) and the vertical from \\(90\\) to \\(270\\) (top to bottom) [MR: I find this description quite confusing, because you are not talking about the horizontal/vertical axis of the metric plot, but rather the orientations in the point patterns. And since certain \\(\\phi\\)s represent these orientations, is it worth adding some shading of the x-axis to highlight this? Thicker lines would also benefit the old people reading this. And I wonder if faceting on celltype would help also. What does the Y-axis represent? And are there local variants of these? Maybe the clustered OD cells have a different orientation than the non-clustered?].\nWe can infer that the orientation of the Ependymal NNs is primarily along the vertical axis, OD mature cells do not show a clear orientation and microglial cells a horizontal orientation in their NNs with a modest peak at \\(\\sim 180\\) (orientation to the top).\nNote also tha the concepts of spacing are not only usable in point pattern analysis but also more broadly in other spatial contexts (e.g., spacing between shapes instead of points).\n\n\n\nThe same consideration about edge effects as for the \\(K\\) (and related) functions need to be made for the spacing functions; uncorrected estimates are negatively biased estimators. The easiest approach is to draw an artificial border and consider NNs within it. Other approaches are based on sampling. Yet another approach relates to survival analysis, with the idea is that a circle of a point to grows homogeneously with increasing radius until it hits the frame of the window and “dies”. This gives survival distributions similar to censored data, where the Kaplan-Meier estimator is the optimal choice (Baddeley, Rubak, and Turner 2015, 286–92)."
  },
  {
    "objectID": "01-within-marks.html#dependencies",
    "href": "01-within-marks.html#dependencies",
    "title": "Discrete Marks",
    "section": "",
    "text": "Code\nsource(\"utils.R\")"
  },
  {
    "objectID": "01-within-marks.html#setup",
    "href": "01-within-marks.html#setup",
    "title": "Discrete Marks",
    "section": "",
    "text": "Code\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#subset the data to only look at sample ID 0.01, 0.06 and 0.26\n# list(\"-0.29\", \"0.01\", \"0.06\")\n#zstack_list &lt;- list(\"-0.04\", '-0.09', '-0.14', '-0.19', '-0.24', '-0.29', '0.01', '0.06', '0.11', '0.16', '0.21', \"0.26\")\n\n#define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n\n#define the celltype that you want to compare across the stacks - hereby we assume independence across the z-stacks which is an assumption that can be challenged\ncelltype_ls &lt;- \"OD Mature\"\n\nselectZstacks &lt;- function(zstack, spe){\n  sub &lt;- spe[, spe$sample_id == zstack]\n  pp &lt;- .ppp(sub, marks = \"cluster_id\")\n  return(pp)\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe)\nnames(pp_ls) &lt;- zstack_list\n\n\nThe theory of spatial point patterns is discussed in great detail in (Baddeley, Rubak, and Turner 2015). The book has an accompanying package called spatstat which offers great functionality to the theoretical concepts discribed in the book (Baddeley and Turner 2005). This chapter relies heavily on both publications."
  },
  {
    "objectID": "01-within-marks.html#concepts-and-definitions-of-point-processes",
    "href": "01-within-marks.html#concepts-and-definitions-of-point-processes",
    "title": "Discrete Marks",
    "section": "",
    "text": "In point pattern analysis we assume that the patterns we observe are a realisation of a stochastic process called a point process. The inferences we make about the point pattern are based on the point process. E.g. the pattern can be said to be created by a poisson point process and thus is evenly distributed in the observation window (Baddeley, Rubak, and Turner 2015, 127).\nWhen considering a pattern with \\(m\\) multiple types, as we do in the (Moffitt et al. 2018) dataset, there are two very closely related concepts. One can view the pattern as a multitype point pattern, where all the points are sampled from the same point process. The other option is to consider the pattern as a multivariate point pattern, where the points come from \\(m\\) distinct point processes. The difference between these two views is that in the multitype framework we assume the points to stem from the same point process and thus depend on each other. In the multivariate framework we assume that the types stem from independent point processes and therefore we can consider dependencies of one type alone. Whether or not the underlying point processes are independent depends on the biological question. If we analyse two celltypes in one slice of a tissue, we should consider them as being sampled from one point process. However, if we consider the distribution of a celltype in two slices of the same tissue we can have grounds to consider the point processes as independent (Baddeley, Rubak, and Turner 2015, 565).\n\n\n\nThe most common set up in point pattern analysis is what we call window sampling. Instead of observing the entire pattern we observe a subset of this pattern in the so called window. In the analysis we try to make inference on the entire point process based on the observed window. An example could be different small microscopy windows through which a big tissue slice is observed. The windows would be samples of the bigger point process. In this case, it would be wrong to assume the window to be the convex hull around the observed points because they are just a sample of the bigger point pattern (Baddeley, Rubak, and Turner 2015, 144–45).\nThere is another concept called the small world model. It assumes that points can only be observed in a finite small world and not beyond these boundaries. When thinking of an entire tissue, this is a very common scenario. Cells can only be observed within the tissue and not beyond. In this case, it would be correct to not assume a rectangular observation window but to use more conservative methods to estimate an unknown sampling window such as the Ripley-Rasson estimate of a spatial domain (Baddeley, Rubak, and Turner 2015, 144–45).\nIn both cases it is important to understand the direction of the bias. If the unknown window is estimated to be smaller than the true window, we underestimate the window. This then again leads to an overestimation of the density of points and to other characteristics of the pattern. Therefore, an underestimation of the window size is more concerning than a slight overestimation (Baddeley, Rubak, and Turner 2015, 144–45).\n\n\nCode\nsetRiprasWindows &lt;- function(pp){\n  Window(pp) &lt;- ripras(pp)\n  marks(pp) &lt;- factor(marks(pp))\n  return(pp)\n}\n#the entire point patterns with the ripras windows\npp &lt;- lapply(pp_ls, setRiprasWindows)\n\nseparateMarks &lt;- function(pp){\n  #split the multitype point process into several single type processes\n  ppls &lt;- split(pp)\n  return (ppls)\n}\n#the point patterns separated by their marks\npp_ls &lt;- lapply(pp, separateMarks)\n\n\n\n\n\nComplete spatial randomness (CSR) is often used as the null model for various point patterns, and is the result of a Poisson process. A completely spatial random process is characterised by two properties, homogeneity and independence, as discussed below (Baddeley, Rubak, and Turner 2015, 132).\n\n\n“Homogeneity […] means that the expected number of points falling in a region B should be proportional to its area |B|” (Baddeley, Rubak, and Turner 2015, 132) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) represents the intensity of the process, i.e., the average number of points in a unit area (Baddeley, Rubak, and Turner 2015, 132–33). :\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|.\n\\label{eq:expected_number_points}\n\\]\n\n\n\nIndependence implies that in two (non-overlapping) regions \\(A\\) and \\(B\\), the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are independent random variables. In other words, the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). In addition, the number of points, \\(N = n(X\\cap B)\\), follows a Poisson distribution:\n\\[\n\\mathbb{P}[N=k] = e^{-\\mu}\\frac{\\mu^k}{k!}\\\\\n\\label{eq:poisson_process}\n\\] where \\(k = \\lambda |B|\\) (Baddeley, Rubak, and Turner 2015, 133).\n\n\n\n\nA Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density, \\(\\lambda(u)\\), sometimes known as the intensity function (see below), is a function of spatial location \\(u\\). In this case, the expected number of points falling into a region \\(B\\), \\(\\mu = n(X\\cap B)\\), is an integration of the intensity function over that region (Baddeley, Rubak, and Turner 2015, 138).\n\\[\n\\mu = \\int_{B} \\lambda(u) du.\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\n\nA point process is called isotropic, if its statistical properties are invariant to rotations; a CSR process is both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 147).\n\n\n\n“A point process is called stationary if, when we view the process through a window W , its statistical properties do not depend on the location of the window in two-dimensional space” (Baddeley, Rubak, and Turner 2015, 146). This is the case for any homogeneous point process, where the statistical properties of the pattern are unchanged given shifting of the observation window. This means it is stationary in all statistical properties; first-order properties (e.g. intensity) and second-order properties (e.g. correlation) (Baddeley, Rubak, and Turner 2015, 218). Not all metrics assume stationarity in its full sense. Inhomogeneous metrics only assume second-order / correlation stationarity. That means while the intensity function can vary spatially (first-order stationarity is not given), the estimates of correlation functions (e.g. the inhomogeneous K-function) should be the same in parts of the window (Baddeley, Rubak, and Turner 2015, 689).\n\n\n\nIf a process is not correlation stationary, so the estimates of the inhomogeneous metric vary between locations, locally-scaled versions of the metric can be applicable. This means in small subregions, the process is still stationary and isotropic, but there is a rescaling factor that can vary across the total process (Baddeley, Rubak, and Turner 2015, 246–47).\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimated functions between the quadrats. It should be noted that this test depends on the arbitrary definition of the quadrats. Given our chosen patterns are not independent but result as marks from an overall point-pattern, the permutation approach is questionable. Furthermore, the outcome of the permutation test depends heavily on the choice of the quadrats. Therefore, the interpretation can be difficult (Baddeley, Rubak, and Turner 2015, 689–93).\n\n\nCode\npermutation_test &lt;- function(pp, mark, split, minpoints) {\n  pp_sel &lt;-  subset(pp, marks %in% mark, drop = TRUE)\n  \n  rho_est &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\n  lambda &lt;- predict(rho_est)\n\n  tesselation &lt;- quantess(unmark(pp_sel), \"x\", 3)\n  tesselation_split &lt;- nestsplit(pp_sel, tesselation, ny=split)\n  \n  plot(tesselation_split, main = mark)\n  \n  tesselation_split$inten &lt;- factor(as.integer(tesselation_split$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n  \n  res.scaled &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kscaled,\n                 minpoints = minpoints)\n  \n  res.inhom &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kinhom,\n                 lambda=lambda, minpoints = minpoints)\n  \n  #p-value of the local-scaling test\n  print(paste0(mark,' local scaling test ', res.scaled$p.value))\n  \n  #p-value of the inhomogeneity test\n  print(paste0(mark,' inhomogeneity test ', res.inhom$p.value))\n}\nlapply(c(\"Microglia\", \"OD Mature\", \"Ependymal\"), function(x) permutation_test(pp[['0.01']], x, split = 3, minpoints = 10))\n\n\nThe p-value of the test for local scaling for microglia cells is \\(&lt;0.05\\) which indicates that the assumption of local scaling is rejected. Therefore, the distribution of microglia cells is not a scaled version of an overall distribution pattern. The p-value of the test for inhomogeneity for both microglia cells is \\(&gt;0.05\\) indicating that the assumption of correlation stationarity is not rejected. In this case we can use the inhomogeneous version of the K-function which assumes correlation stationarity.\nFor ependymal and OD mature cells however, the p-values for both the local scaling test and the inhomogeneity test are \\(&gt;0.05\\) which means that both the correlation stationarity assumption and the local scaling assumption can’t be rejected. [ME: Does this make sense? Or is this just an artifact?]\nAs the interpretation of the permutation test is highly dependent on the quadrats, the results should be interpreted with care. Both inhomogeneous and locally scaled versions of the summary functions have support and both offer interesting insights into the spatial pattern. Therefore, we will compare all versions and show what the choice of metrics means for their interpretation.\n\n\n\nIntensity is the expected density of points per unit area. It can be interpreted as the rate of occurrence or the abundance of events recorded. The intensity represents a first order property because it is related to the expected number of points . More formally the average intensity of a point process is defined as:\n\\[\n\\bar{\\lambda} = \\frac{n(x)}{|W|}\n\\label{eq:average_intensity}\n\\]\nAs this is an average over the entire window, it only really makes sense for a homogeneous point process (Baddeley, Rubak, and Turner 2015, 157–60)\n\n\nFor a homogeneous point process, the intensity can be estimated in a simplistic way: summing the individual intensities of the marks (Baddeley, Rubak, and Turner 2015, 161).\n\n\nCode\nintensityPointProcess &lt;- function(pp,mark) if(mark) intensity(pp) else sum(intensity(pp))\n\nintensityPointProcess(pp_ls[['0.01']], mark = FALSE) %&gt;% round(6)\n\n\n[1] 0.001909\n\n\nOtherwise, we can compute the intensity for each mark individually.\n\n\nCode\nintensityPointProcess(pp_ls[['0.01']], mark = TRUE) %&gt;% round(8)\n\n\n  Ambiguous   Astrocyte Endothelial   Ependymal  Excitatory  Inhibitory \n 0.00024151  0.00020183  0.00014653  0.00008373  0.00036867  0.00061393 \n  Microglia OD Immature   OD Mature   Pericytes \n 0.00003031  0.00006249  0.00014278  0.00001750 \n\n\n\n\n\nIn kernel estimation, we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There are a wide variety of kernel estimators (see (Baddeley, Rubak, and Turner 2015, 168)), but a popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth (Baddeley, Rubak, and Turner 2015, 168).\n\n\nCode\npp_sel &lt;-  subset(pp_ls[['0.01']]$`OD Mature`, drop = TRUE)\nDens &lt;- density(pp_sel, sigma = 100)\nplot(Dens, main = 'Kernel Density (OD Mature cells)')\n\n\n\n\n\n\n\n\nIn quadrat counting, all points falling into a given quadrat are counted. This gives an overview on the characteristics of the point pattern, such as correlation stationarity (Baddeley, Rubak, and Turner 2015, 163).\n\n\nCode\nQ5 &lt;- quadratcount(pp_ls[['0.01']], nx=8, ny=8)\nplot(unmark(pp[['0.01']]), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\nUnder independence assumptions, the quadrat counts can be used for testing homogeneity, i.e., if the points are distributed evenly across the quadrats (Baddeley, Rubak, and Turner 2015, 164–65).\n\n\nCode\nval &lt;- quadrat.test(pp_ls[['0.01']]$`OD Mature`, 5, alternative=\"regular\", method=\"MonteCarlo\")\nval\n\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nX2 = 635.09, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 25 tiles (irregular windows)\n\n\nA p-value of 1 indicates that the null hypothesis of irregularity can not be rejected strongly. Thus, the point pattern of oligodendrocyts is strongly irregular.\nAlternatively, we can inspect departures from the hypothesis that points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types (Buller 2020).\n\n\nCode\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp[['0.01']], marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\n\nWhether or not a point process is completely spatially random (CSR) depends on two characteristics: points need to be distributed homogeneously and they have to be independent of each other (see definitions above). There are various ways to test for CSR, here we show the use-case of the clark-evans test (Baddeley, Rubak, and Turner 2015, 165–66).\n\n\nCode\nclarkevans.test(pp_ls[['0.01']]$`OD Mature`)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nR = 0.77286, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "01-within-marks.html#correlation",
    "href": "01-within-marks.html#correlation",
    "title": "Discrete Marks",
    "section": "",
    "text": "Correlation, or more generally covariance, represents a second-order summary statistic and measures dependence between data points (Baddeley, Rubak, and Turner 2015, 199).\n\n\n\n\nIn the framework of correlation analysis, we often look at distances \\(d_{ij} = ||x_i-x_j||\\) of all points. It is then natural to look at the summary of these distances, \\(d_{ij}\\), e.g. as a histogram. The histogram of this point process depends on the observation window \\(W\\), thus the histogram can change significantly with a different window. Therefore, we look at the empirical distribution function of the distances \\(d_{ij}\\) that are smaller or equal than a radius \\(r\\) (Baddeley, Rubak, and Turner 2015, 203)\nWhat we actually measure here is “the average number of r-neighbours of a typical random point” (Baddeley, Rubak, and Turner 2015, 204). This number is still dependent on the size of the observation window so we can standardise it by the number of points and the window size, \\(|W|\\). We then obtain the empirical Ripley’s \\(K\\) function (Baddeley, Rubak, and Turner 2015, 204):\n\\[\n\\hat{K}(r) = \\frac{|W|}{n(n-1)}\\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n\\{d_{ij}\\leq r\\} e_{ij}(r)\n\\]\nThe standardisation makes it possible to compare point patterns with different observation windows and with different numbers of points. However, using the empirical \\(K\\) function assumes though that the point process has homogeneous intensity, which is often not the case for biological tissue (Baddeley, Rubak, and Turner 2015, 204–5). We will return to this issue below in the Correcting for Inhomogeneity. The term \\(e_{ij}(r)\\) is for edge correction. We will briefly cover this in Edge effects and their corrections for spatial metrics\n\n\n\nEdge effects describe the phenomenon that not the entire point process is observed, but rather only the part within the window \\(W\\). This means the value of various statistics could be biased along the edges (Baddeley, Rubak, and Turner 2015, 213).\nThere are many corrections for edge effects that are briefly listed here (Baddeley, Rubak, and Turner 2015, 214–19):\nBorder correction:\nIn border correction the summation of data points is restricted to \\(x_i\\) for which \\(b(x_i,r)\\) is completely in the window \\(W\\).\nIsotropic correction:\nWe can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.\nTranslation correction:\nA stationary point process \\(X\\) is invariant to translations. So the entire point process can be shifted by a vector \\(s\\) to be at the position \\(X+s\\).\n\n\n\n\nThe \\(K\\)-function can be ``centered’’, which is then called the \\(L\\)-function. The \\(L\\)-function is a variance-stabilising version of the \\(K\\)-function (Canete et al. 2022):\n\\[\nL(r) = \\sqrt{\\frac{K(r)}{\\pi}}.\n\\]\n\n\n\nWe have seen above that the \\(K\\)-function is cumulative. That is, the contributions of all distances smaller equal to \\(r\\) are considered. An alternative is to take the derivative of the \\(K\\)-function in order to obtain contributions of distances between points equal to \\(r\\), according to:\n\\[\ng(r) = \\frac{K'(r)}{2\\pi r},\n\\]\nwhere \\(g(r)\\) is the derivative of the \\(K\\) function (so interactions at exactly \\(r\\)) divided by the probability of a poisson process at this radius (Baddeley, Rubak, and Turner 2015, 225).\n\n\nCode\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricRes &lt;- function(plot_by, pp, celltype, fun, bootstrap, continuous, f){\n  if(continuous){\n    pp &lt;- subset(pp, select = plot_by)\n  }\n  else{\n    pp_sel &lt;- pp[[plot_by]]\n    pp &lt;- subset(pp_sel, marks == celltype)\n  }\n  if(bootstrap){\n    metric.res &lt;- lohboot(pp, fun = fun, f = f)\n  }\n  else{\n    metric.res &lt;- do.call(fun, args = list(X=pp, f=f))\n  }\n  metric.res$type &lt;- celltype\n  metric.res$plot_by &lt;- plot_by\n  return(metric.res)\n}\n\n#PRE: celltypes, function to calculation and edge correction method\n#POST: dataframe of \nmetricResToDF &lt;- function(plot_by, celltype, pp, fun, edgecorr, bootstrap, continuous, f){\n  lapply(plot_by, function(u) {\n    metricRes(u, fun = fun, pp = pp, celltype = celltype, bootstrap, continuous, f)  %&gt;%\n      as.data.frame()\n  }) %&gt;% bind_rows\n}\n\n# [MR: try to write the above a little more compactly]\n\n#PRE: Celltypes of interest, function to analyse, edge correction to perform\n#POST: plot of the metric\nplotMetric &lt;- function(plot_by, pp, celltype = NULL, x, fun, edgecorr, bootstrap = FALSE, continuous = FALSE, f = NULL){\n  #calculate the metric and store as dataframe\n  res_df &lt;- metricResToDF(plot_by, celltype, pp, fun, edgecorr, bootstrap, continuous, f)\n  #plot the curves\n  p &lt;- ggplot(res_df, aes(x=.data[[x]], y=.data[[edgecorr]], col= (plot_by)))+\n      geom_line() +\n      {if(bootstrap)geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)}+\n      ggtitle(paste0(fun, '-function'))+\n      geom_line(aes(x=.data[[x]],y=theo),linetype = \"dashed\")+\n      ylab(edgecorr) +\n      # scale_color_manual(name='Point Processes',\n      #                  breaks=c('-0.29', '0.01',\n      #                           '0.06', 'Poisson'),\n      #                  values=c('-0.29'='red',\n      #                           '0.01'='dark green',\n      #                           '0.06'='blue', 'Poisson'='black'))+\n      theme_light()\n  \n  return(p)\n}\n\np_K &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Kest', 'iso', bootstrap = TRUE)\np_L &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Lest', 'iso', bootstrap = TRUE)\np_g &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'pcf', 'border', bootstrap = TRUE)\n\n\n\n\nCode\np_homo &lt;- wrap_plots(list(p_K,p_L,p_g), guides = 'collect')\np_homo\n\n\n\n\n\nAs we have seen above in the test for homogeneity in oligodendrocytes, the assumptions of homogeneity are not given in our data. Therefore, we will have to use the inhomogeneous alternatives (inhomogeneity correction and local scaling) of the metrics instead.\n\n\n\n\n\nIn the case that a spatial pattern is known or suspected to be inhomogeneous, we have to take this into account in the analysis. Biological point patterns display inhomogeneity very often, therefore this analysis is preferred over the homogeneous alternatives. Inhomogeneous alternatives can be estimated via: \n\\[\n\\hat{K}_{inhom}(r) = \\frac{1}{D^p|W|}\\sum_i\\sum_{j \\neq i} \\frac{\\mathbb{1}\\{||u-x_j||\\leq r\\}}{\\hat{\\lambda}(x_j)\\hat{\\lambda}(x_i)}e(x_j,x_i;r),\n\\]\nwhere \\(e(u,v;r)\\) is an edge correction weight and \\(\\hat{\\lambda}(x_i)\\) is an estimator of the intensity at point \\(x_i\\). The inhomogeneity correction happens via these \\(\\hat{\\lambda}(x_i)\\) per point \\(x_i\\). The estimation of these local intensities can happen in a data-dependent manner via kernel-smoothing. As this is the same data to then calculate the metric on, this can lead to biases. However, in the case where the local intensities are known, the inhomogeneous \\(K\\) function is an unbiased estimator (Baddeley, Rubak, and Turner 2015, 243–44).\n\n\nCode\np_K &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls,'r','Kinhom', 'iso', bootstrap = TRUE)\np_L &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls,'r', 'Linhom', 'iso', bootstrap = TRUE)\np_g &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls,'r', 'pcfinhom', 'border', bootstrap = TRUE)\n\n\n\n\nCode\np_inhomo &lt;- wrap_plots(list(p_K,p_L,p_g), guides = 'collect')\np_inhomo\n\n\n\n\n\nThe inhomogeneous \\(K\\)-function tells us that the microglia cells follow close to a Poisson process (dashed line) closely and can therefore be assumed to be randomly distributed and not clustered. Ependymal cells show a high degree of clustering at a low radius \\(r\\). OD mature cells exhibit a medium level of clustering.\nIn the \\(L\\)-function, the microglia cells are along the dashed Poisson line, indicating no clustering; ependymal cells are highly clustered at low values of \\(r\\), whereas OD mature show intermediate clustering.\nThe pair correlation function is the derivative of the \\(K\\)-function. The pcf plot gives similar information as before: microglia cells are around the dashed Poisson line. OD Mature cells show a rather broad range of correlations between \\(r \\in [20,100]\\). Ependymal cells have a very strong correlation at \\(\\sim r = 25\\).\nInterestingly, the curves for the inhomogeneous functions of ependymal cells and OD mature cells cross the poisson line at \\(r=300\\). This means that the inhomogeneous functions find repulsion of ependymal cells and OD mature cells past a radius of \\(r=300\\).\n\n\n\n\n\n\n\nIn the inhomogeneous \\(K\\)-function approach above, we assume that the intensities can vary locally but the scale of the point process is not changed. This means that while the intensities might vary in the parts of the point pattern, the pattern in one subquadrat is not just a scaled version of another subquadrat. In a biological sample, this assumption is easily violated, e.g. when a gradient of cells increases from one side to another [ME needs a reference]. The correlation structure might scale linearly with the distance (Baddeley, Rubak, and Turner 2015, 246–47) (Prokešová, Hahn, and Jensen 2006).\nTo circumvent this local scaling, we can assume that the process is subdivided into small regions. In these small regions, the point process is a scaled version of a template process. This template process needs to be both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 246–47).\n\n\n\nSince the \\(L\\)-function is simply a transformation of the \\(K\\)-function, the same local scaling framework can be applied to the \\(L\\)-function (Baddeley, Rubak, and Turner 2015, 246–47).\n\n\nCode\np_K &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Kscaled', 'iso', bootstrap = FALSE)\np_L &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Lscaled', 'iso', bootstrap = FALSE)\n#p_g &lt;- plotScaledMetric(zstack_list,celltype_ls, pp_ls, 'pcfscaled', 'iso')$p\n\n\n\n\nCode\np_scaled &lt;- wrap_plots(list(p_K, p_L), guides = 'collect')\np_scaled\n\n\n\n\n\nAs seen by our permutation tests we have grounds to believe that the patterns of ependymal and OD mature cells are locally scaled. Therefore, we will analyse this pattern using a locally scaled K and L function.\nWe see, that again our ependymal cells are very far from the poisson process line, indicating strong clustering among ependymal cells. The OD mature cells range in the middle showing intermediate clustering\n\n\nCode\nwrap_plots(list(p_homo, p_inhomo, p_scaled), nrow = 3, guides = 'collect')\n\n\n\n\n\nIn the section on homogeneity vs. inhomogeneity above we have argued using permutation tests that our pattern is not homogeneous but rather inhomogeneous. In fact, both OD mature cells and ependymal cells even show local scaling in the permutation test. In the plot above we see all variants of the correlation metrics. Given the assumptions of either homogeneity (first row), inhomogeneity (second row) and local scaling (third row) changes the interpretation to some extent.\nDeciding whether a pattern is homogeneous or not is easy and should always be done. In fact, most biological tissue will be inhomogeneous. The kind of inhomogeneity is more difficult to determine. Since the inhomogeneous curves (second row) and the local scaling curves (third row) are very different, it matters a lot to have good grounds to assume one or the other. Given our permutation tests above, we see that most support is found for local scaling metrics.\nAll the variants assume something about the properties of the metrics and given valuable insights. In the choice which metric fits the most, some care has to be taken.\n\n\n\nIt is worth noting that the \\(K\\)- and \\(L\\)-functions described above are summary statistics over the entire pattern (i.e., averaged over all points). However, if we know that there are different regions in our point pattern, an alternative strategy is to compute ``local’’ contributions to these patterns, i.e., local \\(K\\)- ,\\(L\\)- or pair-correlation functions. Baddeley et. al. propose to compare these \\(n\\) functions with so-called functional principal component analysis (see below). We will show here the example of the LISA version of the \\(L\\)-function (Baddeley, Rubak, and Turner 2015, 247–48).\n\n\n\n\nCode\nL_odmature_lisa &lt;- localL(pp_ls[['0.01']]$`OD Mature`)\n\ndf &lt;- as.data.frame(L_odmature_lisa)\ndfm &lt;- reshape2::melt(df, \"r\")\n\nget_sel &lt;- dfm %&gt;% filter(r &gt; 200.5630 & r &lt; 201.4388, variable != \"theo\") %&gt;%\n  mutate(sel = value) %&gt;% select(variable, sel)\n\ndfm &lt;- dfm %&gt;% left_join(get_sel)\n\np &lt;- ggplot(dfm, aes(x=r, y=value, group=variable, colour=sel)) +\n  geom_line() + \n  scale_color_continuous(type = \"viridis\") +\n  geom_vline(xintercept = 200) +\n  theme(legend.position = \"none\") +\n  theme_light()\n\nppdf &lt;- as.data.frame(pp[['0.01']]) %&gt;% filter(marks==\"OD Mature\")\nppdf$sel &lt;- get_sel$sel # assume they are in same order\n\nq &lt;- ggplot(ppdf, aes(x=x, y=y, colour=sel)) + \n  geom_point() +\n  scale_color_continuous(type = \"viridis\") +\n  theme(legend.position = \"none\") +\n  theme_light()\n\n\n\n\nCode\np|q\n\n\n\n\n\nIn the case of the OD mature cells, we obtain further information with this plot. We note that there are two distinct populations of curves: those that are clearly above the mean LISA curve in black and others that are around/underneath. This indicates that there are two different kinds of interactions in the OD mature cells. Stronger clustering and less clustered regions.\nThere are inhomogeneous versions of these (e.g. localLinhom) that are not shown here for brevity.\n\n\n\nWe apply functional PCA to retrieve the main trends in these individual curves. The idea of functional PCA is the same as for ordinary PCA but applied to functional data (i.e., each observation is a function instead of a point). For the \\(n\\) functions above, functional PCA will recover the main trends in the data (Ramsay and Silverman 2005). We use the R package fdapace to perform functional PCA (Zhou et al. 2022).\n\n\nCode\n#adapted from the fdapace vignette\nfunctional.pca.pp &lt;- function(df){\n  df_fdob &lt;- asinh(df %&gt;% as.matrix / 50)  # [MR: should we transform? if so, how?]\n  #df_fdob &lt;- df %&gt;% as.matrix # [MR: should we transform? if so, how?]\n  #remove theo column - we want only the actual estimations in there without the Poisson line theo\n  if('r' %in% colnames(df) || 'theo' %in% colnames(df))\n     df_fdob &lt;- df_fdob[,!colnames(df_fdob) %in% c(\"r\", \"theo\")]\n  if('Ependymal' %in% colnames(df))\n    df_fdob &lt;- df_fdob[,!colnames(df_fdob) %in% c(\"trans\",'iso')]\n\n  #number of columns\n  N &lt;- ncol(df_fdob)\n  #number of rows\n  M &lt;- nrow(df_fdob)\n  #the x values at which all the curves were evaluated, here called tVec\n  s &lt;- df$r\n  #create the FPCA object\n  fd_obj &lt;- fdapace::MakeFPCAInputs(IDs = rep(1:N, each=M),\n                                    tVec=rep(s,N), yVec=df_fdob)\n  print(which( unlist( lapply(fd_obj$Lt, \n                              function(x) length(x) != length(unique(x))))))\n  #check that the FPCA object is valid\n  fdapace::CheckData(fd_obj$Ly, fd_obj$Lt)\n  #run the computation of the FPCA - would work with sparse data.\n  fpca_obj &lt;- fdapace::FPCA(fd_obj$Ly, fd_obj$Lt, \n                            list(plot = TRUE, dataType='Dense', kernel='rect'))\n  fdapace::CreatePathPlot(fpca_obj,K = 3, pch = 4,\n                          showObs = FALSE, showMean = TRUE)\n  return(fpca_obj)\n}\n\nfpca_obj &lt;- functional.pca.pp(L_odmature_lisa)\n\n\n\n\n\n\n\n\nCode\nfpca_pc_df &lt;- as.data.frame(fpca_obj$xiEst) %&gt;% \n  rename(PC1 = V1, PC2 = V2, PC3 = V3)\nfpca_pc_df$sel &lt;- get_sel$sel # assume they are in same order\n\nggplot(fpca_pc_df, aes(x=PC1, y=PC2, col = sel)) + \n  scale_color_continuous(type = \"viridis\") +\n  geom_point() +\n  theme_light() +\n  ggtitle(\"Biplot of the LISA L curves of the OD mature cells\")\n\n\n\n\n\nCode\np1 &lt;- ggplot(ppdf, aes(x=x, y=y, colour = fpca_pc_df$PC1)) + \n  scale_color_continuous(type = \"viridis\") +\n  theme_light() +\n  geom_point()\n\np2 &lt;- ggplot(ppdf, aes(x=x, y=y, colour = fpca_pc_df$PC2)) + \n  scale_color_continuous(type = \"viridis\") +\n  theme_light() +\n  geom_point()\n\np1|p2\n\n\n\n\n\nHere, we see the functional PCA for the OD mature cells. The Design plot tells us that we have a very dense dataset over the entire support [MR: do we need the ‘Design plot’? it doesn’t show much]. The mean curve displays the mean trend over all \\(n\\) LISA \\(L\\)-curves (which is itself similar to the locally-scaled \\(L\\)-function). The scree plot indicates that the first eigenfunction explains more than \\(80 \\%\\) of the variance. The eigenfunction curves in the bottom right panel indicate the deviation from the mean curve.\nLooking at the second plot, we see the smoothed mean curve and the individual curves that are reconstructed from the first three eigenfunctions. The first eigenfunction from the bottom right panel, \\(\\phi_1\\), is above the mean curve, which relates to the population of curves above the mean. \\(\\phi_2\\) is first above the mean curve and then lower than the mean curve. These curves are visible as well. Lastly, \\(\\phi_3\\) is curves that start low and pick up to be larger than the mean curve in the end. This is visible in e.g. the orange dashed line (Ramsay and Silverman 2005).\nThe last plot shows the biplot of the loadings of the functional PCA. Each point is a cell from the OD mature cells with the loadings of the first two principal components plotted. The points are coloured as they were in the plots of the LISA \\(L\\)-curves. The first principal component clearly separates the two populations.\n\n\n\n\n\nSo far we have considered first- and second-order summary statistics and local (or inhomogeneous) adaptations of them. In the second order, one considers (counts of) pairs (e.g., \\(K\\) function). In a third-order setting, we would count triplets of points. A triplet is counted as the normalised expected value of triangles where all edges are smaller than the radius r (Baddeley, Rubak, and Turner 2015, 249)."
  },
  {
    "objectID": "01-within-marks.html#spacing",
    "href": "01-within-marks.html#spacing",
    "title": "Discrete Marks",
    "section": "",
    "text": "So far, most approaches considered intensity and correlation as measures to assess a point pattern. Next, we will look at measures of spacing and shortest-distances to assess spatial arrangements (Baddeley, Rubak, and Turner 2015, 255).\nBaddeley et.al. summarises three basic distances to measure:\n\npairwise distance: \\(d_{i,j} = ||x_i-x_j||\\)\nNN distances: \\(d_i = \\min_{j \\neq i}d_{ij}\\)\nempty-space distance: \\(d(u) = \\min_j||u-x_j||\\)\n\nNote also that there are tests of CSR that are based on spacing, including the Clark-Evans and Hopkins-Skellam Index tests that were discussed above ``Testing for CSR’’.\n\n\nNearest neighbour (NN) methods are based on the notion of “nearness”. In particular, we introduce nndist from spatstat, a method to calculate the distances until \\(k\\) NN are found. This function returns a density for each specified \\(k\\) for the \\(k\\) neighbour distances. We can for instance collapse the \\(k\\) curves into a mean curve per point pattern. This information of the mean nearest neighbour distance (MMND) can be summarised as a density. Note, that these distances are “raw” nearest-neighbour distances which are not corrected for edge effects. Edge correction for the nearest neighbour distance (\\(k = 1\\)) is implemented in the function Gest below (Baddeley, Rubak, and Turner 2015, 256) (Baddeley and Turner 2005).\n\n\nCode\nnndistance &lt;- function(pp, nk){\n  xy &lt;- cbind(pp$x, pp$y)\n  nndistances_k15 &lt;- nndist(xy, k = nk) \n  nndistances_mean &lt;- rowMeans(nndistances_k15)\n  return(nndistances_mean)\n}\n\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricRes_nndist &lt;- function(ppls, celltype, fun){\n  metric.res &lt;- list(res = do.call(fun, args = list(pp=ppls[[celltype]], nk = seq(1:15))))\n  metric.res$type = celltype\n  return(metric.res)\n}\n# [MR: again, this function looks again like those before and maybe could be done as an all-in-one wrapper.]\ncelltypes &lt;- c(\"Ependymal\", \"OD Mature\", \"Microglia\")\n#go through all defined celltypes and calculate the nearest-neighbour distance\nres_ls &lt;- lapply(celltypes, metricRes_nndist, fun = nndistance, ppls = pp_ls[['0.01']])\n#initialise a dataframe for the metric values and the type information\nres_df &lt;- data.frame(metric = numeric(0), type = character(0))\n# Loop through the res_ls list and combine the metric values with their corresponding type - ChatGPT\nfor (i in 1:length(res_ls)) {\n  metric_values &lt;- res_ls[[i]]$res\n  metric_type &lt;- rep(res_ls[[i]]$type, length(metric_values))\n  df &lt;- data.frame(metric = metric_values, type = metric_type)\n  res_df &lt;- rbind(res_df, df)\n}\n#plot the densities\np &lt;- ggplot(res_df, aes(x=metric, col= type))+\n    geom_density(linewidth=1)+\n    scale_x_sqrt() +\n    theme_light() +\n    ggtitle('Sqrt of the Mean Nearest-Neighbour Distance')\np\n\n\n\n\n\nIn the MNND empirical distribution, the ependymal cells show the shortest NN distances, a reflection of their clustering. The OD mature cells have larger NN distances as well as a bimodal distribution, indicating a mix of longer and wider distances (as visible in the LISA \\(L\\)-functions). Microglia cells show the widest distances and the symmetry of the curve indicates similar distances throughout the field of view.\n\n\n\n\n\nUnder a stationary spatial point process, the empty-space distance is defined as:\n\\[\nd(u,X) = \\min\\{||u-x_i||: x_i \\in X\\}\n\\]\nNote that this is an edge-corrected distribution function of the nearest-neighbour distance above.\n[MR: what does one do for a non-stationary process?] [ME: that is a very good question, basically all point pattern methods assume stationarity]\nThe empty space function is then the cumulative distribution function of the empty-space distances defined above:\n\\[\nF(r) = \\mathbb{P}\\{d(u,X)\\leq r\\}.\n\\]\nThe NN distance is defined as:\n\\[\nd_i = \\min_{j\\neq i}||x_j-x_i||.\n\\]\nThe NN distance distribution function \\(G(r)\\) is then defined as:\n\\[\nG(r) = \\mathbb{P}\\{d(x,X\\backslash u \\leq r |X\\ has\\ a\\ point\\ at\\ u\\}.\n\\]\nFor a homogeneous Poisson process, the NN distance distribution is identical to the empty-space function of the same process:\n\\[\nG_{pois} \\equiv F_{pois}.\n\\]\nFor a general point process, the \\(F\\) and \\(G\\) functions are different (Baddeley, Rubak, and Turner 2015, 261–64).\n\n\n\n\nThe \\(F\\) and \\(G\\) functions are, like the \\(K\\) function, cumulative. The same disadvantages as with the \\(K\\) function occur here too [MR: what disadvantages? maybe say them explicitly here]. Therefore, an analogue to the pair-correlation function would make sense to consider. For practical reasons, this is no longer the derivative of the \\(F\\) function but rather a hazard rate:\n\\[\nh(r) = \\frac{f(r)}{1-F(r)}.\n\\]\nFor a CSR process, the hazard rate is:\n\\[\nh_{pois}(r) = 2 \\pi \\lambda r\n\\]\n(i.e., linear in \\(r\\)) (Baddeley, Rubak, and Turner 2015, 271–74).\n\n\n\nThe concepts of the empty-space function \\(F\\) and the NN function \\(G\\) are somewhat complementary. If one decreases, the other increases.\nThus, a related approach is the \\(J\\) function:\n\\[\nJ(r) = \\frac{1-G(r)}{1-F(r)}.\n\\]\nFor a CSR process, \\(J_{pois} \\equiv 1\\), whereas values of \\(J(r) &gt; 1\\) are consistent with a regular (e.g., repelling) pattern, and $J(r) &lt; 1 represents a clustered process (Baddeley, Rubak, and Turner 2015, 274–76).\n\n\nCode\np_G &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Gest', 'rs', bootstrap = FALSE)\np_F &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Fest', 'rs', bootstrap = FALSE)\np_J &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Jest', 'rs', bootstrap = FALSE)\n\n\n\n\nCode\nwrap_plots(list(p_G,p_F,p_J), guides = 'collect')\n\n\n\n\n\n\n\n\n[MR: so if there are inhomogeneous versions, should we skip the plots above? Or not, because the inhomogeneous versions are inaccurate because they still assume correlation stationarity. What do we do?!? We need to be careful not to paint overselves into a corner.]\nThere are inhomogeneous variants of the spacing functions explained above\n\n\nCode\np_G &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Ginhom', 'bord')\np_F &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Finhom', 'bord')\np_J &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Jinhom', 'bord')\n\n\n\n\nCode\nwrap_plots(list(p_G,p_F,p_J), guides = 'collect')\n\n\n\n\n\n[ME: add some text to inhomogeneity]\n\n\n\nNext to the NN distance, we can estimate the orientation of the neighbours, which gives an indication of the orientation of the spacing. It works by taking the angle between each point and its \\(k^{th}\\) nearest neighbour. The angle is anticlockwise from the x-axis (Baddeley, Rubak, and Turner 2015, 278–79) (Baddeley and Turner 2005).\n\n\nCode\np &lt;- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'phi', 'nnorient', 'bordm', bootstrap = FALSE)\np\n\n\n\n\n\nThe values of \\(\\phi\\) correspond to the orientation of the point pattern. The horizontal axis goes from \\(180\\) to \\(0\\) (left to right) and the vertical from \\(90\\) to \\(270\\) (top to bottom) [MR: I find this description quite confusing, because you are not talking about the horizontal/vertical axis of the metric plot, but rather the orientations in the point patterns. And since certain \\(\\phi\\)s represent these orientations, is it worth adding some shading of the x-axis to highlight this? Thicker lines would also benefit the old people reading this. And I wonder if faceting on celltype would help also. What does the Y-axis represent? And are there local variants of these? Maybe the clustered OD cells have a different orientation than the non-clustered?].\nWe can infer that the orientation of the Ependymal NNs is primarily along the vertical axis, OD mature cells do not show a clear orientation and microglial cells a horizontal orientation in their NNs with a modest peak at \\(\\sim 180\\) (orientation to the top).\nNote also tha the concepts of spacing are not only usable in point pattern analysis but also more broadly in other spatial contexts (e.g., spacing between shapes instead of points).\n\n\n\nThe same consideration about edge effects as for the \\(K\\) (and related) functions need to be made for the spacing functions; uncorrected estimates are negatively biased estimators. The easiest approach is to draw an artificial border and consider NNs within it. Other approaches are based on sampling. Yet another approach relates to survival analysis, with the idea is that a circle of a point to grows homogeneously with increasing radius until it hits the frame of the window and “dies”. This gives survival distributions similar to censored data, where the Kaplan-Meier estimator is the optimal choice (Baddeley, Rubak, and Turner 2015, 286–92)."
  },
  {
    "objectID": "01-within-marks.html#session-info",
    "href": "01-within-marks.html#session-info",
    "title": "Discrete Marks",
    "section": "Session info",
    "text": "Session info\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-14                      reshape2_1.4.4                \n[19] patchwork_1.1.3                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.4.4                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] numDeriv_2016.8-1.1           backports_1.4.1              \n  [7] tools_4.3.1                   utf8_1.2.3                   \n  [9] R6_2.5.1                      HDF5Array_1.28.1             \n [11] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [13] withr_2.5.1                   gridExtra_2.3                \n [15] leaflet_2.2.0                 leafem_0.2.3                 \n [17] cli_3.6.1                     labeling_0.4.3               \n [19] proxy_0.4-27                  foreign_0.8-84               \n [21] R.utils_2.12.2                dichromat_2.0-0.1            \n [23] scico_1.5.0                   limma_3.56.2                 \n [25] rstudioapi_0.15.0             RSQLite_2.3.1                \n [27] generics_0.1.3                crosstalk_1.2.0              \n [29] Matrix_1.5-4.1                ggbeeswarm_0.7.2             \n [31] fansi_1.0.5                   abind_1.4-5                  \n [33] R.methodsS3_1.8.2             terra_1.7-55                 \n [35] lifecycle_1.0.3               yaml_2.3.7                   \n [37] edgeR_3.42.4                  rhdf5_2.44.0                 \n [39] tmaptools_3.1-1               grid_4.3.1                   \n [41] blob_1.2.4                    promises_1.2.1               \n [43] dqrng_0.3.1                   crayon_1.5.2                 \n [45] lattice_0.21-8                beachmat_2.16.0              \n [47] KEGGREST_1.40.1               magick_2.8.0                 \n [49] pillar_1.9.0                  knitr_1.44                   \n [51] metapod_1.7.0                 rjson_0.2.21                 \n [53] boot_1.3-28.1                 codetools_0.2-19             \n [55] wk_0.8.0                      glue_1.6.2                   \n [57] data.table_1.14.8             vctrs_0.6.4                  \n [59] png_0.1-8                     gtable_0.3.4                 \n [61] cachem_1.0.8                  xfun_0.40                    \n [63] S4Arrays_1.0.6                mime_0.12                    \n [65] DropletUtils_1.20.0           pracma_2.4.2                 \n [67] units_0.8-4                   statmod_1.5.0                \n [69] bluster_1.10.0                interactiveDisplayBase_1.38.0\n [71] ellipsis_0.3.2                bit64_4.0.5                  \n [73] filelock_1.0.2                irlba_2.3.5.1                \n [75] vipor_0.4.5                   KernSmooth_2.23-21           \n [77] Hmisc_5.1-1                   colorspace_2.1-0             \n [79] DBI_1.1.3                     nnet_7.3-19                  \n [81] raster_3.6-26                 tidyselect_1.2.0             \n [83] bit_4.0.5                     compiler_4.3.1               \n [85] curl_5.1.0                    htmlTable_2.4.1              \n [87] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [89] checkmate_2.2.0               scales_1.2.1                 \n [91] classInt_0.4-10               rappdirs_0.3.3               \n [93] goftest_1.2-3                 fftwtools_0.9-11             \n [95] spatstat.utils_3.0-3          rmarkdown_2.25               \n [97] XVector_0.40.0                htmltools_0.5.6.1            \n [99] pkgconfig_2.0.3               base64enc_0.1-3              \n[101] sparseMatrixStats_1.12.2      fastmap_1.1.1                \n[103] htmlwidgets_1.6.2             shiny_1.7.5.1                \n[105] DelayedMatrixStats_1.22.6     farver_2.1.1                 \n[107] jsonlite_1.8.7                BiocParallel_1.34.2          \n[109] R.oo_1.25.0                   BiocSingular_1.16.0          \n[111] RCurl_1.98-1.12               Formula_1.2-5                \n[113] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[115] Rhdf5lib_1.22.1               munsell_0.5.0                \n[117] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[119] viridis_0.6.4                 stringi_1.7.12               \n[121] leafsync_0.1.0                MASS_7.3-60                  \n[123] zlibbioc_1.46.0               plyr_1.8.9                   \n[125] parallel_4.3.1                ggrepel_0.9.4                \n[127] deldir_1.0-9                  Biostrings_2.68.1            \n[129] stars_0.6-4                   splines_4.3.1                \n[131] tensor_1.5                    locfit_1.5-9.8               \n[133] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[135] BiocVersion_3.17.1            XML_3.99-0.14                \n[137] evaluate_0.22                 BiocManager_1.30.22          \n[139] httpuv_1.6.11                 purrr_1.0.2                  \n[141] polyclip_1.10-6               rsvd_1.0.5                   \n[143] lwgeom_0.2-13                 xtable_1.8-4                 \n[145] fdapace_0.5.9                 e1071_1.7-13                 \n[147] RSpectra_0.16-1               later_1.3.1                  \n[149] viridisLite_0.4.2             class_7.3-22                 \n[151] tibble_3.2.1                  memoise_2.0.1                \n[153] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[155] cluster_2.1.4"
  },
  {
    "objectID": "03-spotbased.html",
    "href": "03-spotbased.html",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\ntheme_set(theme_light())\n\n\n\n\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\n#calculate the highly variable genes\ndec &lt;- scran::modelGeneVar(sfe_tissue, lowess = FALSE)\nhvgs &lt;- scran::getTopHVGs(dec, n = 200)\n\n#calcualte the principal components of \nsfe_tissue &lt;- scater::runPCA(sfe_tissue, ncomponents = 20, subset_row = hvgs) \n\n\n\n\nSpot based data is collected along a regular spaced grid where all sample areas have the same size. Such a grid is also called a regular lattice. In more rigorous terms the data \\(Y\\) is the product of a random process but the sampling locations are fixed along a lattice \\(D\\). The lattice \\(D\\) does not have to regular but in the scope of spot based data it is. The main difference of this type of data in comparison to point patterns is, that the locations of the data are then not results of a stochastic process but rather due to a defined sampling strategy [1].\nThe lattice is composed of individual spatial units\n\\[\nD = \\{A_1, A_2,...,A_n\\}\n\\] where these units are not supposed to overlap\n\\[\nA_i \\cap A_j = \\emptyset \\forall i \\neq j\n\\]\nThe data is then a random variable of the spatial unit along the lattice\n\\[\nY_i = Y(A_i)\n\\]\n–&gt; need to find the papers mentioned here!!\nA lot of lattice data analysis technique build on the concept of neighbours. Therefore, the spatial relationship has to be modelled with e.g. a spatial weigth matrix \\(W\\). There are a lot of ways to define a spatial weigth matrix \\(W\\). An intuitive way is from Cliff and Ord (1981) and Upton and Fingleton (1985). Here, the units that are adjacent are specified with a one and the ones that are not adjacent with a zero (inary coniguity matrix) [1].\n\\[\nw_{ij} = \\begin{cases}\n1 \\text{ if } A_i \\text{ and } A_j \\text{ are adjacent}\\\\\n0 \\text{ otw}\n\\end{cases}\n\\]\nother options to specify the weight matrix \\(W\\) are mentioned in [1].\n\n\n\nGlobal measures are values across an entire field of view. This gives e.g. one number per field of view.\nA common analysis to do with lattice data (and point pattern data) is to check for spatial correlation. This is a second-order property of the form (Getis 1991)\n\\[\n\\sum_i \\sum_j = w_{ij}U_{ij}\n\\]\nwhere \\(w_{ij}\\) is the weight matrix and \\(U_{ij}\\) a dissimilarity measure. [1]\n\n\nA common dissimilarity measure is Morans \\(I\\). It is defined by [1]\n\\[\nI = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(y_i - \\hat{y})(y_j - \\hat{y})}{\\sum_i (y_i - \\hat{y})^2}\n\\]\nUnder the null \\(I\\) takes the value \\(-1/(n-1)\\) in expectation. This value is close to \\(0\\) for large \\(n\\). A value higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation. Negative values indicate negative auto-correlation, but this is not so easy to interpret [1]. The implementation below is a Monte Carlo simulation approach to define a null distribution to test against.\n\n\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\nplotSpatialFeature(sfe_tissue, features = \"nCounts\", \n                   colGeometryName = \"spotPoly\",\n                   annotGeometryName = \"myofiber_simplified\", \n                   aes_use = \"color\", linewidth = 0.5, fill = NA,\n                   annot_aes = list(fill = \"area\"))\n\nsfe_tissue &lt;-  colDataUnivariate(sfe_tissue, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"visium\", nsim = 1000,\n                                type = \"moran.mc\")\n\nres &lt;- colFeatureData(sfe_tissue)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$moran.mc_statistic_Vis5A\n#p-value\nres$moran.mc_p.value_Vis5A\n\nplotMoranMC(sfe_tissue, c(\"nCounts\", \"nGenes\"))\n\n\n\n\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe_tissue, \"visium\")\nspdep::moran.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe_tissue$nGenes  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 19.758, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.3840275174     -0.0010741139      0.0003798881 \n\nspdep::moran.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe_tissue$nCounts  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 27.181, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.5287046946     -0.0010741139      0.0003798881 \n\n\nThe number of genes per spot shows a Moran’s \\(I\\) of \\(\\sim 0.38\\) which indicates auto-correlation. The number of counts per spot shows a Moran’s \\(I\\) of \\(\\sim 0.53\\).\n\n\n\n\nAnother measure of spatial auto-correlation is Geary’s \\(C\\). It is very closely related to Moran’s \\(I\\). Geary’s \\(C\\) is defined by:\n\\[\nC = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(y_i-y_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(y_i-\\bar{y})^2}\n\\]\nThe interpretation is inveresely to Moran’s \\(I\\). A value less than \\(1\\) indicates positive auto-correlation, a value more than \\(1\\) negative auto-correlation. (https://pachterlab.github.io/voyager/articles/visium_10x.html)\nThe testing works similarly to Moran’s \\(I\\), just the objective function changes in the Monte Carlo estimation\n\n\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\nsfe_tissue &lt;-  colDataUnivariate(sfe_tissue, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"visium\", nsim = 1000,\n                                type = \"geary.mc\")\n\nres &lt;- colFeatureData(sfe_tissue)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$geary.mc_statistic_Vis5A\n\n[1] 0.4748925 0.6057966\n\n#p-value\nres$geary.mc_p.value_Vis5A\n\n[1] 0.000999001 0.000999001\n\n\n\n\n\n\nspdep::geary.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe_tissue$nGenes \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 19.996, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     0.6057966472      1.0000000000      0.0003886284 \n\nspdep::geary.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe_tissue$nCounts \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 26.729, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     0.4748924980      1.0000000000      0.0003859596 \n\n\nThe Geary’s \\(C\\) statistic gives a value of \\(0.47\\) for the number of counts and \\(0.61\\) for the number of genes. The interpretation is that both features show positive auto correlation.\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/gean.12164\n\n\n\n\nThe global \\(G\\) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in teh dataset. Formally that is,\n\\[\nG(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j}, \\text{s.t } j \\neq i\n\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather considering both approaches.\n–&gt; weights should be binarised for this test - how to do this?\n\nspdep::globalG.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods)\n\n\n    Getis-Ord global G statistic\n\ndata:  sfe_tissue$nGenes \nweights: weights_neighbourhoods \n\nstandard deviate = 20.757, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.185181e-03       1.074114e-03       2.863192e-11 \n\nspdep::globalG.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods)\n\n\n    Getis-Ord global G statistic\n\ndata:  sfe_tissue$nCounts \nweights: weights_neighbourhoods \n\nstandard deviate = 27.797, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.361423e-03       1.074114e-03       1.068346e-10 \n\n\n[5]\n\n\n\n\n\n\nOften a global measure is not enough. One number determining e.g. the spatial autocorrelation over an entire tissue slice might not be reflective of tissue heterogeneity. Therefore, local indicators of spatial associations have been developed [2]. For each sampling location we calculate as follows (https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1538-4632.1995.tb00338.x) (formula from ?localmoran)\n\\[\nI_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\n\\]\nSince we are calculating several local statistics potentially from the same observations, problems of multiple testing arise. We correct for this issue with standard adjustments, such as Benjamini Hochberg correction (https://rss.onlinelibrary.wiley.com/doi/10.1111/j.2517-6161.1995.tb02031.x). The problem of false positives due to multiple testing is discussed in great detail in [2].\nImplementation with spdep\n\n#calculate local Moran's I and then correct for multiple testing using Benjamini-Hochberg correction if you want to plot p-values\nlocalplot &lt;- function(sfe, var, fun, plotvar){\n  loc &lt;- do.call(fun, args = list(x=sfe[[var]], listw = weights_neighbourhoods))\n  #why so ever, 'localG' has a different return structure than 'localmoran'. Thus, this conditional with different indexing\n  if(fun %in% c('localG')){\n    loc &lt;- attr(loc, 'internals')\n    #extract the effect size\n    locEffect &lt;- loc[,1]\n    #extract the p-value and adjust for multiple testing\n    p.val.adj &lt;- loc[,5] |&gt; p.adjust(\"BH\")\n  }\n  else if(fun == 'localC_perm'){\n    p.val.adj &lt;- attr(loc, 'pseudo-p')[,'Pr(z != E(Ci))']\n    locEffect &lt;- loc\n  }\n  else if (fun == 'LOSH'){\n    locEffect &lt;- loc[,1]\n    p.val.adj &lt;- c()\n  }\n  else{\n    #extract the effect size\n    locEffect &lt;- loc[,1]\n    #extract the p-value and adjust for multiple testing\n    p.val.adj &lt;- loc[,5] |&gt; p.adjust(\"BH\")\n  }\n  \n  #convert into a plain sf object for plotting\n  sf &lt;- colGeometries(sfe)$spotPoly\n  \n  sf$locEffect &lt;- locEffect\n  sf$p.val.adj &lt;- p.val.adj\n  \n  return(tm_shape(sf) + tm_fill(col = plotvar))\n}\n\np &lt;- localplot(sfe_tissue, 'nCounts', fun = 'localmoran', plotvar = 'locEffect')\nq &lt;- localplot(sfe_tissue, 'nGenes', fun = 'localmoran', plotvar = 'locEffect')\n\ntmap_arrange(p,q)\n\n\n\n\n\n\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localmoran\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localmoran\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\n\nGeary’s C can be calculated for local interactions as well.\n\\[\nC_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2\n\\]\nThe interpretation is the same as for local Moran’s \\(I\\) [6].\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'localC_perm', plotvar = 'locEffect')\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'localC_perm', plotvar = 'locEffect')\n\ntmap_arrange(p,q)\n\n\n\n\n\n\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localC_perm\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localC_perm\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\n\nThe local Getis-Ord \\(G_i\\) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\).\n\\[\nG_i(d) = \\frac{\\sum_{j=1}^n w_{ij}(d)x_j}{\\sum_{j=1}^n x_j}, \\text{s.t } j \\neq i\n\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\) which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term. Importantly, \\(G_i(d)\\) is scale-invariant but not location-invariant. That means, the subdivision into the \\(n\\) subregions matterns for the computation of the local statistic [5].\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'localG', plotvar = 'locEffect')\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'localG', plotvar = 'locEffect')\n\ntmap_arrange(p,q)\n\n\n\n\n\n\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\n\nThe univariate methods described above assume homoscedastic variance so that the variance is uniform over the sampling area [4]. In the context of tumour-immune infiltration we could have regions where the mean infiltration is the same but the variability depends on the specific pathology. Therefore, a new statistic was introduced, local spatial heteroscedasticity (LOSH). The aim of LOSH is similar to the local \\(G\\) statistic, where we compared means, to now compare variances. The aim is to compare homogeienity and heterogeneity of groups in space. This statistic is especially interesting in combination with the local \\(G\\) statistic, giving an overview on the mean-variance relationship of the sample [4].\nLOSH is defined formally as follows:\n\\[\nH_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\n\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_j(d), j\\in N(i,d)\\) are the local residuals [4].\nOrd and Getis provide a very nice table for the interpretation of the mean and variance relationship provided by \\(G_i\\) and \\(H_i\\).\n–&gt; insert table\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'LOSH', plotvar = 'locEffect')\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'LOSH', plotvar = 'locEffect')\n\ntmap_arrange(p,q)\n\n\n\n\n\n\n\n\nSo far, we have considered methods for univariate data, so where we looked at the change of one variable in several contexts. Spatial methods for bi- and multivariate data exist as well and will be discussed in the following.\n\n\nThe implementation in the package spdep is as follows:\n\\[\nL(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}}\n\\] (https://r-spatial.github.io/spdep/reference/lee.htmlls)\nLee’s \\(L\\) is a bivariate measure that combines non-spatial Pearson Correlation with spatial autocorrelation via Moran’s \\(I\\) [3]. Instead of looking at the auto-correlation of one signle variable we can now assess the spatial dependence of two variables.\n\nloc &lt;- lee(x = sfe_tissue$nCounts, y = sfe_tissue$nGenes, n = length(sfe_tissue$nCounts), listw = weights_neighbourhoods)\n\n#convert into a plain sf object for plotting\nsf &lt;- colGeometries(sfe_tissue)$spotPoly\n\nsf$locEffect &lt;- loc$localL\n\ntm_shape(sf) + tm_fill(col = 'locEffect')  \n\n\n\n\n\n\n\nsfe_tissue &lt;- runBivariate(sfe_tissue, \"locallee\", swap_rownames = \"symbol\",\n                           feature1 = c('nGenes', 'nCounts'))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\n\n\nThere is a very nice resource explaining in detail the available methods for lattice data (amongst others) (https://pachterlab.github.io/voyager/index.html). We will summarise complement these approaches in this chapter"
  },
  {
    "objectID": "03-spotbased.html#dependencies",
    "href": "03-spotbased.html#dependencies",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\ntheme_set(theme_light())"
  },
  {
    "objectID": "03-spotbased.html#setup-and-preprocessing",
    "href": "03-spotbased.html#setup-and-preprocessing",
    "title": "Preamble",
    "section": "",
    "text": "# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\n#calculate the highly variable genes\ndec &lt;- scran::modelGeneVar(sfe_tissue, lowess = FALSE)\nhvgs &lt;- scran::getTopHVGs(dec, n = 200)\n\n#calcualte the principal components of \nsfe_tissue &lt;- scater::runPCA(sfe_tissue, ncomponents = 20, subset_row = hvgs)"
  },
  {
    "objectID": "03-spotbased.html#regular-lattice-data",
    "href": "03-spotbased.html#regular-lattice-data",
    "title": "Preamble",
    "section": "",
    "text": "Spot based data is collected along a regular spaced grid where all sample areas have the same size. Such a grid is also called a regular lattice. In more rigorous terms the data \\(Y\\) is the product of a random process but the sampling locations are fixed along a lattice \\(D\\). The lattice \\(D\\) does not have to regular but in the scope of spot based data it is. The main difference of this type of data in comparison to point patterns is, that the locations of the data are then not results of a stochastic process but rather due to a defined sampling strategy [1].\nThe lattice is composed of individual spatial units\n\\[\nD = \\{A_1, A_2,...,A_n\\}\n\\] where these units are not supposed to overlap\n\\[\nA_i \\cap A_j = \\emptyset \\forall i \\neq j\n\\]\nThe data is then a random variable of the spatial unit along the lattice\n\\[\nY_i = Y(A_i)\n\\]\n–&gt; need to find the papers mentioned here!!\nA lot of lattice data analysis technique build on the concept of neighbours. Therefore, the spatial relationship has to be modelled with e.g. a spatial weigth matrix \\(W\\). There are a lot of ways to define a spatial weigth matrix \\(W\\). An intuitive way is from Cliff and Ord (1981) and Upton and Fingleton (1985). Here, the units that are adjacent are specified with a one and the ones that are not adjacent with a zero (inary coniguity matrix) [1].\n\\[\nw_{ij} = \\begin{cases}\n1 \\text{ if } A_i \\text{ and } A_j \\text{ are adjacent}\\\\\n0 \\text{ otw}\n\\end{cases}\n\\]\nother options to specify the weight matrix \\(W\\) are mentioned in [1]."
  },
  {
    "objectID": "03-spotbased.html#global-measures-for-univariate-data",
    "href": "03-spotbased.html#global-measures-for-univariate-data",
    "title": "Preamble",
    "section": "",
    "text": "Global measures are values across an entire field of view. This gives e.g. one number per field of view.\nA common analysis to do with lattice data (and point pattern data) is to check for spatial correlation. This is a second-order property of the form (Getis 1991)\n\\[\n\\sum_i \\sum_j = w_{ij}U_{ij}\n\\]\nwhere \\(w_{ij}\\) is the weight matrix and \\(U_{ij}\\) a dissimilarity measure. [1]\n\n\nA common dissimilarity measure is Morans \\(I\\). It is defined by [1]\n\\[\nI = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(y_i - \\hat{y})(y_j - \\hat{y})}{\\sum_i (y_i - \\hat{y})^2}\n\\]\nUnder the null \\(I\\) takes the value \\(-1/(n-1)\\) in expectation. This value is close to \\(0\\) for large \\(n\\). A value higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation. Negative values indicate negative auto-correlation, but this is not so easy to interpret [1]. The implementation below is a Monte Carlo simulation approach to define a null distribution to test against.\n\n\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\nplotSpatialFeature(sfe_tissue, features = \"nCounts\", \n                   colGeometryName = \"spotPoly\",\n                   annotGeometryName = \"myofiber_simplified\", \n                   aes_use = \"color\", linewidth = 0.5, fill = NA,\n                   annot_aes = list(fill = \"area\"))\n\nsfe_tissue &lt;-  colDataUnivariate(sfe_tissue, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"visium\", nsim = 1000,\n                                type = \"moran.mc\")\n\nres &lt;- colFeatureData(sfe_tissue)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$moran.mc_statistic_Vis5A\n#p-value\nres$moran.mc_p.value_Vis5A\n\nplotMoranMC(sfe_tissue, c(\"nCounts\", \"nGenes\"))\n\n\n\n\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe_tissue, \"visium\")\nspdep::moran.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe_tissue$nGenes  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 19.758, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.3840275174     -0.0010741139      0.0003798881 \n\nspdep::moran.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe_tissue$nCounts  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 27.181, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.5287046946     -0.0010741139      0.0003798881 \n\n\nThe number of genes per spot shows a Moran’s \\(I\\) of \\(\\sim 0.38\\) which indicates auto-correlation. The number of counts per spot shows a Moran’s \\(I\\) of \\(\\sim 0.53\\).\n\n\n\n\nAnother measure of spatial auto-correlation is Geary’s \\(C\\). It is very closely related to Moran’s \\(I\\). Geary’s \\(C\\) is defined by:\n\\[\nC = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(y_i-y_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(y_i-\\bar{y})^2}\n\\]\nThe interpretation is inveresely to Moran’s \\(I\\). A value less than \\(1\\) indicates positive auto-correlation, a value more than \\(1\\) negative auto-correlation. (https://pachterlab.github.io/voyager/articles/visium_10x.html)\nThe testing works similarly to Moran’s \\(I\\), just the objective function changes in the Monte Carlo estimation\n\n\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\nsfe_tissue &lt;-  colDataUnivariate(sfe_tissue, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"visium\", nsim = 1000,\n                                type = \"geary.mc\")\n\nres &lt;- colFeatureData(sfe_tissue)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$geary.mc_statistic_Vis5A\n\n[1] 0.4748925 0.6057966\n\n#p-value\nres$geary.mc_p.value_Vis5A\n\n[1] 0.000999001 0.000999001\n\n\n\n\n\n\nspdep::geary.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe_tissue$nGenes \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 19.996, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     0.6057966472      1.0000000000      0.0003886284 \n\nspdep::geary.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe_tissue$nCounts \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 26.729, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     0.4748924980      1.0000000000      0.0003859596 \n\n\nThe Geary’s \\(C\\) statistic gives a value of \\(0.47\\) for the number of counts and \\(0.61\\) for the number of genes. The interpretation is that both features show positive auto correlation.\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/gean.12164\n\n\n\n\nThe global \\(G\\) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in teh dataset. Formally that is,\n\\[\nG(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j}, \\text{s.t } j \\neq i\n\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather considering both approaches.\n–&gt; weights should be binarised for this test - how to do this?\n\nspdep::globalG.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods)\n\n\n    Getis-Ord global G statistic\n\ndata:  sfe_tissue$nGenes \nweights: weights_neighbourhoods \n\nstandard deviate = 20.757, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.185181e-03       1.074114e-03       2.863192e-11 \n\nspdep::globalG.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods)\n\n\n    Getis-Ord global G statistic\n\ndata:  sfe_tissue$nCounts \nweights: weights_neighbourhoods \n\nstandard deviate = 27.797, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.361423e-03       1.074114e-03       1.068346e-10 \n\n\n[5]"
  },
  {
    "objectID": "03-spotbased.html#local-measures-for-univariate-data",
    "href": "03-spotbased.html#local-measures-for-univariate-data",
    "title": "Preamble",
    "section": "",
    "text": "Often a global measure is not enough. One number determining e.g. the spatial autocorrelation over an entire tissue slice might not be reflective of tissue heterogeneity. Therefore, local indicators of spatial associations have been developed [2]. For each sampling location we calculate as follows (https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1538-4632.1995.tb00338.x) (formula from ?localmoran)\n\\[\nI_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\n\\]\nSince we are calculating several local statistics potentially from the same observations, problems of multiple testing arise. We correct for this issue with standard adjustments, such as Benjamini Hochberg correction (https://rss.onlinelibrary.wiley.com/doi/10.1111/j.2517-6161.1995.tb02031.x). The problem of false positives due to multiple testing is discussed in great detail in [2].\nImplementation with spdep\n\n#calculate local Moran's I and then correct for multiple testing using Benjamini-Hochberg correction if you want to plot p-values\nlocalplot &lt;- function(sfe, var, fun, plotvar){\n  loc &lt;- do.call(fun, args = list(x=sfe[[var]], listw = weights_neighbourhoods))\n  #why so ever, 'localG' has a different return structure than 'localmoran'. Thus, this conditional with different indexing\n  if(fun %in% c('localG')){\n    loc &lt;- attr(loc, 'internals')\n    #extract the effect size\n    locEffect &lt;- loc[,1]\n    #extract the p-value and adjust for multiple testing\n    p.val.adj &lt;- loc[,5] |&gt; p.adjust(\"BH\")\n  }\n  else if(fun == 'localC_perm'){\n    p.val.adj &lt;- attr(loc, 'pseudo-p')[,'Pr(z != E(Ci))']\n    locEffect &lt;- loc\n  }\n  else if (fun == 'LOSH'){\n    locEffect &lt;- loc[,1]\n    p.val.adj &lt;- c()\n  }\n  else{\n    #extract the effect size\n    locEffect &lt;- loc[,1]\n    #extract the p-value and adjust for multiple testing\n    p.val.adj &lt;- loc[,5] |&gt; p.adjust(\"BH\")\n  }\n  \n  #convert into a plain sf object for plotting\n  sf &lt;- colGeometries(sfe)$spotPoly\n  \n  sf$locEffect &lt;- locEffect\n  sf$p.val.adj &lt;- p.val.adj\n  \n  return(tm_shape(sf) + tm_fill(col = plotvar))\n}\n\np &lt;- localplot(sfe_tissue, 'nCounts', fun = 'localmoran', plotvar = 'locEffect')\nq &lt;- localplot(sfe_tissue, 'nGenes', fun = 'localmoran', plotvar = 'locEffect')\n\ntmap_arrange(p,q)\n\n\n\n\n\n\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localmoran\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localmoran\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\n\nGeary’s C can be calculated for local interactions as well.\n\\[\nC_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2\n\\]\nThe interpretation is the same as for local Moran’s \\(I\\) [6].\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'localC_perm', plotvar = 'locEffect')\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'localC_perm', plotvar = 'locEffect')\n\ntmap_arrange(p,q)\n\n\n\n\n\n\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localC_perm\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localC_perm\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\n\nThe local Getis-Ord \\(G_i\\) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\).\n\\[\nG_i(d) = \\frac{\\sum_{j=1}^n w_{ij}(d)x_j}{\\sum_{j=1}^n x_j}, \\text{s.t } j \\neq i\n\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\) which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term. Importantly, \\(G_i(d)\\) is scale-invariant but not location-invariant. That means, the subdivision into the \\(n\\) subregions matterns for the computation of the local statistic [5].\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'localG', plotvar = 'locEffect')\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'localG', plotvar = 'locEffect')\n\ntmap_arrange(p,q)\n\n\n\n\n\n\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\n\nThe univariate methods described above assume homoscedastic variance so that the variance is uniform over the sampling area [4]. In the context of tumour-immune infiltration we could have regions where the mean infiltration is the same but the variability depends on the specific pathology. Therefore, a new statistic was introduced, local spatial heteroscedasticity (LOSH). The aim of LOSH is similar to the local \\(G\\) statistic, where we compared means, to now compare variances. The aim is to compare homogeienity and heterogeneity of groups in space. This statistic is especially interesting in combination with the local \\(G\\) statistic, giving an overview on the mean-variance relationship of the sample [4].\nLOSH is defined formally as follows:\n\\[\nH_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\n\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_j(d), j\\in N(i,d)\\) are the local residuals [4].\nOrd and Getis provide a very nice table for the interpretation of the mean and variance relationship provided by \\(G_i\\) and \\(H_i\\).\n–&gt; insert table\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'LOSH', plotvar = 'locEffect')\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'LOSH', plotvar = 'locEffect')\n\ntmap_arrange(p,q)"
  },
  {
    "objectID": "03-spotbased.html#measures-for-bi--and-multivariate-data",
    "href": "03-spotbased.html#measures-for-bi--and-multivariate-data",
    "title": "Preamble",
    "section": "",
    "text": "So far, we have considered methods for univariate data, so where we looked at the change of one variable in several contexts. Spatial methods for bi- and multivariate data exist as well and will be discussed in the following.\n\n\nThe implementation in the package spdep is as follows:\n\\[\nL(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}}\n\\] (https://r-spatial.github.io/spdep/reference/lee.htmlls)\nLee’s \\(L\\) is a bivariate measure that combines non-spatial Pearson Correlation with spatial autocorrelation via Moran’s \\(I\\) [3]. Instead of looking at the auto-correlation of one signle variable we can now assess the spatial dependence of two variables.\n\nloc &lt;- lee(x = sfe_tissue$nCounts, y = sfe_tissue$nGenes, n = length(sfe_tissue$nCounts), listw = weights_neighbourhoods)\n\n#convert into a plain sf object for plotting\nsf &lt;- colGeometries(sfe_tissue)$spotPoly\n\nsf$locEffect &lt;- loc$localL\n\ntm_shape(sf) + tm_fill(col = 'locEffect')  \n\n\n\n\n\n\n\nsfe_tissue &lt;- runBivariate(sfe_tissue, \"locallee\", swap_rownames = \"symbol\",\n                           feature1 = c('nGenes', 'nCounts'))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)"
  },
  {
    "objectID": "03-spotbased.html#voyager",
    "href": "03-spotbased.html#voyager",
    "title": "Preamble",
    "section": "",
    "text": "There is a very nice resource explaining in detail the available methods for lattice data (amongst others) (https://pachterlab.github.io/voyager/index.html). We will summarise complement these approaches in this chapter"
  },
  {
    "objectID": "03-spotbased.html#sources",
    "href": "03-spotbased.html#sources",
    "title": "Preamble",
    "section": "Sources",
    "text": "Sources\n[1] Zuur, A. F., Ieno, E. N., Smith, G. M., Saveliev, A. A., Mukharamova, S. S., & Zuur, A. F. (2007). Analysis and modelling of lattice data. Analysing Ecological Data, 321-339.\n[2] Pebesma, E., & Bivand, R. (2023). Spatial data science: With applications in R. CRC Press.\n[3] Lee, S. I. (2001). Developing a bivariate spatial association measure: an integration of Pearson’s r and Moran’s I. Journal of geographical systems, 3, 369-385.\n[4] Ord, J. K., & Getis, A. (2012). Local spatial heteroscedasticity (LOSH). The Annals of Regional Science, 48, 529-539.\n[5] Getis, A., & Ord, J. K. (1992). The analysis of spatial association by use of distance statistics. Geographical analysis, 24(3), 189-206.\n[6] Anselin, L. (1995). Local indicators of spatial association—LISA. Geographical analysis, 27(2), 93-115. ## Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] stringr_1.5.0                  dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.9.4                  SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-14                     \n[17] reshape2_1.4.4                 patchwork_1.1.3               \n[19] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[21] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[23] dbplyr_2.3.4                   RANN_2.6.1                    \n[25] seg_0.5-7                      sp_2.1-1                      \n[27] rlang_1.1.1                    ggplot2_3.4.4                 \n[29] dplyr_1.1.3                    mixR_0.2.0                    \n[31] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[33] spatstat.model_3.2-6           rpart_4.1.19                  \n[35] spatstat.explore_3.2-3         nlme_3.1-162                  \n[37] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[39] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[41] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[43] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[45] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[47] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[49] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     proxy_0.4-27                 \n [17] dbscan_1.1-11                 R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.2.1                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] spatstat.utils_3.0-3          rmarkdown_2.25               \n [87] XVector_0.40.0                htmltools_0.5.6.1            \n [89] pkgconfig_2.0.3               base64enc_0.1-3              \n [91] sparseMatrixStats_1.12.2      fastmap_1.1.1                \n [93] htmlwidgets_1.6.2             shiny_1.7.5.1                \n [95] DelayedMatrixStats_1.22.6     jsonlite_1.8.7               \n [97] BiocParallel_1.34.2           R.oo_1.25.0                  \n [99] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[101] magrittr_2.0.3                GenomeInfoDbData_1.2.10      \n[103] s2_1.1.4                      Rhdf5lib_1.22.1              \n[105] munsell_0.5.0                 Rcpp_1.0.11                  \n[107] ggnewscale_0.4.9              viridis_0.6.4                \n[109] stringi_1.7.12                leafsync_0.1.0               \n[111] zlibbioc_1.46.0               plyr_1.8.9                   \n[113] parallel_4.3.1                ggrepel_0.9.4                \n[115] deldir_1.0-9                  Biostrings_2.68.1            \n[117] stars_0.6-4                   splines_4.3.1                \n[119] tensor_1.5                    locfit_1.5-9.8               \n[121] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[123] BiocVersion_3.17.1            XML_3.99-0.14                \n[125] evaluate_0.22                 BiocManager_1.30.22          \n[127] httpuv_1.6.11                 purrr_1.0.2                  \n[129] polyclip_1.10-6               rsvd_1.0.5                   \n[131] lwgeom_0.2-13                 xtable_1.8-4                 \n[133] e1071_1.7-13                  RSpectra_0.16-1              \n[135] later_1.3.1                   viridisLite_0.4.2            \n[137] class_7.3-22                  tibble_3.2.1                 \n[139] memoise_2.0.1                 beeswarm_0.4.0               \n[141] AnnotationDbi_1.62.2          cluster_2.1.4"
  },
  {
    "objectID": "02-between-marks.html",
    "href": "02-between-marks.html",
    "title": "Discrete Marks",
    "section": "",
    "text": "source(\"utils.R\")\n\n\n\n\n\nspe &lt;- readRDS(\"../data/spe.rds\")"
  },
  {
    "objectID": "03-irregular-lattices.html",
    "href": "03-irregular-lattices.html",
    "title": "Irregular Lattices",
    "section": "",
    "text": "source(\"utils.R\")\n\nUntil now we have considered the cells to be represented in a point pattern. However, as cells have a shape and area, this might be an oversimplification in some cases. Alternatively, we can rely on the segmentation of indvidual cells that are available for various datasets. The outline of each cell is represented by a polygon and the collection of all cells can be seen as an irregular lattice. Unlike a regular lattice (the representation of spot based spatial tanscriptomics data) the sample areas in an irregular lattice can have different sizes and are not reugularly distributed over the sample space.\nFor this representation of the cells we will rely on the SpatialFeatureExperiment package. For preprocessing of the dataset we refer the reader to the vignette of the voyager package.\n\n(sfe &lt;- HeNSCLCData())\n\nclass: SpatialFeatureExperiment \ndim: 980 100290 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100290): 1_1 1_2 ... 30_4759 30_4760\ncolData names(17): Area AspectRatio ... nCounts nGenes\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n# Empty cells\ncolData(sfe)$is_empty &lt;- colData(sfe)$nCounts &lt; 1\n# Select negative control probes\nneg_inds &lt;- str_detect(rownames(sfe), \"^NegPrb\")\n# Number of negative control probes\nsum(neg_inds)\n\n[1] 20\n\ncolData(sfe)$prop_neg &lt;- colSums(counts(sfe)[neg_inds,])/colData(sfe)$nCounts\n# Remove low quality cells\n(sfe &lt;- sfe[,!sfe$is_empty & sfe$prop_neg &lt; 0.1])\n\nclass: SpatialFeatureExperiment \ndim: 980 100095 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100095): 1_1 1_2 ... 30_4759 30_4760\ncolData names(19): Area AspectRatio ... is_empty prop_neg\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n# Calculate count stats\nrowData(sfe)$means &lt;- rowMeans(counts(sfe))\nrowData(sfe)$vars &lt;- rowVars(counts(sfe))\nrowData(sfe)$is_neg &lt;- neg_inds\n# log Counts\nsfe &lt;- logNormCounts(sfe)\n\n\nplotSpatialFeature(sfe, c(\"nGenes\", \"nCounts\"),\n                   colGeometryName = \"centroids\", ncol = 2, scattermore = TRUE)\n\n\n\n\n\n\n\nMost analysis techniques rely on the a neighborhood matrix, which is a matrix that indicates which cells are neighbors. In the case of the regular lattice, the calculation of the neighborhood matrix is rather straightforward. In the case of the irregular lattice it can be more complicated as the reconstruction of the cells is often not perfect.\n\n\n\n\ncolGraph(sfe, \"knn5\") &lt;- findSpatialNeighbors(sfe, method = \"knearneigh\",\n                                                  dist_type = \"idw\", k = 5, \n                                                  style = \"W\")"
  },
  {
    "objectID": "03-irregular-lattices.html#dependencies",
    "href": "03-irregular-lattices.html#dependencies",
    "title": "Irregular Lattices",
    "section": "",
    "text": "source(\"utils.R\")\n\nUntil now we have considered the cells to be represented in a point pattern. However, as cells have a shape and area, this might be an oversimplification in some cases. Alternatively, we can rely on the segmentation of indvidual cells that are available for various datasets. The outline of each cell is represented by a polygon and the collection of all cells can be seen as an irregular lattice. Unlike a regular lattice (the representation of spot based spatial tanscriptomics data) the sample areas in an irregular lattice can have different sizes and are not reugularly distributed over the sample space.\nFor this representation of the cells we will rely on the SpatialFeatureExperiment package. For preprocessing of the dataset we refer the reader to the vignette of the voyager package.\n\n(sfe &lt;- HeNSCLCData())\n\nclass: SpatialFeatureExperiment \ndim: 980 100290 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100290): 1_1 1_2 ... 30_4759 30_4760\ncolData names(17): Area AspectRatio ... nCounts nGenes\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n# Empty cells\ncolData(sfe)$is_empty &lt;- colData(sfe)$nCounts &lt; 1\n# Select negative control probes\nneg_inds &lt;- str_detect(rownames(sfe), \"^NegPrb\")\n# Number of negative control probes\nsum(neg_inds)\n\n[1] 20\n\ncolData(sfe)$prop_neg &lt;- colSums(counts(sfe)[neg_inds,])/colData(sfe)$nCounts\n# Remove low quality cells\n(sfe &lt;- sfe[,!sfe$is_empty & sfe$prop_neg &lt; 0.1])\n\nclass: SpatialFeatureExperiment \ndim: 980 100095 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100095): 1_1 1_2 ... 30_4759 30_4760\ncolData names(19): Area AspectRatio ... is_empty prop_neg\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n# Calculate count stats\nrowData(sfe)$means &lt;- rowMeans(counts(sfe))\nrowData(sfe)$vars &lt;- rowVars(counts(sfe))\nrowData(sfe)$is_neg &lt;- neg_inds\n# log Counts\nsfe &lt;- logNormCounts(sfe)\n\n\nplotSpatialFeature(sfe, c(\"nGenes\", \"nCounts\"),\n                   colGeometryName = \"centroids\", ncol = 2, scattermore = TRUE)"
  },
  {
    "objectID": "03-irregular-lattices.html#irregular-lattice-and-neighbourhood-matrix",
    "href": "03-irregular-lattices.html#irregular-lattice-and-neighbourhood-matrix",
    "title": "Irregular Lattices",
    "section": "",
    "text": "Most analysis techniques rely on the a neighborhood matrix, which is a matrix that indicates which cells are neighbors. In the case of the regular lattice, the calculation of the neighborhood matrix is rather straightforward. In the case of the irregular lattice it can be more complicated as the reconstruction of the cells is often not perfect."
  },
  {
    "objectID": "03-irregular-lattices.html#neighbourhood-matrix",
    "href": "03-irregular-lattices.html#neighbourhood-matrix",
    "title": "Irregular Lattices",
    "section": "",
    "text": "colGraph(sfe, \"knn5\") &lt;- findSpatialNeighbors(sfe, method = \"knearneigh\",\n                                                  dist_type = \"idw\", k = 5, \n                                                  style = \"W\")"
  },
  {
    "objectID": "03-irregular-lattices.html#implementation-using-voyager",
    "href": "03-irregular-lattices.html#implementation-using-voyager",
    "title": "Irregular Lattices",
    "section": "Implementation using voyager",
    "text": "Implementation using voyager\n\nfeatures_use &lt;- c(\"nGenes\")\nsfe &lt;- colDataMoransI(sfe, features_use, colGraphName = \"knn5\")\n\ncolFeatureData(sfe)[features_use,]\n\nDataFrame with 1 row and 2 columns\n       moran_sample01 K_sample01\n            &lt;numeric&gt;  &lt;numeric&gt;\nnGenes       0.434652    3.19599\n\nsfe &lt;- colDataUnivariate(sfe, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"knn5\", nsim = 200,\n                                type = \"moran.mc\")\nres &lt;- colFeatureData(sfe)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$moran.mc_statistic_sample01\n\n[1] 0.3866646 0.4346525\n\n#p-value\nres$moran.mc_p.value_sample01\n\n[1] 0.004975124 0.004975124"
  },
  {
    "objectID": "03-irregular-lattices.html#implementation-using-spdep",
    "href": "03-irregular-lattices.html#implementation-using-spdep",
    "title": "Irregular Lattices",
    "section": "Implementation using spdep",
    "text": "Implementation using spdep\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe, \"knn5\")\nspdep::moran.test(x = sfe$nGenes, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe$nGenes  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 215.54, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     4.346525e-01     -9.990609e-06      4.066623e-06 \n\nspdep::moran.test(x = sfe$nCounts, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe$nCounts  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 191.75, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     3.866646e-01     -9.990609e-06      4.066623e-06"
  },
  {
    "objectID": "03-irregular-lattices.html#implementation-using-voyager-1",
    "href": "03-irregular-lattices.html#implementation-using-voyager-1",
    "title": "Irregular Lattices",
    "section": "Implementation using voyager",
    "text": "Implementation using voyager\n\nfeatures_use &lt;- c(\"nGenes\")\nsfe &lt;- colDataMoransI(sfe, features_use, colGraphName = \"knn5\")\n\ncolFeatureData(sfe)[features_use,]\n\nDataFrame with 1 row and 8 columns\n       moran_sample01 K_sample01 moran.mc_statistic_sample01\n            &lt;numeric&gt;  &lt;numeric&gt;                   &lt;numeric&gt;\nnGenes       0.434652    3.19599                    0.434652\n       moran.mc_parameter_sample01 moran.mc_p.value_sample01\n                         &lt;numeric&gt;                 &lt;numeric&gt;\nnGenes                         201                0.00497512\n       moran.mc_alternative_sample01 moran.mc_method_sample01\n                         &lt;character&gt;              &lt;character&gt;\nnGenes                       greater   Monte-Carlo simulati..\n                      moran.mc_res_sample01\n                                     &lt;list&gt;\nnGenes 0.00135379,0.00305822,0.00364489,...\n\nsfe &lt;- colDataUnivariate(sfe, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"knn5\", nsim = 200,\n                                type = \"geary.mc\")\nres &lt;- colFeatureData(sfe)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$geary.mc_statistic_sample01\n\n[1] 0.5757917 0.5447198\n\n#p-value\nres$geary.mc_p.value_sample01\n\n[1] 0.004975124 0.004975124"
  },
  {
    "objectID": "03-irregular-lattices.html#implementation-using-spdep-1",
    "href": "03-irregular-lattices.html#implementation-using-spdep-1",
    "title": "Irregular Lattices",
    "section": "Implementation using spdep",
    "text": "Implementation using spdep\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe, \"knn5\")\nspdep::geary.test(x = sfe$nGenes, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe$nGenes \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 215.64, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     5.447198e-01      1.000000e+00      4.457378e-06 \n\nspdep::geary.test(x = sfe$nCounts, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe$nCounts \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 187.84, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     5.757917e-01      1.000000e+00      5.100134e-06"
  },
  {
    "objectID": "03-irregular-lattices.html#session-info",
    "href": "03-irregular-lattices.html#session-info",
    "title": "Irregular Lattices",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] stringr_1.5.0                  dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.9.4                  SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-14                     \n[17] reshape2_1.4.4                 patchwork_1.1.3               \n[19] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[21] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[23] dbplyr_2.3.4                   RANN_2.6.1                    \n[25] seg_0.5-7                      sp_2.1-1                      \n[27] rlang_1.1.1                    ggplot2_3.4.4                 \n[29] dplyr_1.1.3                    mixR_0.2.0                    \n[31] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[33] spatstat.model_3.2-6           rpart_4.1.19                  \n[35] spatstat.explore_3.2-3         nlme_3.1-162                  \n[37] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[39] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[41] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[43] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[45] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[47] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[49] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.2.1                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] spatstat.utils_3.0-3          rmarkdown_2.25               \n [87] XVector_0.40.0                htmltools_0.5.6.1            \n [89] pkgconfig_2.0.3               base64enc_0.1-3              \n [91] sparseMatrixStats_1.12.2      fastmap_1.1.1                \n [93] htmlwidgets_1.6.2             shiny_1.7.5.1                \n [95] DelayedMatrixStats_1.22.6     farver_2.1.1                 \n [97] jsonlite_1.8.7                BiocParallel_1.34.2          \n [99] R.oo_1.25.0                   BiocSingular_1.16.0          \n[101] RCurl_1.98-1.12               magrittr_2.0.3               \n[103] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[105] Rhdf5lib_1.22.1               munsell_0.5.0                \n[107] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[109] viridis_0.6.4                 stringi_1.7.12               \n[111] leafsync_0.1.0                zlibbioc_1.46.0              \n[113] plyr_1.8.9                    parallel_4.3.1               \n[115] ggrepel_0.9.4                 deldir_1.0-9                 \n[117] Biostrings_2.68.1             stars_0.6-4                  \n[119] splines_4.3.1                 tensor_1.5                   \n[121] locfit_1.5-9.8                igraph_1.5.1                 \n[123] ScaledMatrix_1.8.1            BiocVersion_3.17.1           \n[125] XML_3.99-0.14                 evaluate_0.22                \n[127] BiocManager_1.30.22           httpuv_1.6.11                \n[129] purrr_1.0.2                   polyclip_1.10-6              \n[131] scattermore_1.2               rsvd_1.0.5                   \n[133] lwgeom_0.2-13                 xtable_1.8-4                 \n[135] e1071_1.7-13                  RSpectra_0.16-1              \n[137] later_1.3.1                   viridisLite_0.4.2            \n[139] class_7.3-22                  tibble_3.2.1                 \n[141] memoise_2.0.1                 beeswarm_0.4.0               \n[143] AnnotationDbi_1.62.2          cluster_2.1.4"
  },
  {
    "objectID": "01-within-marks.html#setup-1",
    "href": "01-within-marks.html#setup-1",
    "title": "Discrete Marks",
    "section": "Setup",
    "text": "Setup\n\n\nCode\n# redefine the pp here to be zstack 0.01\npp &lt;- pp[['0.01']]\n#subset the data to only look at sample ID 0.01\nsub_2CT = spe[, spe$sample_id == \"0.01\" & spe$cluster_id %in% c(\"Astrocyte\", \"Inhibitory\")]\n(pp_2CT = .ppp(sub_2CT, marks = \"cluster_id\"))\n\n\nMarked planar point pattern: 2611 points\nmarks are of storage type  'character'\nwindow: rectangle = [1222.5635, 3012.4248] x [-3990.104, -2204.671] units\n\n\nCode\nsub &lt;- spe[, spe$sample_id == '0.01']\n#[MR: this above never gets used?]\n\n\nIn spatstat, a mark can basically take any value, discrete (as we have seen above) or continuous (e.g., gene expression). In our example, we take the gene expression of some marker genes from Fig. 6 of the original publication (Baddeley, Rubak, and Turner 2015, 637) (Moffitt et al. 2018). This is a typical numerical mark for points in a biological dataset.\n\n\nCode\n#  Genes from Fig. 6 of Moffitt et al. (2018)\ngenes &lt;- c('Slc18a2', 'Esr1', 'Pgr')\ngex &lt;- assay(sub)[genes,] %&gt;% t %&gt;% as.matrix %&gt;% \n  data.frame %&gt;% set_rownames(NULL)\n# gene expression to marks [ME: is it really expression?]\nmarks(pp) &lt;- gex\n\n\n\nTODO: better plotting?\n\n\n\nCode\nplot(pp)\n\n\n\n\n\nHere we see spatial distribution of the counts of the three genes Slc18a2, Esr1 and Pgr. The size of the circles indicates the counts of the transcripts at that spot. [ME: is this true?] Since there are really a lot of points, we can’t easily distinguish general patterns of count distributions.\nWe can investigate the distribution of the marks against the spatial location of the points and against each other. This is done with the function pairs from spatstat. It generates a scatterplot of the counts of the marks (in our case the three genes) against each other and against the \\(x\\) and \\(y\\) coordinates. We can add a non-linear smoothing curve to make the general trends a bit more obvious (Baddeley, Rubak, and Turner 2015, 641).\n\n\nCode\npairs(as.data.frame(pp), panel = panel.smooth, pch=\".\")\n\n\n\n\n\nWe find that the counts of the three genes are very evenly distributed along the \\(x\\) and \\(y\\) coordinate, indicating a homogeneous distribution. The counts of Esr1 and Pgr are positively associated, indicating a dependence of these two marks. \nNN interpolations uses the nearest mark to measure the intensity at each spatial location. This is conceptually similar to taking a very small bandwidth for Gaussian kernel smoothing (Baddeley, Rubak, and Turner 2015, 642).\n\n\nCode\nplot(nnmark(pp))\n\n\n\n\n\nWe see that there is e.g. a clear spatial structure in the expression of e.g. Esr1. It shows a half moon shape."
  },
  {
    "objectID": "01-within-marks.html#summary-functions",
    "href": "01-within-marks.html#summary-functions",
    "title": "Discrete Marks",
    "section": "Summary functions",
    "text": "Summary functions\nAs in the discrete case the summary functions assume that the point process is stationary.\n\nMark correlation function\nThe mark correlation function measures the dependence between the marks at two points at distance \\(r\\). It is not a correlation in the classical sense, since it can take any nonegative value. The value of 1 indicates no correlation between the marks. The generalized mark correlation function is given by\n\\[ k_f(r) = \\frac{\\mathbb{E}[f(m(u)m(v))]}{\\mathbb{E}[f(M,M')]}\\] where \\(f(m_1,m_2)\\) is a test function with two arguments that represent the marks and returns a non-negative value. For continuous non-negative marks the choice of \\(f\\) is by default \\(f(m_1,m_2)= m_1 m_2\\). \\(M, M′\\) represent independent, identically distributed random points with same distribution as the mark of a randomly chosen point. This denominator is chosen such that random marks have a mark correlation of 1 [1].\n\nplot(markcorr(pp))\n\n\n\n\nWe can compare the mark correlation function to a pointwise simulation envelope in which we generate 5 simulations of random labeling.\n\nppEsr1 &lt;- subset(pp, select = 'Esr1')\nmarkcorr.Esr1 &lt;- envelope(ppEsr1, markcorr, nsim=10)\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\nplot(markcorr.Esr1)\n\n\n\n\nThe plot indicates that the mark correlation function is significantly different from the random case. The positive association of expression of the Esr1 gene declines with distance. This is consistent with clustering we saw in the residual plot above.\n\n\n\n\n\n\n\n\n\n\nMark-weigthed K function\nMark-weigthed K function is a generalization of the K-function in which the contribution of each from each pair of points is weighted by a function of their respective marks. The mark-weighted K-function is given by\n\\[K_f(r) = \\frac 1  \\lambda \\frac{C_f(r)}{E[ f(M_1, M_2) ]}\\] with the function \\(C_f(r) = E \\left[ \\sum_{x \\in X} f(m(u), m(x)) 1{0 &lt; ||u - x|| \\le r} \\; \\big| \\; u \\in X \\right]\\) which is equivalent to the unnormalized mark-weighted \\(K\\)-function. For every point \\(u\\) we sum the euclidean distance \\(||u - x||\\) of all other points \\(x\\) that are within a distance \\(r\\). This sum is weighted by the function \\(f\\) of the marks of \\(u\\) and \\(x\\). The function is standardized by the expected value of \\(f(M, M′)\\) where \\(M, M′\\) represent independent, identically distributed random points with same distribution as the mark of a randomly chosen point [1].\nIn the scenario of random labeling, the mark-weighted \\(K\\)-function corresponds to Ripley’s \\(K\\)-function.\nThe default function is \\(f(m_1, m_2) = m_1 m_2\\).\n\nppEsr1 &lt;- subset(pp, select = 'Esr1')\n\nK.Esr1L &lt;- Kmark(ppEsr1, function(m1,m2) {m1*m2})\nplot(K.Esr1L)\n\n\n\n\nIt is important to note that theoretical value is not very informative since it represents the \\(K\\)-function of a Poisson point process and the underlying point process might not be Poisson. Therefore we compare the mark-weighted with its unmarked analogue.\nHere we will compare the \\(L\\)-functions, which are the variance stabilized \\(K\\)-functions.\n\nL.Esr1L &lt;- Kmark(ppEsr1, function(m1,m2) {m1*m2}, returnL = TRUE)\nLest.ppEsr1 &lt;- Lest(ppEsr1, nlarge=7000)\nplot(eval.fv(L.Esr1L - Lest.ppEsr1))\n\n\n\n\nLike for other functions we can calculate a simulation envelope for the mark-weighted K-function to get confidence intervals [1].\n\nplot(envelope(ppEsr1, fun=Kmark, returnL=TRUE, nsim=50))\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone."
  },
  {
    "objectID": "04-spotbased.html",
    "href": "04-spotbased.html",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\ntheme_set(theme_light())\n\n\n\n\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\n#calculate the highly variable genes\ndec &lt;- scran::modelGeneVar(sfe_tissue, lowess = FALSE)\nhvgs &lt;- scran::getTopHVGs(dec, n = 200)\n\n#calcualte the principal components of \nsfe_tissue &lt;- scater::runPCA(sfe_tissue, ncomponents = 20, subset_row = hvgs)"
  },
  {
    "objectID": "04-spotbased.html#dependencies",
    "href": "04-spotbased.html#dependencies",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\ntheme_set(theme_light())"
  },
  {
    "objectID": "04-spotbased.html#setup-and-preprocessing",
    "href": "04-spotbased.html#setup-and-preprocessing",
    "title": "Preamble",
    "section": "",
    "text": "# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\n#calculate the highly variable genes\ndec &lt;- scran::modelGeneVar(sfe_tissue, lowess = FALSE)\nhvgs &lt;- scran::getTopHVGs(dec, n = 200)\n\n#calcualte the principal components of \nsfe_tissue &lt;- scater::runPCA(sfe_tissue, ncomponents = 20, subset_row = hvgs)"
  },
  {
    "objectID": "04-spotbased.html#regular-lattice-data",
    "href": "04-spotbased.html#regular-lattice-data",
    "title": "Preamble",
    "section": "",
    "text": "Spot based data is collected along a regular spaced grid where all sample areas have the same size. Such a grid is also called a regular lattice. In more rigorous terms the data \\(Y\\) is the product of a random process but the sampling locations are fixed along a lattice \\(D\\). The lattice \\(D\\) does not have to regular but in the scope of spot based data it is. The main difference of this type of data in comparison to point patterns is, that the locations of the data are then not results of a stochastic process but rather due to a defined sampling strategy [1].\nThe lattice is composed of individual spatial units\n\\[\nD = \\{A_1, A_2,...,A_n\\}\n\\] where these units are not supposed to overlap\n\\[\nA_i \\cap A_j = \\emptyset \\forall i \\neq j\n\\]\nThe data is then a random variable of the spatial unit along the lattice\n\\[\nY_i = Y(A_i)\n\\]\n–&gt; need to find the papers mentioned here!!\nA lot of lattice data analysis technique build on the concept of neighbours. Therefore, the spatial relationship has to be modelled with e.g. a spatial weigth matrix \\(W\\). There are a lot of ways to define a spatial weigth matrix \\(W\\). An intuitive way is from Cliff and Ord (1981) and Upton and Fingleton (1985). Here, the units that are adjacent are specified with a one and the ones that are not adjacent with a zero (inary coniguity matrix) [1].\n\\[\nw_{ij} = \\begin{cases}\n1 \\text{ if } A_i \\text{ and } A_j \\text{ are adjacent}\\\\\n0 \\text{ otw}\n\\end{cases}\n\\]\nother options to specify the weight matrix \\(W\\) are mentioned in [1]."
  },
  {
    "objectID": "04-spotbased.html#global-measures-for-univariate-data",
    "href": "04-spotbased.html#global-measures-for-univariate-data",
    "title": "Preamble",
    "section": "Global Measures for Univariate Data",
    "text": "Global Measures for Univariate Data\nGlobal measures are values across an entire field of view. This gives e.g. one number per field of view.\nA common analysis to do with lattice data (and point pattern data) is to check for spatial correlation. This is a second-order property of the form (Getis 1991)\n\\[\n\\sum_i \\sum_j = w_{ij}U_{ij}\n\\]\nwhere \\(w_{ij}\\) is the weight matrix and \\(U_{ij}\\) a dissimilarity measure. [1]\n\nGlobal Moran’s I coefficient\nA common dissimilarity measure is Morans \\(I\\). It is defined by [1]\n\\[\nI = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(y_i - \\hat{y})(y_j - \\hat{y})}{\\sum_i (y_i - \\hat{y})^2}\n\\]\nUnder the null \\(I\\) takes the value \\(-1/(n-1)\\) in expectation. This value is close to \\(0\\) for large \\(n\\). A value higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation. Negative values indicate negative auto-correlation, but this is not so easy to interpret [1]. The implementation below is a Monte Carlo simulation approach to define a null distribution to test against.\n\nImplementation using VOYAGER\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\nplotSpatialFeature(sfe_tissue, features = \"nCounts\", \n                   colGeometryName = \"spotPoly\",\n                   annotGeometryName = \"myofiber_simplified\", \n                   aes_use = \"color\", linewidth = 0.5, fill = NA,\n                   annot_aes = list(fill = \"area\"))\n\nsfe_tissue &lt;-  colDataUnivariate(sfe_tissue, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"visium\", nsim = 1000,\n                                type = \"moran.mc\")\n\nres &lt;- colFeatureData(sfe_tissue)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$moran.mc_statistic_Vis5A\n#p-value\nres$moran.mc_p.value_Vis5A\n\nplotMoranMC(sfe_tissue, c(\"nCounts\", \"nGenes\"))\n\n\n\nImplementation using spdep\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe_tissue, \"visium\")\nspdep::moran.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe_tissue$nGenes  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 19.758, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.3840275174     -0.0010741139      0.0003798881 \n\nspdep::moran.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe_tissue$nCounts  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 27.181, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.5287046946     -0.0010741139      0.0003798881 \n\n\nThe number of genes per spot shows a Moran’s \\(I\\) of \\(\\sim 0.38\\) which indicates auto-correlation. The number of counts per spot shows a Moran’s \\(I\\) of \\(\\sim 0.53\\).\n\n\n\nGlobal Geary’s C coefficient\nAnother measure of spatial auto-correlation is Geary’s \\(C\\). It is very closely related to Moran’s \\(I\\). Geary’s \\(C\\) is defined by:\n\\[\nC = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(y_i-y_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(y_i-\\bar{y})^2}\n\\]\nThe interpretation is inveresely to Moran’s \\(I\\). A value less than \\(1\\) indicates positive auto-correlation, a value more than \\(1\\) negative auto-correlation. (https://pachterlab.github.io/voyager/articles/visium_10x.html)\nThe testing works similarly to Moran’s \\(I\\), just the objective function changes in the Monte Carlo estimation\n\nImplementation using VOYAGER\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\nsfe_tissue &lt;-  colDataUnivariate(sfe_tissue, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"visium\", nsim = 1000,\n                                type = \"geary.mc\")\n\nres &lt;- colFeatureData(sfe_tissue)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$geary.mc_statistic_Vis5A\n\n[1] 0.4748925 0.6057966\n\n#p-value\nres$geary.mc_p.value_Vis5A\n\n[1] 0.000999001 0.000999001\n\n\n\n\nImplementation using spdep\n\nspdep::geary.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe_tissue$nGenes \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 19.996, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     0.6057966472      1.0000000000      0.0003886284 \n\nspdep::geary.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe_tissue$nCounts \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 26.729, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     0.4748924980      1.0000000000      0.0003859596 \n\n\nThe Geary’s \\(C\\) statistic gives a value of \\(0.47\\) for the number of counts and \\(0.61\\) for the number of genes. The interpretation is that both features show positive auto correlation.\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/gean.12164\n\n\n\nGlobal Getis-Ord \\(G\\) statistic\nThe global \\(G\\) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in teh dataset. Formally that is,\n\\[\nG(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j}, \\text{s.t } j \\neq i\n\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather considering both approaches.\n–&gt; weights should be binarised for this test - how to do this?\n\nspdep::globalG.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods)\n\n\n    Getis-Ord global G statistic\n\ndata:  sfe_tissue$nGenes \nweights: weights_neighbourhoods \n\nstandard deviate = 20.757, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.185181e-03       1.074114e-03       2.863192e-11 \n\nspdep::globalG.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods)\n\n\n    Getis-Ord global G statistic\n\ndata:  sfe_tissue$nCounts \nweights: weights_neighbourhoods \n\nstandard deviate = 27.797, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.361423e-03       1.074114e-03       1.068346e-10 \n\n\n[5]"
  },
  {
    "objectID": "04-spotbased.html#local-measures-for-univariate-data",
    "href": "04-spotbased.html#local-measures-for-univariate-data",
    "title": "Preamble",
    "section": "Local Measures for Univariate Data",
    "text": "Local Measures for Univariate Data\n\nLocal Moran’s I coefficient\nOften a global measure is not enough. One number determining e.g. the spatial autocorrelation over an entire tissue slice might not be reflective of tissue heterogeneity. Therefore, local indicators of spatial associations have been developed [2]. For each sampling location we calculate as follows (https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1538-4632.1995.tb00338.x) (formula from ?localmoran)\n\\[\nI_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\n\\]\nSince we are calculating several local statistics potentially from the same observations, problems of multiple testing arise. We correct for this issue with standard adjustments, such as Benjamini Hochberg correction (https://rss.onlinelibrary.wiley.com/doi/10.1111/j.2517-6161.1995.tb02031.x). The problem of false positives due to multiple testing is discussed in great detail in [2].\nImplementation with spdep\n\n#calculate local Moran's I and then correct for multiple testing using Benjamini-Hochberg correction if you want to plot p-values\nlocalplot &lt;- function(sfe, var, fun, plotvar){\n  loc &lt;- do.call(fun, args = list(x=sfe[[var]], listw = weights_neighbourhoods))\n  #why so ever, 'localG' has a different return structure than 'localmoran'. Thus, this conditional with different indexing\n  if(fun %in% c('localG')){\n    loc &lt;- attr(loc, 'internals')\n    #extract the effect size\n    locEffect &lt;- loc[,1]\n    #extract the p-value and adjust for multiple testing\n    p.val.adj &lt;- loc[,5] |&gt; p.adjust(\"BH\")\n  }\n  else if(fun == 'localC_perm'){\n    p.val.adj &lt;- attr(loc, 'pseudo-p')[,'Pr(z != E(Ci))']\n    locEffect &lt;- loc\n  }\n  else if (fun == 'LOSH'){\n    locEffect &lt;- loc[,1]\n    p.val.adj &lt;- c()\n  }\n  else{\n    #extract the effect size\n    locEffect &lt;- loc[,1]\n    #extract the p-value and adjust for multiple testing\n    p.val.adj &lt;- loc[,5] |&gt; p.adjust(\"BH\")\n  }\n  \n  #convert into a plain sf object for plotting\n  sf &lt;- colGeometries(sfe)$spotPoly\n  \n  sf$locEffect &lt;- locEffect\n  sf$p.val.adj &lt;- p.val.adj\n  \n  return(tm_shape(sf) + tm_fill(col = plotvar))\n}\n\np &lt;- localplot(sfe_tissue, 'nCounts', fun = 'localmoran', plotvar = 'locEffect')\nq &lt;- localplot(sfe_tissue, 'nGenes', fun = 'localmoran', plotvar = 'locEffect')\n\ntmap_arrange(p,q)\n\n\n\n\n\nImplementation with Voyager\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localmoran\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localmoran\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\nLocal Geary’s C coefficient\nGeary’s C can be calculated for local interactions as well.\n\\[\nC_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2\n\\]\nThe interpretation is the same as for local Moran’s \\(I\\) [6].\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'localC_perm', plotvar = 'locEffect')\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'localC_perm', plotvar = 'locEffect')\n\ntmap_arrange(p,q)\n\n\n\n\n\nImplementation with Voyager\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localC_perm\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localC_perm\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\nLocal Getis-Ord \\(G_i\\) coefficient\nThe local Getis-Ord \\(G_i\\) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\).\n\\[\nG_i(d) = \\frac{\\sum_{j=1}^n w_{ij}(d)x_j}{\\sum_{j=1}^n x_j}, \\text{s.t } j \\neq i\n\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\) which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term. Importantly, \\(G_i(d)\\) is scale-invariant but not location-invariant. That means, the subdivision into the \\(n\\) subregions matterns for the computation of the local statistic [5].\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'localG', plotvar = 'locEffect')\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'localG', plotvar = 'locEffect')\n\ntmap_arrange(p,q)\n\n\n\n\n\nImplementation with Voyager\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\nLocal Spatial Heteroscedasticity (LOSH)\nThe univariate methods described above assume homoscedastic variance so that the variance is uniform over the sampling area [4]. In the context of tumour-immune infiltration we could have regions where the mean infiltration is the same but the variability depends on the specific pathology. Therefore, a new statistic was introduced, local spatial heteroscedasticity (LOSH). The aim of LOSH is similar to the local \\(G\\) statistic, where we compared means, to now compare variances. The aim is to compare homogeienity and heterogeneity of groups in space. This statistic is especially interesting in combination with the local \\(G\\) statistic, giving an overview on the mean-variance relationship of the sample [4].\nLOSH is defined formally as follows:\n\\[\nH_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\n\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_j(d), j\\in N(i,d)\\) are the local residuals [4].\nOrd and Getis provide a very nice table for the interpretation of the mean and variance relationship provided by \\(G_i\\) and \\(H_i\\).\n–&gt; insert table\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'LOSH', plotvar = 'locEffect')\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'LOSH', plotvar = 'locEffect')\n\ntmap_arrange(p,q)"
  },
  {
    "objectID": "04-spotbased.html#measures-for-bi--and-multivariate-data",
    "href": "04-spotbased.html#measures-for-bi--and-multivariate-data",
    "title": "Preamble",
    "section": "",
    "text": "So far, we have considered methods for univariate data, so where we looked at the change of one variable in several contexts. Spatial methods for bi- and multivariate data exist as well and will be discussed in the following.\n\n\nThe implementation in the package spdep is as follows:\n\\[\nL(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}}\n\\] (https://r-spatial.github.io/spdep/reference/lee.htmlls)\nLee’s \\(L\\) is a bivariate measure that combines non-spatial Pearson Correlation with spatial autocorrelation via Moran’s \\(I\\) [3]. Instead of looking at the auto-correlation of one signle variable we can now assess the spatial dependence of two variables.\n\nloc &lt;- lee(x = sfe_tissue$nCounts, y = sfe_tissue$nGenes, n = length(sfe_tissue$nCounts), listw = weights_neighbourhoods)\n\n#convert into a plain sf object for plotting\nsf &lt;- colGeometries(sfe_tissue)$spotPoly\n\nsf$locEffect &lt;- loc$localL\n\ntm_shape(sf) + tm_fill(col = 'locEffect')  \n\n\n\n\n\n\n\nsfe_tissue &lt;- runBivariate(sfe_tissue, \"locallee\", swap_rownames = \"symbol\",\n                           feature1 = c('nGenes', 'nCounts'))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)"
  },
  {
    "objectID": "04-spotbased.html#voyager",
    "href": "04-spotbased.html#voyager",
    "title": "Preamble",
    "section": "VOYAGER",
    "text": "VOYAGER\nThere is a very nice resource explaining in detail the available methods for lattice data (amongst others) (https://pachterlab.github.io/voyager/index.html). We will summarise complement these approaches in this chapter"
  },
  {
    "objectID": "04-spotbased.html#sources",
    "href": "04-spotbased.html#sources",
    "title": "Preamble",
    "section": "Sources",
    "text": "Sources\n[1] Zuur, A. F., Ieno, E. N., Smith, G. M., Saveliev, A. A., Mukharamova, S. S., & Zuur, A. F. (2007). Analysis and modelling of lattice data. Analysing Ecological Data, 321-339.\n[2] Pebesma, E., & Bivand, R. (2023). Spatial data science: With applications in R. CRC Press.\n[3] Lee, S. I. (2001). Developing a bivariate spatial association measure: an integration of Pearson’s r and Moran’s I. Journal of geographical systems, 3, 369-385.\n[4] Ord, J. K., & Getis, A. (2012). Local spatial heteroscedasticity (LOSH). The Annals of Regional Science, 48, 529-539.\n[5] Getis, A., & Ord, J. K. (1992). The analysis of spatial association by use of distance statistics. Geographical analysis, 24(3), 189-206.\n[6] Anselin, L. (1995). Local indicators of spatial association—LISA. Geographical analysis, 27(2), 93-115. ## Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] stringr_1.5.0                  dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.9.4                  SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-14                     \n[17] reshape2_1.4.4                 patchwork_1.1.3               \n[19] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[21] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[23] dbplyr_2.3.4                   RANN_2.6.1                    \n[25] seg_0.5-7                      sp_2.1-1                      \n[27] rlang_1.1.1                    ggplot2_3.4.4                 \n[29] dplyr_1.1.3                    mixR_0.2.0                    \n[31] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[33] spatstat.model_3.2-6           rpart_4.1.19                  \n[35] spatstat.explore_3.2-3         nlme_3.1-162                  \n[37] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[39] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[41] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[43] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[45] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[47] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[49] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     proxy_0.4-27                 \n [17] dbscan_1.1-11                 R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.2.1                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] spatstat.utils_3.0-3          rmarkdown_2.25               \n [87] XVector_0.40.0                htmltools_0.5.6.1            \n [89] pkgconfig_2.0.3               base64enc_0.1-3              \n [91] sparseMatrixStats_1.12.2      fastmap_1.1.1                \n [93] htmlwidgets_1.6.2             shiny_1.7.5.1                \n [95] DelayedMatrixStats_1.22.6     jsonlite_1.8.7               \n [97] BiocParallel_1.34.2           R.oo_1.25.0                  \n [99] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[101] magrittr_2.0.3                GenomeInfoDbData_1.2.10      \n[103] s2_1.1.4                      Rhdf5lib_1.22.1              \n[105] munsell_0.5.0                 Rcpp_1.0.11                  \n[107] ggnewscale_0.4.9              viridis_0.6.4                \n[109] stringi_1.7.12                leafsync_0.1.0               \n[111] zlibbioc_1.46.0               plyr_1.8.9                   \n[113] parallel_4.3.1                ggrepel_0.9.4                \n[115] deldir_1.0-9                  Biostrings_2.68.1            \n[117] stars_0.6-4                   splines_4.3.1                \n[119] tensor_1.5                    locfit_1.5-9.8               \n[121] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[123] BiocVersion_3.17.1            XML_3.99-0.14                \n[125] evaluate_0.22                 BiocManager_1.30.22          \n[127] httpuv_1.6.11                 purrr_1.0.2                  \n[129] polyclip_1.10-6               rsvd_1.0.5                   \n[131] lwgeom_0.2-13                 xtable_1.8-4                 \n[133] e1071_1.7-13                  RSpectra_0.16-1              \n[135] later_1.3.1                   viridisLite_0.4.2            \n[137] class_7.3-22                  tibble_3.2.1                 \n[139] memoise_2.0.1                 beeswarm_0.4.0               \n[141] AnnotationDbi_1.62.2          cluster_2.1.4"
  },
  {
    "objectID": "04-spotbased.html#local-measures-for-multivariate-data",
    "href": "04-spotbased.html#local-measures-for-multivariate-data",
    "title": "Preamble",
    "section": "Local Measures for Multivariate Data",
    "text": "Local Measures for Multivariate Data\n\nBivariate Lee’s \\(L\\)\nThe implementation in the package spdep is as follows:\n\\[\nL(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}}\n\\] (https://r-spatial.github.io/spdep/reference/lee.htmlls)\nLee’s \\(L\\) is a bivariate measure that combines non-spatial Pearson Correlation with spatial autocorrelation via Moran’s \\(I\\) [3]. Instead of looking at the auto-correlation of one signle variable we can now assess the spatial dependence of two variables.\n\nloc &lt;- lee(x = sfe_tissue$nCounts, y = sfe_tissue$nGenes, n = length(sfe_tissue$nCounts), listw = weights_neighbourhoods)\n\n#convert into a plain sf object for plotting\nsf &lt;- colGeometries(sfe_tissue)$spotPoly\n\nsf$locEffect &lt;- loc$localL\n\ntm_shape(sf) + tm_fill(col = 'locEffect')  \n\n\n\n\n\nImplementation with Voyager\n\nsfe_tissue &lt;- runBivariate(sfe_tissue, \"locallee\", swap_rownames = \"symbol\",\n                           feature1 = c('nGenes', 'nCounts'))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)"
  },
  {
    "objectID": "02-univar-irregular-lattices.html",
    "href": "02-univar-irregular-lattices.html",
    "title": "Irregular Lattices",
    "section": "",
    "text": "source(\"utils.R\")\n\nUntil now we have considered the cells to be represented in a point pattern. However, as cells have a shape and area, this might be an oversimplification in some cases. Alternatively, we can rely on the segmentation of indvidual cells that are available for various datasets. The outline of each cell is represented by a polygon and the collection of all cells can be seen as an irregular lattice. Unlike a regular lattice (the representation of spot based spatial tanscriptomics data) the sample areas in an irregular lattice can have different sizes and are not reugularly distributed over the sample space.\nFor this representation of the cells we will rely on the SpatialFeatureExperiment package. For preprocessing of the dataset we refer the reader to the vignette of the voyager package.\n\n(sfe &lt;- HeNSCLCData())\n\nclass: SpatialFeatureExperiment \ndim: 980 100290 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100290): 1_1 1_2 ... 30_4759 30_4760\ncolData names(17): Area AspectRatio ... nCounts nGenes\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n# Empty cells\ncolData(sfe)$is_empty &lt;- colData(sfe)$nCounts &lt; 1\n# Select negative control probes\nneg_inds &lt;- str_detect(rownames(sfe), \"^NegPrb\")\n# Number of negative control probes\nsum(neg_inds)\n\n[1] 20\n\ncolData(sfe)$prop_neg &lt;- colSums(counts(sfe)[neg_inds,])/colData(sfe)$nCounts\n# Remove low quality cells\n(sfe &lt;- sfe[,!sfe$is_empty & sfe$prop_neg &lt; 0.1])\n\nclass: SpatialFeatureExperiment \ndim: 980 100095 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100095): 1_1 1_2 ... 30_4759 30_4760\ncolData names(19): Area AspectRatio ... is_empty prop_neg\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n# Calculate count stats\nrowData(sfe)$means &lt;- rowMeans(counts(sfe))\nrowData(sfe)$vars &lt;- rowVars(counts(sfe))\nrowData(sfe)$is_neg &lt;- neg_inds\n# log Counts\nsfe &lt;- logNormCounts(sfe)\n\n\nplotSpatialFeature(sfe, c(\"nGenes\", \"nCounts\"),\n                   colGeometryName = \"centroids\", ncol = 2, scattermore = TRUE)\n\n\n\n\n\n\n\nMost analysis techniques rely on the a neighborhood matrix, which is a matrix that indicates which cells are neighbors. In the case of the regular lattice, the calculation of the neighborhood matrix is rather straightforward. In the case of the irregular lattice it can be more complicated as the reconstruction of the cells is often not perfect.\n\n\n\n\ncolGraph(sfe, \"knn5\") &lt;- findSpatialNeighbors(sfe, method = \"knearneigh\",\n                                                  dist_type = \"idw\", k = 5, \n                                                  style = \"W\")"
  },
  {
    "objectID": "02-univar-irregular-lattices.html#dependencies",
    "href": "02-univar-irregular-lattices.html#dependencies",
    "title": "Irregular Lattices",
    "section": "",
    "text": "source(\"utils.R\")\n\nUntil now we have considered the cells to be represented in a point pattern. However, as cells have a shape and area, this might be an oversimplification in some cases. Alternatively, we can rely on the segmentation of indvidual cells that are available for various datasets. The outline of each cell is represented by a polygon and the collection of all cells can be seen as an irregular lattice. Unlike a regular lattice (the representation of spot based spatial tanscriptomics data) the sample areas in an irregular lattice can have different sizes and are not reugularly distributed over the sample space.\nFor this representation of the cells we will rely on the SpatialFeatureExperiment package. For preprocessing of the dataset we refer the reader to the vignette of the voyager package.\n\n(sfe &lt;- HeNSCLCData())\n\nclass: SpatialFeatureExperiment \ndim: 980 100290 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100290): 1_1 1_2 ... 30_4759 30_4760\ncolData names(17): Area AspectRatio ... nCounts nGenes\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n# Empty cells\ncolData(sfe)$is_empty &lt;- colData(sfe)$nCounts &lt; 1\n# Select negative control probes\nneg_inds &lt;- str_detect(rownames(sfe), \"^NegPrb\")\n# Number of negative control probes\nsum(neg_inds)\n\n[1] 20\n\ncolData(sfe)$prop_neg &lt;- colSums(counts(sfe)[neg_inds,])/colData(sfe)$nCounts\n# Remove low quality cells\n(sfe &lt;- sfe[,!sfe$is_empty & sfe$prop_neg &lt; 0.1])\n\nclass: SpatialFeatureExperiment \ndim: 980 100095 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100095): 1_1 1_2 ... 30_4759 30_4760\ncolData names(19): Area AspectRatio ... is_empty prop_neg\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n# Calculate count stats\nrowData(sfe)$means &lt;- rowMeans(counts(sfe))\nrowData(sfe)$vars &lt;- rowVars(counts(sfe))\nrowData(sfe)$is_neg &lt;- neg_inds\n# log Counts\nsfe &lt;- logNormCounts(sfe)\n\n\nplotSpatialFeature(sfe, c(\"nGenes\", \"nCounts\"),\n                   colGeometryName = \"centroids\", ncol = 2, scattermore = TRUE)"
  },
  {
    "objectID": "02-univar-irregular-lattices.html#irregular-lattice-and-neighbourhood-matrix",
    "href": "02-univar-irregular-lattices.html#irregular-lattice-and-neighbourhood-matrix",
    "title": "Irregular Lattices",
    "section": "",
    "text": "Most analysis techniques rely on the a neighborhood matrix, which is a matrix that indicates which cells are neighbors. In the case of the regular lattice, the calculation of the neighborhood matrix is rather straightforward. In the case of the irregular lattice it can be more complicated as the reconstruction of the cells is often not perfect."
  },
  {
    "objectID": "02-univar-irregular-lattices.html#neighbourhood-matrix",
    "href": "02-univar-irregular-lattices.html#neighbourhood-matrix",
    "title": "Irregular Lattices",
    "section": "",
    "text": "colGraph(sfe, \"knn5\") &lt;- findSpatialNeighbors(sfe, method = \"knearneigh\",\n                                                  dist_type = \"idw\", k = 5, \n                                                  style = \"W\")"
  },
  {
    "objectID": "02-univar-irregular-lattices.html#implementation-using-voyager",
    "href": "02-univar-irregular-lattices.html#implementation-using-voyager",
    "title": "Irregular Lattices",
    "section": "Implementation using voyager",
    "text": "Implementation using voyager\n\nfeatures_use &lt;- c(\"nGenes\")\nsfe &lt;- colDataMoransI(sfe, features_use, colGraphName = \"knn5\")\n\ncolFeatureData(sfe)[features_use,]\n\nDataFrame with 1 row and 2 columns\n       moran_sample01 K_sample01\n            &lt;numeric&gt;  &lt;numeric&gt;\nnGenes       0.434643    3.19599\n\nsfe &lt;- colDataUnivariate(sfe, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"knn5\", nsim = 200,\n                                type = \"moran.mc\")\nres &lt;- colFeatureData(sfe)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$moran.mc_statistic_sample01\n\n[1] 0.3866521 0.4346425\n\n#p-value\nres$moran.mc_p.value_sample01\n\n[1] 0.004975124 0.004975124"
  },
  {
    "objectID": "02-univar-irregular-lattices.html#implementation-using-spdep",
    "href": "02-univar-irregular-lattices.html#implementation-using-spdep",
    "title": "Irregular Lattices",
    "section": "Implementation using spdep",
    "text": "Implementation using spdep\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe, \"knn5\")\nspdep::moran.test(x = sfe$nGenes, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe$nGenes  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 215.54, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     4.346425e-01     -9.990609e-06      4.066625e-06 \n\nspdep::moran.test(x = sfe$nCounts, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe$nCounts  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 191.74, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     3.866521e-01     -9.990609e-06      4.066625e-06"
  },
  {
    "objectID": "02-univar-irregular-lattices.html#implementation-using-voyager-1",
    "href": "02-univar-irregular-lattices.html#implementation-using-voyager-1",
    "title": "Irregular Lattices",
    "section": "Implementation using voyager",
    "text": "Implementation using voyager\n\nfeatures_use &lt;- c(\"nGenes\")\nsfe &lt;- colDataMoransI(sfe, features_use, colGraphName = \"knn5\")\n\ncolFeatureData(sfe)[features_use,]\n\nDataFrame with 1 row and 8 columns\n       moran_sample01 K_sample01 moran.mc_statistic_sample01\n            &lt;numeric&gt;  &lt;numeric&gt;                   &lt;numeric&gt;\nnGenes       0.434643    3.19599                    0.434643\n       moran.mc_parameter_sample01 moran.mc_p.value_sample01\n                         &lt;numeric&gt;                 &lt;numeric&gt;\nnGenes                         201                0.00497512\n       moran.mc_alternative_sample01 moran.mc_method_sample01\n                         &lt;character&gt;              &lt;character&gt;\nnGenes                       greater   Monte-Carlo simulati..\n                      moran.mc_res_sample01\n                                     &lt;list&gt;\nnGenes 0.00137841,0.00305125,0.00364505,...\n\nsfe &lt;- colDataUnivariate(sfe, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"knn5\", nsim = 200,\n                                type = \"geary.mc\")\nres &lt;- colFeatureData(sfe)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$geary.mc_statistic_sample01\n\n[1] 0.5757786 0.5447089\n\n#p-value\nres$geary.mc_p.value_sample01\n\n[1] 0.004975124 0.004975124"
  },
  {
    "objectID": "02-univar-irregular-lattices.html#implementation-using-spdep-1",
    "href": "02-univar-irregular-lattices.html#implementation-using-spdep-1",
    "title": "Irregular Lattices",
    "section": "Implementation using spdep",
    "text": "Implementation using spdep\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe, \"knn5\")\nspdep::geary.test(x = sfe$nGenes, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe$nGenes \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 215.65, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     5.447089e-01      1.000000e+00      4.457420e-06 \n\nspdep::geary.test(x = sfe$nCounts, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe$nCounts \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 187.84, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     5.757786e-01      1.000000e+00      5.100241e-06"
  },
  {
    "objectID": "02-univar-irregular-lattices.html#session-info",
    "href": "02-univar-irregular-lattices.html#session-info",
    "title": "Irregular Lattices",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] stringr_1.5.0                  dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.9.4                  SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-14                     \n[17] reshape2_1.4.4                 patchwork_1.1.3               \n[19] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[21] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[23] dbplyr_2.3.4                   RANN_2.6.1                    \n[25] seg_0.5-7                      sp_2.1-1                      \n[27] rlang_1.1.1                    ggplot2_3.4.4                 \n[29] dplyr_1.1.3                    mixR_0.2.0                    \n[31] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[33] spatstat.model_3.2-6           rpart_4.1.19                  \n[35] spatstat.explore_3.2-3         nlme_3.1-162                  \n[37] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[39] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[41] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[43] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[45] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[47] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[49] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.2.1                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] spatstat.utils_3.0-3          rmarkdown_2.25               \n [87] XVector_0.40.0                htmltools_0.5.6.1            \n [89] pkgconfig_2.0.3               base64enc_0.1-3              \n [91] sparseMatrixStats_1.12.2      fastmap_1.1.1                \n [93] htmlwidgets_1.6.2             shiny_1.7.5.1                \n [95] DelayedMatrixStats_1.22.6     farver_2.1.1                 \n [97] jsonlite_1.8.7                BiocParallel_1.34.2          \n [99] R.oo_1.25.0                   BiocSingular_1.16.0          \n[101] RCurl_1.98-1.12               magrittr_2.0.3               \n[103] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[105] Rhdf5lib_1.22.1               munsell_0.5.0                \n[107] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[109] viridis_0.6.4                 stringi_1.7.12               \n[111] leafsync_0.1.0                zlibbioc_1.46.0              \n[113] plyr_1.8.9                    parallel_4.3.1               \n[115] ggrepel_0.9.4                 deldir_1.0-9                 \n[117] Biostrings_2.68.1             stars_0.6-4                  \n[119] splines_4.3.1                 tensor_1.5                   \n[121] locfit_1.5-9.8                igraph_1.5.1                 \n[123] ScaledMatrix_1.8.1            BiocVersion_3.17.1           \n[125] XML_3.99-0.14                 evaluate_0.22                \n[127] BiocManager_1.30.22           httpuv_1.6.11                \n[129] purrr_1.0.2                   polyclip_1.10-6              \n[131] scattermore_1.2               rsvd_1.0.5                   \n[133] lwgeom_0.2-13                 xtable_1.8-4                 \n[135] e1071_1.7-13                  RSpectra_0.16-1              \n[137] later_1.3.1                   viridisLite_0.4.2            \n[139] class_7.3-22                  tibble_3.2.1                 \n[141] memoise_2.0.1                 beeswarm_0.4.0               \n[143] AnnotationDbi_1.62.2          cluster_2.1.4"
  },
  {
    "objectID": "03-between-marks.html",
    "href": "03-between-marks.html",
    "title": "Discrete Marks",
    "section": "",
    "text": "Code\nsource(\"utils.R\")\n\n\n\n\n\n\n\nCode\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#subset the data to only look at sample ID 0.01, 0.06 and 0.26\n# list(\"-0.29\", \"0.01\", \"0.06\")\n#zstack_list &lt;- list(\"-0.04\", '-0.09', '-0.14', '-0.19', '-0.24', '-0.29', '0.01', '0.06', '0.11', '0.16', '0.21', \"0.26\")\n\n#define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n\n#define the celltype that you want to compare across the stacks - hereby we assume independence across the z-stacks which is an assumption that can be challenged\ncelltype_ls &lt;- \"OD Mature\"\n\nselectZstacks &lt;- function(zstack, spe){\n  sub &lt;- spe[, spe$sample_id == zstack]\n  pp &lt;- .ppp(sub, marks = \"cluster_id\")\n  return(pp)\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe)\nnames(pp_ls) &lt;- zstack_list\n\n\nThe theory of spatial point patterns is discussed in great detail in (Baddeley, Rubak, and Turner 2015). The book has an accompanying package called spatstat which offers great functionality to the theoretical concepts discribed in the book (Baddeley and Turner 2005). This chapter relies heavily on both publications.\n\n\n\n\n\nIn point pattern analysis we assume that the patterns we observe are a realisation of a stochastic process called a point process. The inferences we make about the point pattern are based on the point process. E.g. the pattern can be said to be created by a poisson point process and thus is evenly distributed in the observation window (Baddeley, Rubak, and Turner 2015, 127).\nWhen considering a pattern with \\(m\\) multiple types, as we do in the (Moffitt et al. 2018) dataset, there are two very closely related concepts. One can view the pattern as a multitype point pattern, where all the points are sampled from the same point process. The other option is to consider the pattern as a multivariate point pattern, where the points come from \\(m\\) distinct point processes. The difference between these two views is that in the multitype framework we assume the points to stem from the same point process and thus depend on each other. In the multivariate framework we assume that the types stem from independent point processes and therefore we can consider dependencies of one type alone. Whether or not the underlying point processes are independent depends on the biological question. If we analyse two celltypes in one slice of a tissue, we should consider them as being sampled from one point process. However, if we consider the distribution of a celltype in two slices of the same tissue we can have grounds to consider the point processes as independent (Baddeley, Rubak, and Turner 2015, 565).\n\n\n\nThe most common set up in point pattern analysis is what we call window sampling. Instead of observing the entire pattern we observe a subset of this pattern in the so called window. In the analysis we try to make inference on the entire point process based on the observed window. An example could be different small microscopy windows through which a big tissue slice is observed. The windows would be samples of the bigger point process. In this case, it would be wrong to assume the window to be the convex hull around the observed points because they are just a sample of the bigger point pattern (Baddeley, Rubak, and Turner 2015, 144–45).\nThere is another concept called the small world model. It assumes that points can only be observed in a finite small world and not beyond these boundaries. When thinking of an entire tissue, this is a very common scenario. Cells can only be observed within the tissue and not beyond. In this case, it would be correct to not assume a rectangular observation window but to use more conservative methods to estimate an unknown sampling window such as the Ripley-Rasson estimate of a spatial domain (Baddeley, Rubak, and Turner 2015, 144–45).\nIn both cases it is important to understand the direction of the bias. If the unknown window is estimated to be smaller than the true window, we underestimate the window. This then again leads to an overestimation of the density of points and to other characteristics of the pattern. Therefore, an underestimation of the window size is more concerning than a slight overestimation (Baddeley, Rubak, and Turner 2015, 144–45).\n\n\nCode\nsetRiprasWindows &lt;- function(pp){\n  Window(pp) &lt;- ripras(pp)\n  marks(pp) &lt;- factor(marks(pp))\n  return(pp)\n}\n#the entire point patterns with the ripras windows\npp &lt;- lapply(pp_ls, setRiprasWindows)\n\nseparateMarks &lt;- function(pp){\n  #split the multitype point process into several single type processes\n  ppls &lt;- split(pp)\n  return (ppls)\n}\n#the point patterns separated by their marks\npp_ls &lt;- lapply(pp, separateMarks)\n\n\n\n\n\nComplete spatial randomness (CSR) is often used as the null model for various point patterns, and is the result of a Poisson process. A completely spatial random process is characterised by two properties, homogeneity and independence, as discussed below (Baddeley, Rubak, and Turner 2015, 132).\n\n\n“Homogeneity […] means that the expected number of points falling in a region B should be proportional to its area |B|” (Baddeley, Rubak, and Turner 2015, 132) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) represents the intensity of the process, i.e., the average number of points in a unit area (Baddeley, Rubak, and Turner 2015, 132–33). :\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|.\n\\label{eq:expected_number_points}\n\\]\n\n\n\nIndependence implies that in two (non-overlapping) regions \\(A\\) and \\(B\\), the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are independent random variables. In other words, the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). In addition, the number of points, \\(N = n(X\\cap B)\\), follows a Poisson distribution:\n\\[\n\\mathbb{P}[N=k] = e^{-\\mu}\\frac{\\mu^k}{k!}\\\\\n\\label{eq:poisson_process}\n\\] where \\(k = \\lambda |B|\\) (Baddeley, Rubak, and Turner 2015, 133).\n\n\n\n\nA Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density, \\(\\lambda(u)\\), sometimes known as the intensity function (see below), is a function of spatial location \\(u\\). In this case, the expected number of points falling into a region \\(B\\), \\(\\mu = n(X\\cap B)\\), is an integration of the intensity function over that region (Baddeley, Rubak, and Turner 2015, 138).\n\\[\n\\mu = \\int_{B} \\lambda(u) du.\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\n\nA point process is called isotropic, if its statistical properties are invariant to rotations; a CSR process is both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 147).\n\n\n\n“A point process is called stationary if, when we view the process through a window W , its statistical properties do not depend on the location of the window in two-dimensional space” (Baddeley, Rubak, and Turner 2015, 146). This is the case for any homogeneous point process, where the statistical properties of the pattern are unchanged given shifting of the observation window. This means it is stationary in all statistical properties; first-order properties (e.g. intensity) and second-order properties (e.g. correlation) (Baddeley, Rubak, and Turner 2015, 218). Not all metrics assume stationarity in its full sense. Inhomogeneous metrics only assume second-order / correlation stationarity. That means while the intensity function can vary spatially (first-order stationarity is not given), the estimates of correlation functions (e.g. the inhomogeneous K-function) should be the same in parts of the window (Baddeley, Rubak, and Turner 2015, 689).\n\n\n\nIf a process is not correlation stationary, so the estimates of the inhomogeneous metric vary between locations, locally-scaled versions of the metric can be applicable. This means in small subregions, the process is still stationary and isotropic, but there is a rescaling factor that can vary across the total process (Baddeley, Rubak, and Turner 2015, 246–47).\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimated functions between the quadrats. It should be noted that this test depends on the arbitrary definition of the quadrats. Given our chosen patterns are not independent but result as marks from an overall point-pattern, the permutation approach is questionable. Furthermore, the outcome of the permutation test depends heavily on the choice of the quadrats. Therefore, the interpretation can be difficult (Baddeley, Rubak, and Turner 2015, 689–93).\n\n\nCode\npermutation_test &lt;- function(pp, mark, split, minpoints) {\n  pp_sel &lt;-  subset(pp, marks %in% mark, drop = TRUE)\n  \n  rho_est &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\n  lambda &lt;- predict(rho_est)\n\n  tesselation &lt;- quantess(unmark(pp_sel), \"x\", 3)\n  tesselation_split &lt;- nestsplit(pp_sel, tesselation, ny=split)\n  \n  plot(tesselation_split, main = mark)\n  \n  tesselation_split$inten &lt;- factor(as.integer(tesselation_split$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n  \n  res.scaled &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kscaled,\n                 minpoints = minpoints)\n  \n  res.inhom &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kinhom,\n                 lambda=lambda, minpoints = minpoints)\n  \n  #p-value of the local-scaling test\n  print(paste0(mark,' local scaling test ', res.scaled$p.value))\n  \n  #p-value of the inhomogeneity test\n  print(paste0(mark,' inhomogeneity test ', res.inhom$p.value))\n}\nlapply(c(\"Microglia\", \"OD Mature\", \"Ependymal\"), function(x) permutation_test(pp[['0.01']], x, split = 3, minpoints = 10))\n\n\nThe p-value of the test for local scaling for microglia cells is \\(&lt;0.05\\) which indicates that the assumption of local scaling is rejected. Therefore, the distribution of microglia cells is not a scaled version of an overall distribution pattern. The p-value of the test for inhomogeneity for both microglia cells is \\(&gt;0.05\\) indicating that the assumption of correlation stationarity is not rejected. In this case we can use the inhomogeneous version of the K-function which assumes correlation stationarity.\nFor ependymal and OD mature cells however, the p-values for both the local scaling test and the inhomogeneity test are \\(&gt;0.05\\) which means that both the correlation stationarity assumption and the local scaling assumption can’t be rejected. [ME: Does this make sense? Or is this just an artifact?]\nAs the interpretation of the permutation test is highly dependent on the quadrats, the results should be interpreted with care. Both inhomogeneous and locally scaled versions of the summary functions have support and both offer interesting insights into the spatial pattern. Therefore, we will compare all versions and show what the choice of metrics means for their interpretation.\n\n\n\nIntensity is the expected density of points per unit area. It can be interpreted as the rate of occurrence or the abundance of events recorded. The intensity represents a first order property because it is related to the expected number of points . More formally the average intensity of a point process is defined as:\n\\[\n\\bar{\\lambda} = \\frac{n(x)}{|W|}\n\\label{eq:average_intensity}\n\\]\nAs this is an average over the entire window, it only really makes sense for a homogeneous point process (Baddeley, Rubak, and Turner 2015, 157–60)\n\n\nFor a homogeneous point process, the intensity can be estimated in a simplistic way: summing the individual intensities of the marks (Baddeley, Rubak, and Turner 2015, 161).\n\n\nCode\nintensityPointProcess &lt;- function(pp,mark) if(mark) intensity(pp) else sum(intensity(pp))\n\nintensityPointProcess(pp_ls[['0.01']], mark = FALSE) %&gt;% round(6)\n\n\n[1] 0.001909\n\n\nOtherwise, we can compute the intensity for each mark individually.\n\n\nCode\nintensityPointProcess(pp_ls[['0.01']], mark = TRUE) %&gt;% round(8)\n\n\n  Ambiguous   Astrocyte Endothelial   Ependymal  Excitatory  Inhibitory \n 0.00024151  0.00020183  0.00014653  0.00008373  0.00036867  0.00061393 \n  Microglia OD Immature   OD Mature   Pericytes \n 0.00003031  0.00006249  0.00014278  0.00001750 \n\n\n\n\n\nIn kernel estimation, we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There are a wide variety of kernel estimators (see (Baddeley, Rubak, and Turner 2015, 168)), but a popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth (Baddeley, Rubak, and Turner 2015, 168).\n\n\nCode\npp_sel &lt;-  subset(pp_ls[['0.01']]$`OD Mature`, drop = TRUE)\nDens &lt;- density(pp_sel, sigma = 100)\nplot(Dens, main = 'Kernel Density (OD Mature cells)')\n\n\n\n\n\n\n\n\nIn quadrat counting, all points falling into a given quadrat are counted. This gives an overview on the characteristics of the point pattern, such as correlation stationarity (Baddeley, Rubak, and Turner 2015, 163).\n\n\nCode\nQ5 &lt;- quadratcount(pp_ls[['0.01']], nx=8, ny=8)\nplot(unmark(pp[['0.01']]), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\nUnder independence assumptions, the quadrat counts can be used for testing homogeneity, i.e., if the points are distributed evenly across the quadrats (Baddeley, Rubak, and Turner 2015, 164–65).\n\n\nCode\nval &lt;- quadrat.test(pp_ls[['0.01']]$`OD Mature`, 5, alternative=\"regular\", method=\"MonteCarlo\")\nval\n\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nX2 = 635.09, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 25 tiles (irregular windows)\n\n\nA p-value of 1 indicates that the null hypothesis of irregularity can not be rejected strongly. Thus, the point pattern of oligodendrocyts is strongly irregular.\nAlternatively, we can inspect departures from the hypothesis that points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types (Buller 2020).\n\n\nCode\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp[['0.01']], marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\n\nWhether or not a point process is completely spatially random (CSR) depends on two characteristics: points need to be distributed homogeneously and they have to be independent of each other (see definitions above). There are various ways to test for CSR, here we show the use-case of the clark-evans test (Baddeley, Rubak, and Turner 2015, 165–66).\n\n\nCode\nclarkevans.test(pp_ls[['0.01']]$`OD Mature`)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nR = 0.77286, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "03-between-marks.html#dependencies",
    "href": "03-between-marks.html#dependencies",
    "title": "Discrete Marks",
    "section": "",
    "text": "Code\nsource(\"utils.R\")"
  },
  {
    "objectID": "03-between-marks.html#setup",
    "href": "03-between-marks.html#setup",
    "title": "Discrete Marks",
    "section": "",
    "text": "Code\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#subset the data to only look at sample ID 0.01, 0.06 and 0.26\n# list(\"-0.29\", \"0.01\", \"0.06\")\n#zstack_list &lt;- list(\"-0.04\", '-0.09', '-0.14', '-0.19', '-0.24', '-0.29', '0.01', '0.06', '0.11', '0.16', '0.21', \"0.26\")\n\n#define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n\n#define the celltype that you want to compare across the stacks - hereby we assume independence across the z-stacks which is an assumption that can be challenged\ncelltype_ls &lt;- \"OD Mature\"\n\nselectZstacks &lt;- function(zstack, spe){\n  sub &lt;- spe[, spe$sample_id == zstack]\n  pp &lt;- .ppp(sub, marks = \"cluster_id\")\n  return(pp)\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe)\nnames(pp_ls) &lt;- zstack_list\n\n\nThe theory of spatial point patterns is discussed in great detail in (Baddeley, Rubak, and Turner 2015). The book has an accompanying package called spatstat which offers great functionality to the theoretical concepts discribed in the book (Baddeley and Turner 2005). This chapter relies heavily on both publications."
  },
  {
    "objectID": "03-between-marks.html#spatial-proximity",
    "href": "03-between-marks.html#spatial-proximity",
    "title": "Discrete Marks",
    "section": "Spatial Proximity",
    "text": "Spatial Proximity\nIndex of Spatial Proximity developed by White (1983) [White, M. J. (1983). The measurement of spatial segregation. The American Journal of Sociology, 88, 1008-1018.].\n\nThis numerical value indicates the degree of segregation. A value of 1 indicates evenness in the sample, and values greater than 1.0 indicate clustering. If the index value is smaller than one, it indicates an unusual form of segregation (i.e., some groups are closer to other groups). It compares the average distance between members of one group with that between all individuals, irrespective of group assignment. It may change depend on the definition of distance.\n\n\n# Index of spatial proximity\npaste0('Index of spatial proximity: ',\nisp(pp_sel,\n    data = model.matrix))\n\n[1] \"Index of spatial proximity: 2.94890271873706\""
  },
  {
    "objectID": "03-between-marks.html#distances-and-nearest-neighbors",
    "href": "03-between-marks.html#distances-and-nearest-neighbors",
    "title": "Discrete Marks",
    "section": "Distances and nearest neighbors",
    "text": "Distances and nearest neighbors\nInvestigating the nearest neighbor distance between point for all combinations of marks can be done as follows:\n\nd &lt;- nndist(pp_sel,by = marks(pp_sel))\na &lt;- aggregate(d,by = list(from=marks(pp_sel)),min)\na\n\n       from Ependymal Microglia OD Mature\n1 Ependymal  3.225180  8.176169 12.959456\n2 Microglia  8.176169 16.443565  6.215464\n3 OD Mature 12.959456  6.215464  6.428006"
  },
  {
    "objectID": "03-between-marks.html#nearest-neighbor-correlations",
    "href": "03-between-marks.html#nearest-neighbor-correlations",
    "title": "Discrete Marks",
    "section": "Nearest neighbor correlations",
    "text": "Nearest neighbor correlations\nA overall correlation between marks can be calculated with nncorr. It returns two values: unnormalised, which is the probability that a point and its nearest neighbor have the same type and normalised, which divides the unnormalised probability by the probability of random labeling. So a value close to 1 indicates random labeling. A value much larger than 1 means neighboring point are often of the same type.\n\nnncorr(pp_sel)\n\nunnormalised   normalised \n   0.8081321    1.8823711 \n\n\n\nAnother possibility is to work with nearest neighborhood contingency tables to do statistical tests using the dixon function from the R package dixon. It allows to calculate the statistic “segregation of species” S which indicates either random labeling (if S=0), attraction (if S&lt;0) or seggregation (if S&gt;0).\n\n\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\n\n       From        To     Obs.Count     Exp. Count    S      Z    p-val.Z\n1 Ependymal Ependymal           262          87.16  1.96  20.04    0.0000\n2 Ependymal Microglia             3          31.66 -1.07  -5.66    0.0000\n3 Ependymal OD Mature             3         149.18 -2.04 -16.87    0.0000\n4 Microglia Ependymal             9          31.66 -0.68  -4.92    0.0000\n5 Microglia Microglia            21          11.34  0.32   2.50    0.0124\n6 Microglia OD Mature            67          53.99  0.25   2.60    0.0094\n7 OD Mature Ependymal             8         149.18 -1.43 -14.26    0.0000\n8 OD Mature Microglia            69          53.99  0.12   2.35    0.0190\n9 OD Mature OD Mature           380         253.83  0.60  11.43    0.0000\n    p-val.Nobs\n1         0.01\n2         0.01\n3         0.01\n4         0.01\n5         0.03\n6         0.01\n7         0.01\n8         0.01\n9         0.01"
  },
  {
    "objectID": "03-between-marks.html#summary-functions-for-pairs-of-types",
    "href": "03-between-marks.html#summary-functions-for-pairs-of-types",
    "title": "Discrete Marks",
    "section": "Summary functions for pairs of types",
    "text": "Summary functions for pairs of types\nSimilar to the simple case without marks, it is possible to estimate summary functions. In particular, summary functions between different marks can be calculated. Note that the canonical functions assume that the multi-type process is stationary.\n\nCross K-function\nThe cross K-function is a summary function that measures the average number of points of type j within a distance r of a point of type i. The formula is given by:\n\\[\nK(r) = \\frac{1}{\\lambda_j} \\mathbb{E} [t(u,r,X^{j})|u \\in X^{i}],\n\\]\nwhere \\(X^{i}\\) is the point pattern of type \\(i\\) and \\(t(u,r,X^{j})\\) is the number of points of type \\(j\\) in a circle of radius \\(r\\) around \\(u\\) (Baddeley, Rubak, and Turner 2015, 594–95).\nFirst, we plot an overview over the cross K function for the different types.\n\n\nCode\nplotCrossAll &lt;- function(ppp, fun, edgecorr){\n  nMarks &lt;- length(unique(marks(ppp)))\n  Fall &lt;- alltypes(ppp, fun)\n  \n  # Create a list of ggplot objects using lapply\n  plot_list &lt;- lapply(Fall[[\"fns\"]], function(res) {\n    ggplot(res, aes(x = r, y = .data[[edgecorr]])) +\n      geom_line(linewidth = 1) +\n      geom_line(aes(x = r, y = theo), \n                linetype = \"dotted\", linewidth = 1) +\n      geom_line() +\n      labs(title = attributes(res)$yexp) +\n      theme_minimal()\n  })\n  \n  p &lt;- wrap_plots(plot_list, ncol = nMarks) + \n    plot_layout(guides = \"collect\") & theme(legend.position='bottom')\n  return(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplotCrossAll(pp_sel, \"Kcross.inhom\", \"iso\")\n\n\n\n\n\n\nThe diagonal of the imhomogeneous cross K-function plot shows the K-function for the different marks (indication of Poisson or non-Poisson point processes). Off-diagonal panels give indication of independence of points when the number of points follows the expected K-function but does not imply that the individual marks follow a Poisson process. If the types are independent, they are also uncorrelated.\nIt is important to remember that the ihomogeneous cross K-function assumes that the multitype process is correlation stationary. If this is not the case, there is a risk in misinterpreting the results. The problem is the confounding between clustering and inhomogeneity, c.f. (Baddeley, Rubak, and Turner 2015, 151–52) . In the example above, assuming that the process is inhomogeneous, the Ependymals cells appear to be regularly spaced, which seems counter intuitive. However, this is the result of the pattern being inhomogeneous with spatially varying intensity. When accounting for this, the pattern is more regular than expected under an inhomogeneous point process. The estimation of the inhomogeneous cross functions is not straightforward and results change based on the estimation of the local intensity and the edge correction, c.f. (Baddeley, Rubak, and Turner 2015, 605).\nIn this overview, we can see that there is indication that Microglia and OD Mature cells are independent of each other. The other types seem to be dependent on each other. Let’s focus a bit more on the relationship between Ependymal and the other two cell types. We will also calculate confidence intervals for the different cross K-functions. We have already seen that our dataset most likely does not satisfy the assumption of stationarity. For this reason, we will calculate further calculate the inhomogeneous cross K-function.\n\n\nCode\nplotCrossMetric &lt;- function(ppp, fun, from, to, edgecorr){\n  lce &lt;- lohboot(ppp, fun, from = from, to = to)\n  p &lt;- ggplot(lce, aes(x = r, y = .data[[edgecorr]])) +\n    geom_line(size = 1) +\n    geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)+\n    geom_line(aes(x = r, y = theo), linetype = \"dotted\", size = 1) +\n    geom_line() +\n    labs(title = attributes(lce)$yexp) +\n    theme_minimal()\n  return(p)\n}\n\np_epen_od &lt;- plotCrossMetric(pp_sel, \"Kcross.inhom\", \n                             \"Ependymal\", \"OD Mature\", \"iso\")\np_epend_micro &lt;- plotCrossMetric(pp_sel, \"Kcross.inhom\", \n                                 \"Ependymal\", \"Microglia\", \"iso\")\n\n\n\n\nCode\n# fig-width: 10\n# fig-height: 10\np_epen_od + p_epend_micro\n\n\n\n\n\nRemember that the dashed line represents the assumption of a multitype Poisson process. If the line lies above the dotted line, there is indication of clustering while if the line is below the dotted line there is indication of repulsion. In the plot above we can see that there is indication of clustering between Ependymal and OD Mature cells while there is indication of repulsion between Ependymal and Microglia cells.\n\n\nCross L-function\nAlternatively the L cross function with similar interpretation can be calculated using the Lcross function (Baddeley, Rubak, and Turner 2015, 596ff).\n\n\nCode\n# fig-width: 10\n# fig-height: 10\np_epen_od + p_epend_micro\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMark connection function\nThe mark connection function is the cross pair-correlation function, i.e. the generalization of the pair correlation function to a multitype point processes, divided by the unmarked pair-correlation function. It can be interpreted as the conditional probability that two points a distance \\(r\\)apart have labels of type A and of type B, given the presence of those points (Baddeley, Rubak, and Turner 2015, 596–97).\n\n\nCode\nplotCrossAll(pp_sel, \"markconnect\", \"iso\") + \n  scale_y_continuous(limits = c(0, 1))\n\n\n\n\n\n\nThe dashed lines indicate expected values under random labeling. The values measure dependence (or association) between the different labelled points. Positive values indicate that nearby points are more likely to have different types than expected by chance. This positive association between different cell types does not necessarily imply dependence, as it could be influenced by a negative association between cells of the same type, as it it could be the case for the Microglia cells. Furthermore, as the calculation is based on the \\(K\\) function, the mark connection function assumes homogenity.\n\n\nCross F-function (empty space function), cross G-function (Nearest-neighbor function) and cross J-function\nThe cross F-function is the cumulative distribution function of the distance from a location to the nearest point of the same type. For each type \\(i\\), it is defined as:\n\\[F_i(r) = \\mathbb{P}\\{d(u,X^{i}\\leq r\\}.\\]\nThe cross G-function is the cumulative distribution function of the distance from a location to the nearest point of another type and is defined as:\n\\[G_{ij}(r) = \\mathbb{P}\\{d(x,X^{(j)} \\setminus u \\leq r \\mid X^{(i)} \\ \\text{has a point at u}).\\]\nIf the points are independent of each other, the G and F function are identical. Both assume that the process is stationary. There are inhomogenous alternatives, in case the intensity is varying. Then we only assume correlation stationarity.\nThere exists a difference in the interpretation of the theoretical values of the K-cross and the G-cross function. For the K-cross, the theoretical value indicates independence between marks while for the G-cross the theoretical value is consistent with the assumption that the points of type j are Poisson in addition to being independent of the points of type \\(i\\) (Baddeley, Rubak, and Turner 2015, 597 ff).\nThe cross J-function is defined as:\n\\[J_{ij}(r) = \\frac{1-G_{ij}(r)}{1-F_{j}(r)}\\]\nand summarizes the interpoint dependence between type \\(i\\) and \\(j\\). Under the hypothesis of independent components, i.e., that the point processes of each type are independent, the G-function is equivalent to the F-function and the J-function is equal to 1 (Baddeley, Rubak, and Turner 2015, 597 ff).\n\n\n\n\n\n\n\n\n\n\nDot functions\nFor each K-, G- and J- function, there also exist dot functions, which measure distances from points of one type to points of any type. These functions allow us to measure the dependence of one mark with all other marks at once. For expample, the K-dot function represents the expected number of an other point within distance \\(r\\) of a typical point of type \\(i\\) (Baddeley, Rubak, and Turner 2015, 600 ff).\n\n\nCode\nplotCrossAll(pp_sel, \"Kdot.inhom\", \"iso\")\n\n\n\n\n\nThe dot functions are useful summary statistics to analyse the dependence of one mark with all other marks."
  },
  {
    "objectID": "03-between-marks.html#summary-function-within-and-between-types",
    "href": "03-between-marks.html#summary-function-within-and-between-types",
    "title": "Discrete Marks",
    "section": "Summary function within and between types",
    "text": "Summary function within and between types\nIn our original dataset, we have a large number of different marks. We picked three: OD mature, Ependymal and Microglia for illustrative purposes. An alternative to looking at all cross summary function combinations, it is possible to compare between and within types (Baddeley, Rubak, and Turner 2015).\n\nMark equality function\nThe Mark or Type Equality function for a stationary multitype point process measures the correlation between types of two points separated by distance r. It is the sum of the mark connection function of all pairs of points of the same type.\nIf k &lt; 1, points at distance r are less likely than expected to be of the same type. If &gt; 1, they are more likely to be of the same type. The value 1 indicates a lack of correlation (Baddeley, Rubak, and Turner 2015, 603 ff).\n\n\nCode\nplotMarkCorr &lt;- function(pp, edgecorr = \"iso\") {\n    me &lt;- markcorr(pp)\n    ggplot(me, aes(x = r, y = .data[[edgecorr]])) +\n        geom_line(size = 1) +\n        geom_line(aes(x = r, y = theo), linetype = \"dotted\", size = 1) +\n        geom_line() +\n        labs(title = attributes(me)$yexp) +\n        theme_minimal()\n}\n\nplotMarkCorr(pp_sel)\n\n\n\n\n\nWe can see that in our dataset that it the more likely it is to find points of the same type at shorter distances. The curve never crosses the dashed line at 1, which means that it is generally more likely to find points of the same type at any distance than expected by chance."
  },
  {
    "objectID": "03-between-marks.html#testing-random-labelling",
    "href": "03-between-marks.html#testing-random-labelling",
    "title": "Discrete Marks",
    "section": "Testing random labelling",
    "text": "Testing random labelling\nThe random labeling test is most logical when the marks represents its status, which is not most appropriate assumption when considering cell types. Testing for random labeling can be done using permutation test, in which the labels are randomly permuted. Random labeling can be assumed if the permuted datasets are statistically equivalent to the original dataset (Baddeley, Rubak, and Turner 2015, 609 ff)."
  },
  {
    "objectID": "03-between-marks.html#testing-the-indepenence-of-components-assumption",
    "href": "03-between-marks.html#testing-the-indepenence-of-components-assumption",
    "title": "Discrete Marks",
    "section": "Testing the indepenence of components assumption",
    "text": "Testing the indepenence of components assumption\nThe i-to-j functions are useful to test the independence of different subprocesses. If the processes of type i and j are independent, then \\(K_{ij} = \\pi r^2, G_{ij}(r) = F_{j}(r), J_{ij}(r) \\equiv 1\\). Alternatively, randomization tests can be used in which simulated patterns from the dataset are generated and randomly split into subpatterns. These are then compared to the null hypothesis in which all subpatterns should be statistically equivalent to the original. However, this approach assumes stationarity and there is a need to handle edge effects (Baddeley, Rubak, and Turner 2015, 606 ff).\n\n\nCode\nplotEnvCross &lt;- function(pp, i, j, fun, nsim = 39, radius = 150, global = FALSE){\n  pp_scaled &lt;- rescale(pp)\n  E1 &lt;- envelope(pp_scaled, fun, nsim=nsim, i=i, j=j,\n                 simulate=expression(rshift(pp_scaled, radius = radius)), global = global)\n  p &lt;- ggplot(E1, aes(x = r, y = .data[[\"mmean\"]])) +\n    geom_line(size = 1) +\n    geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)+\n    geom_line(aes(x = r, y = obs), linetype = \"dotted\", size = 1) +\n    geom_line() +\n    labs(title = attributes(E1)$yexp) +\n    theme_minimal()\n  return(p)\n}\n\npEnv &lt;- plotEnvCross(pp_sel, fun = \"Kcross.inhom\", \n                     \"Ependymal\", \"OD Mature\", nsim = 39, radius = 150)\n\n\n\n\nCode\npEnv\n\n\n\n\n\n\n\nCode\nplotEnvCross(pp_sel, fun = \"Kcross.inhom\", \n             \"Ependymal\", \"OD Mature\", nsim = 39, radius = 150, global = TRUE)\n\n\nGenerating 78 simulations by evaluating expression (39 to estimate the mean and \n39 to calculate envelopes) ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, \n78.\n\nDone.\n\n\n\n\n\nWe have indication that the independence-of-components assumption should not be rejected. Therefore, we conclude that Ependymal and OD Mature cells are independent."
  },
  {
    "objectID": "03-between-marks.html#session-info",
    "href": "03-between-marks.html#session-info",
    "title": "Discrete Marks",
    "section": "Session info",
    "text": "Session info\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-14                      reshape2_1.4.4                \n[19] patchwork_1.1.3                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.4.4                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.2.1                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] fftwtools_0.9-11              spatstat.utils_3.0-3         \n [87] rmarkdown_2.25                XVector_0.40.0               \n [89] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [91] base64enc_0.1-3               sparseMatrixStats_1.12.2     \n [93] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [95] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [97] farver_2.1.1                  jsonlite_1.8.7               \n [99] BiocParallel_1.34.2           R.oo_1.25.0                  \n[101] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[103] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[105] Rhdf5lib_1.22.1               munsell_0.5.0                \n[107] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[109] viridis_0.6.4                 stringi_1.7.12               \n[111] leafsync_0.1.0                zlibbioc_1.46.0              \n[113] plyr_1.8.9                    parallel_4.3.1               \n[115] ggrepel_0.9.4                 deldir_1.0-9                 \n[117] Biostrings_2.68.1             stars_0.6-4                  \n[119] splines_4.3.1                 tensor_1.5                   \n[121] locfit_1.5-9.8                igraph_1.5.1                 \n[123] ScaledMatrix_1.8.1            BiocVersion_3.17.1           \n[125] XML_3.99-0.14                 evaluate_0.22                \n[127] BiocManager_1.30.22           httpuv_1.6.11                \n[129] purrr_1.0.2                   polyclip_1.10-6              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4"
  },
  {
    "objectID": "04-multivar-irregular-lattices.html",
    "href": "04-multivar-irregular-lattices.html",
    "title": "Irregular Lattices",
    "section": "",
    "text": "source(\"utils.R\")\n\n–&gt; add bivariate Lee’s L and multivariate Geary’s \\(C\\)"
  },
  {
    "objectID": "04-multivar-irregular-lattices.html#dependencies",
    "href": "04-multivar-irregular-lattices.html#dependencies",
    "title": "Irregular Lattices",
    "section": "",
    "text": "source(\"utils.R\")\n\n–&gt; add bivariate Lee’s L and multivariate Geary’s \\(C\\)"
  },
  {
    "objectID": "04-multivar-irregular-lattices.html#session-info",
    "href": "04-multivar-irregular-lattices.html#session-info",
    "title": "Irregular Lattices",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] stringr_1.5.0                  dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.9.4                  SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-14                     \n[17] reshape2_1.4.4                 patchwork_1.1.3               \n[19] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[21] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[23] dbplyr_2.3.4                   RANN_2.6.1                    \n[25] seg_0.5-7                      sp_2.1-1                      \n[27] rlang_1.1.1                    ggplot2_3.4.4                 \n[29] dplyr_1.1.3                    mixR_0.2.0                    \n[31] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[33] spatstat.model_3.2-6           rpart_4.1.19                  \n[35] spatstat.explore_3.2-3         nlme_3.1-162                  \n[37] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[39] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[41] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[43] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[45] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[47] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[49] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] splines_4.3.1                 later_1.3.1                  \n  [3] bitops_1.0-7                  filelock_1.0.2               \n  [5] tibble_3.2.1                  R.oo_1.25.0                  \n  [7] polyclip_1.10-6               XML_3.99-0.14                \n  [9] lifecycle_1.0.3               edgeR_3.42.4                 \n [11] lattice_0.21-8                crosstalk_1.2.0              \n [13] magrittr_2.0.3                limma_3.56.2                 \n [15] rmarkdown_2.25                yaml_2.3.7                   \n [17] metapod_1.7.0                 httpuv_1.6.11                \n [19] spatstat.sparse_3.0-2         RColorBrewer_1.1-3           \n [21] DBI_1.1.3                     abind_1.4-5                  \n [23] zlibbioc_1.46.0               purrr_1.0.2                  \n [25] R.utils_2.12.2                RCurl_1.98-1.12              \n [27] rappdirs_0.3.3                GenomeInfoDbData_1.2.10      \n [29] ggrepel_0.9.4                 irlba_2.3.5.1                \n [31] spatstat.utils_3.0-3          terra_1.7-55                 \n [33] units_0.8-4                   goftest_1.2-3                \n [35] RSpectra_0.16-1               dqrng_0.3.1                  \n [37] DelayedMatrixStats_1.22.6     codetools_0.2-19             \n [39] DropletUtils_1.20.0           DelayedArray_0.26.7          \n [41] tidyselect_1.2.0              raster_3.6-26                \n [43] viridis_0.6.4                 ScaledMatrix_1.8.1           \n [45] base64enc_0.1-3               jsonlite_1.8.7               \n [47] BiocNeighbors_1.18.0          e1071_1.7-13                 \n [49] ellipsis_0.3.2                ggnewscale_0.4.9             \n [51] tools_4.3.1                   Rcpp_1.0.11                  \n [53] glue_1.6.2                    gridExtra_2.3                \n [55] xfun_0.40                     mgcv_1.8-42                  \n [57] HDF5Array_1.28.1              withr_2.5.1                  \n [59] BiocManager_1.30.22           fastmap_1.1.1                \n [61] boot_1.3-28.1                 rhdf5filters_1.12.1          \n [63] bluster_1.10.0                fansi_1.0.5                  \n [65] rsvd_1.0.5                    R6_2.5.1                     \n [67] mime_0.12                     colorspace_2.1-0             \n [69] wk_0.8.0                      tensor_1.5                   \n [71] dichromat_2.0-0.1             RSQLite_2.3.1                \n [73] R.methodsS3_1.8.2             utf8_1.2.3                   \n [75] generics_0.1.3                class_7.3-22                 \n [77] httr_1.4.7                    htmlwidgets_1.6.2            \n [79] S4Arrays_1.0.6                tmaptools_3.1-1              \n [81] pkgconfig_2.0.3               scico_1.5.0                  \n [83] gtable_0.3.4                  blob_1.2.4                   \n [85] XVector_0.40.0                htmltools_0.5.6.1            \n [87] scales_1.2.1                  png_0.1-8                    \n [89] knitr_1.44                    rstudioapi_0.15.0            \n [91] rjson_0.2.21                  curl_5.1.0                   \n [93] proxy_0.4-27                  cachem_1.0.8                 \n [95] rhdf5_2.44.0                  BiocVersion_3.17.1           \n [97] KernSmooth_2.23-21            vipor_0.4.5                  \n [99] parallel_4.3.1                AnnotationDbi_1.62.2         \n[101] leafsync_0.1.0                s2_1.1.4                     \n[103] pillar_1.9.0                  grid_4.3.1                   \n[105] vctrs_0.6.4                   promises_1.2.1               \n[107] BiocSingular_1.16.0           beachmat_2.16.0              \n[109] xtable_1.8-4                  cluster_2.1.4                \n[111] beeswarm_0.4.0                evaluate_0.22                \n[113] magick_2.8.0                  cli_3.6.1                    \n[115] locfit_1.5-9.8                compiler_4.3.1               \n[117] crayon_1.5.2                  classInt_0.4-10              \n[119] ggbeeswarm_0.7.2              plyr_1.8.9                   \n[121] stringi_1.7.12                stars_0.6-4                  \n[123] viridisLite_0.4.2             deldir_1.0-9                 \n[125] BiocParallel_1.34.2           munsell_0.5.0                \n[127] Biostrings_2.68.1             leaflet_2.2.0                \n[129] Matrix_1.5-4.1                leafem_0.2.3                 \n[131] sparseMatrixStats_1.12.2      bit64_4.0.5                  \n[133] Rhdf5lib_1.22.1               statmod_1.5.0                \n[135] KEGGREST_1.40.1               shiny_1.7.5.1                \n[137] interactiveDisplayBase_1.38.0 igraph_1.5.1                 \n[139] memoise_2.0.1                 lwgeom_0.2-13                \n[141] bit_4.0.5"
  },
  {
    "objectID": "05-spotbased.html#local-measures-for-multivariate-data",
    "href": "05-spotbased.html#local-measures-for-multivariate-data",
    "title": "Preamble",
    "section": "Local Measures for Multivariate Data",
    "text": "Local Measures for Multivariate Data\n\nBivariate Lee’s \\(L\\)\nThe implementation in the package spdep is as follows:\n\\[\nL(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}}\n\\] (https://r-spatial.github.io/spdep/reference/lee.htmlls)\nLee’s \\(L\\) is a bivariate measure that combines non-spatial Pearson Correlation with spatial autocorrelation via Moran’s \\(I\\) [3]. Instead of looking at the auto-correlation of one signle variable we can now assess the spatial dependence of two variables.\n\nloc &lt;- lee(x = sfe_tissue$nCounts, y = sfe_tissue$nGenes, n = length(sfe_tissue$nCounts), listw = weights_neighbourhoods)\n\n#convert into a plain sf object for plotting\nsf &lt;- colGeometries(sfe_tissue)$spotPoly\n\nsf$locEffect &lt;- loc$localL\n\ntm_shape(sf) + tm_fill(col = 'locEffect')  \n\n\n\n\n\nImplementation with Voyager\n\nsfe_tissue &lt;- runBivariate(sfe_tissue, \"locallee\", swap_rownames = \"symbol\",\n                           feature1 = c('nGenes', 'nCounts'))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)"
  },
  {
    "objectID": "00-setup.html#dependencies",
    "href": "00-setup.html#dependencies",
    "title": "Preamble",
    "section": "",
    "text": "Show the code\nlibrary(ggplot2)\nlibrary(RColorBrewer)\nlibrary(ExperimentHub)\nlibrary(SpatialExperiment)\nlibrary(STexampleData)"
  },
  {
    "objectID": "00-setup.html#setup",
    "href": "00-setup.html#setup",
    "title": "Preamble",
    "section": "Setup",
    "text": "Setup\n\n\nShow the code\neh &lt;- ExperimentHub()\nq &lt;- query(eh, \"MERFISH\")\ndf &lt;- eh[[\"EH7546\"]]"
  },
  {
    "objectID": "00-setup.html#wrangling",
    "href": "00-setup.html#wrangling",
    "title": "Preamble",
    "section": "Wrangling",
    "text": "Wrangling\n\n\nShow the code\n# extract cell metadata\ni &lt;- seq_len(9)\ncd &lt;- data.frame(df[, i], row.names = 1)\n\n# set sample identifiers\nid &lt;- grep(\"Bregma\", names(cd))\nnames(cd)[id] &lt;- \"sample_id\"\n\n# rename spatial coordinates\nxy &lt;- grep(\"Centroid\", names(cd))\nxy &lt;- names(cd)[xy] &lt;- c(\"x\", \"y\")\n\n# simplify annotations\ncd$cluster_id &lt;- cd$Cell_class\nfor (. in c(\"Endothelial\", \"OD Mature\", \"OD Immature\"))\n  cd$cluster_id[grep(., cd$cluster_id)] &lt;- .\n\n# extract & sparsify assay data\ny &lt;- data.frame(df[, -i], row.names = df[, 1])\ny &lt;- as(t(as.matrix(y)), \"dgCMatrix\")\n\n# construct SPE\n(spe &lt;- SpatialExperiment(\n  assays = list(exprs  = y),\n  spatialCoordsNames = xy,\n  colData = cd))\n\n\nclass: SpatialExperiment \ndim: 161 73655 \nmetadata(0):\nassays(1): exprs\nrownames(161): Ace2 Adora2a ... Ucn3 Vgf\nrowData names(0):\ncolnames(73655): 6749ccb4-2ed1-4029-968f-820a287f43c8\n  6cac74bd-4ea7-4701-8701-42563cc65eb8 ...\n  6b666f81-7b73-4100-9e02-b5381b39f0f3\n  fdcddd97-7701-462a-b48f-979111245bd5\ncolData names(7): Animal_ID Animal_sex ... Neuron_cluster_ID cluster_id\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : x y\nimgData names(0):\n\n\n\n\nShow the code\ngg &lt;- data.frame(spatialCoords(spe), colData(spe))\npal &lt;- brewer.pal(length(unique(gg$cluster_id)), \"Paired\")\nggplot(gg, aes(x, y, col = cluster_id)) +\n  facet_wrap(~ sample_id, scales = \"free\") +\n  geom_point(size = 0.1) + scale_color_manual(values = pal) +\n  guides(col = guide_legend(override.aes = list(size = 2))) +\n  theme_void() + theme(legend.key.size = unit(0.5, \"lines\"))"
  },
  {
    "objectID": "00-setup.html#setup-1",
    "href": "00-setup.html#setup-1",
    "title": "Preamble",
    "section": "Setup",
    "text": "Setup\n\n\nShow the code\nspe_vis &lt;- Visium_humanDLPFC()"
  },
  {
    "objectID": "05-univar-spotbased.html",
    "href": "05-univar-spotbased.html",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\ntheme_set(theme_light())\n\n\n\n\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, namels Mdkand Ncl[7]."
  },
  {
    "objectID": "05-univar-spotbased.html#dependencies",
    "href": "05-univar-spotbased.html#dependencies",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\ntheme_set(theme_light())"
  },
  {
    "objectID": "05-univar-spotbased.html#setup-and-preprocessing",
    "href": "05-univar-spotbased.html#setup-and-preprocessing",
    "title": "Preamble",
    "section": "",
    "text": "# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, namels Mdkand Ncl[7]."
  },
  {
    "objectID": "05-univar-spotbased.html#global-measures-for-univariate-data",
    "href": "05-univar-spotbased.html#global-measures-for-univariate-data",
    "title": "Preamble",
    "section": "Global Measures for Univariate Data",
    "text": "Global Measures for Univariate Data\nGlobal measures are values across an entire field of view. This gives e.g. one number per field of view.\nA common analysis to do with lattice data (and point pattern data) is to check for spatial correlation. This is a second-order property of the form (Getis 1991)\n\\[\n\\sum_i \\sum_j = w_{ij}U_{ij}\n\\]\nwhere \\(w_{ij}\\) is the weight matrix and \\(U_{ij}\\) a dissimilarity measure. [1]\n\nGlobal Moran’s I coefficient\nA common dissimilarity measure is Morans \\(I\\). It is defined by [1]\n\\[\nI = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(y_i - \\hat{y})(y_j - \\hat{y})}{\\sum_i (y_i - \\hat{y})^2}\n\\]\nUnder the null \\(I\\) takes the value \\(-1/(n-1)\\) in expectation. This value is close to \\(0\\) for large \\(n\\). A value higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation. Negative values indicate negative auto-correlation, but this is not so easy to interpret [1]. The implementation below is a Monte Carlo simulation approach to define a null distribution to test against.\n\nImplementation using VOYAGER\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n# plotSpatialFeature(sfe_tissue, features = \"nCounts\",\n#                    colGeometryName = \"spotPoly\",\n#                    annotGeometryName = \"myofiber_simplified\",\n#                    aes_use = \"color\", linewidth = 0.5, fill = NA,\n#                    annot_aes = list(fill = \"area\"))\n\nsfe_tissue &lt;-  colDataUnivariate(sfe_tissue, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"visium\", nsim = 1000,\n                                type = \"moran.mc\")\n\nres &lt;- colFeatureData(sfe_tissue)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$moran.mc_statistic_Vis5A\n\n[1] 0.5287047 0.3840275\n\n#p-value\nres$moran.mc_p.value_Vis5A\n\n[1] 0.000999001 0.000999001\n\nplotMoranMC(sfe_tissue, c(\"nCounts\", \"nGenes\"))\n\n\n\n\n\n\nImplementation using spdep\n\n#create nearest neighbours weights \nweights_neighbourhoods &lt;- colGraph(sfe_tissue, \"visium\")\n\nsfe_tissue[rowData(sfe_tissue)[,'symbol'] == 'Myh2',]\n\nclass: SpatialFeatureExperiment \ndim: 1 932 \nmetadata(0):\nassays(2): counts logcounts\nrownames(1): ENSMUSG00000033196\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(932): AAACATTTCCCGGATT AAACCTAAGCAGCCGG ... TTGTGTTTCCCGAAAG\n  TTGTTGTGTGTCAAGA\ncolData names(13): barcode col ... in_tissue sizeFactor\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: col: visium\n\nspdep::moran.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe_tissue$nGenes  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 19.758, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.3840275174     -0.0010741139      0.0003798881 \n\nspdep::moran.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods, randomisation = FALSE)\n\n\n    Moran I test under normality\n\ndata:  sfe_tissue$nCounts  \nweights: weights_neighbourhoods    \n\nMoran I statistic standard deviate = 27.181, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.5287046946     -0.0010741139      0.0003798881 \n\n\nThe number of genes per spot shows a Moran’s \\(I\\) of \\(\\sim 0.38\\) which indicates auto-correlation. The number of counts per spot shows a Moran’s \\(I\\) of \\(\\sim 0.53\\).\n\n\n\nGlobal Geary’s C coefficient\nAnother measure of spatial auto-correlation is Geary’s \\(C\\). It is very closely related to Moran’s \\(I\\). Geary’s \\(C\\) is defined by:\n\\[\nC = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(y_i-y_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(y_i-\\bar{y})^2}\n\\]\nThe interpretation is inveresely to Moran’s \\(I\\). A value less than \\(1\\) indicates positive auto-correlation, a value more than \\(1\\) negative auto-correlation. (https://pachterlab.github.io/voyager/articles/visium_10x.html)\nThe testing works similarly to Moran’s \\(I\\), just the objective function changes in the Monte Carlo estimation\n\nImplementation using VOYAGER\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\nsfe_tissue &lt;-  colDataUnivariate(sfe_tissue, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"visium\", nsim = 1000,\n                                type = \"geary.mc\")\n\nres &lt;- colFeatureData(sfe_tissue)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$geary.mc_statistic_Vis5A\n\n[1] 0.4748925 0.6057966\n\n#p-value\nres$geary.mc_p.value_Vis5A\n\n[1] 0.000999001 0.000999001\n\n\n\n\nImplementation using spdep\n\nspdep::geary.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe_tissue$nGenes \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 19.996, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     0.6057966472      1.0000000000      0.0003886284 \n\nspdep::geary.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods, randomisation = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  sfe_tissue$nCounts \nweights: weights_neighbourhoods \n\nGeary C statistic standard deviate = 26.729, p-value &lt; 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     0.4748924980      1.0000000000      0.0003859596 \n\n\nThe Geary’s \\(C\\) statistic gives a value of \\(0.47\\) for the number of counts and \\(0.61\\) for the number of genes. The interpretation is that both features show positive auto correlation.\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/gean.12164\n\n\n\nGlobal Getis-Ord \\(G\\) statistic\nThe global \\(G\\) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in teh dataset. Formally that is,\n\\[\nG(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j}, \\text{s.t } j \\neq i\n\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather considering both approaches.\n–&gt; weights should be binarised for this test - how to do this?\n\nspdep::globalG.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods)\n\n\n    Getis-Ord global G statistic\n\ndata:  sfe_tissue$nGenes \nweights: weights_neighbourhoods \n\nstandard deviate = 20.757, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.185181e-03       1.074114e-03       2.863192e-11 \n\nspdep::globalG.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods)\n\n\n    Getis-Ord global G statistic\n\ndata:  sfe_tissue$nCounts \nweights: weights_neighbourhoods \n\nstandard deviate = 27.797, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.361423e-03       1.074114e-03       1.068346e-10 \n\n\n[5]"
  },
  {
    "objectID": "05-univar-spotbased.html#local-measures-for-univariate-data",
    "href": "05-univar-spotbased.html#local-measures-for-univariate-data",
    "title": "Preamble",
    "section": "Local Measures for Univariate Data",
    "text": "Local Measures for Univariate Data\n\nLocal Moran’s I coefficient\nOften a global measure is not enough. One number determining e.g. the spatial autocorrelation over an entire tissue slice might not be reflective of tissue heterogeneity. Therefore, local indicators of spatial associations have been developed [2]. For each sampling location we calculate as follows (https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1538-4632.1995.tb00338.x) (formula from ?localmoran)\n\\[\nI_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\n\\]\nSince we are calculating several local statistics potentially from the same observations, problems of multiple testing arise. We correct for this issue with standard adjustments, such as Benjamini Hochberg correction (https://rss.onlinelibrary.wiley.com/doi/10.1111/j.2517-6161.1995.tb02031.x). The problem of false positives due to multiple testing is discussed in great detail in [2].\nImplementation with spdep\n\n#calculate local Moran's I and then correct for multiple testing using Benjamini-Hochberg correction if you want to plot p-values\nlocalplot &lt;- function(sfe, var, fun, plotvar, weights_neighbourhoods){\n  loc &lt;- do.call(fun, args = list(x=sfe[[var]], listw = weights_neighbourhoods))\n  #why so ever, 'localG' has a different return structure than 'localmoran'. Thus, this conditional with different indexing\n  if(fun %in% c('localG')){\n    loc &lt;- attr(loc, 'internals')\n    #extract the effect size\n    locEffect &lt;- loc[,1]\n    #extract the p-value and adjust for multiple testing\n    p.val.adj &lt;- loc[,5] |&gt; p.adjust(\"BH\")\n  }\n  else if(fun == 'localC_perm'){\n    p.val.adj &lt;- attr(loc, 'pseudo-p')[,'Pr(z != E(Ci))']\n    locEffect &lt;- loc\n  }\n  else if (fun == 'LOSH'){\n    locEffect &lt;- loc[,1]\n    p.val.adj &lt;- c()\n  }\n  else{\n    #extract the effect size\n    locEffect &lt;- loc[,1]\n    #extract the p-value and adjust for multiple testing\n    p.val.adj &lt;- loc[,5] |&gt; p.adjust(\"BH\")\n  }\n  \n  #convert into a plain sf object for plotting\n  sf &lt;- colGeometries(sfe)$spotPoly\n  \n  sf$locEffect &lt;- locEffect\n  sf$p.val.adj &lt;- p.val.adj\n  \n  return(tm_shape(sf) + tm_fill(col = plotvar))\n}\n\np &lt;- localplot(sfe_tissue, 'nCounts', fun = 'localmoran', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\nq &lt;- localplot(sfe_tissue, 'nGenes', fun = 'localmoran', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\n\ntmap_arrange(p,q)\n\n\n\n\n\nImplementation with Voyager\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localmoran\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localmoran\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\nLocal Geary’s C coefficient\nGeary’s C can be calculated for local interactions as well.\n\\[\nC_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2\n\\]\nThe interpretation is the same as for local Moran’s \\(I\\) [6].\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'localC_perm', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'localC_perm', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\n\ntmap_arrange(p,q)\n\n\n\n\n\nImplementation with Voyager\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localC_perm\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localC_perm\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\nLocal Getis-Ord \\(G_i\\) coefficient\nThe local Getis-Ord \\(G_i\\) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\).\n\\[\nG_i(d) = \\frac{\\sum_{j=1}^n w_{ij}(d)x_j}{\\sum_{j=1}^n x_j}, \\text{s.t } j \\neq i\n\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\) which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term. Importantly, \\(G_i(d)\\) is scale-invariant but not location-invariant. That means, the subdivision into the \\(n\\) subregions matterns for the computation of the local statistic [5].\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'localG', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'localG', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\n\ntmap_arrange(p,q)\n\n\n\n\n\nImplementation with Voyager\n\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\nLocal Spatial Heteroscedasticity (LOSH)\nThe univariate methods described above assume homoscedastic variance so that the variance is uniform over the sampling area [4]. In the context of tumour-immune infiltration we could have regions where the mean infiltration is the same but the variability depends on the specific pathology. Therefore, a new statistic was introduced, local spatial heteroscedasticity (LOSH). The aim of LOSH is similar to the local \\(G\\) statistic, where we compared means, to now compare variances. The aim is to compare homogeienity and heterogeneity of groups in space. This statistic is especially interesting in combination with the local \\(G\\) statistic, giving an overview on the mean-variance relationship of the sample [4].\nLOSH is defined formally as follows:\n\\[\nH_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\n\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_j(d), j\\in N(i,d)\\) are the local residuals [4].\nOrd and Getis provide a very nice table for the interpretation of the mean and variance relationship provided by \\(G_i\\) and \\(H_i\\).\nThe LOSH should be interpreted in the combination with local Getis-Ord \\(G_i^*\\) statistic. The \\(G_i^*\\) quantifies the local mean of the variable of interest, while \\(H_i\\) quantifies the local variance. This table provided by Ord and Getis (2012) summarizes the interpretation of the combination of \\(G_i^*\\) and \\(H_i\\).\n\n\n\n\n\n\n\n\n\nhigh \\(H_i\\)\nlow \\(H_i\\)\n\n\n\n\nlarge \\(\\|G_i^*\\|\\)\nA hot spot with heterogeneous local conditions\nA hot spot with similar surrounding areas; the map would indicate whether the affected region is larger than the single “cell”\n\n\nsmall $ |G_i^*| $\nHeterogeneous local conditions but at a low average level (an unlikely event)\nHomogeneous local conditions and a low average level\n\n\n\n\np &lt;- localplot(sfe_tissue, var = 'nCounts', fun = 'LOSH', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\nq &lt;- localplot(sfe_tissue, var = 'nGenes', fun = 'LOSH', plotvar = 'locEffect', weights_neighbourhoods = weights_neighbourhoods)\n\ntmap_arrange(p,q)"
  },
  {
    "objectID": "05-univar-spotbased.html#voyager",
    "href": "05-univar-spotbased.html#voyager",
    "title": "Preamble",
    "section": "VOYAGER",
    "text": "VOYAGER\nThere is a very nice resource explaining in detail the available methods for lattice data (amongst others) (https://pachterlab.github.io/voyager/index.html). We will summarise complement these approaches in this chapter"
  },
  {
    "objectID": "05-univar-spotbased.html#sources",
    "href": "05-univar-spotbased.html#sources",
    "title": "Preamble",
    "section": "Sources",
    "text": "Sources\n[1] Zuur, A. F., Ieno, E. N., Smith, G. M., Saveliev, A. A., Mukharamova, S. S., & Zuur, A. F. (2007). Analysis and modelling of lattice data. Analysing Ecological Data, 321-339.\n[2] Pebesma, E., & Bivand, R. (2023). Spatial data science: With applications in R. CRC Press.\n[3] Lee, S. I. (2001). Developing a bivariate spatial association measure: an integration of Pearson’s r and Moran’s I. Journal of geographical systems, 3, 369-385.\n[4] Ord, J. K., & Getis, A. (2012). Local spatial heteroscedasticity (LOSH). The Annals of Regional Science, 48, 529-539.\n[5] Getis, A., & Ord, J. K. (1992). The analysis of spatial association by use of distance statistics. Geographical analysis, 24(3), 189-206.\n[6] Anselin, L. (1995). Local indicators of spatial association—LISA. Geographical analysis, 27(2), 93-115.\n[7] McKellar, D. W., Walter, L. D., Song, L. T., Mantri, M., Wang, M. F., De Vlaminck, I., & Cosgrove, B. D. (2021). Large-scale integration of single-cell transcriptomic data captures transitional progenitor states in mouse skeletal muscle regeneration. Communications biology, 4(1), 1280. ## Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] stringr_1.5.0                  dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.10.3                 SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-14                     \n[17] reshape2_1.4.4                 patchwork_1.1.3               \n[19] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[21] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[23] dbplyr_2.3.4                   RANN_2.6.1                    \n[25] seg_0.5-7                      sp_2.1-1                      \n[27] rlang_1.1.1                    ggplot2_3.4.4                 \n[29] dplyr_1.1.3                    mixR_0.2.0                    \n[31] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[33] spatstat.model_3.2-6           rpart_4.1.19                  \n[35] spatstat.explore_3.2-3         nlme_3.1-162                  \n[37] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[39] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[41] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[43] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[45] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[47] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[49] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  dbscan_1.1-11                \n [19] R.utils_2.12.2                dichromat_2.0-0.1            \n [21] scico_1.5.0                   limma_3.56.2                 \n [23] rstudioapi_0.15.0             RSQLite_2.3.1                \n [25] generics_0.1.3                crosstalk_1.2.0              \n [27] Matrix_1.5-4.1                ggbeeswarm_0.7.2             \n [29] fansi_1.0.5                   abind_1.4-5                  \n [31] R.methodsS3_1.8.2             terra_1.7-55                 \n [33] lifecycle_1.0.3               yaml_2.3.7                   \n [35] edgeR_3.42.4                  rhdf5_2.44.0                 \n [37] tmaptools_3.1-1               grid_4.3.1                   \n [39] blob_1.2.4                    promises_1.2.1               \n [41] dqrng_0.3.1                   crayon_1.5.2                 \n [43] lattice_0.21-8                beachmat_2.16.0              \n [45] KEGGREST_1.40.1               magick_2.8.0                 \n [47] pillar_1.9.0                  knitr_1.44                   \n [49] metapod_1.7.0                 rjson_0.2.21                 \n [51] boot_1.3-28.1                 codetools_0.2-19             \n [53] wk_0.8.0                      glue_1.6.2                   \n [55] vctrs_0.6.4                   png_0.1-8                    \n [57] gtable_0.3.4                  cachem_1.0.8                 \n [59] xfun_0.40                     S4Arrays_1.0.6               \n [61] mime_0.12                     DropletUtils_1.20.0          \n [63] units_0.8-4                   statmod_1.5.0                \n [65] bluster_1.10.0                interactiveDisplayBase_1.38.0\n [67] ellipsis_0.3.2                bit64_4.0.5                  \n [69] filelock_1.0.2                irlba_2.3.5.1                \n [71] vipor_0.4.5                   KernSmooth_2.23-21           \n [73] colorspace_2.1-0              DBI_1.1.3                    \n [75] raster_3.6-26                 tidyselect_1.2.0             \n [77] bit_4.0.5                     compiler_4.3.1               \n [79] curl_5.1.0                    BiocNeighbors_1.18.0         \n [81] DelayedArray_0.26.7           scales_1.2.1                 \n [83] classInt_0.4-10               rappdirs_0.3.3               \n [85] goftest_1.2-3                 spatstat.utils_3.0-3         \n [87] rmarkdown_2.25                XVector_0.40.0               \n [89] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [91] base64enc_0.1-3               sparseMatrixStats_1.12.2     \n [93] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [95] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [97] farver_2.1.1                  jsonlite_1.8.7               \n [99] BiocParallel_1.34.2           R.oo_1.25.0                  \n[101] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[103] magrittr_2.0.3                GenomeInfoDbData_1.2.10      \n[105] s2_1.1.4                      Rhdf5lib_1.22.1              \n[107] munsell_0.5.0                 Rcpp_1.0.11                  \n[109] ggnewscale_0.4.9              viridis_0.6.4                \n[111] stringi_1.7.12                leafsync_0.1.0               \n[113] zlibbioc_1.46.0               plyr_1.8.9                   \n[115] parallel_4.3.1                ggrepel_0.9.4                \n[117] deldir_1.0-9                  Biostrings_2.68.1            \n[119] stars_0.6-4                   splines_4.3.1                \n[121] tensor_1.5                    locfit_1.5-9.8               \n[123] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[125] BiocVersion_3.17.1            XML_3.99-0.14                \n[127] evaluate_0.22                 BiocManager_1.30.22          \n[129] httpuv_1.6.11                 purrr_1.0.2                  \n[131] polyclip_1.10-6               rsvd_1.0.5                   \n[133] lwgeom_0.2-13                 xtable_1.8-4                 \n[135] e1071_1.7-13                  RSpectra_0.16-1              \n[137] later_1.3.1                   viridisLite_0.4.2            \n[139] class_7.3-22                  tibble_3.2.1                 \n[141] memoise_2.0.1                 beeswarm_0.4.0               \n[143] AnnotationDbi_1.62.2          cluster_2.1.4"
  },
  {
    "objectID": "06-multivar-spotbased.html",
    "href": "06-multivar-spotbased.html",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\ntheme_set(theme_light())\n\n\n\n\n\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\nweights_neighbourhoods &lt;- colGraph(sfe_tissue, \"visium\")\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, namels Mdkand Ncl[7]."
  },
  {
    "objectID": "06-multivar-spotbased.html#dependencies",
    "href": "06-multivar-spotbased.html#dependencies",
    "title": "Preamble",
    "section": "",
    "text": "source(\"utils.R\")\ntheme_set(theme_light())"
  },
  {
    "objectID": "06-multivar-spotbased.html#setup-and-preprocessing",
    "href": "06-multivar-spotbased.html#setup-and-preprocessing",
    "title": "Preamble",
    "section": "",
    "text": "# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\nweights_neighbourhoods &lt;- colGraph(sfe_tissue, \"visium\")\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, namels Mdkand Ncl[7]."
  },
  {
    "objectID": "06-multivar-spotbased.html#local-measures-for-multivariate-data",
    "href": "06-multivar-spotbased.html#local-measures-for-multivariate-data",
    "title": "Preamble",
    "section": "Local Measures for Multivariate Data",
    "text": "Local Measures for Multivariate Data\n\nBivariate Lee’s \\(L\\)\nThe implementation in the package spdep is as follows:\n\\[\nL(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}}\n\\] (https://r-spatial.github.io/spdep/reference/lee.htmlls)\nLee’s \\(L\\) is a bivariate measure that combines non-spatial Pearson Correlation with spatial autocorrelation via Moran’s \\(I\\) [3]. Instead of looking at the auto-correlation of one signle variable we can now assess the spatial dependence of two variables.\n\nloc &lt;- lee(x = sfe_tissue$nCounts, y = sfe_tissue$nGenes, n = length(sfe_tissue$nCounts), listw = weights_neighbourhoods)\n\n#convert into a plain sf object for plotting\nsf &lt;- colGeometries(sfe_tissue)$spotPoly\n\nsf$locEffect &lt;- loc$localL\n\ntm_shape(sf) + tm_fill(col = 'locEffect')  \n\n\n\n\n\nImplementation with Voyager\n\nsfe_tissue &lt;- runBivariate(sfe_tissue, \"locallee\", swap_rownames = \"symbol\",\n                           feature1 = c('nGenes', 'nCounts'))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0, image_id = \"lowres\", maxcell = 5e4)\n\n\n\n\nMultivariate local Geary’s C\nGeary’s C is a measure of spatial autocorrelation that is based on the difference between a variable and its neighbours. It is defined as\n\\[C_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2\\]\nand can be generalized to \\(k\\) parameters by expanding\n\\[c_{k,i} = \\sum_{v=1}^k c_{v,i}\\]\nwhere \\(c_{v,i}\\) is the local Geary’s C for the \\(v\\)th variable at location \\(i\\). Compared to bivariates Lee it means that we use more than two variables.\n\nhvgs &lt;- getTopHVGs(sfe_tissue, fdr.threshold = 0.01)\n\nsfe_tissue &lt;- runMultivariate(sfe_tissue, type = \"localC_multi\",\n                    subset_row = hvgs,\n                    dest = \"colData\")\n\n#plotSpatialFeature(sfe_tissue,\"localC_multi\", colGeometryName = \"spotPoly\", image_id = NULL)"
  },
  {
    "objectID": "06-multivar-spotbased.html#voyager",
    "href": "06-multivar-spotbased.html#voyager",
    "title": "Preamble",
    "section": "VOYAGER",
    "text": "VOYAGER\nThere is a very nice resource explaining in detail the available methods for lattice data (amongst others) (https://pachterlab.github.io/voyager/index.html). We will summarise complement these approaches in this chapter"
  },
  {
    "objectID": "06-multivar-spotbased.html#sources",
    "href": "06-multivar-spotbased.html#sources",
    "title": "Preamble",
    "section": "Sources",
    "text": "Sources\n[1] Zuur, A. F., Ieno, E. N., Smith, G. M., Saveliev, A. A., Mukharamova, S. S., & Zuur, A. F. (2007). Analysis and modelling of lattice data. Analysing Ecological Data, 321-339.\n[2] Pebesma, E., & Bivand, R. (2023). Spatial data science: With applications in R. CRC Press.\n[3] Lee, S. I. (2001). Developing a bivariate spatial association measure: an integration of Pearson’s r and Moran’s I. Journal of geographical systems, 3, 369-385.\n[4] Ord, J. K., & Getis, A. (2012). Local spatial heteroscedasticity (LOSH). The Annals of Regional Science, 48, 529-539.\n[5] Getis, A., & Ord, J. K. (1992). The analysis of spatial association by use of distance statistics. Geographical analysis, 24(3), 189-206.\n[6] Anselin, L. (1995). Local indicators of spatial association—LISA. Geographical analysis, 27(2), 93-115.\n[7] McKellar, D. W., Walter, L. D., Song, L. T., Mantri, M., Wang, M. F., De Vlaminck, I., & Cosgrove, B. D. (2021). Large-scale integration of single-cell transcriptomic data captures transitional progenitor states in mouse skeletal muscle regeneration. Communications biology, 4(1), 1280. ## Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] stringr_1.5.0                  dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.10.3                 SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-14                     \n[17] reshape2_1.4.4                 patchwork_1.1.3               \n[19] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[21] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[23] dbplyr_2.3.4                   RANN_2.6.1                    \n[25] seg_0.5-7                      sp_2.1-1                      \n[27] rlang_1.1.1                    ggplot2_3.4.4                 \n[29] dplyr_1.1.3                    mixR_0.2.0                    \n[31] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[33] spatstat.model_3.2-6           rpart_4.1.19                  \n[35] spatstat.explore_3.2-3         nlme_3.1-162                  \n[37] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[39] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[41] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[43] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[45] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[47] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[49] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     proxy_0.4-27                 \n [17] dbscan_1.1-11                 R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.2.1                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] spatstat.utils_3.0-3          rmarkdown_2.25               \n [87] XVector_0.40.0                htmltools_0.5.6.1            \n [89] pkgconfig_2.0.3               base64enc_0.1-3              \n [91] sparseMatrixStats_1.12.2      fastmap_1.1.1                \n [93] htmlwidgets_1.6.2             shiny_1.7.5.1                \n [95] DelayedMatrixStats_1.22.6     jsonlite_1.8.7               \n [97] BiocParallel_1.34.2           R.oo_1.25.0                  \n [99] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[101] magrittr_2.0.3                GenomeInfoDbData_1.2.10      \n[103] s2_1.1.4                      Rhdf5lib_1.22.1              \n[105] munsell_0.5.0                 Rcpp_1.0.11                  \n[107] ggnewscale_0.4.9              viridis_0.6.4                \n[109] stringi_1.7.12                leafsync_0.1.0               \n[111] zlibbioc_1.46.0               plyr_1.8.9                   \n[113] parallel_4.3.1                ggrepel_0.9.4                \n[115] deldir_1.0-9                  Biostrings_2.68.1            \n[117] stars_0.6-4                   splines_4.3.1                \n[119] tensor_1.5                    locfit_1.5-9.8               \n[121] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[123] BiocVersion_3.17.1            XML_3.99-0.14                \n[125] evaluate_0.22                 BiocManager_1.30.22          \n[127] httpuv_1.6.11                 purrr_1.0.2                  \n[129] polyclip_1.10-6               rsvd_1.0.5                   \n[131] lwgeom_0.2-13                 xtable_1.8-4                 \n[133] e1071_1.7-13                  RSpectra_0.16-1              \n[135] later_1.3.1                   viridisLite_0.4.2            \n[137] class_7.3-22                  tibble_3.2.1                 \n[139] memoise_2.0.1                 beeswarm_0.4.0               \n[141] AnnotationDbi_1.62.2          cluster_2.1.4"
  },
  {
    "objectID": "01-within-marks.html#sources",
    "href": "01-within-marks.html#sources",
    "title": "Discrete Marks",
    "section": "Sources",
    "text": "Sources\n[1] Baddeley, A., Rubak, E., & Turner, R. (2015). Spatial point patterns: methodology and applications with R. CRC press.\n[2] Ramsay JO, Silverman BW (2005). Functional Data Analysis. 2nd edition. Springer-Verlag, New York."
  },
  {
    "objectID": "01-within-marks.html#summary-functions-for-continuous-marks",
    "href": "01-within-marks.html#summary-functions-for-continuous-marks",
    "title": "Discrete Marks",
    "section": "Summary functions for continuous marks",
    "text": "Summary functions for continuous marks\nAs in the discrete case, summary functions assume that the point process is stationary.\n\nMark correlation function\nThe mark correlation function measures the dependence between two marks for two points at distance \\(r\\). It is applicable to stationary point processes with marks. It is not a correlation in the classical sense, since it cannot take negative values [MR: was this a typo? is this correct?]. Instead, a value of 1 indicates no correlation between the marks [MR: does this mean that negative correlation is not allowed? Or, would it appear as ‘less than 1’?]. The generalized mark correlation function is given by:\n\\[ k_f(r) = \\frac{\\mathbb{E}[f(m(u),m(v))]}{\\mathbb{E}[f(M,M')]},\\] where \\(f(m_1,m_2)\\) is a test function with two arguments (representing the two marks) and returns a non-negative value [MR: what are \\(u\\) and \\(v\\) in the formula above?]. For continuous non-negative marks, the canonical choice for \\(f\\) is typically \\(f(m_1,m_2)= m_1 m_2\\). \\(M\\) and \\(M′\\) represent independent, identically distributed random points with the same distribution as the mark of a randomly chosen point. This denominator is chosen such that random marks have a mark correlation of 1 (Baddeley, Rubak, and Turner 2015, 644–45).\n\n\nCode\nplotMetric(plot_by = genes,  pp = pp, x = 'r', fun = 'markcorr', edgecorr = 'iso', continuous = TRUE)\n\n\n\n\n\nFrom this plot we show that all genes show a positive correlation at small distances which decline with increasing radius \\(r\\). The association is strongest for the Slc18a2 gene. We can calculate simulation envelopes to estimate the significance of this association. This is not shown for brevity.\n\n\nMark-weighted \\(K\\)-function\nThe mark-weigthed \\(K\\)-function is a generalization of the \\(K\\)-function in which the contribution from each pair of points is weighted by a function of their respective marks. It is given by:\n\\[K_f(r) = \\frac 1  \\lambda \\frac{C_f(r)}{E[ f(M_1, M_2) ]},\\] where:\n\\[ C_f(r) = E \\left[ \\sum_{x \\in X} f(m(u), m(x)) 1\\{0 &lt; ||u - x|| \\le r\\} \\;  \\big| \\; u \\in X \\right], \\]\nis equivalent to the unnormalized mark-weighted \\(K\\)-function. For every point \\(u\\), we sum the euclidean distance \\(||u - x||\\) of all other points \\(x\\) that are within a distance \\(r\\). This sum is weighted by the function \\(f(.,.)\\) of the marks of \\(u\\) and \\(x\\). The function is standardized by the expected value of \\(f(M_1, M_2)\\) where \\(M_1, M_2\\) represent independent, identically distributed random points with the same distribution as the mark of a randomly chosen point (Baddeley, Rubak, and Turner 2015, 646–47).\nIn the scenario of random labeling, so where the labels or in this case marks are distributed randomly, the mark-weighted \\(K\\)-function corresponds to the standard Ripley’s \\(K\\)-function.\nAlso here, the canonical function is: \\(f(m_1, m_2) = m_1 m_2\\). This means we weigh each interaction between points by the product of the continuous marks of both points.\n\n\nCode\nplotMetric(plot_by = genes,  pp = pp, x = 'r', fun = 'Kmark', edgecorr = 'iso', continuous = TRUE, f = function(m1,m2){m1*m2})\n\n\n\n\n\nIt is important to note that the theoretical value of the \\(K\\)-function is not very informative since it represents the \\(K\\)-function of a Poisson point process and the underlying point process might not be Poisson. Therefore we compare the mark-weighted with its unmarked analogue. Like this, we can assess whether the points weighted by a continuous mark are more or less correlated than their unmarked analogues (Baddeley, Rubak, and Turner 2015, 647).\nHere we will compare the \\(L\\)-functions weighted by the mark of the gene Esr1 and the unmarked \\(L\\)-function.\n\n\nCode\nppEsr1 &lt;- subset(pp, select = 'Esr1')\nL.Esr1L &lt;- Kmark(ppEsr1, function(m1,m2) {m1*m2}, returnL = TRUE)\nLest.ppEsr1 &lt;- Lest(ppEsr1, nlarge=7000)\nplot(eval.fv(L.Esr1L - Lest.ppEsr1))\n\n\n\n\n\nWe note that the difference between \\(L\\)-function weighted by the expression of Esr1 minus the unmarked \\(L\\)-function is positively different to the poisson difference, meaning that the expression of the continuous mark Esr1 is correlated among itself."
  },
  {
    "objectID": "00-home.html",
    "href": "00-home.html",
    "title": "",
    "section": "",
    "text": "Imaging-based data can be interpreted as a point pattern either via the transcript locations or via cell centroids. Alternatively, the segmented cellular outlines can be interpreted as an irregular lattice. High throughput (HTS)-based approaches are most often recorded on a regular lattice. This enables either point pattern or lattice data analysis (Baddeley, Rubak, and Turner 2015; Pebesma and Bivand 2023; Rao et al. 2021). Data: (Shi et al. 2023; 10X 2022).. \n\nThis vignette provides an overview of exploratory data analysis techniques tailored to the data modalities arising from the two primary spatial transcriptomic technologies: image-based methods (e.g., MERFISH, CosMx, Xenium) and spot-based approaches (e.g., Visium).\nImage-based techniques yield subcellular-resolution images, allowing for the study of cells within their natural context. This data can be analysed as spatial point pattern where the points represent cells. Alternatively, we can rely on the segmentation of each individual cell and interpret the collection of all cells as an irregular lattice.\nIn contrast, spot-based methods, not yet achieving subcellular resolution, produce data represented as a regularly spaced grid corresponding to the sampling locations (spots). Each location has the same area and consists of a collection of different measurements.\n\n\n\n\n©2024 The pasta authors. Content is published under Creative Commons CC-BY-4.0 License for the text and GPL-3 License for any code.References\n\n10X. 2022. “Mouse Brain Section (Coronal).” https://www.10xgenomics.com/datasets/mouse-brain-section-coronal-1-standard.\n\n\nBaddeley, Adrian, Ege Rubak, and Rolf Turner. 2015. Spatial Point Patterns. 1st ed. CRC Interdisciplinary Statistics Series. CRC Press, Taylor & Francis Group.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. 1st ed. New York: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nRao, Anjali, Dalia Barkley, Gustavo S. França, and Itai Yanai. 2021. “Exploring Tissue Architecture Using Spatial Transcriptomics.” Nature 596 (7871): 211–20. https://doi.org/10.1038/s41586-021-03634-9.\n\n\nShi, Hailing, Yichun He, Yiming Zhou, Jiahao Huang, Kamal Maher, Brandon Wang, Zefang Tang, et al. 2023. “Spatial Atlas of the Mouse Central Nervous System at Molecular Resolution.” Nature 622 (7983): 552–61."
  },
  {
    "objectID": "pp_theory_helper.html",
    "href": "pp_theory_helper.html",
    "title": "",
    "section": "",
    "text": "Code\nsource(\"utils.R\")"
  },
  {
    "objectID": "pp_theory_helper.html#dependencies",
    "href": "pp_theory_helper.html#dependencies",
    "title": "",
    "section": "",
    "text": "Code\nsource(\"utils.R\")"
  },
  {
    "objectID": "pp_theory_helper.html#setup",
    "href": "pp_theory_helper.html#setup",
    "title": "",
    "section": "Setup",
    "text": "Setup\n\n\nCode\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#subset the data to only look at sample ID 0.01, 0.06 and 0.26\n# list(\"-0.29\", \"0.01\", \"0.06\")\n#zstack_list &lt;- list(\"-0.04\", '-0.09', '-0.14', '-0.19', '-0.24', '-0.29', '0.01', '0.06', '0.11', '0.16', '0.21', \"0.26\")\n\n#define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n\n#define the celltype that you want to compare across the stacks - hereby we assume independence across the z-stacks which is an assumption that can be challenged\ncelltype_ls &lt;- \"OD Mature\"\n\nselectZstacks &lt;- function(zstack, spe){\n  sub &lt;- spe[, spe$sample_id == zstack]\n  pp &lt;- .ppp(sub, marks = \"cluster_id\")\n  return(pp)\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe)\nnames(pp_ls) &lt;- zstack_list\n\n\nThe theory of spatial point patterns is discussed in great detail in (Baddeley, Rubak, and Turner 2015). The book has an accompanying package called spatstat which offers great functionality to the theoretical concepts discribed in the book (Baddeley and Turner 2005). This chapter relies heavily on both publications."
  },
  {
    "objectID": "pp_theory_helper.html#concepts-and-definitions-of-point-processes",
    "href": "pp_theory_helper.html#concepts-and-definitions-of-point-processes",
    "title": "",
    "section": "Concepts and Definitions of Point Processes",
    "text": "Concepts and Definitions of Point Processes\n\nPoint Process\nIn point pattern analysis we assume that the patterns we observe are a realisation of a stochastic process called a point process. The inferences we make about the point pattern are based on the point process. E.g. the pattern can be said to be created by a poisson point process and thus is evenly distributed in the observation window (Baddeley, Rubak, and Turner 2015, 127).\nWhen considering a pattern with \\(m\\) multiple types, as we do in the (Moffitt et al. 2018) dataset, there are two very closely related concepts. One can view the pattern as a multitype point pattern, where all the points are sampled from the same point process. The other option is to consider the pattern as a multivariate point pattern, where the points come from \\(m\\) distinct point processes. The difference between these two views is that in the multitype framework we assume the points to stem from the same point process and thus depend on each other. In the multivariate framework we assume that the types stem from independent point processes and therefore we can consider dependencies of one type alone. Whether or not the underlying point processes are independent depends on the biological question. If we analyse two celltypes in one slice of a tissue, we should consider them as being sampled from one point process. However, if we consider the distribution of a celltype in two slices of the same tissue we can have grounds to consider the point processes as independent (Baddeley, Rubak, and Turner 2015, 565).\n\n\nObservation Windows\nThe most common set up in point pattern analysis is what we call window sampling. Instead of observing the entire pattern we observe a subset of this pattern in the so called window. In the analysis we try to make inference on the entire point process based on the observed window. An example could be different small microscopy windows through which a big tissue slice is observed. The windows would be samples of the bigger point process. In this case, it would be wrong to assume the window to be the convex hull around the observed points because they are just a sample of the bigger point pattern (Baddeley, Rubak, and Turner 2015, 144–45).\nThere is another concept called the small world model. It assumes that points can only be observed in a finite small world and not beyond these boundaries. When thinking of an entire tissue, this is a very common scenario. Cells can only be observed within the tissue and not beyond. In this case, it would be correct to not assume a rectangular observation window but to use more conservative methods to estimate an unknown sampling window such as the Ripley-Rasson estimate of a spatial domain (Baddeley, Rubak, and Turner 2015, 144–45).\nIn both cases it is important to understand the direction of the bias. If the unknown window is estimated to be smaller than the true window, we underestimate the window. This then again leads to an overestimation of the density of points and to other characteristics of the pattern. Therefore, an underestimation of the window size is more concerning than a slight overestimation (Baddeley, Rubak, and Turner 2015, 144–45).\n\n\nCode\nsetRiprasWindows &lt;- function(pp){\n  Window(pp) &lt;- ripras(pp)\n  marks(pp) &lt;- factor(marks(pp))\n  return(pp)\n}\n#the entire point patterns with the ripras windows\npp &lt;- lapply(pp_ls, setRiprasWindows)\n\nseparateMarks &lt;- function(pp){\n  #split the multitype point process into several single type processes\n  ppls &lt;- split(pp)\n  return (ppls)\n}\n#the point patterns separated by their marks\npp_ls &lt;- lapply(pp, separateMarks)\n\n\n\n\nComplete Spatial Randomness\nComplete spatial randomness (CSR) is often used as the null model for various point patterns, and is the result of a Poisson process. A completely spatial random process is characterised by two properties, homogeneity and independence, as discussed below (Baddeley, Rubak, and Turner 2015, 132).\n\nHomogeneity\n“Homogeneity […] means that the expected number of points falling in a region B should be proportional to its area |B|” (Baddeley, Rubak, and Turner 2015, 132) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) represents the intensity of the process, i.e., the average number of points in a unit area (Baddeley, Rubak, and Turner 2015, 132–33). :\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|.\n\\label{eq:expected_number_points}\n\\]\n\n\nIndependence\nIndependence implies that in two (non-overlapping) regions \\(A\\) and \\(B\\), the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are independent random variables. In other words, the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). In addition, the number of points, \\(N = n(X\\cap B)\\), follows a Poisson distribution:\n\\[\n\\mathbb{P}[N=k] = e^{-\\mu}\\frac{\\mu^k}{k!}\\\\\n\\label{eq:poisson_process}\n\\] where \\(k = \\lambda |B|\\) (Baddeley, Rubak, and Turner 2015, 133).\n\n\n\nInhomogeneous Poisson Process\nA Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density, \\(\\lambda(u)\\), sometimes known as the intensity function (see below), is a function of spatial location \\(u\\). In this case, the expected number of points falling into a region \\(B\\), \\(\\mu = n(X\\cap B)\\), is an integration of the intensity function over that region (Baddeley, Rubak, and Turner 2015, 138).\n\\[\n\\mu = \\int_{B} \\lambda(u) du.\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\nIsotropy\nA point process is called isotropic, if its statistical properties are invariant to rotations; a CSR process is both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 147).\n\n\nStationarity\n“A point process is called stationary if, when we view the process through a window W , its statistical properties do not depend on the location of the window in two-dimensional space” (Baddeley, Rubak, and Turner 2015, 146). This is the case for any homogeneous point process, where the statistical properties of the pattern are unchanged given shifting of the observation window. This means it is stationary in all statistical properties; first-order properties (e.g. intensity) and second-order properties (e.g. correlation) (Baddeley, Rubak, and Turner 2015, 218). Not all metrics assume stationarity in its full sense. Inhomgeneous metrics only assume second-order / correlation stationarity. That means while the intensity function can vary spatially (first-order homogeneity is not given), the estimates of correlation functions (e.g. the inhomogeneous K-function) should be the same in parts of the window (Baddeley, Rubak, and Turner 2015, 689).\n\n\nLocal scaling\nIf a process is not correlation stationary, so the estimates of the inhomogeneous metric vary between locations, locally-scaled versions of the metric can be applicable. This means in small subregions, the process is still stationary and isotropic, but there is a rescaling factor that can vary across the total process (Baddeley, Rubak, and Turner 2015, 246–47).\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimated functions between the quadrats. It should be noted that this test depends on the arbitrary definition of the quadrats. Given our chosen patterns are not independent but result as marks from an overall point-pattern, the permutation approach is questionable. Furthermore, the outcome of the permutation test depends heavily on the choice of the quadrats. Therefore, the interpretation can be difficult (Baddeley, Rubak, and Turner 2015, 689–93).\n\n\nCode\npermutation_test &lt;- function(pp, mark, split, minpoints) {\n  pp_sel &lt;-  subset(pp, marks %in% mark, drop = TRUE)\n  \n  rho_est &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\n  lambda &lt;- predict(rho_est)\n\n  tesselation &lt;- quantess(unmark(pp_sel), \"x\", 3)\n  tesselation_split &lt;- nestsplit(pp_sel, tesselation, ny=split)\n  \n  plot(tesselation_split, main = mark)\n  \n  tesselation_split$inten &lt;- factor(as.integer(tesselation_split$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n  \n  res.scaled &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kscaled,\n                 minpoints = minpoints)\n  \n  res.inhom &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kinhom,\n                 lambda=lambda, minpoints = minpoints)\n  \n  #p-value of the local-scaling test\n  print(paste0(mark,' local scaling test ', res.scaled$p.value))\n  \n  #p-value of the inhomogeneity test\n  print(paste0(mark,' inhomogeneity test ', res.inhom$p.value))\n}\nlapply(c(\"Microglia\", \"OD Mature\", \"Ependymal\"), function(x) permutation_test(pp[['0.01']], x, split = 3, minpoints = 10))\n\n\nThe p-value of the test for local scaling for microglia cells is \\(&lt;0.05\\) which indicates that the assumption of local scaling is rejected. Therefore, the distribution of microglia cells is not a scaled version of an overall distribution pattern. The p-value of the test for inhomogeneity for both microglia cells is \\(&gt;0.05\\) indicating that the assumption of correlation stationarity is not rejected. In this case we can use the inhomogeneous version of the K-function which assumes correlation stationarity.\nFor ependymal and OD mature cells however, the p-values for both the local scaling test and the inhomogeneity test are \\(&gt;0.05\\) which means that both the correlation stationarity assumption and the local scaling assumption can’t be rejected. [ME: Does this make sense? Or is this just an artifact?]\nAs the interpretation of the permutation test is highly dependent on the quadrats, the results should be interpreted with care. Both inhomogeneous and locally scaled versions of the summary functions have support and both offer interesting insights into the spatial pattern. Therefore, we will compare all versions and show what the choice of metrics means for their interpretation.\n\n\nIntensity\nIntensity is the expected density of points per unit area. It can be interpreted as the rate of occurrence or the abundance of events recorded. The intensity represents a first order property because it is related to the expected number of points . More formally the average intensity of a point process is defined as:\n\\[\n\\bar{\\lambda} = \\frac{n(x)}{|W|}\n\\label{eq:average_intensity}\n\\]\nAs this is an average over the entire window, it only really makes sense for a homogeneous point process (Baddeley, Rubak, and Turner 2015, 157–60)\n\nEstimating Intensity\nFor a homogeneous point process, the intensity can be estimated in a simplistic way: summing the individual intensities of the marks (Baddeley, Rubak, and Turner 2015, 161).\n\n\nCode\nintensityPointProcess &lt;- function(pp,mark) if(mark) intensity(pp) else sum(intensity(pp))\n\nintensityPointProcess(pp_ls[['0.01']], mark = FALSE) %&gt;% round(6)\n\n\n[1] 0.001909\n\n\nOtherwise, we can compute the intensity for each mark individually.\n\n\nCode\nintensityPointProcess(pp_ls[['0.01']], mark = TRUE) %&gt;% round(8)\n\n\n  Ambiguous   Astrocyte Endothelial   Ependymal  Excitatory  Inhibitory \n 0.00024151  0.00020183  0.00014653  0.00008373  0.00036867  0.00061393 \n  Microglia OD Immature   OD Mature   Pericytes \n 0.00003031  0.00006249  0.00014278  0.00001750 \n\n\n\n\nKernel Estimation\nIn kernel estimation, we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There are a wide variety of kernel estimators (see (Baddeley, Rubak, and Turner 2015, 168)), but a popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth (Baddeley, Rubak, and Turner 2015, 168).\n\n\nCode\npp_sel &lt;-  subset(pp_ls[['0.01']]$`OD Mature`, drop = TRUE)\nDens &lt;- density(pp_sel, sigma = 100)\nplot(Dens, main = 'Kernel Density (OD Mature cells)')\n\n\n\n\n\n\n\nQuadrat Counting\nIn quadrat counting, all points falling into a given quadrat are counted. This gives an overview on the characteristics of the point pattern, such as correlation stationarity (Baddeley, Rubak, and Turner 2015, 163).\n\n\nCode\nQ5 &lt;- quadratcount(pp_ls[['0.01']], nx=8, ny=8)\nplot(unmark(pp[['0.01']]), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\nUnder independence assumptions, the quadrat counts can be used for testing homogeneity, i.e., if the points are distributed evenly across the quadrats (Baddeley, Rubak, and Turner 2015, 164–65).\n\n\nCode\nval &lt;- quadrat.test(pp_ls[['0.01']]$`OD Mature`, 5, alternative=\"regular\", method=\"MonteCarlo\")\nval\n\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nX2 = 635.09, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 25 tiles (irregular windows)\n\n\nA p-value of 1 indicates that the null hypothesis of irregularity can not be rejected strongly. Thus, the point pattern of oligodendrocyts is strongly irregular.\nAlternatively, we can inspect departures from the hypothesis that points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types (Buller 2020).\n\n\nCode\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp[['0.01']], marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\nTesting for CSR\nWhether or not a point process is completely spatially random (CSR) depends on two characteristics: points need to be distributed homogeneously and they have to be independent of each other (see definitions above). There are various ways to test for CSR, here we show the use-case of the clark-evans test (Baddeley, Rubak, and Turner 2015, 165–66).\n\n\nCode\nclarkevans.test(pp_ls[['0.01']]$`OD Mature`)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nR = 0.77286, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "03-between-marks.html#concepts-and-definitions-of-point-processes",
    "href": "03-between-marks.html#concepts-and-definitions-of-point-processes",
    "title": "Discrete Marks",
    "section": "",
    "text": "In point pattern analysis we assume that the patterns we observe are a realisation of a stochastic process called a point process. The inferences we make about the point pattern are based on the point process. E.g. the pattern can be said to be created by a poisson point process and thus is evenly distributed in the observation window (Baddeley, Rubak, and Turner 2015, 127).\nWhen considering a pattern with \\(m\\) multiple types, as we do in the (Moffitt et al. 2018) dataset, there are two very closely related concepts. One can view the pattern as a multitype point pattern, where all the points are sampled from the same point process. The other option is to consider the pattern as a multivariate point pattern, where the points come from \\(m\\) distinct point processes. The difference between these two views is that in the multitype framework we assume the points to stem from the same point process and thus depend on each other. In the multivariate framework we assume that the types stem from independent point processes and therefore we can consider dependencies of one type alone. Whether or not the underlying point processes are independent depends on the biological question. If we analyse two celltypes in one slice of a tissue, we should consider them as being sampled from one point process. However, if we consider the distribution of a celltype in two slices of the same tissue we can have grounds to consider the point processes as independent (Baddeley, Rubak, and Turner 2015, 565).\n\n\n\nThe most common set up in point pattern analysis is what we call window sampling. Instead of observing the entire pattern we observe a subset of this pattern in the so called window. In the analysis we try to make inference on the entire point process based on the observed window. An example could be different small microscopy windows through which a big tissue slice is observed. The windows would be samples of the bigger point process. In this case, it would be wrong to assume the window to be the convex hull around the observed points because they are just a sample of the bigger point pattern (Baddeley, Rubak, and Turner 2015, 144–45).\nThere is another concept called the small world model. It assumes that points can only be observed in a finite small world and not beyond these boundaries. When thinking of an entire tissue, this is a very common scenario. Cells can only be observed within the tissue and not beyond. In this case, it would be correct to not assume a rectangular observation window but to use more conservative methods to estimate an unknown sampling window such as the Ripley-Rasson estimate of a spatial domain (Baddeley, Rubak, and Turner 2015, 144–45).\nIn both cases it is important to understand the direction of the bias. If the unknown window is estimated to be smaller than the true window, we underestimate the window. This then again leads to an overestimation of the density of points and to other characteristics of the pattern. Therefore, an underestimation of the window size is more concerning than a slight overestimation (Baddeley, Rubak, and Turner 2015, 144–45).\n\n\nCode\nsetRiprasWindows &lt;- function(pp){\n  Window(pp) &lt;- ripras(pp)\n  marks(pp) &lt;- factor(marks(pp))\n  return(pp)\n}\n#the entire point patterns with the ripras windows\npp &lt;- lapply(pp_ls, setRiprasWindows)\n\nseparateMarks &lt;- function(pp){\n  #split the multitype point process into several single type processes\n  ppls &lt;- split(pp)\n  return (ppls)\n}\n#the point patterns separated by their marks\npp_ls &lt;- lapply(pp, separateMarks)\n\n\n\n\n\nComplete spatial randomness (CSR) is often used as the null model for various point patterns, and is the result of a Poisson process. A completely spatial random process is characterised by two properties, homogeneity and independence, as discussed below (Baddeley, Rubak, and Turner 2015, 132).\n\n\n“Homogeneity […] means that the expected number of points falling in a region B should be proportional to its area |B|” (Baddeley, Rubak, and Turner 2015, 132) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) represents the intensity of the process, i.e., the average number of points in a unit area (Baddeley, Rubak, and Turner 2015, 132–33). :\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|.\n\\label{eq:expected_number_points}\n\\]\n\n\n\nIndependence implies that in two (non-overlapping) regions \\(A\\) and \\(B\\), the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are independent random variables. In other words, the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). In addition, the number of points, \\(N = n(X\\cap B)\\), follows a Poisson distribution:\n\\[\n\\mathbb{P}[N=k] = e^{-\\mu}\\frac{\\mu^k}{k!}\\\\\n\\label{eq:poisson_process}\n\\] where \\(k = \\lambda |B|\\) (Baddeley, Rubak, and Turner 2015, 133).\n\n\n\n\nA Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density, \\(\\lambda(u)\\), sometimes known as the intensity function (see below), is a function of spatial location \\(u\\). In this case, the expected number of points falling into a region \\(B\\), \\(\\mu = n(X\\cap B)\\), is an integration of the intensity function over that region (Baddeley, Rubak, and Turner 2015, 138).\n\\[\n\\mu = \\int_{B} \\lambda(u) du.\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\n\nA point process is called isotropic, if its statistical properties are invariant to rotations; a CSR process is both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 147).\n\n\n\n“A point process is called stationary if, when we view the process through a window W , its statistical properties do not depend on the location of the window in two-dimensional space” (Baddeley, Rubak, and Turner 2015, 146). This is the case for any homogeneous point process, where the statistical properties of the pattern are unchanged given shifting of the observation window. This means it is stationary in all statistical properties; first-order properties (e.g. intensity) and second-order properties (e.g. correlation) (Baddeley, Rubak, and Turner 2015, 218). Not all metrics assume stationarity in its full sense. Inhomogeneous metrics only assume second-order / correlation stationarity. That means while the intensity function can vary spatially (first-order stationarity is not given), the estimates of correlation functions (e.g. the inhomogeneous K-function) should be the same in parts of the window (Baddeley, Rubak, and Turner 2015, 689).\n\n\n\nIf a process is not correlation stationary, so the estimates of the inhomogeneous metric vary between locations, locally-scaled versions of the metric can be applicable. This means in small subregions, the process is still stationary and isotropic, but there is a rescaling factor that can vary across the total process (Baddeley, Rubak, and Turner 2015, 246–47).\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimated functions between the quadrats. It should be noted that this test depends on the arbitrary definition of the quadrats. Given our chosen patterns are not independent but result as marks from an overall point-pattern, the permutation approach is questionable. Furthermore, the outcome of the permutation test depends heavily on the choice of the quadrats. Therefore, the interpretation can be difficult (Baddeley, Rubak, and Turner 2015, 689–93).\n\n\nCode\npermutation_test &lt;- function(pp, mark, split, minpoints) {\n  pp_sel &lt;-  subset(pp, marks %in% mark, drop = TRUE)\n  \n  rho_est &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\n  lambda &lt;- predict(rho_est)\n\n  tesselation &lt;- quantess(unmark(pp_sel), \"x\", 3)\n  tesselation_split &lt;- nestsplit(pp_sel, tesselation, ny=split)\n  \n  plot(tesselation_split, main = mark)\n  \n  tesselation_split$inten &lt;- factor(as.integer(tesselation_split$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n  \n  res.scaled &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kscaled,\n                 minpoints = minpoints)\n  \n  res.inhom &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kinhom,\n                 lambda=lambda, minpoints = minpoints)\n  \n  #p-value of the local-scaling test\n  print(paste0(mark,' local scaling test ', res.scaled$p.value))\n  \n  #p-value of the inhomogeneity test\n  print(paste0(mark,' inhomogeneity test ', res.inhom$p.value))\n}\nlapply(c(\"Microglia\", \"OD Mature\", \"Ependymal\"), function(x) permutation_test(pp[['0.01']], x, split = 3, minpoints = 10))\n\n\nThe p-value of the test for local scaling for microglia cells is \\(&lt;0.05\\) which indicates that the assumption of local scaling is rejected. Therefore, the distribution of microglia cells is not a scaled version of an overall distribution pattern. The p-value of the test for inhomogeneity for both microglia cells is \\(&gt;0.05\\) indicating that the assumption of correlation stationarity is not rejected. In this case we can use the inhomogeneous version of the K-function which assumes correlation stationarity.\nFor ependymal and OD mature cells however, the p-values for both the local scaling test and the inhomogeneity test are \\(&gt;0.05\\) which means that both the correlation stationarity assumption and the local scaling assumption can’t be rejected. [ME: Does this make sense? Or is this just an artifact?]\nAs the interpretation of the permutation test is highly dependent on the quadrats, the results should be interpreted with care. Both inhomogeneous and locally scaled versions of the summary functions have support and both offer interesting insights into the spatial pattern. Therefore, we will compare all versions and show what the choice of metrics means for their interpretation.\n\n\n\nIntensity is the expected density of points per unit area. It can be interpreted as the rate of occurrence or the abundance of events recorded. The intensity represents a first order property because it is related to the expected number of points . More formally the average intensity of a point process is defined as:\n\\[\n\\bar{\\lambda} = \\frac{n(x)}{|W|}\n\\label{eq:average_intensity}\n\\]\nAs this is an average over the entire window, it only really makes sense for a homogeneous point process (Baddeley, Rubak, and Turner 2015, 157–60)\n\n\nFor a homogeneous point process, the intensity can be estimated in a simplistic way: summing the individual intensities of the marks (Baddeley, Rubak, and Turner 2015, 161).\n\n\nCode\nintensityPointProcess &lt;- function(pp,mark) if(mark) intensity(pp) else sum(intensity(pp))\n\nintensityPointProcess(pp_ls[['0.01']], mark = FALSE) %&gt;% round(6)\n\n\n[1] 0.001909\n\n\nOtherwise, we can compute the intensity for each mark individually.\n\n\nCode\nintensityPointProcess(pp_ls[['0.01']], mark = TRUE) %&gt;% round(8)\n\n\n  Ambiguous   Astrocyte Endothelial   Ependymal  Excitatory  Inhibitory \n 0.00024151  0.00020183  0.00014653  0.00008373  0.00036867  0.00061393 \n  Microglia OD Immature   OD Mature   Pericytes \n 0.00003031  0.00006249  0.00014278  0.00001750 \n\n\n\n\n\nIn kernel estimation, we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There are a wide variety of kernel estimators (see (Baddeley, Rubak, and Turner 2015, 168)), but a popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth (Baddeley, Rubak, and Turner 2015, 168).\n\n\nCode\npp_sel &lt;-  subset(pp_ls[['0.01']]$`OD Mature`, drop = TRUE)\nDens &lt;- density(pp_sel, sigma = 100)\nplot(Dens, main = 'Kernel Density (OD Mature cells)')\n\n\n\n\n\n\n\n\nIn quadrat counting, all points falling into a given quadrat are counted. This gives an overview on the characteristics of the point pattern, such as correlation stationarity (Baddeley, Rubak, and Turner 2015, 163).\n\n\nCode\nQ5 &lt;- quadratcount(pp_ls[['0.01']], nx=8, ny=8)\nplot(unmark(pp[['0.01']]), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\nUnder independence assumptions, the quadrat counts can be used for testing homogeneity, i.e., if the points are distributed evenly across the quadrats (Baddeley, Rubak, and Turner 2015, 164–65).\n\n\nCode\nval &lt;- quadrat.test(pp_ls[['0.01']]$`OD Mature`, 5, alternative=\"regular\", method=\"MonteCarlo\")\nval\n\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nX2 = 635.09, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 25 tiles (irregular windows)\n\n\nA p-value of 1 indicates that the null hypothesis of irregularity can not be rejected strongly. Thus, the point pattern of oligodendrocyts is strongly irregular.\nAlternatively, we can inspect departures from the hypothesis that points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types (Buller 2020).\n\n\nCode\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp[['0.01']], marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\n\nWhether or not a point process is completely spatially random (CSR) depends on two characteristics: points need to be distributed homogeneously and they have to be independent of each other (see definitions above). There are various ways to test for CSR, here we show the use-case of the clark-evans test (Baddeley, Rubak, and Turner 2015, 165–66).\n\n\nCode\nclarkevans.test(pp_ls[['0.01']]$`OD Mature`)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nR = 0.77286, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "03-between-marks.html#multitype-and-multivariate-viewpoint",
    "href": "03-between-marks.html#multitype-and-multivariate-viewpoint",
    "title": "Discrete Marks",
    "section": "Multitype and Multivariate viewpoint",
    "text": "Multitype and Multivariate viewpoint\nA pattern with multiple type of points, e.g. cell types, can be seen in different ways. One the one hand, the multitype approach assumes that the points \\(x\\) were recorded together with with their labels \\(m\\) and that they were generated at the same time. The locations and labels therefore have a joint distribution \\(P(X,M)\\). On the other hand one can assume that the pattern with multiple types of points is a combination of several distinct point patterns, one for each type of point. This is the multivariate approach and the different point patterns \\(A\\) and \\(B\\) form a joint distribution \\(P(A,B)\\). To test if the labels depend on the location one can assume the following null hypotheses (Baddeley, Rubak, and Turner 2015, 565–67):\n\ncomplete spatial randomness and independence (CSRI): the points are distributed at random; the type of each points is randomly allocated; independence between points of different types; allocation of the types independently of the other points and of its location.\nrandom labeling: each point is assigned a type at random independently of its location\nindependence of components: the points of different types are independent of each other.\n\nApart from CSRI is is also important for the analysis if we can assume stationarity, i.e. the statistical properties of the point pattern do not change in the window.\nFor simplicity, we will focus on three cell types of our point pattern: Ependymal, OD Mature and Microglia. This is appropriate if we assume that the point processes are independent. We could also assume that they come from the same process. In this case we have to check the stationarity assumption of the pattern.\n\n\nCode\nmarks(pp) &lt;- factor(marks(pp))\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\n\npp_sel &lt;-  subset(pp, marks %in% selection, drop = TRUE)\n\n\n\n\nCode\npp_sel |&gt; as.data.frame() |&gt; \n  ggplot(aes(x = x, y = y, color = marks)) +\n  geom_point() +\n  theme_minimal() +\n  coord_fixed() +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\nThe summary of pp (point pattern) object returns general properties, plus intensities, combined and per mark type.\n\n\nCode\nsummary(pp)\n\n\nMarked planar point pattern:  6111 points\nAverage intensity 0.001906561 points per square unit\n\nCoordinates are given to 4 decimal places\n\nMultitype:\n            frequency  proportion    intensity\nAmbiguous         773 0.126493200 2.411670e-04\nAstrocyte         646 0.105711000 2.015445e-04\nEndothelial       469 0.076746850 1.463225e-04\nEpendymal         268 0.043855340 8.361288e-05\nExcitatory       1180 0.193094400 3.681463e-04\nInhibitory       1965 0.321551300 6.130571e-04\nMicroglia          97 0.015873020 3.026287e-05\nOD Immature       200 0.032727870 6.239767e-05\nOD Mature         457 0.074783180 1.425787e-04\nPericytes          56 0.009163803 1.747135e-05\n\nWindow: rectangle = [1222.5635, 3012.4248] x [-3993.535, -2202.755] units\n                    (1790 x 1791 units)\nWindow area = 3205250 square units\n\n\nTo get the overall intensity the individual intensities can be summed up. Assuming that the the multitype process is first order stationary (i.e. each sub-process is stationary) the individual intensities sum up to the intensity of the unmarked point process (Baddeley, Rubak, and Turner 2015, 574ff.).\n\n\nCode\nsum(intensity(pp)) == intensity(unmark(pp))\n\n\n[1] TRUE\n\n\nThe stationarity assumption is not appropriate in all cases. To assess first-order stationarity visually, we can plot the kernel density estimates per type.\n\n\nCode\nppls &lt;- split(pp_sel) # split by mark\nplot(density(ppls))\n\n\n\n\n\nEpendymal and OD Mature cells are cleary inhomogeneous, while for Microglia cells it is not so clear and we could assume homogeneity, especially as there are no cells in the bottom middle of the window.\n\n\n\n\n\n\n\nTo further inverstiagte the spatial arrangement of the different cell types we can calculate the relative risk, i.e., the probability of observing a given celltype at a given location. It is calculated using the function relrisk. The bandwidth for smoothing is calculated with bw.relrisk and might need to be adjusted (Baddeley, Rubak, and Turner 2015, 577–83).\nThe relrisk function further gives us the dominant mark for different regions of the tissue of interest. This could be interesting in the annotation of spatial domains. It indicates at each location, which cell type is most likely to occur.\n\n\nCode\nrpd &lt;- relrisk(pp_sel, diggle = TRUE)\ndom &lt;- im.apply(rpd, which.max)\ndom &lt;- eval.im(factor(dom, levels = seq_along(levels(unique(marks(pp_sel)))),\n                      labels = levels(unique(marks(pp_sel)))))\nplot(dom,las=2,main=\"Dominant mark\")"
  },
  {
    "objectID": "03-between-marks.html#nearest-neighbourhood-contingency",
    "href": "03-between-marks.html#nearest-neighbourhood-contingency",
    "title": "Discrete Marks",
    "section": "Nearest neighbourhood contingency",
    "text": "Nearest neighbourhood contingency\nTo further investigate the spatial distribution of the marks we can investigate the nearest neighbourhood of each cell type. One possibility is to work with nearest neighborhood contingency tables developed by (Dixon 2002). The statistical tests are implemented in the R package dixon (Cruz 2008).\nThe measure of segregation \\(S\\) is defined in (Dixon 2002) as\n\\[S_{i,j}= \\frac{\\log[(N_{i,j}/(N_i−N_{i,j})]}{[(N_i−1)/(N−N_i)]}\\] where \\(N_i\\) is the number of individuals \\(i\\), \\(N_{i,j}\\) is the number of individuals of type \\(i\\) with a nearest neighbor of type \\(j\\), and \\(N\\) is the total number of individuals.\nA value of \\(S=0\\) is consistent with random labeling. A value larger than 0 indicates that the two types are more segregated than expected by chance, the larger the value the more segregated. Note that segregated means that it is more likely to expect a neigbour of type \\(j\\) than by chance. In the case that the neigbour is of the same type this is equivalent to “clustering”. On the other hand if \\(S&lt;0\\) it indicates that type \\(j\\) is less likely to be a neigbour than by chance. The P-values are calculated using expected numbers of nearest neighbors under the null hypothesis of random labeling using a Monte-Carlo simulation and assumes an asymptotic \\(\\chi^2\\) distribution.\n\n\nCode\nout &lt;- dixon(as.data.frame(pp_sel), nsim = 99)\n\n\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\n\nCode\nout$tablaZ %&gt;% \n  arrange(desc(abs(`Z `))) %&gt;%\n  select(-`  p-val.Nobs`)\n\n\n       From        To     Obs.Count     Exp. Count    S      Z    p-val.Z\n1 Ependymal Ependymal           262          87.16  1.96  20.04    0.0000\n2 Ependymal OD Mature             3         149.18 -2.04 -16.87    0.0000\n3 OD Mature Ependymal             8         149.18 -1.43 -14.26    0.0000\n4 OD Mature OD Mature           380         253.83  0.60  11.43    0.0000\n5 Ependymal Microglia             3          31.66 -1.07  -5.66    0.0000\n6 Microglia Ependymal             9          31.66 -0.68  -4.92    0.0000\n7 Microglia OD Mature            67          53.99  0.25   2.60    0.0094\n8 Microglia Microglia            21          11.34  0.32   2.50    0.0124\n9 OD Mature Microglia            69          53.99  0.12   2.35    0.0190\n\n\nIn this table we see that most Ependymal cells are very clustered, while Microglia are more evenly distributed. Further we see that it is less likely to find a Ependymal cells next to a OD mature cells than by chance.\nOD Mature cells show this interesting characteristic that they are clustered in some parts of the tissue and more evenly distributed in other parts of the structure. This characteristic is not visible in the table. The statistic also considers only the nearest neighbour and ignores neighbours that are further away."
  },
  {
    "objectID": "01-within-marks.html#univariate-viewpoint",
    "href": "01-within-marks.html#univariate-viewpoint",
    "title": "Discrete Marks",
    "section": "",
    "text": "In the following document we will often compare the distribution of mature oligodendrocytes (OD mature cells) across different z-slices of the same tissue. We assume these slices to be enough far away to be considered independent. Therefore, we assume that these patterns were generated independently by different point processes. Since we consider the dependence of one mark among itself, we are in a univariate setting per slide. We compare several univariate curves along different z-slices, which is in turn a multivariate comparison (Baddeley, Rubak, and Turner 2015, 565).\nIn our example dataset we analyse the mouse preoptic hypothalamus (Moffitt et al. 2018). This is a tissue of the mouse brain that is cut out of a bigger context. The lower boundary is the end of the tissue whereas the upper three boundaries are a technical boundary. Therefore, our example is a mixture between window sampling and the small world model. In order to decrease the bias of the tissue boarder, we use the Ripley-Rasson estimate of a spatial domain to estimate the sampling window.\n\n\nCode\npar(mfrow=c(1,3))\n#Plot the marks separately \nlapply(zstack_list, function(zstack){\n  plot(pp_ls[[zstack]][[celltype_ls]], main = zstack, legend = FALSE)\n})\n\n\n\n\n\n[[1]]\nSymbol map with constant values\ncols: #000000E4\n\n[[2]]\nSymbol map with constant values\ncols: #000000C2\n\n[[3]]\nSymbol map with constant values\ncols: #0000007B\n\n\nCode\ndev.off()\n\n\nnull device \n          1"
  },
  {
    "objectID": "01-cell-univar-point.html",
    "href": "01-cell-univar-point.html",
    "title": "Discrete Marks",
    "section": "",
    "text": "Code\nsource(\"utils.R\")\n\n\n\n\n\n\n\nCode\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n\n#define the celltype that you want to compare across the stacks - hereby we assume independence across the z-stacks which is an assumption that can be challenged\ncelltype_ls &lt;- \"OD Mature\"\n\nselectZstacks &lt;- function(zstack, spe){\n  sub &lt;- spe[, spe$sample_id == zstack]\n  pp &lt;- .ppp(sub, marks = \"cluster_id\")\n  return(pp)\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe)\nnames(pp_ls) &lt;- zstack_list\n\n\nThe theory of spatial point patterns is discussed in great detail in (Baddeley, Rubak, and Turner 2015). The book has an accompanying package called spatstat which offers great functionality to the theoretical concepts described in the book (Baddeley and Turner 2005). This chapter relies heavily on both publications.\n\n\n\n\n\nIn point pattern analysis we assume that the patterns we observe are a realisation of a stochastic process called a point process. The inferences we make about the point pattern are based on the point process. For example, if a pattern is created by a Poisson point process it will be evenly distributed in the observation window (Baddeley, Rubak, and Turner 2015, 127).\nWhen considering a pattern with \\(m\\) multiple types, as we do in the (Moffitt et al. 2018) dataset, there are two very closely related concepts. One can view the pattern as a multitype point pattern, where all the points are sampled from the same point process. The other option is to consider the pattern as a multivariate point pattern, where the points come from \\(m\\) distinct point processes. The difference between these two views is that in the multitype framework we assume the points to stem from the same point process. In the multivariate framework we assume that the types stem from distinct point processes and therefore we can consider dependencies of one type alone. Whether or not the patterns stem from the same point process depends on the biological question. If we analyse two cell types in one slice of a tissue, we should consider them as being sampled from one point process. However, if we consider the distribution of a cell type in two slices of the same tissue we can have grounds to consider them as distinct processes (Baddeley, Rubak, and Turner 2015, 564–65).\n\n\n\nThe most common set up in point pattern analysis is what we call window sampling. Instead of observing the entire pattern we observe a subset of this pattern in the so called window. An example could be different small microscopy windows through which a big tissue slice is observed. In this case, it would be wrong to assume the window to be the convex hull around the observed points because they are just a sample of the bigger point pattern (Baddeley, Rubak, and Turner 2015, 143–45).\nThere is another concept called the small world model. It assumes that points can only be observed in a finite small world and not beyond these boundaries. When thinking of an entire tissue, this is a very common scenario. Cells can only be observed within the tissue and not beyond. In this case, it would be correct to not assume a rectangular observation window but to use methods to estimate an unknown sampling window such as the Ripley-Rasson estimate of a spatial region (Baddeley, Rubak, and Turner 2015, 144–45; Ripley and Rasson 1977).\n\n\nCode\nsetRiprasWindows &lt;- function(pp){\n  Window(pp) &lt;- ripras(pp)\n  return(pp)\n}\n#the entire point patterns with the ripras windows\npp &lt;- lapply(pp_ls, setRiprasWindows)\n\nseparateMarks &lt;- function(pp){\n  #split the multitype point process into several single type processes\n  ppls &lt;- split(pp)\n  return (ppls)\n}\n#the point patterns separated by their marks\npp_ls &lt;- lapply(pp, separateMarks)\n\n\n\n\n\nComplete spatial randomness (CSR) is often used as the null model for various point patterns. It is the result of a Poisson process. A completely spatial random process is characterised by two properties, homogeneity and independence, as discussed below (Baddeley, Rubak, and Turner 2015, 132).\n\n\n“Homogeneity […] means that the expected number of points falling in a region B should be proportional to its area |B|” (Baddeley, Rubak, and Turner 2015, 132) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) represents the intensity of the process, i.e., the average number of points in a unit area (Baddeley, Rubak, and Turner 2015, 132–33). :\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|.\n\\label{eq:expected_number_points}\n\\]\n\n\n\nIndependence implies that in two (non-overlapping) regions \\(A\\) and \\(B\\), the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are independent random variables. In other words, the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). (Baddeley, Rubak, and Turner 2015, 133).\n\n\n\n\nA Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density, \\(\\lambda(u)\\), sometimes known as the intensity function (see below), is a function of the spatial location \\(u\\). In this case, the expected number of points falling into a region \\(B\\), \\(\\mu = n(X\\cap B)\\), is an integration of the intensity function over that region (Baddeley, Rubak, and Turner 2015, 138).\n\\[\n\\mu = \\int_{B} \\lambda(u) du.\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\n\nA point process is called isotropic, if its statistical properties are invariant to rotations; a CSR process is both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 147).\n\n\n\n“A point process is called stationary if, when we view the process through a window W , its statistical properties do not depend on the location of the window in two-dimensional space.” (Baddeley, Rubak, and Turner 2015, 146). This is the case for any homogeneous point process, where the statistical properties of the pattern are unchanged given shifting of the observation window. This means it is stationary in all statistical properties; first-order properties (e.g. intensity) and second-order properties (e.g. correlation) (Baddeley, Rubak, and Turner 2015, 218). Not all metrics assume stationarity in its full sense. Inhomogeneous metrics only assume second-order / correlation stationarity. That means while the intensity function can vary spatially (first-order stationarity is not given), the estimates of correlation functions (e.g. the inhomogeneous K-function) should be the same in parts of the window (Baddeley, Rubak, and Turner 2015, 689 ff.).\n\n\n\nIf a process is not correlation stationary, so the estimates of the inhomogeneous metric vary between locations, locally-scaled versions of the metric can be applicable. This means in subregions, the process is still stationary and isotropic, but there is a rescaling factor that can vary across the total process (Baddeley, Rubak, and Turner 2015, 246–47).\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimated functions between the quadrats. It should be noted that this test depends on the arbitrary definition of the quadrats. Given our chosen patterns are not independent but result as marks from an overall point-pattern, the permutation approach is questionable (Baddeley, Rubak, and Turner 2015, 689–93).\n\n\nCode\npermutation_test &lt;- function(pp, mark, split, minpoints) {\n  pp_sel &lt;-  subset(pp, marks %in% mark, drop = TRUE)\n  \n  rho_est &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\n  lambda &lt;- predict(rho_est)\n\n  tesselation &lt;- quantess(unmark(pp_sel), \"x\", 3)\n  tesselation_split &lt;- nestsplit(pp_sel, tesselation, ny=split)\n  \n  plot(tesselation_split, main = mark)\n  \n  tesselation_split$inten &lt;- factor(as.integer(tesselation_split$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n  \n  res.scaled &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kscaled,\n                 minpoints = minpoints)\n  \n  res.inhom &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kinhom,\n                 lambda=lambda, minpoints = minpoints)\n  \n  #p-value of the local-scaling test\n  print(paste0(mark,' local scaling test ', res.scaled$p.value))\n  \n  #p-value of the inhomogeneity test\n  print(paste0(mark,' inhomogeneity test ', res.inhom$p.value))\n}\nlapply(c(\"Microglia\", \"OD Mature\", \"Ependymal\"), function(x) permutation_test(pp[['0.01']], x, split = 3, minpoints = 10))\n\n\nThe p-value of the test for local scaling for microglia cells is \\(&lt;0.05\\) which indicates that the assumption of local scaling is rejected. Therefore, the distribution of microglia cells is not a scaled version of an overall distribution pattern. The p-value of the test for inhomogeneity for both microglia cells is \\(&gt;0.05\\) indicating that the assumption of correlation stationarity is not rejected. In this case we can use the inhomogeneous version of the K-function which assumes correlation stationarity.\nFor ependymal and OD mature cells however, the p-values for both the local scaling test and the inhomogeneity test are \\(&gt;0.05\\) which means that for this choice of quadrats both the correlation stationarity assumption and the local scaling assumption can’t be rejected.\nAs the interpretation of the permutation test is highly dependent on the quadrats, the results should be interpreted with care. Both inhomogeneous and locally scaled versions of the summary functions have support and both offer interesting insights into the spatial pattern. Therefore, we will compare all versions and show what the choice of metrics means for their interpretation.\n\n\n\nIntensity is the expected density of points per unit area. It can be interpreted as the rate of occurrence or the abundance of events. The intensity represents a first order property because it is related to the expected number of points. More formally the average intensity of a point process is defined as:\n\\[\n\\bar{\\lambda} = \\frac{n(x)}{|W|}\n\\label{eq:average_intensity}\n\\]\nAs this is an average over the entire window, it is a good estimate for a homogeneous point process (Baddeley, Rubak, and Turner 2015, 157–60)\n\n\nFor a homogeneous point process, the intensity can be estimated in a simplistic way: summing the individual intensities of the marks (Baddeley, Rubak, and Turner 2015, 161).\n\n\nCode\nintensityPointProcess &lt;- function(pp,mark) if(mark) intensity(pp) else sum(intensity(pp))\n\nintensityPointProcess(pp_ls[['0.01']], mark = FALSE) %&gt;% round(6)\n\n\n[1] 0.001909\n\n\nOtherwise, we can compute the intensity for each mark individually.\n\n\nCode\nintensityPointProcess(pp_ls[['0.01']], mark = TRUE) %&gt;% round(8)\n\n\n  Ambiguous   Astrocyte Endothelial   Ependymal  Excitatory  Inhibitory \n 0.00024151  0.00020183  0.00014653  0.00008373  0.00036867  0.00061393 \n  Microglia OD Immature   OD Mature   Pericytes \n 0.00003031  0.00006249  0.00014278  0.00001750 \n\n\n\n\n\nIn kernel estimation, we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There is a wide variety of kernel estimators (see (Baddeley, Rubak, and Turner 2015, 168)), but a popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth (Baddeley, Rubak, and Turner 2015, 168).\n\n\nCode\npp_sel &lt;-  subset(pp_ls[['0.01']]$`OD Mature`, drop = TRUE)\nDens &lt;- density(pp_sel, sigma = 100)\nplot(Dens, main = 'Kernel Density (OD Mature cells)')\n\n\n\n\n\n\n\n\nIn quadrat counting, all points falling into a given quadrat are counted. This gives an overview on the characteristics of the point pattern, such as correlation stationarity (Baddeley, Rubak, and Turner 2015, 163).\n\n\nCode\nQ5 &lt;- quadratcount(pp_ls[['0.01']], nx=8, ny=8)\nplot(unmark(pp[['0.01']]), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\nUnder independence assumptions, the quadrat counts can be used for testing homogeneity, i.e., whether the points are distributed evenly across the quadrats (Baddeley, Rubak, and Turner 2015, 164–65).\n\n\nCode\nval &lt;- quadrat.test(pp_ls[['0.01']]$`OD Mature`, 5, alternative=\"regular\", method=\"MonteCarlo\")\nval\n\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nX2 = 635.09, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 25 tiles (irregular windows)\n\n\nA p-value of 1 indicates that the null hypothesis of irregularity can not be rejected strongly. Thus, the point pattern of oligodendrocyts is strongly irregular.\nAlternatively, we can inspect departures from the hypothesis that points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types (Buller 2020).\n\n\nCode\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp[['0.01']], marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\n\nWhether or not a point process is completely spatially random (CSR) depends on two characteristics: points need to be distributed homogeneously and they have to be independent of each other (see definitions above). There are various ways to test for CSR, here we show the use-case of the clark-evans test (Baddeley, Rubak, and Turner 2015, 165–66).\n\n\nCode\nclarkevans.test(pp_ls[['0.01']]$`OD Mature`)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nR = 0.77286, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\n\nIn the following document we will often compare the distribution of mature oligodendrocytes (OD mature cells) across different z-slices of the same tissue. We assume these slices to be enough apart to be considered as generated by different point processes. Since we consider the dependence of one mark among itself, we are in a within cell type setting per slide. We compare several curves along different z-slices, which is in turn a multivariate comparison (Baddeley, Rubak, and Turner 2015, 564 ff.).\nIn our example dataset we analyse the mouse preoptic hypothalamus (Moffitt et al. 2018). The lower boundary is the end of the tissue whereas the upper three boundaries are a technical boundary. Therefore, our example is a mixture between window sampling and the small world model. In order to decrease the bias of the tissue border, we use the Ripley-Rasson estimate of a spatial domain to estimate the sampling window (Baddeley, Rubak, and Turner 2015, 55; Ripley and Rasson 1977).\n\n\nCode\nlibrary('spatialFDA')\npar(mfrow=c(1,3))\n#Plot the marks separately \nlapply(zstack_list, function(zstack){\n  plot(pp_ls[[zstack]][[celltype_ls]], main = zstack, legend = FALSE)\n})\n\n\n\n\n\n[[1]]\nSymbol map with constant values\ncols: #000000E4\n\n[[2]]\nSymbol map with constant values\ncols: #000000C2\n\n[[3]]\nSymbol map with constant values\ncols: #0000007B\n\n\nCode\ndev.off()\n\n\nnull device \n          1 \n\n\nCode\npls &lt;- lapply(zstack_list, function(zstack){\n  pp_sel &lt;- pp_ls[[zstack]][[celltype_ls]]\n  p &lt;- pp_sel |&gt; as.data.frame() |&gt; \n  ggplot(aes(x = x, y = y, alpha = 0.3)) +\n  geom_point(size=0.75) +\n  theme_minimal() +\n  coord_fixed() +\n  ggtitle(zstack)\n  return(p)\n})\nwrap_plots(pls, guides = 'collect')\n\n\n\n\n\nCorrelation, or more generally covariance, represents a second-order summary statistic and measures dependence between data points (Baddeley, Rubak, and Turner 2015, 199 ff.).\n\n\n\n\nWith Ripley’s \\(K\\) we measure “the average number of \\(r\\)-neighbours of a typical random point” (Baddeley, Rubak, and Turner 2015, 204). This number is still dependent on the size of the observation window so we can normalise it by the number of points \\(n\\) and the window size, \\(|W|\\). We then obtain the empirical Ripley’s \\(K\\) function (Baddeley, Rubak, and Turner 2015, 204; Ripley 1977, 1976):\n\\[\n\\hat{K}(r) = \\frac{|W|}{n(n-1)}\\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n\\{d_{ij}\\leq r\\} e_{ij}(r)\n\\]\nThe standardisation makes it possible to compare point patterns with different observation windows and with different numbers of points. However, using the empirical \\(K\\) function assumes that the point process has homogeneous intensity, which is often not the case for biological tissue (Baddeley, Rubak, and Turner 2015, 204–5). We will return to this issue below in the Correcting for Inhomogeneity. The term \\(e_{ij}(r)\\) is an edge correction. We will briefly cover this in Edge effects and their corrections for spatial metrics\n\n\n\nEdge effects describe the phenomenon that not the entire point process is observed, but rather only the part within the window \\(W\\). This means the value of various statistics could be biased along the edges (Baddeley, Rubak, and Turner 2015, 213 ff.).\nThere are many corrections for edge effects that are briefly listed here (Baddeley, Rubak, and Turner 2015, 214–19):\nBorder correction:\nIn border correction the summation of data points is restricted to \\(x_i\\) for which \\(b(x_i,r)\\) is completely in the window \\(W\\).\nIsotropic correction:\nWe can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.\nTranslation correction:\nA stationary point process \\(X\\) is invariant to translations. So the entire point process can be shifted by a vector \\(s\\) to be at the position \\(X+s\\).\n\n\n\n\nThe \\(K\\)-function can be ``centered’’, which is then referred to as Besag’s \\(L\\)-function. The \\(L\\)-function is a variance-stabilising version of the \\(K\\)-function (Canete et al. 2022; Besag 1977, 1977):\n\\[\nL(r) = \\sqrt{\\frac{K(r)}{\\pi}}.\n\\]\nBy taking the square root the variance is approximately constant across the domain (Bartlett 1947).\n\n\n\nWe have seen above that the \\(K\\)-function is cumulative. That is, the contributions of all distances smaller equal to \\(r\\) are considered. An alternative is to take the derivative of the \\(K\\)-function in order to obtain contributions of distances between points equal to \\(r\\), according to:\n\\[\ng(r) = \\frac{K'(r)}{2\\pi r},\n\\]\nwhere the derivative of the \\(K\\) function divided by the probability of a Poisson process at this radius (Baddeley, Rubak, and Turner 2015, 225 ff.).\n\n\nCode\nres_ls &lt;- lapply(list('Kest', 'Lest', 'pcf'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')})\n\n\n\n\n\n\nCode\np_homo &lt;- wrap_plots(p_ls, guides = 'collect')\np_homo\n\n\n\n\n\nIn the homogeneous case we see that all slices are above the Poisson line, indicating positive association for all slices. The association is strongest for slice $-0.09$ followed by $0.01$ and $0.21$. Interestingly, at radii \\(r&gt;300\\) the \\(K\\) curve for slice \\(0.21\\) crosses the other two curves.\n\n\n\n\n\nIn the case that a spatial pattern is known or suspected to be inhomogeneous, we have to take this into account in the analysis. Inhomogeneous alternatives can be estimated via:\n\\[\n\\hat{K}_{inhom}(r) = \\frac{1}{D^p|W|}\\sum_i\\sum_{j \\neq i} \\frac{\\mathbb{1}\\{||u-x_j||\\leq r\\}}{\\hat{\\lambda}(x_j)\\hat{\\lambda}(x_i)}e(x_j,x_i;r),\n\\]\nwhere \\(e(u,v;r)\\) is an edge correction weight and \\(\\hat{\\lambda}(x_i)\\) is an estimator of the intensity at point \\(x_i\\). The estimation of the local intensities can happen in a data-dependent manner via kernel-smoothing. As this is the same data to then calculate the metric on, this can lead to biases. However, if the local intensities are known, the inhomogeneous \\(K\\) function is an unbiased estimator (Baddeley, Rubak, and Turner 2015, 242–46).\n\n\nCode\nres_ls &lt;- lapply(list('Kinhom', 'Linhom'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\nres_pcf &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = 'pcfinhom', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id')) \nres_pcf &lt;- subset(res_pcf, sample_id %in% c('-0.09', '0.01', '0.21'))\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"border\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\np &lt;- plotMetricPerFov(res_pcf, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'sample_id')\n\n\n\n\nCode\np_inhomo &lt;- wrap_plots(p_ls, guides = 'collect')\np_inhomo &lt;- wrap_plots(p_inhomo, p, guides = 'collect', widths=c(2,1))\np_inhomo\n\n\n\n\n\nThe inhomogeneous \\(K\\)-function indicates that the oligodendrocytes of slice 0.21 are close to a Poisson process (dashed line) and can therefore be assumed to be randomly distributed and not clustered. The two other slices show a slightly stronger association among the oligodendrocytes than the slice 0.21.\nThe \\(L\\) function is complementary to the \\(K\\) function in this example.\nThe pair correlation function is the derivative of the \\(K\\)-function. The pcf plot gives similar information as before: Oligodendrocytes show the strongest association at \\(\\sim r = 25\\) whereas the association is weaker in slice 0.21.\nInterestingly, the curves for the inhomogeneous functions of slices -0.09 and 0.01 cross the Poisson line at \\(r\\sim350\\). This means that the inhomogeneous functions find repulsion of slices past a radius of \\(350\\).\n\n\n\n\n\n\nIn the inhomogeneous \\(K\\)-function approach above, we assume that the intensities can vary locally but the scale of the point process is not changed. This means that while the intensities might vary in the parts of the point pattern, the pattern in one subquadrat is not just a scaled version of another subquadrat (Baddeley, Rubak, and Turner 2015, 246–47; Prokešová, Hahn, and Jensen 2006).\nTo account for this local scaling, we can assume that the process is subdivided into small regions. In these small regions, the point process is a scaled version of a template process. This template process needs to be both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 246–47).\n\n\n\nSince the \\(L\\)-function is simply a transformation of the \\(K\\)-function, the same local scaling framework can be applied to the \\(L\\)-function (Baddeley, Rubak, and Turner 2015, 246–47).\n\n\nCode\nres_ls &lt;- lapply(list('Kscaled', 'Lscaled'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\n\n\n\n\nCode\np_scaled &lt;- wrap_plots(p_ls, guides = 'collect')\np_scaled\n\n\n\n\n\nWe see, that in slice 0.01 oligodendrocytes are far from the Poisson process line, indicating a strong association. The other two slices show a less strong association.\n\n\nCode\np &lt;- wrap_plots(list(p_homo, p_inhomo, p_scaled), nrow = 3, guides = 'collect') + plot_annotation(tag_levels = 'A')\np\n\n\n\n\n\nCode\nggsave('pp_function_comparison.pdf', plot = p, width = 8, height = 9)\n\n\nIn the plot above we see all variants of the correlation metrics. The assumptions of either homogeneity (first row), inhomogeneity (second row) and local scaling (third row) change the interpretation of these example point patterns. In summary, in this example homogeneous variants show a positive association for all slices whereas inhomogeneity infered a Poisson distribution for slice \\(0.21\\). Furthermore, the inhomogeneous variant estimated repulsion for slices \\(-0.09\\) and \\(0.01\\), whereas homogeneous variants estimated clustering for all radii, whereas slice \\(0.21\\) became stronger than the other two slices past \\(r&gt;350\\). The locally scaled version showed positive associations for all slices and no crossing of curves over the radii.\nDeciding whether a pattern is homogeneous or inhomogeneous depends on the biological question. We provide some recommendations in the “Getting started” vignettes.\n\n\n\nIt is worth noting that the \\(K\\)- and \\(L\\)-functions described above are summary statistics over the entire pattern (i.e., averaged over all points). However, if we know that there are different regions in our point pattern, an alternative strategy is to compute `local` contributions to these patterns, i.e., local \\(K\\)- ,\\(L\\)- or pair-correlation functions. Baddeley et. al. propose to compare these \\(n\\) functions with so-called functional principal component analysis (see below). We will show here the example of the LISA version of the \\(L\\)-function (Baddeley, Rubak, and Turner 2015, 247–48).\n\n\n\n\nCode\nL_odmature_lisa &lt;- localL(pp_ls[['0.01']]$`OD Mature`)      \n\ndf &lt;- as.data.frame(L_odmature_lisa)\ndfm &lt;- reshape2::melt(df, \"r\")\n\nget_sel &lt;- dfm %&gt;% filter(r &gt; 200.5630 & r &lt; 201.4388, variable != \"theo\") %&gt;%\n  mutate(sel = value) %&gt;% select(variable, sel)\n\ndfm &lt;- dfm %&gt;% left_join(get_sel)\n\np &lt;- ggplot(dfm, aes(x=r, y=value, group=variable, colour=sel)) +\n  geom_line() + \n  scale_color_continuous(type = \"viridis\") +\n  geom_vline(xintercept = 200) +\n  theme(legend.position = \"none\") +\n  theme_light() +\n  ggtitle(\"LISA curves of slice 0.01\")\n\nppdf &lt;- as.data.frame(pp[['0.01']]) %&gt;% filter(marks==\"OD Mature\")\nppdf$sel &lt;- get_sel$sel # assume they are in same order\n\nq &lt;- ggplot(ppdf, aes(x=x, y=y, colour=sel)) + \n  geom_point(size=0.75) +\n  scale_color_continuous(type = \"viridis\") +\n  theme(legend.position = \"none\") +\n  theme_light()+\n  ggtitle(\"Points coloured by LISA value at r ~ 200\")\n\n\n\n\nCode\np|q\n\n\n\n\n\nIn the case of the OD mature cells, we obtain further information with this plot. We note that there are two distinct populations of curves: those that are clearly above the mean LISA curve in black and others that are around/underneath. This indicates that there are two different kinds of interactions in the OD mature cells. Stronger and less clustered regions.\nThere are inhomogeneous versions of these (e.g. localLinhom) that are not shown here for brevity.\n\n\n\nWe apply functional PCA to retrieve the main trends in these individual curves. The idea of functional PCA is the same as for ordinary PCA but applied to functional data (i.e., each observation is a function). For the \\(n\\) functions above, functional PCA will recover the main trends in the data (Ramsay and Silverman 2005). We use the R package refund to perform functional PCA (Xiao et al. 2016).\n\n\nCode\n#normalise the data\ndf_fdob &lt;- asinh(df %&gt;% as.matrix / 50) %&gt;% as.data.frame()\n# extract the functional response matrix\nmat &lt;- df_fdob %&gt;%\n   select(!c(r,theo)) %&gt;%\n  t()\n# create a dataframe as required by pffr\ndat &lt;- data.frame(ID = rownames(mat))\ndat$Y &lt;- mat \ndat$sel &lt;- get_sel$sel\n\n# perform functional PCA\nres &lt;- functionalPCA(dat = dat, r = df_fdob$r |&gt; unique(), knots = 30, pve = 0.99)\n# extract the scores\nscores_df &lt;- res$scores %&gt;% as.data.frame()\n# plot a biplot\np_biplot &lt;- ggplot(scores_df, aes(scores_df[, 1], scores_df[, 2], colour = (dat[['sel']]))) +\n        geom_point() +\n        coord_equal() +\n        theme_light() +\n        scale_color_continuous(type = \"viridis\") +\n        xlab('PC1') +\n        ylab('PC2')\n\n\n\n\nCode\np_biplot\n\n\n\n\n\n\n\nCode\np1 &lt;- ggplot(ppdf, aes(x=x, y=y, colour = res$scores[,1])) + \n  scale_color_continuous(type = \"viridis\", name = 'loading PC1') +\n  theme_light() +\n  geom_point(size=0.75)\n\np2 &lt;- ggplot(ppdf, aes(x=x, y=y, colour = res$scores[,2])) + \n  scale_color_continuous(type = \"viridis\", name = 'loading PC2') +\n  theme_light() +\n  geom_point(size=0.75)\n\n\n\n\nCode\np1|p2\n\n\n\n\n\nThe biplot shows the distribution of the first two loadings of the functional PCA. The points are coloured as they were in the plots of the LISA \\(L\\)-curves. The first principal component clearly separates the two populations. In the last plot we project the loadings of the fPCs back onto the biological slices and find the same separation.\n\n\n\n\n\nSo far we have considered first- and second-order summary statistics and local (or inhomogeneous) adaptations of them. In the second order, one considers (counts of) pairs (e.g., \\(K\\) function). In a third-order setting, we would count triplets of points. A triplet is counted as the normalised expected value of triangles where all edges are smaller than the radius \\(r\\) (Baddeley, Rubak, and Turner 2015, 249).\n\n\n\n\n\nSo far, most approaches considered intensity and correlation as measures to assess a point pattern. Next, we will look at measures of spacing and shortest-distances to assess spatial arrangements (Baddeley, Rubak, and Turner 2015, 255).\nBaddeley et al. summarises three basic distances:\n\npairwise distance: \\(d_{i,j} = ||x_i-x_j||\\)\nNN distances: \\(d_i = \\min_{j \\neq i}d_{ij}\\)\nempty-space distance: \\(d(u) = \\min_j||u-x_j||\\)\n\nNote also that there are tests of CSR that are based on spacing, including the Clark-Evans and Hopkins-Skellam Index tests that were discussed above ``Testing for CSR’’.\n\n\nNearest neighbour (NN) methods are based on the notion of “nearness”. In particular, we introduce nndist from spatstat, a method to calculate the distances until \\(k\\) NN are found. This function returns a density for each specified \\(k\\) for the \\(k\\) neighbour distances. We can for instance collapse the \\(k\\) curves into a mean curve per point pattern. This information of the mean nearest neighbour distance (MMND) can be summarised as a density. Note, that these distances are “raw” nearest-neighbour distances which are not corrected for edge effects. Edge correction for the nearest neighbour distance (\\(k = 1\\)) is implemented in the function Gest below (Baddeley, Rubak, and Turner 2015, 256) (Baddeley and Turner 2005).\n\n\nCode\nnndistance &lt;- function(pp, nk){\n  xy &lt;- cbind(pp$x, pp$y)\n  nndistances_k15 &lt;- nndist(xy, k = nk) \n  nndistances_mean &lt;- rowMeans(nndistances_k15)\n  return(nndistances_mean)\n}\n\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricRes_nndist &lt;- function(ppls, celltype, fun){\n  metric.res &lt;- list(res = do.call(fun, args = list(pp=ppls[[celltype]], nk = seq(1:15))))\n  metric.res$type = celltype\n  return(metric.res)\n}\n# [MR: again, this function looks again like those before and maybe could be done as an all-in-one wrapper.]\ncelltypes &lt;- c(\"Ependymal\", \"OD Mature\", \"Microglia\")\n#go through all defined celltypes and calculate the nearest-neighbour distance\nres_ls &lt;- lapply(celltypes, metricRes_nndist, fun = nndistance, ppls = pp_ls[['0.01']])\n#initialise a dataframe for the metric values and the type information\nres_df &lt;- data.frame(metric = numeric(0), type = character(0))\n# Loop through the res_ls list and combine the metric values with their corresponding type - ChatGPT\nfor (i in 1:length(res_ls)) {\n  metric_values &lt;- res_ls[[i]]$res\n  metric_type &lt;- rep(res_ls[[i]]$type, length(metric_values))\n  df &lt;- data.frame(metric = metric_values, type = metric_type)\n  res_df &lt;- rbind(res_df, df)\n}\n#plot the densities\np &lt;- ggplot(res_df, aes(x=metric, col= type))+\n    geom_density(linewidth=1)+\n    scale_x_sqrt() +\n    theme_light() +\n    ggtitle('Sqrt of the Mean Nearest-Neighbour Distance')\np\n\n\n\n\n\nIn the MNND empirical distribution, the ependymal cells show the shortest NN distances, a reflection of their clustering. The OD mature cells have larger NN distances as well as a bimodal distribution, indicating a mix of shorter and longer distances (as visible in the LISA \\(L\\)-functions). Microglia cells show the widest distances and the symmetry of the curve indicates similar distances throughout the field of view.\n\n\n\n\n\nIn a stationary spatial point process, the empty-space distance is defined as:\n\\[\nd(u,X) = \\min\\{||u-x_i||: x_i \\in X\\}\n\\]\nNote that this is an edge-corrected distribution function of the nearest-neighbour distance above.\nThe empty space function is then the cumulative distribution function of the empty-space distances defined above:\n\\[\nF(r) = \\mathbb{P}\\{d(u,X)\\leq r\\}.\n\\]\nThe NN distance is defined as:\n\\[\nd_i = \\min_{j\\neq i}||x_j-x_i||.\n\\]\nThe NN distance distribution function \\(G(r)\\) is then defined as:\n\\[\nG(r) = \\mathbb{P}\\{d(x,X\\backslash u \\leq r |X\\ has\\ a\\ point\\ at\\ u\\}.\n\\]\nFor a homogeneous Poisson process, the NN distance distribution is identical to the empty-space function of the same process:\n\\[\nG_{pois} \\equiv F_{pois}.\n\\]\nFor a general point process, the \\(F\\) and \\(G\\) functions are different (Baddeley, Rubak, and Turner 2015, 261–67).\n\n\n\n\nThe \\(F\\) and \\(G\\) functions are, like the \\(K\\) function, cumulative. The same disadvantages as with the \\(K\\) function occur here too, namely their cumulative nature. Therefore, an analogue to the pair-correlation function would make sense to consider. For practical reasons, this is no longer the derivative of the \\(F\\) function but rather a hazard rate:\n\\[\nh(r) = \\frac{f(r)}{1-F(r)}.\n\\]\n(Baddeley, Rubak, and Turner 2015, 271–74).\n\n\n\nThe concepts of the empty-space function \\(F\\) and the NN function \\(G\\) are complementary. If one decreases, the other increases.\nThus, the \\(J\\) function is a combination of both functions:\n\\[\nJ(r) = \\frac{1-G(r)}{1-F(r)}.\n\\]\nFor a CSR process, \\(J_{pois} \\equiv 1\\), whereas values of \\(J(r) &gt; 1\\) are consistent with a regular (e.g., repelling) pattern, and $J(r) &lt; 1 represents a clustered process (Baddeley, Rubak, and Turner 2015, 275–77).\n\n\nCode\nres_ls &lt;- lapply(list('Gest', 'Fest', 'Jest'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"rs\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\n\n\n\n\nCode\nwrap_plots(p_ls, guides = 'collect')\n\n\n\n\n\n\n\n\nThere are inhomogeneous variants of the spacing functions explained above (Baddeley, Rubak, and Turner 2015, 277–78)\n\n\nCode\nres_ls &lt;- lapply(list('Ginhom', 'Finhom', 'Jinhom'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"bord\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\n\n\n\n\nCode\nwrap_plots(p_ls, guides = 'collect')\n\n\n\n\n\nThe inhomogeneous curves look different to their homogeneous counterparts but the relative ordering is of the curves per plot is the same.\n\n\n\nNext to the NN distance, we can estimate the orientation of the neighbours, which gives an indication of the orientation of the spacing. It works by taking the angle between each point and its \\(k^{th}\\) nearest neighbour. The angle is anticlockwise from the x-axis (Baddeley, Rubak, and Turner 2015, 278–79) (Baddeley and Turner 2005).\n\n\nCode\nres &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = 'nnorient', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n\n\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-352.270177372156, -78.8407753876126, -111.046745026638, \n-258.840775387612, -163.103596647317, -1.12337497669819, -181.123374976698, \n-77.2123525877966, -266.69655510861, -156.591799675296, -226.263809918599, \n-86.6965551086096, -58.578151960682, -325.608317167433, -45.6149560153542, \n-225.614956015354, -105.189192778811, -348.269448227482, -168.269448227482, \n-63.0089629188483, -243.008962918848, -13.2439006043352, -193.243900604335, \n-295.969055063992, -115.969055063992, -298.481458827673, -211.844140222042, \n-31.844140222042, -348.307933087447, -134.221070388405, -63.4124830246728, \n-302.466416297019, -314.221070388405, -243.412483024673, -188.449991857503, \n-296.59498464773, -104.078505032114, -100.545591125103, -280.545591125103, \n-204.483448188219, -8.44999185750282, -303.940263380113, -149.809798260312, \n-201.053219046732, -311.89208497532, -67.9595994951025, -332.784936569921, \n-8.82028174168437, -74.0767654457289, -225.844538522669, -79.3964368623119, \n-188.820281741684, -113.297182120676, -305.197543854312, -307.618500227702, \n-355.965169024395, -40.6780360188148, -254.076765445729, -293.297182120676, \n-39.1505020381276, -219.150502038128, -200.543630530714, -20.5436305307144, \n-339.484093876425, -159.484093876425, -57.1267789677657, -237.126778967766, \n-152.784936569921, -209.248811480034, -290.446084051197, -303.637902437449, \n-70.6500113335375, -185.699471390362, -222.924098568549, -269.297471568842, \n-123.637902437449, -284.996025313062, -272.615969084589, -92.6159690845892, \n-346.170195141824, -162.965859268129, -232.094320001281, -77.8656618006115, \n-15.4642774288034, -195.464277428803, -150.100181240554, -21.3744630245959, \n-94.2980567804455, -297.307301793814, -232.878900761254, -137.835301857452, \n-257.307183906531, -357.629382730416, -92.569484422423, -141.075930895391, \n-177.629382730416, -321.075930895391, -201.374463024596, -317.835301857452, \n-342.965859268129, -281.939334837023, -101.939334837023, -353.653488352489, \n-173.653488352489, -98.1315720644685, -12.3792275338427, -322.583232043193, \n-230.983428313025, -192.379227533843, -203.304191922505, -152.506999167441, \n-203.892619196912, -323.663661329153, -248.830970930664, -200.047123150142, \n-1.38606474159587, -293.916356614058, -359.572861541834, -75.1700923878964, \n-255.170092387896, -25.7869048859995, -205.786904885999, -158.45780561965, \n-71.8851513684932, -251.885151368493, -59.403476140586, -356.066116677889, \n-186.27671586379, -75.9112508510436, -255.911250851044, -338.179878042894, \n-270.649829818654, -23.5020856230652, -203.502085623065, -78.0257116416499, \n-234.989230735614, -320.542382770207, -9.50589792171149, -236.758947198611, \n-140.542382770207, -96.1220558312287, -350.721952486165, -174.269962575491, \n-54.9892307356145, -116.851258052999, -231.814380162457, -179.572861541834, \n-239.403476140586, -176.066116677889, -158.179878042894, -163.55668718861, \n-71.2297500794803, -312.34673249094, -95.39242833464, -73.6609985496231, \n-248.35913101654, -87.0647807709773, -253.660998549623, -68.3591310165398, \n-37.1309655628759, -119.90425747821, -275.39242&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-5.11581056159167, -88.5443555273749, -268.544355527375, \n-130.04175171566, -333.006562148466, -284.247300287698, -310.04175171566, \n-276.199053293487, -252.353285814794, -6.2279079985766, -72.9293859909634, \n-278.672202485416, -186.227907998577, -72.353285814794, -284.11823402956, \n-312.646975373578, -338.478193486814, -158.478193486814, -276.92112412748, \n-355.838323058898, -104.11823402956, -98.6722024854164, -79.5391300528095, \n-25.167722028218, -205.167722028218, -257.640669409134, -77.6406694091344, \n-285.02306716158, -106.384535903058, -336.402031124996, -77.7517823878251, \n-341.008707781084, -257.751782387825, -263.008064661683, -357.8279639433, \n-229.93784753933, -105.02306716158, -58.3848544490431, -278.80644694667, \n-98.8064469466702, -156.402031124996, -286.554141866854, -49.9378475393302, \n-41.6488902114526, -221.648890211453, -241.19002443605, -169.374533781563, \n-105.608441092327, -285.608441092327, -240.221640100979, -308.284104993064, \n-175.43056236321, -153.006562148466, -198.254973003552, -60.2216401009789, \n-128.284104993064, -206.120022237854, -87.2691858696724, -267.269185869672, \n-48.2491327327264, -168.197831018745, -110.648429986763, -277.618856993432, \n-207.985633928158, -281.947872247649, -315.15894459726, -280.738805698306, \n-294.424433099205, -58.1518885875648, -135.15894459726, -78.2585436647492, \n-258.258543664749, -293.920635316806, -89.7933472447544, -159.547724219966, \n-202.020927708805, -354.580924383252, -227.657743789333, -163.419509891769, \n-336.646350813012, -238.151888587565, -16.0063098805552, -113.920635316806, \n-174.580924383252, -196.006309880555, -279.718982242703, -99.7189822427031, \n-168.956874862177, -348.956874862177, -45.9402311382274, -80.2134577226362, \n-148.739507163703, -115.363287257624, -184.687657144868, -295.363287257624, \n-4.68765714486818, -247.507901607414, -251.482674648623, -2.0654722270823, \n-95.3514045541011, -115.26390688921, -17.1439650832485, -345.542933275486, \n-165.542933275486, -45.8720537034065, -275.351404554101, -38.5483810721091, \n-218.548381072109, -349.371925775176, -169.371925775176, -264.077561870819, \n-11.6815724060601, -334.42873490927, -154.42873490927, -358.412545353368, \n-71.4097622391083, -5.43111302006025, -313.189489214986, -286.547113373596, \n-287.3069851888, -300.698920499573, -40.6184832829754, -120.698920499573, \n-250.743771742036, -70.743771742036, -21.2299198970712, -201.229919897071, \n-33.4117566742984, -182.122609876558, -64.7090136231507, -278.504712262058, \n-356.326861155484, -262.631985110487, -176.326861155484, -312.572118724145, \n-244.709013623151, -347.856615921828, -24.2912415846981, -306.844848777968, \n-126.844848777968, -99.4203453391343, -18.5161276955999, -43.3465899881173, \n-64.7759252950781, -69.5964260512068, -249.596426051207, -50.7832329953741, \n-78.4968261158162, -86.514645666547, -130.342819065401, -280.353671085214, \n-100.353671085214, -350.094097427955, -279.420345339134, -310.051332574459, \n-144.568596441412, -258.496826115816, -27.128466092271, -207.128466092271, \n-25.1375205912781, -244.775925295078, -286.956795248144, -10&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-256.187188719964, -244.616749956277, -151.710979871396, \n-27.7742480514179, -6.02924055350525, -240.273991987081, -331.710979871396, \n-151.674303660818, -207.774248051418, -186.029240553505, -279.985191260697, \n-283.230613628714, -265.980595173003, -358.196974997928, -178.196974997928, \n-265.497247642895, -85.4972476428946, -48.572709111639, -296.774942787172, \n-174.310357286171, -47.2989248596632, -354.310357286171, -271.610421522174, \n-235.213450796739, -91.6104215221742, -3.91822485109896, -7.19043482518987, \n-4.56607064881291, -66.8627483608174, -72.9347171365887, -236.620856310673, \n-106.359595886177, -61.3305919284884, -250.08816340711, -353.267693066311, \n-241.330591928488, -173.267693066311, -18.7008211041673, -252.365785399095, \n-161.372261566949, -88.4559986093578, -268.455998609358, -1.2419193818933, \n-180.670046926597, -181.968764777714, -181.241919381893, -162.874588296894, \n-70.0881634071102, -240.219597606341, -1.9687647777144, -212.452708745007, \n-335.767717350867, -282.69448999164, -102.69448999164, -341.372261566949, \n-242.966522975313, -56.6208563106729, -32.4527087450072, -349.43676282839, \n-64.9372045669958, -115.309689157341, -244.937204566996, -38.6881624022836, \n-251.191366077449, -71.1913660774489, -251.141471631164, -295.309689157341, \n-228.572709111639, -190.088612597927, -281.363604723856, -290.431740617624, \n-161.883514313476, -170.371251663487, -78.4135765129114, -341.883514313476, \n-258.413576512911, -60.177692440165, -92.10975722666, -293.933293173144, \n-240.177692440165, -245.774222273138, -131.507328542113, -22.0447648552548, \n-341.120935739201, -161.120935739201, -58.4098289967349, -28.7283866177453, \n-208.728386617745, -165.531470483647, -53.1534867157802, -233.15348671578, \n-207.747975794346, -347.082988038268, -167.082988038268, -271.496704247835, \n-66.8191644709821, -246.819164470982, -10.807073546099, -53.1897156550762, \n-133.77427683927, -233.189715655076, -248.38109440873, -55.5873314946821, \n-250.187343624747, -164.053783485272, -171.951838010199, -80.4686575612183, \n-70.1873436247467, -235.587331494682, -351.951838010199, -186.964800417911, \n-333.504965812855, -153.504965812855, -106.72438826863, -230.744020740803, \n-286.72438826863, -335.399900618576, -93.8265002966102, -273.82650029661, \n-349.965376191442, -78.3961649584372, -258.396164958437, -295.000365724814, \n-95.8340960831191, -275.834096083119, -169.965376191442, -68.7251903037761, \n-248.725190303776, -334.78901966399, -30.2179367571306, -296.834065912993, \n-116.834065912993, -184.432493541505, -287.943036589064, -296.12567748176, \n-346.879910125259, -91.1131634639628, -50.9870233277884, -230.987023327788, \n-21.1138616747963, -110.436009979727, -276.050538170885, -96.0505381708853, \n-226.560877143928, -83.7484038865432, -91.7876554676624, -89.4151550515377, \n-263.748403886543, -105.230407975521, -10.1720888212641, -359.980032209763, \n-269.522093781849, -285.230407975521, -290.436009979727, -179.980032209763, \n-46.5608771439282, -314.731434412755, -283.944780011375, -134.731434412755, \n-43.8562540887355, -355.389543652185, -132.829944331&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-359.022889701311, -10.3186004397934, -190.318600439793, \n-85.0534576172009, -57.4074850705547, -180.625969004942, -49.9909081715182, \n-0.625969004941908, -61.2955392795462, -154.55005712375, -31.2190840962529, \n-74.2594817730113, -254.259481773011, -274.24411063909, -353.858770127011, \n-35.7014241856737, -357.9526873717, -255.247832199031, -75.247832199031, \n-175.630198512273, -355.630198512273, -77.5081778040884, -2.55197556701631, \n-48.1881554054164, -41.0007288317315, -57.1282280253656, -7.40212952298413, \n-53.0156781479643, -66.5946902178152, -45.5364822885348, -327.364027595428, \n-331.756842704065, -113.424317843876, -74.6681446853861, -151.756842704065, \n-243.483744935823, -120.266905446712, -158.315565579037, -246.594690217815, \n-176.205615211407, -121.756314120413, -293.424317843876, -97.3370223216581, \n-237.065778844705, -302.883954323519, -122.883954323519, -277.337022321658, \n-308.214201038948, -48.9042063133615, -104.050190517741, -324.097448105525, \n-144.097448105525, -102.673919111154, -177.9526873717, -170.418845279864, \n-48.3881291044983, -355.57804361351, -18.9173272395449, -338.92931628436, \n-158.92931628436, -139.109075858483, -156.33966854139, -319.109075858483, \n-175.57804361351, -286.414393060473, -106.414393060473, -7.111705720587, \n-68.2229583628549, -78.7973920262517, -336.841976049693, -74.8015503065966, \n-254.801550306597, -203.256492528996, -342.308363022304, -162.308363022304, \n-77.0219881691848, -297.754105681217, -245.23470865174, -358.656023077959, \n-178.656023077959, -4.72025338616834, -62.615494198678, -197.40830901473, \n-98.3240366753043, -144.632095077267, -17.4083090147302, -192.464394802183, \n-262.909086296409, -278.324036675304, -105.605887543362, -324.632095077267, \n-289.054915478821, -109.054915478821, -149.006416953543, -329.006416953543, \n-229.166231660404, -156.841976049693, -218.841949191799, -302.06271440585, \n-341.116797719257, -38.7708419374275, -317.481991803109, -63.4490328445047, \n-243.449032844505, -327.978879140214, -122.06271440585, -34.6341526268563, \n-81.4042419087321, -323.181485825026, -41.693895227706, -221.693895227706, \n-195.012871029775, -296.840356712563, -116.840356712563, -86.3245286037807, \n-14.4236422397064, -335.791374516871, -155.791374516871, -10.0620844259316, \n-69.3282681054038, -18.2962023577373, -280.809551955893, -353.470480059569, \n-178.138328142679, -305.416801429556, -281.605969011734, -55.8218208528094, \n-313.916618073517, -119.55658974049, -299.55658974049, -358.138328142679, \n-131.032095223652, -346.110311589285, -337.408492729086, -19.8850796377156, \n-166.110311589285, -72.2643881330561, -252.264388133056, -310.703497420158, \n-25.4941792539828, -290.131537015391, -237.597240990107, -205.494179253983, \n-82.912475158119, -79.8768394295633, -171.341324717763, -225.544070568794, \n-132.259558526082, -256.54559230756, -110.131537015391, -204.07368502775, \n-312.259558526082, -259.876839429563, -351.341324717763, -175.014876188443, \n-4.3440605433309, -17.7309243279956, -157.407272365019, -70.419790005528, \n-169.833356255775, -145.496114343817, -56.2889757547783, -3&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-295.078691969693, -345.884682494487, -226.945112055437, \n-327.864976541037, -295.951725328425, -115.951725328425, -46.9451120554368, \n-170.821621866206, -278.842862709139, -98.8428627091391, -323.140649288203, \n-348.005202108591, -168.005202108591, -337.400437163284, -260.619767993709, \n-291.999850513972, -195.895457955538, -274.395991134374, -94.3959911343742, \n-17.0900164066101, -66.3503143656714, -111.999850513972, -322.223484201711, \n-103.17395719, -279.442639143589, -351.992654968402, -133.745815339215, \n-279.203946161739, -343.233225396631, -254.922342219767, -18.0070008010953, \n-89.6460975336653, -272.349381061038, -336.28332241013, -171.992654968402, \n-302.870380553809, -52.5118882095554, -232.511888209555, -283.17395719, \n-198.007000801095, -145.876012317324, -216.7290887983, -72.3559451506542, \n-252.355945150654, -41.052553925061, -11.2016150927394, -47.093122717356, \n-191.201615092739, -227.093122717356, -9.39983010099297, -17.7167129564581, \n-189.399830100993, -294.819789336715, -75.028394163274, -121.318695662446, \n-137.443096790202, -255.028394163274, -317.443096790202, -222.871298177999, \n-36.7376674378823, -358.476780334732, -292.498014022431, -324.376669311221, \n-44.7777859327134, -299.125995487646, -7.05927224504006, -343.508842602808, \n-187.05927224504, -72.9464745648854, -252.946474564885, -134.451606184991, \n-32.0613107598587, -177.420371458507, -301.512442762811, -202.746447385796, \n-99.4827934143214, -3.00448756442569, -183.004487564426, -22.3652118364236, \n-347.607593549918, -281.432194052777, -240.082025829668, -212.061310759859, \n-279.482793414321, -184.34807194668, -240.37555597264, -112.687660277792, \n-42.4979873085491, -75.125962090887, -294.56508262713, -114.56508262713, \n-255.125962090887, -138.432404337313, -134.694538356377, -189.659481818812, \n-9.65948181881214, -115.078691969693, -335.835229685532, -304.739137387853, \n-124.739137387853, -196.368920923487, -174.159620281147, -189.17101907872, \n-50.5289308480709, -149.16287352449, -329.16287352449, -289.090661448386, \n-89.2440968427562, -269.244096842756, -310.465819559658, -13.7032426558678, \n-60.2716757967153, -54.4510381103862, -234.451038110386, -193.703242655868, \n-130.465819559658, -61.1034213165887, -241.103421316589, -168.785582797427, \n-196.986663614766, -116.369703225974, -230.528930848071, -3.15207885150801, \n-155.835229685532, -183.152078851508, -12.4606784633418, -192.460678463342, \n-356.370615147144, -314.195320715308, -285.393098274532, -5.49003603310842, \n-185.490036033108, -341.596579748326, -185.35228780869, -242.92318818289, \n-331.675549480863, -62.9231881828899, -262.895219601585, -230.469564014638, \n-134.195320715308, -345.273616647451, -332.554021283449, -248.341301993562, \n-63.9880945227726, -65.0058708627749, -243.988094522773, -245.005870862775, \n-68.3413019935617, -13.5335177583586, -341.714053505448, -53.9635700920196, \n-140.48562202935, -331.817305993421, -320.48562202935, -10.4447887409476, \n-176.274824891663, -33.3860780193136, -213.386078019314, -356.274824891663, \n-9.42596824642874, -221.8299235111, -244.414728348301, -342.&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-333.69615899261, -18.3245907525347, -198.324590752535, \n-68.468299289097, -121.330231603319, -194.64079495848, -290.258989674082, \n-242.133875896947, -260.468654724404, -126.662838131614, -232.514772324754, \n-150.481223418954, -52.5147723247538, -29.2405968325377, -86.2833715821758, \n-246.702681442096, -19.9912901192075, -298.399165163087, -266.283371582176, \n-208.351240393526, -351.223491106052, -171.223491106052, -145.411828109325, \n-66.7026814420957, -49.9534396533909, -229.953439653391, -136.003061468328, \n-224.585773676087, -91.010966282723, -11.7056288162052, -82.0119366007121, \n-262.011936600712, -85.7499185258491, -233.691073325693, -206.367206707834, \n-265.749918525849, -7.04485359169519, -60.7260281806411, -43.9547871550668, \n-280.723371337382, -319.287192515066, -139.287192515066, -169.600629072393, \n-163.231986245987, -228.623634897795, -319.124715932603, -44.0594783557237, \n-139.124715932603, -341.212481312672, -18.2537533369971, -161.212481312672, \n-319.973430989719, -198.253753336997, -337.327823979224, -85.9497451108446, \n-46.511847134337, -69.1335300672727, -224.059478355724, -8.34150414308664, \n-345.382607225578, -240.566801370581, -100.723371337382, -265.949745110845, \n-4.49353298990343, -14.3727868471123, -338.443140047995, -223.954787155067, \n-158.443140047995, -249.527050070613, -346.736165189697, -284.460146073115, \n-104.460146073115, -263.037295161041, -330.279330583746, -78.5044942758017, \n-353.517702871151, -258.504494275802, -251.785280895844, -190.300104697781, \n-355.807454668385, -175.807454668385, -91.823016546645, -271.823016546645, \n-178.830738179573, -14.9894828835853, -358.830738179573, -194.989482883585, \n-274.185843095135, -335.286935596061, -155.286935596061, -94.1858430951348, \n-192.616939784196, -282.850580673368, -102.850580673368, -301.873433969956, \n-123.091318820104, -260.740217737532, -80.7402177375325, -259.351936126478, \n-199.512576655189, -212.162557560454, -167.275574800717, -122.116803165792, \n-212.942999294845, -32.942999294845, -119.873870369514, -208.935773275665, \n-235.400359743041, -162.760926084384, -199.680351007517, -173.92189284147, \n-125.685883890894, -218.03028588247, -346.650028749198, -332.01974220177, \n-67.3469858648216, -226.503036521507, -327.990277123815, -147.990277123815, \n-168.467555269635, -74.8222687438255, -254.822268743826, -88.0640039095194, \n-9.54317293109068, -46.5030365215073, -247.346985864822, -233.666116241396, \n-163.310434807235, -196.397218077954, -248.424274685937, -8.76151922676928, \n-341.789268358469, -226.601379432246, -15.4906700129932, -2.5999104644327, \n-73.9573304333646, -124.542170698342, -298.328589305214, -304.542170698342, \n-290.965091123721, -110.965091123721, -32.2138208854877, -218.388576220553, \n-38.3885762205533, -66.1098015102177, -189.80507613823, -9.80507613822954, \n-194.152436358693, -14.1524363586928, -30.1577754069467, -274.691365345944, \n-94.6913653459437, -111.524219266683, -45.858098167169, -66.7608259075767, \n-225.858098167169, -36.9821922327898, -264.153975377028, -216.98219223279, \n-84.1539753770276, -77.4662770665508, -172.1872&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-312.362714698029, -285.31881385321, -105.31881385321, \n-233.066624591695, -333.496373871918, -137.06188230087, -94.7691479515943, \n-291.319193774187, -213.737259471425, -306.582771337255, -350.795119916787, \n-95.4682509115135, -24.3229569605057, -126.582771337255, -17.9321093798362, \n-277.58352292484, -247.514643453907, -275.468250911513, -197.932109379836, \n-55.0327031998197, -235.03270319982, -64.6137350588743, -303.813555369703, \n-123.813555369703, -244.613735058874, -96.1518545180419, -35.4489853147538, \n-50.971181385277, -9.40634606855383, -189.406346068554, -336.327830991331, \n-281.203443449227, -101.203443449227, -346.367548795879, -211.918098088264, \n-292.200599779626, -295.294630845175, -115.294630845175, -135.141350204943, \n-164.797082273751, -50.1068617287659, -75.3866336126738, -43.8220011242647, \n-255.386633612674, -180.096958261148, -187.938155695536, -223.822001124265, \n-161.689223491411, -28.0157033601806, -31.9180980882641, -315.141350204943, \n-306.470391250417, -122.454480736094, -62.6621143966691, -237.020457399504, \n-297.368250983766, -243.514829287618, -270.706870057678, -89.3017014737697, \n-269.30170147377, -348.130321607612, -168.130321607612, -100.689108638544, \n-26.4577688036176, -206.457768803618, -118.245051236299, -7.30213406388293, \n-172.870562497621, -241.506470918043, -196.448066125379, -352.870562497621, \n-145.60179537718, -325.60179537718, -70.6314143295759, -250.631414329576, \n-125.147026065004, -305.147026065004, -214.044848958149, -287.59317489641, \n-203.706068839751, -107.59317489641, -258.776382330176, -8.84556318772354, \n-256.60096321302, -301.603337714307, -198.998570512395, -186.961964434335, \n-163.890443264117, -18.9985705123952, -238.036544082217, -261.605551962232, \n-76.6009632130201, -6.9619644343349, -208.015703360181, -62.149372490478, \n-242.149372490478, -346.937379018742, -7.4479030439602, -353.684201812379, \n-21.0533276449089, -201.053327644909, -166.937379018742, -5.81990453569966, \n-159.609716588605, -19.3890972709094, -286.184215993755, -197.805617617324, \n-106.184215993755, -287.323049925313, -280.450163135488, -100.450163135488, \n-305.255839953553, -125.255839953553, -110.526826257068, -166.635984256943, \n-197.123138083507, -184.240922564567, -202.200920030606, -104.720298744487, \n-187.44790304396, -262.227513224643, -86.0302911848752, -45.855818253176, \n-11.4170224730747, -4.81707828014805, -340.520970919903, -160.520970919903, \n-184.817078280148, -152.414693725295, -163.311312527714, -357.674635654074, \n-225.855818253176, -329.712478472788, -351.713521585186, -307.171037266955, \n-302.232584868812, -96.7290928393226, -291.102142535746, -86.5190209479484, \n-69.3982663594125, -249.398266359412, -276.729092839323, -280.858584810572, \n-207.81842213514, -171.45746244653, -314.398596256328, -134.398596256328, \n-327.598698558015, -264.085987841675, -78.3161716131646, -4.19353456008366, \n-281.996098937925, -230.504364865086, -172.108981176328, -48.1470885494984, \n-271.161378042166, -120.365667179453, -91.1613780421658, -258.335056861053, \n-133.558692093453, -238.794887213693, -264.935904318&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-290.482910237945, -275.871728195883, -339.024787384244, \n-159.024787384244, -246.169327586256, -296.038415639151, -75.4054148442453, \n-58.6866191821143, -118.82165004161, -45.2896862245597, -181.835596843418, \n-333.809043662663, -153.809043662663, -225.28968622456, -66.1693275862556, \n-298.82165004161, -161.717370181058, -296.326312164721, -16.7090084549014, \n-307.740226085856, -127.740226085856, -196.709008454901, -182.138161211504, \n-191.721280039561, -2.13816121150376, -274.771439397617, -89.7605056020227, \n-94.7714393976173, -311.288166080397, -3.2549072305581, -346.706761380775, \n-209.521491027004, -76.7888488671645, -166.706761380775, -60.5496123347615, \n-240.549612334762, -328.87176728581, -148.87176728581, -225.916039969689, \n-69.8446892071964, -79.3714061151016, -331.546092344188, -60.1464090290089, \n-240.146409029009, -259.371406115102, -318.296931250038, -82.4669756285982, \n-195.747598117563, -316.185023424654, -18.482601598807, -136.185023424654, \n-262.948127990608, -198.482601598807, -302.968214889426, -24.6173853581151, \n-204.617385358115, -359.470272902777, -345.085979960884, -63.4170693483985, \n-27.1900665898104, -243.417069348399, -165.085979960884, -207.19006658981, \n-37.8133730460074, -262.466975628598, -82.9481279906082, -109.297666582582, \n-115.590057124375, -15.7475981175635, -316.175502795008, -272.323083534419, \n-354.828022530688, -341.318786062773, -174.828022530688, -295.590057124375, \n-38.8884661922355, -97.173797303457, -302.245641193959, -182.444041694007, \n-266.844909753395, -2.44404169400701, -86.8449097533947, -257.78681265584, \n-281.950626083003, -203.096614670013, -101.950626083003, -91.6230799586116, \n-271.623079958612, -125.278605494821, -188.421689172827, -4.3942801658182, \n-116.038415639151, -224.925016357327, -185.058768862965, -184.394280165818, \n-5.05876886296539, -98.3129421859619, -251.374307062102, -194.817055696638, \n-271.416567046309, -49.093008002573, -91.4165670463092, -135.33274119588, \n-285.49554510697, -105.49554510697, -9.12989597410734, -102.618957680861, \n-189.129895974107, -136.797215558646, -171.33382579815, -351.33382579815, \n-293.905851190381, -298.978272003568, -138.587290837793, -21.6542558934896, \n-343.915898611187, -224.348994516929, -8.75421358315566, -188.754213583156, \n-194.356551153962, -318.587290837793, -335.58263392403, -33.7981255302574, \n-342.328048593967, -213.798125530257, -290.577208108514, -110.577208108514, \n-53.8241422735892, -163.915898611187, -44.3489945169295, -112.087402621736, \n-278.840690940988, -345.427737715983, -234.630528778402, -265.865712159004, \n-120.825729922581, -165.427737715983, -222.871197450848, -279.565208571509, \n-89.3437420533828, -51.981215655615, -31.8404697675792, -10.4250059821736, \n-62.7287244502886, -190.425005982174, -336.662189776031, -87.7669327573259, \n-195.682870244662, -267.766932757326, -121.117548104025, -117.121435028457, \n-42.8711974508481, -14.061164309887, -140.378388862204, -242.728724450289, \n-169.976002401697, -23.5251000436456, -99.5652085715088, -194.061164309887, \n-349.976002401697, -78.9420301312682, -89.41798331289&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-300.614717340708, -192.807715099217, -341.388864955616, \n-88.3588384053499, -262.595509713719, -120.614717340708, -329.065276209013, \n-286.157722874051, -250.986097391059, -353.993243010854, -254.630978352829, \n-246.584189549134, -293.963559793537, -173.993243010854, -70.9860973910593, \n-320.753771138442, -140.753771138442, -321.374961107713, -141.374961107713, \n-162.455801006255, -98.7461714400711, -220.597574221103, -119.598217002419, \n-31.358475372092, -110.28096274261, -190.830364155748, -211.358475372092, \n-261.987343474087, -81.9873434740866, -207.349148802249, -115.858574907941, \n-74.6979906222125, -295.445749049976, -205.515104415053, -204.050211473668, \n-56.325965366401, -314.877308751101, -236.325965366401, -134.877308751101, \n-85.3820555417506, -265.382055541751, -25.5151044150534, -295.975242679584, \n-115.975242679584, -323.772708440371, -174.557107707318, -301.930987089763, \n-38.7168807429865, -337.18711027648, -297.418587380517, -117.418587380517, \n-29.0416388323812, -320.286927123967, -94.2630069866786, -36.6192699257358, \n-183.788369466469, -162.723809674433, -43.1969734920112, -223.196973492011, \n-243.085311850147, -216.619269925736, -63.0853118501468, -209.041638832381, \n-274.263006986679, -341.104214928886, -201.940869863284, -17.164152737129, \n-302.935376984222, -157.8586339928, -122.935376984222, -306.45119575141, \n-273.970495744644, -126.45119575141, -129.262154605071, -50.0662903904077, \n-161.104214928886, -337.8586339928, -117.392652217638, -262.640384881124, \n-297.392652217638, -348.253913594158, -199.096523880084, -335.774838381832, \n-253.986362006477, -150.057802766993, -272.189815335836, -19.9291505224668, \n-92.1898153358359, -348.284237867971, -309.875152054433, -129.875152054433, \n-143.852295307064, -308.016055732661, -73.9553205575834, -128.016055732661, \n-338.488065786237, -158.488065786237, -314.660854414991, -85.4342868667177, \n-265.434286866718, -151.29940020492, -238.870558247076, -168.294859003007, \n-49.8539227832667, -348.116672776043, -236.980532552227, -168.116672776043, \n-80.2553593540476, -254.934776650254, -229.853922783267, -3.27228116706596, \n-292.667574857253, -112.667574857253, -147.736633486386, -55.5711775121034, \n-105.748190386858, -54.9542907199938, -310.68649631, -79.8368523997744, \n-144.051084158798, -130.68649631, -297.83306159551, -279.933602625912, \n-76.0734819312863, -256.073481931286, -47.7580180869138, -279.852834107574, \n-99.852834107574, -335.114087327099, -36.2042422155669, -216.204242215567, \n-155.114087327099, -126.45550287378, -313.517519148651, -133.517519148651, \n-357.485308199534, -177.485308199534, -5.50480310785395, -185.504803107854, \n-6.57157688597715, -287.466352686031, -56.6510821757817, -236.651082175782, \n-257.081951452707, -137.698799946735, -146.107635195236, -338.972069286105, \n-11.0143833226114, -342.860297144979, -17.2063395723788, -38.9664669340035, \n-286.454628081951, -2.33743915687762, -197.206339572379, -106.454628081951, \n-218.966466934003, -182.337439156878, -127.403069984869, -81.4373683210264, \n-25.6569369043103, -3.74345131356023, -87.9702697534809,&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-19.0722345681253, -289.026608267759, -32.1611937835791, \n-216.827178834489, -225.374620446502, -212.161193783579, -45.3746204465019, \n-36.8271788344892, -58.223516179125, -90.4522572745457, -238.223516179125, \n-72.856653913689, -273.71381888527, -226.794503549598, -237.213178240362, \n-166.507418214354, -46.7945035495977, -93.7138188852696, -111.626776515177, \n-2.21114773201288, -291.626776515177, -343.184135307563, -291.348112993214, \n-111.348112993214, -244.66518137199, -97.3832453061409, -325.29428196656, \n-90.0472920098521, -145.294281966561, -155.021213388116, -75.5983513021192, \n-111.469820763044, -235.025754485307, -241.208936612483, -242.910585092277, \n-353.792861619085, -55.025754485307, -59.6857092939361, -62.9105850922766, \n-28.9791578458617, -323.512715015919, -143.512715015919, -185.819060624613, \n-237.331163050175, -336.237665203754, -57.331163050175, -189.640854042445, \n-359.153015540742, -4.04407064954381, -223.221555422929, -344.615014094027, \n-164.615014094027, -2.22973876473156, -257.715699925788, -182.229738764732, \n-76.488218331902, -256.488218331902, -168.415923567932, -184.044070649544, \n-272.111068513859, -317.637410782113, -18.9844772361412, -198.984477236141, \n-281.43812908435, -281.309334077882, -174.526345232509, -43.2215554229286, \n-226.933866925367, -354.154140547773, -8.53886678340177, -305.535998228753, \n-170.559295484935, -188.538866783402, -348.864235848612, -302.142544983195, \n-168.864235848612, -147.284353994622, -166.494320272196, -323.051488894166, \n-290.932114960094, -58.5258714123176, -238.525871412318, -65.3398251794126, \n-341.378489027753, -353.558270964277, -284.362123879853, -104.362123879853, \n-1.25237875464683, -181.252378754647, -252.703045930826, -345.363543765783, \n-76.0883009535952, -207.024961743094, -256.088300953595, -257.501399381971, \n-344.32757993514, -336.622127570479, -90.6339530388033, -1.57853732477707, \n-338.660094565645, -181.578537324777, -333.159451375156, -346.744865809227, \n-166.744865809227, -148.204293175918, -74.9490240199468, -165.363543765783, \n-160.035299718595, -98.6361348080032, -341.439960276833, -338.340686599702, \n-161.439960276833, -352.173602448891, -172.173602448891, -245.339825179413, \n-27.024961743094, -332.577650724746, -158.660094565645, -218.048974217276, \n-110.932114960094, -225.762051048517, -292.334109944894, -270.633953038803, \n-113.078152921894, -315.412377426179, -282.761865824056, -102.761865824056, \n-182.765890143275, -15.1482074517208, -135.412377426179, -64.7069756855693, \n-195.148207451721, -158.700230813562, -86.7147537982913, -149.750186944515, \n-43.6231230808638, -66.3063870310367, -261.559354574408, -337.267445450963, \n-246.306387031037, -157.267445450963, -150.166158007963, -300.093331465655, \n-264.033722677516, -246.655898931515, -120.093331465655, -358.422737455732, \n-315.556143316152, -342.764744991875, -29.6895864755422, -36.4881560304218, \n-209.689586475542, -341.925120507847, -266.714753798291, -161.925120507847, \n-330.166158007963, -6.5536191832058, -162.764744991875, -278.32482920266, \n-95.2965924685982, -150.179286552697, -59.3101&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-350.11651230383, -87.7941575981745, -348.569517012102, \n-168.569517012102, -173.9674675514, -37.4789403416743, -49.6200476353754, \n-229.620047635375, -170.11651230383, -267.794157598174, -281.289945034656, \n-101.289945034656, -194.360441253012, -235.654116294963, -228.641370204827, \n-129.719039653279, -14.3604412530119, -312.111697730582, -132.111697730582, \n-43.1882332752699, -223.18823327527, -358.26946868518, -326.534961538993, \n-146.534961538993, -341.512953403402, -161.512953403402, -178.26946868518, \n-237.729409874853, -79.0004514168811, -165.596378482571, -259.000451416881, \n-147.548724020057, -252.29676648554, -181.022710971938, -35.0453275907514, \n-215.045327590751, -76.6337236758052, -225.670967145559, -327.548724020057, \n-72.2967664855403, -226.455986204607, -43.6254968765124, -223.625496876512, \n-22.5150908123213, -107.446136464262, -46.4559862046069, -240.163784817069, \n-266.03234486109, -12.1890624935978, -347.948014744242, -344.540870231621, \n-24.4472394084113, -164.540870231621, -4.34547444531643, -276.579576627341, \n-184.345474445316, -263.451470383465, -97.1992595335554, -91.9721910703423, \n-27.7499703586082, -242.971693014712, -64.8300067519527, -244.830006751953, \n-49.9663351344594, -140.080172315738, -300.484256682244, -144.527916681382, \n-342.279575835122, -307.213976006491, -162.279575835122, -288.090742526264, \n-271.163312602268, -167.948014744242, -168.640565559241, -321.61574717994, \n-229.966335134459, -6.56157796802097, -351.32336291602, -171.32336291602, \n-159.387348416499, -301.652879766748, -207.749970358608, -348.640565559241, \n-214.139396308011, -108.090742526264, -59.3508004478106, -317.448652507497, \n-265.546830748587, -85.5468307485871, -332.931903134743, -152.931903134743, \n-320.87087700895, -267.041238517279, -340.572567473479, -12.6764655982298, \n-227.215468395259, -322.911943380121, -339.485162570833, -192.67646559823, \n-159.485162570833, -343.283470935766, -77.9880388896819, -260.365579767691, \n-156.59563284432, -171.896110461463, -91.877863687455, -149.68260314801, \n-336.59563284432, -239.350800447811, -57.7670494893038, -237.767049489304, \n-160.572567473479, -163.283470935766, -351.896110461463, -328.250114096114, \n-148.250114096114, -68.4047478772992, -74.597418337964, -328.366364364943, \n-148.366364364943, -111.863541075229, -210.551978298933, -141.455692463996, \n-314.453038071713, -118.636314752062, -45.049772387589, -102.81194634816, \n-327.335852963333, -154.613241378022, -18.2017652670402, -175.230939213367, \n-30.1652985457742, -6.60124232020911, -147.335852963333, -355.230939213367, \n-349.468529550949, -208.661328299706, -62.7112525745186, -280.142383254977, \n-24.2324671680763, -37.3441151698909, -133.568585210135, -340.331665021207, \n-74.0724855138362, -349.295276643723, -107.791733098847, -287.791733098847, \n-339.829619453847, -239.526588188875, -11.8991609453852, -340.362191477639, \n-268.401674095239, -159.829619453847, -234.390127502364, -324.20310800042, \n-112.490313695067, -290.630869710557, -96.5801037662826, -239.325690867302, \n-3.5989847693935, -46.9256601952172, -204.232467168076,&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-357.068808740585, -177.068808740585, -337.967116718778, \n-346.232806783086, -263.501880439567, -259.01421548681, -321.908145748608, \n-187.03716422805, -141.908145748608, -203.436324772663, -187.98554609791, \n-41.8822010571368, -221.882201057137, -85.0190437228459, -265.019043722846, \n-141.649276308621, -182.71342133365, -218.659469848835, -276.708059699014, \n-7.03716422804985, -69.1252601405176, -300.558099349712, -45.2221207123512, \n-225.222120712351, -260.886273371619, -115.717218636336, -204.209264034953, \n-38.6594698488347, -295.717218636336, -80.8862733716187, -24.2092640349526, \n-344.748746280308, -8.98034299308904, -328.510782311078, -269.24861012542, \n-89.2486101254199, -272.854309626093, -92.8543096260926, -21.5367331227903, \n-8.12476588915746, -210.655179626068, -188.124765889157, -201.53673312279, \n-13.7550820271672, -295.14225101197, -115.14225101197, -87.708825690266, \n-25.6544885519618, -328.776157797454, -323.392139365687, -315.154030677455, \n-148.776157797454, -329.787781685202, -143.392139365687, -273.944570913455, \n-94.8597454546561, -93.9445709134549, -62.067181491154, -356.414997414726, \n-356.541749504358, -59.3342639404862, -176.414997414726, -176.541749504358, \n-202.840503067635, -77.5621376801925, -257.562137680193, -62.7592163264139, \n-188.331142708914, -346.737624437795, -3.21311672287032, -183.21311672287, \n-343.280868092102, -163.280868092102, -224.043329403492, -58.6438487373914, \n-342.599050867298, -67.1764376595142, -44.5275919803719, -247.176437659514, \n-164.957467840919, -356.348036021488, -316.881877945196, -111.492403398166, \n-176.348036021488, -111.463093008493, -310.012865943167, -28.8757134569444, \n-347.580897141844, -22.8405030676351, -167.580897141844, -8.33114270891377, \n-17.9966612247375, -44.0433294034917, -130.012865943167, -355.614129755364, \n-4.2282129146335, -175.614129755364, -96.3558539120737, -162.375085357504, \n-323.142288523535, -143.142288523535, -135.154030677455, -290.559590103871, \n-327.436066767257, -147.436066767257, -348.60701241524, -176.689162244968, \n-340.413286984334, -62.1267764365396, -355.118323809515, -242.12677643654, \n-150.835726181628, -236.272600182985, -211.158141864945, -13.2008989303128, \n-308.915970069498, -289.632187536632, -278.887096630962, -128.915970069498, \n-307.425430254133, -127.425430254133, -2.31892936272919, -293.295641026572, \n-110.559590103871, -160.413286984334, -98.8870966309619, -311.133266173703, \n-337.093867711656, -113.295641026572, -175.118323809515, -193.200898930313, \n-270.112144711814, -254.551570017635, -184.228212914633, -356.689162244968, \n-344.025076998768, -164.025076998768, -116.516820542819, -157.093867711656, \n-258.023062517049, -131.133266173703, -296.516820542819, -194.632158331805, \n-353.647234845187, -5.94435093364956, -173.647234845187, -354.47057944274, \n-299.93105205524, -174.47057944274, -338.515646523367, -158.515646523367, \n-222.552685184285, -134.689325320837, -44.1027095779897, -349.898106854639, \n-59.4391589754227, -352.607970321607, -119.93105205524, -42.5526851842851, \n-94.2568492391647, -274.256849239165, -20.597172524&gt;\n\n\nCode\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\np &lt;- plotMetricPerFov(res, correction = \"bordm\", theo = TRUE, x = \"phi\", image_id = 'sample_id')\np\n\n\n\n\n\nThe values of \\(\\phi\\) correspond to the orientation of the original point pattern. The horizontal axis goes from \\(180\\) to \\(0\\) (left to right) and the vertical from \\(90\\) to \\(270\\) (top to bottom)\nan easier representation of the above metric can be plotted as a rose diagram\n\n\nCode\npar(1,3)\n\n\n[[1]]\nNULL\n\n[[2]]\nNULL\n\n\nCode\nlapply(pp, function(x){rose(nnorient(x))})\n\n\n\n\n\n\n\n\n\n\n\n$`-0.09`\nwindow: rectangle = [-0.004850711, 0.004850711] x [-0.004850711, 0.004850711] \nunits\n\n$`0.01`\nwindow: rectangle = [-0.005200848, 0.005200848] x [-0.005200848, 0.005200848] \nunits\n\n$`0.21`\nwindow: rectangle = [-0.004397865, 0.004397865] x [-0.004397865, 0.004397865] \nunits\n\n\nCode\ndev.off()\n\n\nnull device \n          1 \n\n\nThe two plots are complementary and show which are the preferred orientations of the point patterns. Furthermore, they show whether or not the assumption of isotropy (no change in the statistical properties of a point pattern after rotations) is justified or not (Baddeley, Rubak, and Turner 2015, 236 ff.). Isotropy is an assumption that a lot of spatial metrics make and in our example we note, that the point patterns are in fact anisotropic. An option for analysing anisotropic stationary point patterns is to not calculate the metric on the actual point pattern but rather calculating it on the fry plot of the point pattern. This generalises e.g. Ripley’s \\(K\\) function from circles to arbitrary shapes (Baddeley, Rubak, and Turner 2015, 239 ff.).\nNote also that the concepts of spacing are not only usable in point pattern analysis but also more broadly in other spatial contexts (e.g., spacing between shapes instead of points) (Baddeley, Rubak, and Turner 2015, 279 ff.).\n\n\n\nThe same consideration about edge effects as for the \\(K\\) (and related) functions need to be made for the spacing functions; uncorrected estimates are negatively biased estimators. The easiest approach is to draw an artificial border and consider NNs within it. Other approaches are based on sampling. Yet another approach relates to survival analysis, with the idea is that a circle of a point to grows homogeneously with increasing radius until it hits the frame of the window and “dies”. This gives survival distributions similar to censored data, where the Kaplan-Meier estimator is the optimal choice (Baddeley, Rubak, and Turner 2015, 285–92)."
  },
  {
    "objectID": "01-cell-univar-point.html#dependencies",
    "href": "01-cell-univar-point.html#dependencies",
    "title": "Discrete Marks",
    "section": "",
    "text": "Code\nsource(\"utils.R\")"
  },
  {
    "objectID": "01-cell-univar-point.html#setup",
    "href": "01-cell-univar-point.html#setup",
    "title": "Discrete Marks",
    "section": "",
    "text": "Code\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n\n#define the celltype that you want to compare across the stacks - hereby we assume independence across the z-stacks which is an assumption that can be challenged\ncelltype_ls &lt;- \"OD Mature\"\n\nselectZstacks &lt;- function(zstack, spe){\n  sub &lt;- spe[, spe$sample_id == zstack]\n  pp &lt;- .ppp(sub, marks = \"cluster_id\")\n  return(pp)\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe)\nnames(pp_ls) &lt;- zstack_list\n\n\nThe theory of spatial point patterns is discussed in great detail in (Baddeley, Rubak, and Turner 2015). The book has an accompanying package called spatstat which offers great functionality to the theoretical concepts described in the book (Baddeley and Turner 2005). This chapter relies heavily on both publications."
  },
  {
    "objectID": "01-cell-univar-point.html#concepts-and-definitions-of-point-processes",
    "href": "01-cell-univar-point.html#concepts-and-definitions-of-point-processes",
    "title": "Discrete Marks",
    "section": "",
    "text": "In point pattern analysis we assume that the patterns we observe are a realisation of a stochastic process called a point process. The inferences we make about the point pattern are based on the point process. For example, if a pattern is created by a Poisson point process it will be evenly distributed in the observation window (Baddeley, Rubak, and Turner 2015, 127).\nWhen considering a pattern with \\(m\\) multiple types, as we do in the (Moffitt et al. 2018) dataset, there are two very closely related concepts. One can view the pattern as a multitype point pattern, where all the points are sampled from the same point process. The other option is to consider the pattern as a multivariate point pattern, where the points come from \\(m\\) distinct point processes. The difference between these two views is that in the multitype framework we assume the points to stem from the same point process. In the multivariate framework we assume that the types stem from distinct point processes and therefore we can consider dependencies of one type alone. Whether or not the patterns stem from the same point process depends on the biological question. If we analyse two cell types in one slice of a tissue, we should consider them as being sampled from one point process. However, if we consider the distribution of a cell type in two slices of the same tissue we can have grounds to consider them as distinct processes (Baddeley, Rubak, and Turner 2015, 564–65).\n\n\n\nThe most common set up in point pattern analysis is what we call window sampling. Instead of observing the entire pattern we observe a subset of this pattern in the so called window. An example could be different small microscopy windows through which a big tissue slice is observed. In this case, it would be wrong to assume the window to be the convex hull around the observed points because they are just a sample of the bigger point pattern (Baddeley, Rubak, and Turner 2015, 143–45).\nThere is another concept called the small world model. It assumes that points can only be observed in a finite small world and not beyond these boundaries. When thinking of an entire tissue, this is a very common scenario. Cells can only be observed within the tissue and not beyond. In this case, it would be correct to not assume a rectangular observation window but to use methods to estimate an unknown sampling window such as the Ripley-Rasson estimate of a spatial region (Baddeley, Rubak, and Turner 2015, 144–45; Ripley and Rasson 1977).\n\n\nCode\nsetRiprasWindows &lt;- function(pp){\n  Window(pp) &lt;- ripras(pp)\n  return(pp)\n}\n#the entire point patterns with the ripras windows\npp &lt;- lapply(pp_ls, setRiprasWindows)\n\nseparateMarks &lt;- function(pp){\n  #split the multitype point process into several single type processes\n  ppls &lt;- split(pp)\n  return (ppls)\n}\n#the point patterns separated by their marks\npp_ls &lt;- lapply(pp, separateMarks)\n\n\n\n\n\nComplete spatial randomness (CSR) is often used as the null model for various point patterns. It is the result of a Poisson process. A completely spatial random process is characterised by two properties, homogeneity and independence, as discussed below (Baddeley, Rubak, and Turner 2015, 132).\n\n\n“Homogeneity […] means that the expected number of points falling in a region B should be proportional to its area |B|” (Baddeley, Rubak, and Turner 2015, 132) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) represents the intensity of the process, i.e., the average number of points in a unit area (Baddeley, Rubak, and Turner 2015, 132–33). :\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|.\n\\label{eq:expected_number_points}\n\\]\n\n\n\nIndependence implies that in two (non-overlapping) regions \\(A\\) and \\(B\\), the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are independent random variables. In other words, the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). (Baddeley, Rubak, and Turner 2015, 133).\n\n\n\n\nA Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density, \\(\\lambda(u)\\), sometimes known as the intensity function (see below), is a function of the spatial location \\(u\\). In this case, the expected number of points falling into a region \\(B\\), \\(\\mu = n(X\\cap B)\\), is an integration of the intensity function over that region (Baddeley, Rubak, and Turner 2015, 138).\n\\[\n\\mu = \\int_{B} \\lambda(u) du.\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\n\nA point process is called isotropic, if its statistical properties are invariant to rotations; a CSR process is both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 147).\n\n\n\n“A point process is called stationary if, when we view the process through a window W , its statistical properties do not depend on the location of the window in two-dimensional space.” (Baddeley, Rubak, and Turner 2015, 146). This is the case for any homogeneous point process, where the statistical properties of the pattern are unchanged given shifting of the observation window. This means it is stationary in all statistical properties; first-order properties (e.g. intensity) and second-order properties (e.g. correlation) (Baddeley, Rubak, and Turner 2015, 218). Not all metrics assume stationarity in its full sense. Inhomogeneous metrics only assume second-order / correlation stationarity. That means while the intensity function can vary spatially (first-order stationarity is not given), the estimates of correlation functions (e.g. the inhomogeneous K-function) should be the same in parts of the window (Baddeley, Rubak, and Turner 2015, 689 ff.).\n\n\n\nIf a process is not correlation stationary, so the estimates of the inhomogeneous metric vary between locations, locally-scaled versions of the metric can be applicable. This means in subregions, the process is still stationary and isotropic, but there is a rescaling factor that can vary across the total process (Baddeley, Rubak, and Turner 2015, 246–47).\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimated functions between the quadrats. It should be noted that this test depends on the arbitrary definition of the quadrats. Given our chosen patterns are not independent but result as marks from an overall point-pattern, the permutation approach is questionable (Baddeley, Rubak, and Turner 2015, 689–93).\n\n\nCode\npermutation_test &lt;- function(pp, mark, split, minpoints) {\n  pp_sel &lt;-  subset(pp, marks %in% mark, drop = TRUE)\n  \n  rho_est &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\n  lambda &lt;- predict(rho_est)\n\n  tesselation &lt;- quantess(unmark(pp_sel), \"x\", 3)\n  tesselation_split &lt;- nestsplit(pp_sel, tesselation, ny=split)\n  \n  plot(tesselation_split, main = mark)\n  \n  tesselation_split$inten &lt;- factor(as.integer(tesselation_split$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n  \n  res.scaled &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kscaled,\n                 minpoints = minpoints)\n  \n  res.inhom &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kinhom,\n                 lambda=lambda, minpoints = minpoints)\n  \n  #p-value of the local-scaling test\n  print(paste0(mark,' local scaling test ', res.scaled$p.value))\n  \n  #p-value of the inhomogeneity test\n  print(paste0(mark,' inhomogeneity test ', res.inhom$p.value))\n}\nlapply(c(\"Microglia\", \"OD Mature\", \"Ependymal\"), function(x) permutation_test(pp[['0.01']], x, split = 3, minpoints = 10))\n\n\nThe p-value of the test for local scaling for microglia cells is \\(&lt;0.05\\) which indicates that the assumption of local scaling is rejected. Therefore, the distribution of microglia cells is not a scaled version of an overall distribution pattern. The p-value of the test for inhomogeneity for both microglia cells is \\(&gt;0.05\\) indicating that the assumption of correlation stationarity is not rejected. In this case we can use the inhomogeneous version of the K-function which assumes correlation stationarity.\nFor ependymal and OD mature cells however, the p-values for both the local scaling test and the inhomogeneity test are \\(&gt;0.05\\) which means that for this choice of quadrats both the correlation stationarity assumption and the local scaling assumption can’t be rejected.\nAs the interpretation of the permutation test is highly dependent on the quadrats, the results should be interpreted with care. Both inhomogeneous and locally scaled versions of the summary functions have support and both offer interesting insights into the spatial pattern. Therefore, we will compare all versions and show what the choice of metrics means for their interpretation.\n\n\n\nIntensity is the expected density of points per unit area. It can be interpreted as the rate of occurrence or the abundance of events. The intensity represents a first order property because it is related to the expected number of points. More formally the average intensity of a point process is defined as:\n\\[\n\\bar{\\lambda} = \\frac{n(x)}{|W|}\n\\label{eq:average_intensity}\n\\]\nAs this is an average over the entire window, it is a good estimate for a homogeneous point process (Baddeley, Rubak, and Turner 2015, 157–60)\n\n\nFor a homogeneous point process, the intensity can be estimated in a simplistic way: summing the individual intensities of the marks (Baddeley, Rubak, and Turner 2015, 161).\n\n\nCode\nintensityPointProcess &lt;- function(pp,mark) if(mark) intensity(pp) else sum(intensity(pp))\n\nintensityPointProcess(pp_ls[['0.01']], mark = FALSE) %&gt;% round(6)\n\n\n[1] 0.001909\n\n\nOtherwise, we can compute the intensity for each mark individually.\n\n\nCode\nintensityPointProcess(pp_ls[['0.01']], mark = TRUE) %&gt;% round(8)\n\n\n  Ambiguous   Astrocyte Endothelial   Ependymal  Excitatory  Inhibitory \n 0.00024151  0.00020183  0.00014653  0.00008373  0.00036867  0.00061393 \n  Microglia OD Immature   OD Mature   Pericytes \n 0.00003031  0.00006249  0.00014278  0.00001750 \n\n\n\n\n\nIn kernel estimation, we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There is a wide variety of kernel estimators (see (Baddeley, Rubak, and Turner 2015, 168)), but a popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth (Baddeley, Rubak, and Turner 2015, 168).\n\n\nCode\npp_sel &lt;-  subset(pp_ls[['0.01']]$`OD Mature`, drop = TRUE)\nDens &lt;- density(pp_sel, sigma = 100)\nplot(Dens, main = 'Kernel Density (OD Mature cells)')\n\n\n\n\n\n\n\n\nIn quadrat counting, all points falling into a given quadrat are counted. This gives an overview on the characteristics of the point pattern, such as correlation stationarity (Baddeley, Rubak, and Turner 2015, 163).\n\n\nCode\nQ5 &lt;- quadratcount(pp_ls[['0.01']], nx=8, ny=8)\nplot(unmark(pp[['0.01']]), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\nUnder independence assumptions, the quadrat counts can be used for testing homogeneity, i.e., whether the points are distributed evenly across the quadrats (Baddeley, Rubak, and Turner 2015, 164–65).\n\n\nCode\nval &lt;- quadrat.test(pp_ls[['0.01']]$`OD Mature`, 5, alternative=\"regular\", method=\"MonteCarlo\")\nval\n\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nX2 = 635.09, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 25 tiles (irregular windows)\n\n\nA p-value of 1 indicates that the null hypothesis of irregularity can not be rejected strongly. Thus, the point pattern of oligodendrocyts is strongly irregular.\nAlternatively, we can inspect departures from the hypothesis that points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types (Buller 2020).\n\n\nCode\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp[['0.01']], marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\n\nWhether or not a point process is completely spatially random (CSR) depends on two characteristics: points need to be distributed homogeneously and they have to be independent of each other (see definitions above). There are various ways to test for CSR, here we show the use-case of the clark-evans test (Baddeley, Rubak, and Turner 2015, 165–66).\n\n\nCode\nclarkevans.test(pp_ls[['0.01']]$`OD Mature`)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nR = 0.77286, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "01-cell-univar-point.html#univariate-viewpoint",
    "href": "01-cell-univar-point.html#univariate-viewpoint",
    "title": "Discrete Marks",
    "section": "",
    "text": "In the following document we will often compare the distribution of mature oligodendrocytes (OD mature cells) across different z-slices of the same tissue. We assume these slices to be enough apart to be considered as generated by different point processes. Since we consider the dependence of one mark among itself, we are in a within cell type setting per slide. We compare several curves along different z-slices, which is in turn a multivariate comparison (Baddeley, Rubak, and Turner 2015, 564 ff.).\nIn our example dataset we analyse the mouse preoptic hypothalamus (Moffitt et al. 2018). The lower boundary is the end of the tissue whereas the upper three boundaries are a technical boundary. Therefore, our example is a mixture between window sampling and the small world model. In order to decrease the bias of the tissue border, we use the Ripley-Rasson estimate of a spatial domain to estimate the sampling window (Baddeley, Rubak, and Turner 2015, 55; Ripley and Rasson 1977).\n\n\nCode\nlibrary('spatialFDA')\npar(mfrow=c(1,3))\n#Plot the marks separately \nlapply(zstack_list, function(zstack){\n  plot(pp_ls[[zstack]][[celltype_ls]], main = zstack, legend = FALSE)\n})\n\n\n\n\n\n[[1]]\nSymbol map with constant values\ncols: #000000E4\n\n[[2]]\nSymbol map with constant values\ncols: #000000C2\n\n[[3]]\nSymbol map with constant values\ncols: #0000007B\n\n\nCode\ndev.off()\n\n\nnull device \n          1 \n\n\nCode\npls &lt;- lapply(zstack_list, function(zstack){\n  pp_sel &lt;- pp_ls[[zstack]][[celltype_ls]]\n  p &lt;- pp_sel |&gt; as.data.frame() |&gt; \n  ggplot(aes(x = x, y = y, alpha = 0.3)) +\n  geom_point(size=0.75) +\n  theme_minimal() +\n  coord_fixed() +\n  ggtitle(zstack)\n  return(p)\n})\nwrap_plots(pls, guides = 'collect')"
  },
  {
    "objectID": "01-cell-univar-point.html#correlation",
    "href": "01-cell-univar-point.html#correlation",
    "title": "Discrete Marks",
    "section": "",
    "text": "Correlation, or more generally covariance, represents a second-order summary statistic and measures dependence between data points (Baddeley, Rubak, and Turner 2015, 199 ff.).\n\n\n\n\nWith Ripley’s \\(K\\) we measure “the average number of \\(r\\)-neighbours of a typical random point” (Baddeley, Rubak, and Turner 2015, 204). This number is still dependent on the size of the observation window so we can normalise it by the number of points \\(n\\) and the window size, \\(|W|\\). We then obtain the empirical Ripley’s \\(K\\) function (Baddeley, Rubak, and Turner 2015, 204; Ripley 1977, 1976):\n\\[\n\\hat{K}(r) = \\frac{|W|}{n(n-1)}\\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n\\{d_{ij}\\leq r\\} e_{ij}(r)\n\\]\nThe standardisation makes it possible to compare point patterns with different observation windows and with different numbers of points. However, using the empirical \\(K\\) function assumes that the point process has homogeneous intensity, which is often not the case for biological tissue (Baddeley, Rubak, and Turner 2015, 204–5). We will return to this issue below in the Correcting for Inhomogeneity. The term \\(e_{ij}(r)\\) is an edge correction. We will briefly cover this in Edge effects and their corrections for spatial metrics\n\n\n\nEdge effects describe the phenomenon that not the entire point process is observed, but rather only the part within the window \\(W\\). This means the value of various statistics could be biased along the edges (Baddeley, Rubak, and Turner 2015, 213 ff.).\nThere are many corrections for edge effects that are briefly listed here (Baddeley, Rubak, and Turner 2015, 214–19):\nBorder correction:\nIn border correction the summation of data points is restricted to \\(x_i\\) for which \\(b(x_i,r)\\) is completely in the window \\(W\\).\nIsotropic correction:\nWe can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.\nTranslation correction:\nA stationary point process \\(X\\) is invariant to translations. So the entire point process can be shifted by a vector \\(s\\) to be at the position \\(X+s\\).\n\n\n\n\nThe \\(K\\)-function can be ``centered’’, which is then referred to as Besag’s \\(L\\)-function. The \\(L\\)-function is a variance-stabilising version of the \\(K\\)-function (Canete et al. 2022; Besag 1977, 1977):\n\\[\nL(r) = \\sqrt{\\frac{K(r)}{\\pi}}.\n\\]\nBy taking the square root the variance is approximately constant across the domain (Bartlett 1947).\n\n\n\nWe have seen above that the \\(K\\)-function is cumulative. That is, the contributions of all distances smaller equal to \\(r\\) are considered. An alternative is to take the derivative of the \\(K\\)-function in order to obtain contributions of distances between points equal to \\(r\\), according to:\n\\[\ng(r) = \\frac{K'(r)}{2\\pi r},\n\\]\nwhere the derivative of the \\(K\\) function divided by the probability of a Poisson process at this radius (Baddeley, Rubak, and Turner 2015, 225 ff.).\n\n\nCode\nres_ls &lt;- lapply(list('Kest', 'Lest', 'pcf'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')})\n\n\n\n\n\n\nCode\np_homo &lt;- wrap_plots(p_ls, guides = 'collect')\np_homo\n\n\n\n\n\nIn the homogeneous case we see that all slices are above the Poisson line, indicating positive association for all slices. The association is strongest for slice $-0.09$ followed by $0.01$ and $0.21$. Interestingly, at radii \\(r&gt;300\\) the \\(K\\) curve for slice \\(0.21\\) crosses the other two curves.\n\n\n\n\n\nIn the case that a spatial pattern is known or suspected to be inhomogeneous, we have to take this into account in the analysis. Inhomogeneous alternatives can be estimated via:\n\\[\n\\hat{K}_{inhom}(r) = \\frac{1}{D^p|W|}\\sum_i\\sum_{j \\neq i} \\frac{\\mathbb{1}\\{||u-x_j||\\leq r\\}}{\\hat{\\lambda}(x_j)\\hat{\\lambda}(x_i)}e(x_j,x_i;r),\n\\]\nwhere \\(e(u,v;r)\\) is an edge correction weight and \\(\\hat{\\lambda}(x_i)\\) is an estimator of the intensity at point \\(x_i\\). The estimation of the local intensities can happen in a data-dependent manner via kernel-smoothing. As this is the same data to then calculate the metric on, this can lead to biases. However, if the local intensities are known, the inhomogeneous \\(K\\) function is an unbiased estimator (Baddeley, Rubak, and Turner 2015, 242–46).\n\n\nCode\nres_ls &lt;- lapply(list('Kinhom', 'Linhom'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\nres_pcf &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = 'pcfinhom', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id')) \nres_pcf &lt;- subset(res_pcf, sample_id %in% c('-0.09', '0.01', '0.21'))\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"border\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\np &lt;- plotMetricPerFov(res_pcf, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'sample_id')\n\n\n\n\nCode\np_inhomo &lt;- wrap_plots(p_ls, guides = 'collect')\np_inhomo &lt;- wrap_plots(p_inhomo, p, guides = 'collect', widths=c(2,1))\np_inhomo\n\n\n\n\n\nThe inhomogeneous \\(K\\)-function indicates that the oligodendrocytes of slice 0.21 are close to a Poisson process (dashed line) and can therefore be assumed to be randomly distributed and not clustered. The two other slices show a slightly stronger association among the oligodendrocytes than the slice 0.21.\nThe \\(L\\) function is complementary to the \\(K\\) function in this example.\nThe pair correlation function is the derivative of the \\(K\\)-function. The pcf plot gives similar information as before: Oligodendrocytes show the strongest association at \\(\\sim r = 25\\) whereas the association is weaker in slice 0.21.\nInterestingly, the curves for the inhomogeneous functions of slices -0.09 and 0.01 cross the Poisson line at \\(r\\sim350\\). This means that the inhomogeneous functions find repulsion of slices past a radius of \\(350\\).\n\n\n\n\n\n\nIn the inhomogeneous \\(K\\)-function approach above, we assume that the intensities can vary locally but the scale of the point process is not changed. This means that while the intensities might vary in the parts of the point pattern, the pattern in one subquadrat is not just a scaled version of another subquadrat (Baddeley, Rubak, and Turner 2015, 246–47; Prokešová, Hahn, and Jensen 2006).\nTo account for this local scaling, we can assume that the process is subdivided into small regions. In these small regions, the point process is a scaled version of a template process. This template process needs to be both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 246–47).\n\n\n\nSince the \\(L\\)-function is simply a transformation of the \\(K\\)-function, the same local scaling framework can be applied to the \\(L\\)-function (Baddeley, Rubak, and Turner 2015, 246–47).\n\n\nCode\nres_ls &lt;- lapply(list('Kscaled', 'Lscaled'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\n\n\n\n\nCode\np_scaled &lt;- wrap_plots(p_ls, guides = 'collect')\np_scaled\n\n\n\n\n\nWe see, that in slice 0.01 oligodendrocytes are far from the Poisson process line, indicating a strong association. The other two slices show a less strong association.\n\n\nCode\np &lt;- wrap_plots(list(p_homo, p_inhomo, p_scaled), nrow = 3, guides = 'collect') + plot_annotation(tag_levels = 'A')\np\n\n\n\n\n\nCode\nggsave('pp_function_comparison.pdf', plot = p, width = 8, height = 9)\n\n\nIn the plot above we see all variants of the correlation metrics. The assumptions of either homogeneity (first row), inhomogeneity (second row) and local scaling (third row) change the interpretation of these example point patterns. In summary, in this example homogeneous variants show a positive association for all slices whereas inhomogeneity infered a Poisson distribution for slice \\(0.21\\). Furthermore, the inhomogeneous variant estimated repulsion for slices \\(-0.09\\) and \\(0.01\\), whereas homogeneous variants estimated clustering for all radii, whereas slice \\(0.21\\) became stronger than the other two slices past \\(r&gt;350\\). The locally scaled version showed positive associations for all slices and no crossing of curves over the radii.\nDeciding whether a pattern is homogeneous or inhomogeneous depends on the biological question. We provide some recommendations in the “Getting started” vignettes.\n\n\n\nIt is worth noting that the \\(K\\)- and \\(L\\)-functions described above are summary statistics over the entire pattern (i.e., averaged over all points). However, if we know that there are different regions in our point pattern, an alternative strategy is to compute `local` contributions to these patterns, i.e., local \\(K\\)- ,\\(L\\)- or pair-correlation functions. Baddeley et. al. propose to compare these \\(n\\) functions with so-called functional principal component analysis (see below). We will show here the example of the LISA version of the \\(L\\)-function (Baddeley, Rubak, and Turner 2015, 247–48).\n\n\n\n\nCode\nL_odmature_lisa &lt;- localL(pp_ls[['0.01']]$`OD Mature`)      \n\ndf &lt;- as.data.frame(L_odmature_lisa)\ndfm &lt;- reshape2::melt(df, \"r\")\n\nget_sel &lt;- dfm %&gt;% filter(r &gt; 200.5630 & r &lt; 201.4388, variable != \"theo\") %&gt;%\n  mutate(sel = value) %&gt;% select(variable, sel)\n\ndfm &lt;- dfm %&gt;% left_join(get_sel)\n\np &lt;- ggplot(dfm, aes(x=r, y=value, group=variable, colour=sel)) +\n  geom_line() + \n  scale_color_continuous(type = \"viridis\") +\n  geom_vline(xintercept = 200) +\n  theme(legend.position = \"none\") +\n  theme_light() +\n  ggtitle(\"LISA curves of slice 0.01\")\n\nppdf &lt;- as.data.frame(pp[['0.01']]) %&gt;% filter(marks==\"OD Mature\")\nppdf$sel &lt;- get_sel$sel # assume they are in same order\n\nq &lt;- ggplot(ppdf, aes(x=x, y=y, colour=sel)) + \n  geom_point(size=0.75) +\n  scale_color_continuous(type = \"viridis\") +\n  theme(legend.position = \"none\") +\n  theme_light()+\n  ggtitle(\"Points coloured by LISA value at r ~ 200\")\n\n\n\n\nCode\np|q\n\n\n\n\n\nIn the case of the OD mature cells, we obtain further information with this plot. We note that there are two distinct populations of curves: those that are clearly above the mean LISA curve in black and others that are around/underneath. This indicates that there are two different kinds of interactions in the OD mature cells. Stronger and less clustered regions.\nThere are inhomogeneous versions of these (e.g. localLinhom) that are not shown here for brevity.\n\n\n\nWe apply functional PCA to retrieve the main trends in these individual curves. The idea of functional PCA is the same as for ordinary PCA but applied to functional data (i.e., each observation is a function). For the \\(n\\) functions above, functional PCA will recover the main trends in the data (Ramsay and Silverman 2005). We use the R package refund to perform functional PCA (Xiao et al. 2016).\n\n\nCode\n#normalise the data\ndf_fdob &lt;- asinh(df %&gt;% as.matrix / 50) %&gt;% as.data.frame()\n# extract the functional response matrix\nmat &lt;- df_fdob %&gt;%\n   select(!c(r,theo)) %&gt;%\n  t()\n# create a dataframe as required by pffr\ndat &lt;- data.frame(ID = rownames(mat))\ndat$Y &lt;- mat \ndat$sel &lt;- get_sel$sel\n\n# perform functional PCA\nres &lt;- functionalPCA(dat = dat, r = df_fdob$r |&gt; unique(), knots = 30, pve = 0.99)\n# extract the scores\nscores_df &lt;- res$scores %&gt;% as.data.frame()\n# plot a biplot\np_biplot &lt;- ggplot(scores_df, aes(scores_df[, 1], scores_df[, 2], colour = (dat[['sel']]))) +\n        geom_point() +\n        coord_equal() +\n        theme_light() +\n        scale_color_continuous(type = \"viridis\") +\n        xlab('PC1') +\n        ylab('PC2')\n\n\n\n\nCode\np_biplot\n\n\n\n\n\n\n\nCode\np1 &lt;- ggplot(ppdf, aes(x=x, y=y, colour = res$scores[,1])) + \n  scale_color_continuous(type = \"viridis\", name = 'loading PC1') +\n  theme_light() +\n  geom_point(size=0.75)\n\np2 &lt;- ggplot(ppdf, aes(x=x, y=y, colour = res$scores[,2])) + \n  scale_color_continuous(type = \"viridis\", name = 'loading PC2') +\n  theme_light() +\n  geom_point(size=0.75)\n\n\n\n\nCode\np1|p2\n\n\n\n\n\nThe biplot shows the distribution of the first two loadings of the functional PCA. The points are coloured as they were in the plots of the LISA \\(L\\)-curves. The first principal component clearly separates the two populations. In the last plot we project the loadings of the fPCs back onto the biological slices and find the same separation.\n\n\n\n\n\nSo far we have considered first- and second-order summary statistics and local (or inhomogeneous) adaptations of them. In the second order, one considers (counts of) pairs (e.g., \\(K\\) function). In a third-order setting, we would count triplets of points. A triplet is counted as the normalised expected value of triangles where all edges are smaller than the radius \\(r\\) (Baddeley, Rubak, and Turner 2015, 249)."
  },
  {
    "objectID": "01-cell-univar-point.html#spacing",
    "href": "01-cell-univar-point.html#spacing",
    "title": "Discrete Marks",
    "section": "",
    "text": "So far, most approaches considered intensity and correlation as measures to assess a point pattern. Next, we will look at measures of spacing and shortest-distances to assess spatial arrangements (Baddeley, Rubak, and Turner 2015, 255).\nBaddeley et al. summarises three basic distances:\n\npairwise distance: \\(d_{i,j} = ||x_i-x_j||\\)\nNN distances: \\(d_i = \\min_{j \\neq i}d_{ij}\\)\nempty-space distance: \\(d(u) = \\min_j||u-x_j||\\)\n\nNote also that there are tests of CSR that are based on spacing, including the Clark-Evans and Hopkins-Skellam Index tests that were discussed above ``Testing for CSR’’.\n\n\nNearest neighbour (NN) methods are based on the notion of “nearness”. In particular, we introduce nndist from spatstat, a method to calculate the distances until \\(k\\) NN are found. This function returns a density for each specified \\(k\\) for the \\(k\\) neighbour distances. We can for instance collapse the \\(k\\) curves into a mean curve per point pattern. This information of the mean nearest neighbour distance (MMND) can be summarised as a density. Note, that these distances are “raw” nearest-neighbour distances which are not corrected for edge effects. Edge correction for the nearest neighbour distance (\\(k = 1\\)) is implemented in the function Gest below (Baddeley, Rubak, and Turner 2015, 256) (Baddeley and Turner 2005).\n\n\nCode\nnndistance &lt;- function(pp, nk){\n  xy &lt;- cbind(pp$x, pp$y)\n  nndistances_k15 &lt;- nndist(xy, k = nk) \n  nndistances_mean &lt;- rowMeans(nndistances_k15)\n  return(nndistances_mean)\n}\n\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricRes_nndist &lt;- function(ppls, celltype, fun){\n  metric.res &lt;- list(res = do.call(fun, args = list(pp=ppls[[celltype]], nk = seq(1:15))))\n  metric.res$type = celltype\n  return(metric.res)\n}\n# [MR: again, this function looks again like those before and maybe could be done as an all-in-one wrapper.]\ncelltypes &lt;- c(\"Ependymal\", \"OD Mature\", \"Microglia\")\n#go through all defined celltypes and calculate the nearest-neighbour distance\nres_ls &lt;- lapply(celltypes, metricRes_nndist, fun = nndistance, ppls = pp_ls[['0.01']])\n#initialise a dataframe for the metric values and the type information\nres_df &lt;- data.frame(metric = numeric(0), type = character(0))\n# Loop through the res_ls list and combine the metric values with their corresponding type - ChatGPT\nfor (i in 1:length(res_ls)) {\n  metric_values &lt;- res_ls[[i]]$res\n  metric_type &lt;- rep(res_ls[[i]]$type, length(metric_values))\n  df &lt;- data.frame(metric = metric_values, type = metric_type)\n  res_df &lt;- rbind(res_df, df)\n}\n#plot the densities\np &lt;- ggplot(res_df, aes(x=metric, col= type))+\n    geom_density(linewidth=1)+\n    scale_x_sqrt() +\n    theme_light() +\n    ggtitle('Sqrt of the Mean Nearest-Neighbour Distance')\np\n\n\n\n\n\nIn the MNND empirical distribution, the ependymal cells show the shortest NN distances, a reflection of their clustering. The OD mature cells have larger NN distances as well as a bimodal distribution, indicating a mix of shorter and longer distances (as visible in the LISA \\(L\\)-functions). Microglia cells show the widest distances and the symmetry of the curve indicates similar distances throughout the field of view.\n\n\n\n\n\nIn a stationary spatial point process, the empty-space distance is defined as:\n\\[\nd(u,X) = \\min\\{||u-x_i||: x_i \\in X\\}\n\\]\nNote that this is an edge-corrected distribution function of the nearest-neighbour distance above.\nThe empty space function is then the cumulative distribution function of the empty-space distances defined above:\n\\[\nF(r) = \\mathbb{P}\\{d(u,X)\\leq r\\}.\n\\]\nThe NN distance is defined as:\n\\[\nd_i = \\min_{j\\neq i}||x_j-x_i||.\n\\]\nThe NN distance distribution function \\(G(r)\\) is then defined as:\n\\[\nG(r) = \\mathbb{P}\\{d(x,X\\backslash u \\leq r |X\\ has\\ a\\ point\\ at\\ u\\}.\n\\]\nFor a homogeneous Poisson process, the NN distance distribution is identical to the empty-space function of the same process:\n\\[\nG_{pois} \\equiv F_{pois}.\n\\]\nFor a general point process, the \\(F\\) and \\(G\\) functions are different (Baddeley, Rubak, and Turner 2015, 261–67).\n\n\n\n\nThe \\(F\\) and \\(G\\) functions are, like the \\(K\\) function, cumulative. The same disadvantages as with the \\(K\\) function occur here too, namely their cumulative nature. Therefore, an analogue to the pair-correlation function would make sense to consider. For practical reasons, this is no longer the derivative of the \\(F\\) function but rather a hazard rate:\n\\[\nh(r) = \\frac{f(r)}{1-F(r)}.\n\\]\n(Baddeley, Rubak, and Turner 2015, 271–74).\n\n\n\nThe concepts of the empty-space function \\(F\\) and the NN function \\(G\\) are complementary. If one decreases, the other increases.\nThus, the \\(J\\) function is a combination of both functions:\n\\[\nJ(r) = \\frac{1-G(r)}{1-F(r)}.\n\\]\nFor a CSR process, \\(J_{pois} \\equiv 1\\), whereas values of \\(J(r) &gt; 1\\) are consistent with a regular (e.g., repelling) pattern, and $J(r) &lt; 1 represents a clustered process (Baddeley, Rubak, and Turner 2015, 275–77).\n\n\nCode\nres_ls &lt;- lapply(list('Gest', 'Fest', 'Jest'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"rs\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\n\n\n\n\nCode\nwrap_plots(p_ls, guides = 'collect')\n\n\n\n\n\n\n\n\nThere are inhomogeneous variants of the spacing functions explained above (Baddeley, Rubak, and Turner 2015, 277–78)\n\n\nCode\nres_ls &lt;- lapply(list('Ginhom', 'Finhom', 'Jinhom'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"bord\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\n\n\n\n\nCode\nwrap_plots(p_ls, guides = 'collect')\n\n\n\n\n\nThe inhomogeneous curves look different to their homogeneous counterparts but the relative ordering is of the curves per plot is the same.\n\n\n\nNext to the NN distance, we can estimate the orientation of the neighbours, which gives an indication of the orientation of the spacing. It works by taking the angle between each point and its \\(k^{th}\\) nearest neighbour. The angle is anticlockwise from the x-axis (Baddeley, Rubak, and Turner 2015, 278–79) (Baddeley and Turner 2005).\n\n\nCode\nres &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = 'nnorient', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n\n\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-352.270177372156, -78.8407753876126, -111.046745026638, \n-258.840775387612, -163.103596647317, -1.12337497669819, -181.123374976698, \n-77.2123525877966, -266.69655510861, -156.591799675296, -226.263809918599, \n-86.6965551086096, -58.578151960682, -325.608317167433, -45.6149560153542, \n-225.614956015354, -105.189192778811, -348.269448227482, -168.269448227482, \n-63.0089629188483, -243.008962918848, -13.2439006043352, -193.243900604335, \n-295.969055063992, -115.969055063992, -298.481458827673, -211.844140222042, \n-31.844140222042, -348.307933087447, -134.221070388405, -63.4124830246728, \n-302.466416297019, -314.221070388405, -243.412483024673, -188.449991857503, \n-296.59498464773, -104.078505032114, -100.545591125103, -280.545591125103, \n-204.483448188219, -8.44999185750282, -303.940263380113, -149.809798260312, \n-201.053219046732, -311.89208497532, -67.9595994951025, -332.784936569921, \n-8.82028174168437, -74.0767654457289, -225.844538522669, -79.3964368623119, \n-188.820281741684, -113.297182120676, -305.197543854312, -307.618500227702, \n-355.965169024395, -40.6780360188148, -254.076765445729, -293.297182120676, \n-39.1505020381276, -219.150502038128, -200.543630530714, -20.5436305307144, \n-339.484093876425, -159.484093876425, -57.1267789677657, -237.126778967766, \n-152.784936569921, -209.248811480034, -290.446084051197, -303.637902437449, \n-70.6500113335375, -185.699471390362, -222.924098568549, -269.297471568842, \n-123.637902437449, -284.996025313062, -272.615969084589, -92.6159690845892, \n-346.170195141824, -162.965859268129, -232.094320001281, -77.8656618006115, \n-15.4642774288034, -195.464277428803, -150.100181240554, -21.3744630245959, \n-94.2980567804455, -297.307301793814, -232.878900761254, -137.835301857452, \n-257.307183906531, -357.629382730416, -92.569484422423, -141.075930895391, \n-177.629382730416, -321.075930895391, -201.374463024596, -317.835301857452, \n-342.965859268129, -281.939334837023, -101.939334837023, -353.653488352489, \n-173.653488352489, -98.1315720644685, -12.3792275338427, -322.583232043193, \n-230.983428313025, -192.379227533843, -203.304191922505, -152.506999167441, \n-203.892619196912, -323.663661329153, -248.830970930664, -200.047123150142, \n-1.38606474159587, -293.916356614058, -359.572861541834, -75.1700923878964, \n-255.170092387896, -25.7869048859995, -205.786904885999, -158.45780561965, \n-71.8851513684932, -251.885151368493, -59.403476140586, -356.066116677889, \n-186.27671586379, -75.9112508510436, -255.911250851044, -338.179878042894, \n-270.649829818654, -23.5020856230652, -203.502085623065, -78.0257116416499, \n-234.989230735614, -320.542382770207, -9.50589792171149, -236.758947198611, \n-140.542382770207, -96.1220558312287, -350.721952486165, -174.269962575491, \n-54.9892307356145, -116.851258052999, -231.814380162457, -179.572861541834, \n-239.403476140586, -176.066116677889, -158.179878042894, -163.55668718861, \n-71.2297500794803, -312.34673249094, -95.39242833464, -73.6609985496231, \n-248.35913101654, -87.0647807709773, -253.660998549623, -68.3591310165398, \n-37.1309655628759, -119.90425747821, -275.39242&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-5.11581056159167, -88.5443555273749, -268.544355527375, \n-130.04175171566, -333.006562148466, -284.247300287698, -310.04175171566, \n-276.199053293487, -252.353285814794, -6.2279079985766, -72.9293859909634, \n-278.672202485416, -186.227907998577, -72.353285814794, -284.11823402956, \n-312.646975373578, -338.478193486814, -158.478193486814, -276.92112412748, \n-355.838323058898, -104.11823402956, -98.6722024854164, -79.5391300528095, \n-25.167722028218, -205.167722028218, -257.640669409134, -77.6406694091344, \n-285.02306716158, -106.384535903058, -336.402031124996, -77.7517823878251, \n-341.008707781084, -257.751782387825, -263.008064661683, -357.8279639433, \n-229.93784753933, -105.02306716158, -58.3848544490431, -278.80644694667, \n-98.8064469466702, -156.402031124996, -286.554141866854, -49.9378475393302, \n-41.6488902114526, -221.648890211453, -241.19002443605, -169.374533781563, \n-105.608441092327, -285.608441092327, -240.221640100979, -308.284104993064, \n-175.43056236321, -153.006562148466, -198.254973003552, -60.2216401009789, \n-128.284104993064, -206.120022237854, -87.2691858696724, -267.269185869672, \n-48.2491327327264, -168.197831018745, -110.648429986763, -277.618856993432, \n-207.985633928158, -281.947872247649, -315.15894459726, -280.738805698306, \n-294.424433099205, -58.1518885875648, -135.15894459726, -78.2585436647492, \n-258.258543664749, -293.920635316806, -89.7933472447544, -159.547724219966, \n-202.020927708805, -354.580924383252, -227.657743789333, -163.419509891769, \n-336.646350813012, -238.151888587565, -16.0063098805552, -113.920635316806, \n-174.580924383252, -196.006309880555, -279.718982242703, -99.7189822427031, \n-168.956874862177, -348.956874862177, -45.9402311382274, -80.2134577226362, \n-148.739507163703, -115.363287257624, -184.687657144868, -295.363287257624, \n-4.68765714486818, -247.507901607414, -251.482674648623, -2.0654722270823, \n-95.3514045541011, -115.26390688921, -17.1439650832485, -345.542933275486, \n-165.542933275486, -45.8720537034065, -275.351404554101, -38.5483810721091, \n-218.548381072109, -349.371925775176, -169.371925775176, -264.077561870819, \n-11.6815724060601, -334.42873490927, -154.42873490927, -358.412545353368, \n-71.4097622391083, -5.43111302006025, -313.189489214986, -286.547113373596, \n-287.3069851888, -300.698920499573, -40.6184832829754, -120.698920499573, \n-250.743771742036, -70.743771742036, -21.2299198970712, -201.229919897071, \n-33.4117566742984, -182.122609876558, -64.7090136231507, -278.504712262058, \n-356.326861155484, -262.631985110487, -176.326861155484, -312.572118724145, \n-244.709013623151, -347.856615921828, -24.2912415846981, -306.844848777968, \n-126.844848777968, -99.4203453391343, -18.5161276955999, -43.3465899881173, \n-64.7759252950781, -69.5964260512068, -249.596426051207, -50.7832329953741, \n-78.4968261158162, -86.514645666547, -130.342819065401, -280.353671085214, \n-100.353671085214, -350.094097427955, -279.420345339134, -310.051332574459, \n-144.568596441412, -258.496826115816, -27.128466092271, -207.128466092271, \n-25.1375205912781, -244.775925295078, -286.956795248144, -10&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-256.187188719964, -244.616749956277, -151.710979871396, \n-27.7742480514179, -6.02924055350525, -240.273991987081, -331.710979871396, \n-151.674303660818, -207.774248051418, -186.029240553505, -279.985191260697, \n-283.230613628714, -265.980595173003, -358.196974997928, -178.196974997928, \n-265.497247642895, -85.4972476428946, -48.572709111639, -296.774942787172, \n-174.310357286171, -47.2989248596632, -354.310357286171, -271.610421522174, \n-235.213450796739, -91.6104215221742, -3.91822485109896, -7.19043482518987, \n-4.56607064881291, -66.8627483608174, -72.9347171365887, -236.620856310673, \n-106.359595886177, -61.3305919284884, -250.08816340711, -353.267693066311, \n-241.330591928488, -173.267693066311, -18.7008211041673, -252.365785399095, \n-161.372261566949, -88.4559986093578, -268.455998609358, -1.2419193818933, \n-180.670046926597, -181.968764777714, -181.241919381893, -162.874588296894, \n-70.0881634071102, -240.219597606341, -1.9687647777144, -212.452708745007, \n-335.767717350867, -282.69448999164, -102.69448999164, -341.372261566949, \n-242.966522975313, -56.6208563106729, -32.4527087450072, -349.43676282839, \n-64.9372045669958, -115.309689157341, -244.937204566996, -38.6881624022836, \n-251.191366077449, -71.1913660774489, -251.141471631164, -295.309689157341, \n-228.572709111639, -190.088612597927, -281.363604723856, -290.431740617624, \n-161.883514313476, -170.371251663487, -78.4135765129114, -341.883514313476, \n-258.413576512911, -60.177692440165, -92.10975722666, -293.933293173144, \n-240.177692440165, -245.774222273138, -131.507328542113, -22.0447648552548, \n-341.120935739201, -161.120935739201, -58.4098289967349, -28.7283866177453, \n-208.728386617745, -165.531470483647, -53.1534867157802, -233.15348671578, \n-207.747975794346, -347.082988038268, -167.082988038268, -271.496704247835, \n-66.8191644709821, -246.819164470982, -10.807073546099, -53.1897156550762, \n-133.77427683927, -233.189715655076, -248.38109440873, -55.5873314946821, \n-250.187343624747, -164.053783485272, -171.951838010199, -80.4686575612183, \n-70.1873436247467, -235.587331494682, -351.951838010199, -186.964800417911, \n-333.504965812855, -153.504965812855, -106.72438826863, -230.744020740803, \n-286.72438826863, -335.399900618576, -93.8265002966102, -273.82650029661, \n-349.965376191442, -78.3961649584372, -258.396164958437, -295.000365724814, \n-95.8340960831191, -275.834096083119, -169.965376191442, -68.7251903037761, \n-248.725190303776, -334.78901966399, -30.2179367571306, -296.834065912993, \n-116.834065912993, -184.432493541505, -287.943036589064, -296.12567748176, \n-346.879910125259, -91.1131634639628, -50.9870233277884, -230.987023327788, \n-21.1138616747963, -110.436009979727, -276.050538170885, -96.0505381708853, \n-226.560877143928, -83.7484038865432, -91.7876554676624, -89.4151550515377, \n-263.748403886543, -105.230407975521, -10.1720888212641, -359.980032209763, \n-269.522093781849, -285.230407975521, -290.436009979727, -179.980032209763, \n-46.5608771439282, -314.731434412755, -283.944780011375, -134.731434412755, \n-43.8562540887355, -355.389543652185, -132.829944331&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-359.022889701311, -10.3186004397934, -190.318600439793, \n-85.0534576172009, -57.4074850705547, -180.625969004942, -49.9909081715182, \n-0.625969004941908, -61.2955392795462, -154.55005712375, -31.2190840962529, \n-74.2594817730113, -254.259481773011, -274.24411063909, -353.858770127011, \n-35.7014241856737, -357.9526873717, -255.247832199031, -75.247832199031, \n-175.630198512273, -355.630198512273, -77.5081778040884, -2.55197556701631, \n-48.1881554054164, -41.0007288317315, -57.1282280253656, -7.40212952298413, \n-53.0156781479643, -66.5946902178152, -45.5364822885348, -327.364027595428, \n-331.756842704065, -113.424317843876, -74.6681446853861, -151.756842704065, \n-243.483744935823, -120.266905446712, -158.315565579037, -246.594690217815, \n-176.205615211407, -121.756314120413, -293.424317843876, -97.3370223216581, \n-237.065778844705, -302.883954323519, -122.883954323519, -277.337022321658, \n-308.214201038948, -48.9042063133615, -104.050190517741, -324.097448105525, \n-144.097448105525, -102.673919111154, -177.9526873717, -170.418845279864, \n-48.3881291044983, -355.57804361351, -18.9173272395449, -338.92931628436, \n-158.92931628436, -139.109075858483, -156.33966854139, -319.109075858483, \n-175.57804361351, -286.414393060473, -106.414393060473, -7.111705720587, \n-68.2229583628549, -78.7973920262517, -336.841976049693, -74.8015503065966, \n-254.801550306597, -203.256492528996, -342.308363022304, -162.308363022304, \n-77.0219881691848, -297.754105681217, -245.23470865174, -358.656023077959, \n-178.656023077959, -4.72025338616834, -62.615494198678, -197.40830901473, \n-98.3240366753043, -144.632095077267, -17.4083090147302, -192.464394802183, \n-262.909086296409, -278.324036675304, -105.605887543362, -324.632095077267, \n-289.054915478821, -109.054915478821, -149.006416953543, -329.006416953543, \n-229.166231660404, -156.841976049693, -218.841949191799, -302.06271440585, \n-341.116797719257, -38.7708419374275, -317.481991803109, -63.4490328445047, \n-243.449032844505, -327.978879140214, -122.06271440585, -34.6341526268563, \n-81.4042419087321, -323.181485825026, -41.693895227706, -221.693895227706, \n-195.012871029775, -296.840356712563, -116.840356712563, -86.3245286037807, \n-14.4236422397064, -335.791374516871, -155.791374516871, -10.0620844259316, \n-69.3282681054038, -18.2962023577373, -280.809551955893, -353.470480059569, \n-178.138328142679, -305.416801429556, -281.605969011734, -55.8218208528094, \n-313.916618073517, -119.55658974049, -299.55658974049, -358.138328142679, \n-131.032095223652, -346.110311589285, -337.408492729086, -19.8850796377156, \n-166.110311589285, -72.2643881330561, -252.264388133056, -310.703497420158, \n-25.4941792539828, -290.131537015391, -237.597240990107, -205.494179253983, \n-82.912475158119, -79.8768394295633, -171.341324717763, -225.544070568794, \n-132.259558526082, -256.54559230756, -110.131537015391, -204.07368502775, \n-312.259558526082, -259.876839429563, -351.341324717763, -175.014876188443, \n-4.3440605433309, -17.7309243279956, -157.407272365019, -70.419790005528, \n-169.833356255775, -145.496114343817, -56.2889757547783, -3&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-295.078691969693, -345.884682494487, -226.945112055437, \n-327.864976541037, -295.951725328425, -115.951725328425, -46.9451120554368, \n-170.821621866206, -278.842862709139, -98.8428627091391, -323.140649288203, \n-348.005202108591, -168.005202108591, -337.400437163284, -260.619767993709, \n-291.999850513972, -195.895457955538, -274.395991134374, -94.3959911343742, \n-17.0900164066101, -66.3503143656714, -111.999850513972, -322.223484201711, \n-103.17395719, -279.442639143589, -351.992654968402, -133.745815339215, \n-279.203946161739, -343.233225396631, -254.922342219767, -18.0070008010953, \n-89.6460975336653, -272.349381061038, -336.28332241013, -171.992654968402, \n-302.870380553809, -52.5118882095554, -232.511888209555, -283.17395719, \n-198.007000801095, -145.876012317324, -216.7290887983, -72.3559451506542, \n-252.355945150654, -41.052553925061, -11.2016150927394, -47.093122717356, \n-191.201615092739, -227.093122717356, -9.39983010099297, -17.7167129564581, \n-189.399830100993, -294.819789336715, -75.028394163274, -121.318695662446, \n-137.443096790202, -255.028394163274, -317.443096790202, -222.871298177999, \n-36.7376674378823, -358.476780334732, -292.498014022431, -324.376669311221, \n-44.7777859327134, -299.125995487646, -7.05927224504006, -343.508842602808, \n-187.05927224504, -72.9464745648854, -252.946474564885, -134.451606184991, \n-32.0613107598587, -177.420371458507, -301.512442762811, -202.746447385796, \n-99.4827934143214, -3.00448756442569, -183.004487564426, -22.3652118364236, \n-347.607593549918, -281.432194052777, -240.082025829668, -212.061310759859, \n-279.482793414321, -184.34807194668, -240.37555597264, -112.687660277792, \n-42.4979873085491, -75.125962090887, -294.56508262713, -114.56508262713, \n-255.125962090887, -138.432404337313, -134.694538356377, -189.659481818812, \n-9.65948181881214, -115.078691969693, -335.835229685532, -304.739137387853, \n-124.739137387853, -196.368920923487, -174.159620281147, -189.17101907872, \n-50.5289308480709, -149.16287352449, -329.16287352449, -289.090661448386, \n-89.2440968427562, -269.244096842756, -310.465819559658, -13.7032426558678, \n-60.2716757967153, -54.4510381103862, -234.451038110386, -193.703242655868, \n-130.465819559658, -61.1034213165887, -241.103421316589, -168.785582797427, \n-196.986663614766, -116.369703225974, -230.528930848071, -3.15207885150801, \n-155.835229685532, -183.152078851508, -12.4606784633418, -192.460678463342, \n-356.370615147144, -314.195320715308, -285.393098274532, -5.49003603310842, \n-185.490036033108, -341.596579748326, -185.35228780869, -242.92318818289, \n-331.675549480863, -62.9231881828899, -262.895219601585, -230.469564014638, \n-134.195320715308, -345.273616647451, -332.554021283449, -248.341301993562, \n-63.9880945227726, -65.0058708627749, -243.988094522773, -245.005870862775, \n-68.3413019935617, -13.5335177583586, -341.714053505448, -53.9635700920196, \n-140.48562202935, -331.817305993421, -320.48562202935, -10.4447887409476, \n-176.274824891663, -33.3860780193136, -213.386078019314, -356.274824891663, \n-9.42596824642874, -221.8299235111, -244.414728348301, -342.&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-333.69615899261, -18.3245907525347, -198.324590752535, \n-68.468299289097, -121.330231603319, -194.64079495848, -290.258989674082, \n-242.133875896947, -260.468654724404, -126.662838131614, -232.514772324754, \n-150.481223418954, -52.5147723247538, -29.2405968325377, -86.2833715821758, \n-246.702681442096, -19.9912901192075, -298.399165163087, -266.283371582176, \n-208.351240393526, -351.223491106052, -171.223491106052, -145.411828109325, \n-66.7026814420957, -49.9534396533909, -229.953439653391, -136.003061468328, \n-224.585773676087, -91.010966282723, -11.7056288162052, -82.0119366007121, \n-262.011936600712, -85.7499185258491, -233.691073325693, -206.367206707834, \n-265.749918525849, -7.04485359169519, -60.7260281806411, -43.9547871550668, \n-280.723371337382, -319.287192515066, -139.287192515066, -169.600629072393, \n-163.231986245987, -228.623634897795, -319.124715932603, -44.0594783557237, \n-139.124715932603, -341.212481312672, -18.2537533369971, -161.212481312672, \n-319.973430989719, -198.253753336997, -337.327823979224, -85.9497451108446, \n-46.511847134337, -69.1335300672727, -224.059478355724, -8.34150414308664, \n-345.382607225578, -240.566801370581, -100.723371337382, -265.949745110845, \n-4.49353298990343, -14.3727868471123, -338.443140047995, -223.954787155067, \n-158.443140047995, -249.527050070613, -346.736165189697, -284.460146073115, \n-104.460146073115, -263.037295161041, -330.279330583746, -78.5044942758017, \n-353.517702871151, -258.504494275802, -251.785280895844, -190.300104697781, \n-355.807454668385, -175.807454668385, -91.823016546645, -271.823016546645, \n-178.830738179573, -14.9894828835853, -358.830738179573, -194.989482883585, \n-274.185843095135, -335.286935596061, -155.286935596061, -94.1858430951348, \n-192.616939784196, -282.850580673368, -102.850580673368, -301.873433969956, \n-123.091318820104, -260.740217737532, -80.7402177375325, -259.351936126478, \n-199.512576655189, -212.162557560454, -167.275574800717, -122.116803165792, \n-212.942999294845, -32.942999294845, -119.873870369514, -208.935773275665, \n-235.400359743041, -162.760926084384, -199.680351007517, -173.92189284147, \n-125.685883890894, -218.03028588247, -346.650028749198, -332.01974220177, \n-67.3469858648216, -226.503036521507, -327.990277123815, -147.990277123815, \n-168.467555269635, -74.8222687438255, -254.822268743826, -88.0640039095194, \n-9.54317293109068, -46.5030365215073, -247.346985864822, -233.666116241396, \n-163.310434807235, -196.397218077954, -248.424274685937, -8.76151922676928, \n-341.789268358469, -226.601379432246, -15.4906700129932, -2.5999104644327, \n-73.9573304333646, -124.542170698342, -298.328589305214, -304.542170698342, \n-290.965091123721, -110.965091123721, -32.2138208854877, -218.388576220553, \n-38.3885762205533, -66.1098015102177, -189.80507613823, -9.80507613822954, \n-194.152436358693, -14.1524363586928, -30.1577754069467, -274.691365345944, \n-94.6913653459437, -111.524219266683, -45.858098167169, -66.7608259075767, \n-225.858098167169, -36.9821922327898, -264.153975377028, -216.98219223279, \n-84.1539753770276, -77.4662770665508, -172.1872&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-312.362714698029, -285.31881385321, -105.31881385321, \n-233.066624591695, -333.496373871918, -137.06188230087, -94.7691479515943, \n-291.319193774187, -213.737259471425, -306.582771337255, -350.795119916787, \n-95.4682509115135, -24.3229569605057, -126.582771337255, -17.9321093798362, \n-277.58352292484, -247.514643453907, -275.468250911513, -197.932109379836, \n-55.0327031998197, -235.03270319982, -64.6137350588743, -303.813555369703, \n-123.813555369703, -244.613735058874, -96.1518545180419, -35.4489853147538, \n-50.971181385277, -9.40634606855383, -189.406346068554, -336.327830991331, \n-281.203443449227, -101.203443449227, -346.367548795879, -211.918098088264, \n-292.200599779626, -295.294630845175, -115.294630845175, -135.141350204943, \n-164.797082273751, -50.1068617287659, -75.3866336126738, -43.8220011242647, \n-255.386633612674, -180.096958261148, -187.938155695536, -223.822001124265, \n-161.689223491411, -28.0157033601806, -31.9180980882641, -315.141350204943, \n-306.470391250417, -122.454480736094, -62.6621143966691, -237.020457399504, \n-297.368250983766, -243.514829287618, -270.706870057678, -89.3017014737697, \n-269.30170147377, -348.130321607612, -168.130321607612, -100.689108638544, \n-26.4577688036176, -206.457768803618, -118.245051236299, -7.30213406388293, \n-172.870562497621, -241.506470918043, -196.448066125379, -352.870562497621, \n-145.60179537718, -325.60179537718, -70.6314143295759, -250.631414329576, \n-125.147026065004, -305.147026065004, -214.044848958149, -287.59317489641, \n-203.706068839751, -107.59317489641, -258.776382330176, -8.84556318772354, \n-256.60096321302, -301.603337714307, -198.998570512395, -186.961964434335, \n-163.890443264117, -18.9985705123952, -238.036544082217, -261.605551962232, \n-76.6009632130201, -6.9619644343349, -208.015703360181, -62.149372490478, \n-242.149372490478, -346.937379018742, -7.4479030439602, -353.684201812379, \n-21.0533276449089, -201.053327644909, -166.937379018742, -5.81990453569966, \n-159.609716588605, -19.3890972709094, -286.184215993755, -197.805617617324, \n-106.184215993755, -287.323049925313, -280.450163135488, -100.450163135488, \n-305.255839953553, -125.255839953553, -110.526826257068, -166.635984256943, \n-197.123138083507, -184.240922564567, -202.200920030606, -104.720298744487, \n-187.44790304396, -262.227513224643, -86.0302911848752, -45.855818253176, \n-11.4170224730747, -4.81707828014805, -340.520970919903, -160.520970919903, \n-184.817078280148, -152.414693725295, -163.311312527714, -357.674635654074, \n-225.855818253176, -329.712478472788, -351.713521585186, -307.171037266955, \n-302.232584868812, -96.7290928393226, -291.102142535746, -86.5190209479484, \n-69.3982663594125, -249.398266359412, -276.729092839323, -280.858584810572, \n-207.81842213514, -171.45746244653, -314.398596256328, -134.398596256328, \n-327.598698558015, -264.085987841675, -78.3161716131646, -4.19353456008366, \n-281.996098937925, -230.504364865086, -172.108981176328, -48.1470885494984, \n-271.161378042166, -120.365667179453, -91.1613780421658, -258.335056861053, \n-133.558692093453, -238.794887213693, -264.935904318&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-290.482910237945, -275.871728195883, -339.024787384244, \n-159.024787384244, -246.169327586256, -296.038415639151, -75.4054148442453, \n-58.6866191821143, -118.82165004161, -45.2896862245597, -181.835596843418, \n-333.809043662663, -153.809043662663, -225.28968622456, -66.1693275862556, \n-298.82165004161, -161.717370181058, -296.326312164721, -16.7090084549014, \n-307.740226085856, -127.740226085856, -196.709008454901, -182.138161211504, \n-191.721280039561, -2.13816121150376, -274.771439397617, -89.7605056020227, \n-94.7714393976173, -311.288166080397, -3.2549072305581, -346.706761380775, \n-209.521491027004, -76.7888488671645, -166.706761380775, -60.5496123347615, \n-240.549612334762, -328.87176728581, -148.87176728581, -225.916039969689, \n-69.8446892071964, -79.3714061151016, -331.546092344188, -60.1464090290089, \n-240.146409029009, -259.371406115102, -318.296931250038, -82.4669756285982, \n-195.747598117563, -316.185023424654, -18.482601598807, -136.185023424654, \n-262.948127990608, -198.482601598807, -302.968214889426, -24.6173853581151, \n-204.617385358115, -359.470272902777, -345.085979960884, -63.4170693483985, \n-27.1900665898104, -243.417069348399, -165.085979960884, -207.19006658981, \n-37.8133730460074, -262.466975628598, -82.9481279906082, -109.297666582582, \n-115.590057124375, -15.7475981175635, -316.175502795008, -272.323083534419, \n-354.828022530688, -341.318786062773, -174.828022530688, -295.590057124375, \n-38.8884661922355, -97.173797303457, -302.245641193959, -182.444041694007, \n-266.844909753395, -2.44404169400701, -86.8449097533947, -257.78681265584, \n-281.950626083003, -203.096614670013, -101.950626083003, -91.6230799586116, \n-271.623079958612, -125.278605494821, -188.421689172827, -4.3942801658182, \n-116.038415639151, -224.925016357327, -185.058768862965, -184.394280165818, \n-5.05876886296539, -98.3129421859619, -251.374307062102, -194.817055696638, \n-271.416567046309, -49.093008002573, -91.4165670463092, -135.33274119588, \n-285.49554510697, -105.49554510697, -9.12989597410734, -102.618957680861, \n-189.129895974107, -136.797215558646, -171.33382579815, -351.33382579815, \n-293.905851190381, -298.978272003568, -138.587290837793, -21.6542558934896, \n-343.915898611187, -224.348994516929, -8.75421358315566, -188.754213583156, \n-194.356551153962, -318.587290837793, -335.58263392403, -33.7981255302574, \n-342.328048593967, -213.798125530257, -290.577208108514, -110.577208108514, \n-53.8241422735892, -163.915898611187, -44.3489945169295, -112.087402621736, \n-278.840690940988, -345.427737715983, -234.630528778402, -265.865712159004, \n-120.825729922581, -165.427737715983, -222.871197450848, -279.565208571509, \n-89.3437420533828, -51.981215655615, -31.8404697675792, -10.4250059821736, \n-62.7287244502886, -190.425005982174, -336.662189776031, -87.7669327573259, \n-195.682870244662, -267.766932757326, -121.117548104025, -117.121435028457, \n-42.8711974508481, -14.061164309887, -140.378388862204, -242.728724450289, \n-169.976002401697, -23.5251000436456, -99.5652085715088, -194.061164309887, \n-349.976002401697, -78.9420301312682, -89.41798331289&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-300.614717340708, -192.807715099217, -341.388864955616, \n-88.3588384053499, -262.595509713719, -120.614717340708, -329.065276209013, \n-286.157722874051, -250.986097391059, -353.993243010854, -254.630978352829, \n-246.584189549134, -293.963559793537, -173.993243010854, -70.9860973910593, \n-320.753771138442, -140.753771138442, -321.374961107713, -141.374961107713, \n-162.455801006255, -98.7461714400711, -220.597574221103, -119.598217002419, \n-31.358475372092, -110.28096274261, -190.830364155748, -211.358475372092, \n-261.987343474087, -81.9873434740866, -207.349148802249, -115.858574907941, \n-74.6979906222125, -295.445749049976, -205.515104415053, -204.050211473668, \n-56.325965366401, -314.877308751101, -236.325965366401, -134.877308751101, \n-85.3820555417506, -265.382055541751, -25.5151044150534, -295.975242679584, \n-115.975242679584, -323.772708440371, -174.557107707318, -301.930987089763, \n-38.7168807429865, -337.18711027648, -297.418587380517, -117.418587380517, \n-29.0416388323812, -320.286927123967, -94.2630069866786, -36.6192699257358, \n-183.788369466469, -162.723809674433, -43.1969734920112, -223.196973492011, \n-243.085311850147, -216.619269925736, -63.0853118501468, -209.041638832381, \n-274.263006986679, -341.104214928886, -201.940869863284, -17.164152737129, \n-302.935376984222, -157.8586339928, -122.935376984222, -306.45119575141, \n-273.970495744644, -126.45119575141, -129.262154605071, -50.0662903904077, \n-161.104214928886, -337.8586339928, -117.392652217638, -262.640384881124, \n-297.392652217638, -348.253913594158, -199.096523880084, -335.774838381832, \n-253.986362006477, -150.057802766993, -272.189815335836, -19.9291505224668, \n-92.1898153358359, -348.284237867971, -309.875152054433, -129.875152054433, \n-143.852295307064, -308.016055732661, -73.9553205575834, -128.016055732661, \n-338.488065786237, -158.488065786237, -314.660854414991, -85.4342868667177, \n-265.434286866718, -151.29940020492, -238.870558247076, -168.294859003007, \n-49.8539227832667, -348.116672776043, -236.980532552227, -168.116672776043, \n-80.2553593540476, -254.934776650254, -229.853922783267, -3.27228116706596, \n-292.667574857253, -112.667574857253, -147.736633486386, -55.5711775121034, \n-105.748190386858, -54.9542907199938, -310.68649631, -79.8368523997744, \n-144.051084158798, -130.68649631, -297.83306159551, -279.933602625912, \n-76.0734819312863, -256.073481931286, -47.7580180869138, -279.852834107574, \n-99.852834107574, -335.114087327099, -36.2042422155669, -216.204242215567, \n-155.114087327099, -126.45550287378, -313.517519148651, -133.517519148651, \n-357.485308199534, -177.485308199534, -5.50480310785395, -185.504803107854, \n-6.57157688597715, -287.466352686031, -56.6510821757817, -236.651082175782, \n-257.081951452707, -137.698799946735, -146.107635195236, -338.972069286105, \n-11.0143833226114, -342.860297144979, -17.2063395723788, -38.9664669340035, \n-286.454628081951, -2.33743915687762, -197.206339572379, -106.454628081951, \n-218.966466934003, -182.337439156878, -127.403069984869, -81.4373683210264, \n-25.6569369043103, -3.74345131356023, -87.9702697534809,&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-19.0722345681253, -289.026608267759, -32.1611937835791, \n-216.827178834489, -225.374620446502, -212.161193783579, -45.3746204465019, \n-36.8271788344892, -58.223516179125, -90.4522572745457, -238.223516179125, \n-72.856653913689, -273.71381888527, -226.794503549598, -237.213178240362, \n-166.507418214354, -46.7945035495977, -93.7138188852696, -111.626776515177, \n-2.21114773201288, -291.626776515177, -343.184135307563, -291.348112993214, \n-111.348112993214, -244.66518137199, -97.3832453061409, -325.29428196656, \n-90.0472920098521, -145.294281966561, -155.021213388116, -75.5983513021192, \n-111.469820763044, -235.025754485307, -241.208936612483, -242.910585092277, \n-353.792861619085, -55.025754485307, -59.6857092939361, -62.9105850922766, \n-28.9791578458617, -323.512715015919, -143.512715015919, -185.819060624613, \n-237.331163050175, -336.237665203754, -57.331163050175, -189.640854042445, \n-359.153015540742, -4.04407064954381, -223.221555422929, -344.615014094027, \n-164.615014094027, -2.22973876473156, -257.715699925788, -182.229738764732, \n-76.488218331902, -256.488218331902, -168.415923567932, -184.044070649544, \n-272.111068513859, -317.637410782113, -18.9844772361412, -198.984477236141, \n-281.43812908435, -281.309334077882, -174.526345232509, -43.2215554229286, \n-226.933866925367, -354.154140547773, -8.53886678340177, -305.535998228753, \n-170.559295484935, -188.538866783402, -348.864235848612, -302.142544983195, \n-168.864235848612, -147.284353994622, -166.494320272196, -323.051488894166, \n-290.932114960094, -58.5258714123176, -238.525871412318, -65.3398251794126, \n-341.378489027753, -353.558270964277, -284.362123879853, -104.362123879853, \n-1.25237875464683, -181.252378754647, -252.703045930826, -345.363543765783, \n-76.0883009535952, -207.024961743094, -256.088300953595, -257.501399381971, \n-344.32757993514, -336.622127570479, -90.6339530388033, -1.57853732477707, \n-338.660094565645, -181.578537324777, -333.159451375156, -346.744865809227, \n-166.744865809227, -148.204293175918, -74.9490240199468, -165.363543765783, \n-160.035299718595, -98.6361348080032, -341.439960276833, -338.340686599702, \n-161.439960276833, -352.173602448891, -172.173602448891, -245.339825179413, \n-27.024961743094, -332.577650724746, -158.660094565645, -218.048974217276, \n-110.932114960094, -225.762051048517, -292.334109944894, -270.633953038803, \n-113.078152921894, -315.412377426179, -282.761865824056, -102.761865824056, \n-182.765890143275, -15.1482074517208, -135.412377426179, -64.7069756855693, \n-195.148207451721, -158.700230813562, -86.7147537982913, -149.750186944515, \n-43.6231230808638, -66.3063870310367, -261.559354574408, -337.267445450963, \n-246.306387031037, -157.267445450963, -150.166158007963, -300.093331465655, \n-264.033722677516, -246.655898931515, -120.093331465655, -358.422737455732, \n-315.556143316152, -342.764744991875, -29.6895864755422, -36.4881560304218, \n-209.689586475542, -341.925120507847, -266.714753798291, -161.925120507847, \n-330.166158007963, -6.5536191832058, -162.764744991875, -278.32482920266, \n-95.2965924685982, -150.179286552697, -59.3101&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-350.11651230383, -87.7941575981745, -348.569517012102, \n-168.569517012102, -173.9674675514, -37.4789403416743, -49.6200476353754, \n-229.620047635375, -170.11651230383, -267.794157598174, -281.289945034656, \n-101.289945034656, -194.360441253012, -235.654116294963, -228.641370204827, \n-129.719039653279, -14.3604412530119, -312.111697730582, -132.111697730582, \n-43.1882332752699, -223.18823327527, -358.26946868518, -326.534961538993, \n-146.534961538993, -341.512953403402, -161.512953403402, -178.26946868518, \n-237.729409874853, -79.0004514168811, -165.596378482571, -259.000451416881, \n-147.548724020057, -252.29676648554, -181.022710971938, -35.0453275907514, \n-215.045327590751, -76.6337236758052, -225.670967145559, -327.548724020057, \n-72.2967664855403, -226.455986204607, -43.6254968765124, -223.625496876512, \n-22.5150908123213, -107.446136464262, -46.4559862046069, -240.163784817069, \n-266.03234486109, -12.1890624935978, -347.948014744242, -344.540870231621, \n-24.4472394084113, -164.540870231621, -4.34547444531643, -276.579576627341, \n-184.345474445316, -263.451470383465, -97.1992595335554, -91.9721910703423, \n-27.7499703586082, -242.971693014712, -64.8300067519527, -244.830006751953, \n-49.9663351344594, -140.080172315738, -300.484256682244, -144.527916681382, \n-342.279575835122, -307.213976006491, -162.279575835122, -288.090742526264, \n-271.163312602268, -167.948014744242, -168.640565559241, -321.61574717994, \n-229.966335134459, -6.56157796802097, -351.32336291602, -171.32336291602, \n-159.387348416499, -301.652879766748, -207.749970358608, -348.640565559241, \n-214.139396308011, -108.090742526264, -59.3508004478106, -317.448652507497, \n-265.546830748587, -85.5468307485871, -332.931903134743, -152.931903134743, \n-320.87087700895, -267.041238517279, -340.572567473479, -12.6764655982298, \n-227.215468395259, -322.911943380121, -339.485162570833, -192.67646559823, \n-159.485162570833, -343.283470935766, -77.9880388896819, -260.365579767691, \n-156.59563284432, -171.896110461463, -91.877863687455, -149.68260314801, \n-336.59563284432, -239.350800447811, -57.7670494893038, -237.767049489304, \n-160.572567473479, -163.283470935766, -351.896110461463, -328.250114096114, \n-148.250114096114, -68.4047478772992, -74.597418337964, -328.366364364943, \n-148.366364364943, -111.863541075229, -210.551978298933, -141.455692463996, \n-314.453038071713, -118.636314752062, -45.049772387589, -102.81194634816, \n-327.335852963333, -154.613241378022, -18.2017652670402, -175.230939213367, \n-30.1652985457742, -6.60124232020911, -147.335852963333, -355.230939213367, \n-349.468529550949, -208.661328299706, -62.7112525745186, -280.142383254977, \n-24.2324671680763, -37.3441151698909, -133.568585210135, -340.331665021207, \n-74.0724855138362, -349.295276643723, -107.791733098847, -287.791733098847, \n-339.829619453847, -239.526588188875, -11.8991609453852, -340.362191477639, \n-268.401674095239, -159.829619453847, -234.390127502364, -324.20310800042, \n-112.490313695067, -290.630869710557, -96.5801037662826, -239.325690867302, \n-3.5989847693935, -46.9256601952172, -204.232467168076,&gt;\n&lt;simpleWarning: In (function (x, bw = \"nrd0\", adjust = 1, kernel = c(\"gaussian\", \n    \"epanechnikov\", \"rectangular\", \"triangular\", \"biweight\", \n    \"cosine\", \"optcosine\"), weights = NULL, window = kernel, \n    width, give.Rkern = FALSE, subdensity = FALSE, warnWbw = var(weights) &gt; \n        0, n = 512, from, to, cut = 3, na.rm = FALSE, ...) \n{\n    chkDots(...)\n    if (!missing(window) && missing(kernel)) \n        kernel &lt;- window\n    kernel &lt;- match.arg(kernel)\n    if (give.Rkern) \n        return(switch(kernel, gaussian = 1/(2 * sqrt(pi)), rectangular = sqrt(3)/6, \n            triangular = sqrt(6)/9, epanechnikov = 3/(5 * sqrt(5)), \n            biweight = 5 * sqrt(7)/49, cosine = 3/4 * sqrt(1/3 - \n                2/pi^2), optcosine = sqrt(1 - 8/pi^2) * pi^2/16))\n    if (!is.numeric(x)) \n        stop(\"argument 'x' must be numeric\")\n    name &lt;- deparse1(substitute(x))\n    x &lt;- as.vector(x)\n    N &lt;- length(x)\n    if (has.wts &lt;- !is.null(weights)) {\n        if (length(weights) != N) \n            stop(\"'x' and 'weights' have unequal length\")\n    }\n    x.na &lt;- is.na(x)\n    if (any(x.na)) {\n        if (na.rm) {\n            N &lt;- length(x &lt;- x[!x.na])\n            if (has.wts) {\n                trueD &lt;- isTRUE(all.equal(1, sum(weights)))\n                weights &lt;- weights[!x.na]\n                if (trueD) \n                  weights &lt;- weights/sum(weights)\n            }\n        }\n        else stop(\"'x' contains missing values\")\n    }\n    nx &lt;- N &lt;- as.integer(N)\n    if (is.na(N)) \n        stop(gettextf(\"invalid value of %s\", \"length(x)\"), domain = NA)\n    x.finite &lt;- is.finite(x)\n    if (any(!x.finite)) {\n        x &lt;- x[x.finite]\n        nx &lt;- length(x)\n    }\n    if (!has.wts) {\n        weights &lt;- rep.int(1/nx, nx)\n        totMass &lt;- nx/N\n    }\n    else {\n        if (!all(is.finite(weights))) \n            stop(\"'weights' must all be finite\")\n        if (any(weights &lt; 0)) \n            stop(\"'weights' must not be negative\")\n        wsum &lt;- sum(weights)\n        if (any(!x.finite)) {\n            weights &lt;- weights[x.finite]\n            totMass &lt;- sum(weights)/wsum\n        }\n        else totMass &lt;- 1\n        if (!subdensity && !isTRUE(all.equal(1, wsum))) \n            warning(\"sum(weights) != 1  -- will not get true density\")\n    }\n    n.user &lt;- n\n    n &lt;- max(n, 512)\n    if (n &gt; 512) \n        n &lt;- 2^ceiling(log2(n))\n    if (missing(bw) && !missing(width)) {\n        if (is.numeric(width)) {\n            fac &lt;- switch(kernel, gaussian = 4, rectangular = 2 * \n                sqrt(3), triangular = 2 * sqrt(6), epanechnikov = 2 * \n                sqrt(5), biweight = 2 * sqrt(7), cosine = 2/sqrt(1/3 - \n                2/pi^2), optcosine = 2/sqrt(1 - 8/pi^2))\n            bw &lt;- width/fac\n        }\n        if (is.character(width)) \n            bw &lt;- width\n    }\n    if (is.character(bw)) {\n        if (nx &lt; 2) \n            stop(\"need at least 2 points to select a bandwidth automatically\")\n        if (has.wts && warnWbw) \n            warning(\"Selecting bandwidth *not* using 'weights'\")\n        bw &lt;- switch(tolower(bw), nrd0 = bw.nrd0(x), nrd = bw.nrd(x), \n            ucv = bw.ucv(x), bcv = bw.bcv(x), sj = , `sj-ste` = bw.SJ(x, \n                method = \"ste\"), `sj-dpi` = bw.SJ(x, method = \"dpi\"), \n            stop(\"unknown bandwidth rule\"))\n    }\n    if (!is.finite(bw)) \n        stop(\"non-finite 'bw'\")\n    bw &lt;- adjust * bw\n    if (bw &lt;= 0) \n        stop(\"'bw' is not positive.\")\n    if (missing(from)) \n        from &lt;- min(x) - cut * bw\n    if (missing(to)) \n        to &lt;- max(x) + cut * bw\n    if (!is.finite(from)) \n        stop(\"non-finite 'from'\")\n    if (!is.finite(to)) \n        stop(\"non-finite 'to'\")\n    lo &lt;- from - 4 * bw\n    up &lt;- to + 4 * bw\n    y &lt;- .Call(C_BinDist, x, weights, lo, up, n) * totMass\n    kords &lt;- seq.int(0, 2 * (up - lo), length.out = 2 * n)\n    kords[(n + 2):(2 * n)] &lt;- -kords[n:2]\n    kords &lt;- switch(kernel, gaussian = dnorm(kords, sd = bw), \n        rectangular = {\n            a &lt;- bw * sqrt(3)\n            ifelse(abs(kords) &lt; a, 0.5/a, 0)\n        }, triangular = {\n            a &lt;- bw * sqrt(6)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, (1 - ax/a)/a, 0)\n        }, epanechnikov = {\n            a &lt;- bw * sqrt(5)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 3/4 * (1 - (ax/a)^2)/a, 0)\n        }, biweight = {\n            a &lt;- bw * sqrt(7)\n            ax &lt;- abs(kords)\n            ifelse(ax &lt; a, 15/16 * (1 - (ax/a)^2)^2/a, 0)\n        }, cosine = {\n            a &lt;- bw/sqrt(1/3 - 2/pi^2)\n            ifelse(abs(kords) &lt; a, (1 + cos(pi * kords/a))/(2 * \n                a), 0)\n        }, optcosine = {\n            a &lt;- bw/sqrt(1 - 8/pi^2)\n            ifelse(abs(kords) &lt; a, pi/4 * cos(pi * kords/(2 * \n                a))/a, 0)\n        })\n    kords &lt;- fft(fft(y) * Conj(fft(kords)), inverse = TRUE)\n    kords &lt;- pmax.int(0, Re(kords)[1:n]/length(y))\n    xords &lt;- seq.int(lo, up, length.out = n)\n    x &lt;- seq.int(from, to, length.out = n.user)\n    structure(list(x = x, y = approx(xords, kords, x)$y, bw = bw, \n        n = N, call = match.call(), data.name = name, has.na = FALSE), \n        class = \"density\")\n})(x = c(-357.068808740585, -177.068808740585, -337.967116718778, \n-346.232806783086, -263.501880439567, -259.01421548681, -321.908145748608, \n-187.03716422805, -141.908145748608, -203.436324772663, -187.98554609791, \n-41.8822010571368, -221.882201057137, -85.0190437228459, -265.019043722846, \n-141.649276308621, -182.71342133365, -218.659469848835, -276.708059699014, \n-7.03716422804985, -69.1252601405176, -300.558099349712, -45.2221207123512, \n-225.222120712351, -260.886273371619, -115.717218636336, -204.209264034953, \n-38.6594698488347, -295.717218636336, -80.8862733716187, -24.2092640349526, \n-344.748746280308, -8.98034299308904, -328.510782311078, -269.24861012542, \n-89.2486101254199, -272.854309626093, -92.8543096260926, -21.5367331227903, \n-8.12476588915746, -210.655179626068, -188.124765889157, -201.53673312279, \n-13.7550820271672, -295.14225101197, -115.14225101197, -87.708825690266, \n-25.6544885519618, -328.776157797454, -323.392139365687, -315.154030677455, \n-148.776157797454, -329.787781685202, -143.392139365687, -273.944570913455, \n-94.8597454546561, -93.9445709134549, -62.067181491154, -356.414997414726, \n-356.541749504358, -59.3342639404862, -176.414997414726, -176.541749504358, \n-202.840503067635, -77.5621376801925, -257.562137680193, -62.7592163264139, \n-188.331142708914, -346.737624437795, -3.21311672287032, -183.21311672287, \n-343.280868092102, -163.280868092102, -224.043329403492, -58.6438487373914, \n-342.599050867298, -67.1764376595142, -44.5275919803719, -247.176437659514, \n-164.957467840919, -356.348036021488, -316.881877945196, -111.492403398166, \n-176.348036021488, -111.463093008493, -310.012865943167, -28.8757134569444, \n-347.580897141844, -22.8405030676351, -167.580897141844, -8.33114270891377, \n-17.9966612247375, -44.0433294034917, -130.012865943167, -355.614129755364, \n-4.2282129146335, -175.614129755364, -96.3558539120737, -162.375085357504, \n-323.142288523535, -143.142288523535, -135.154030677455, -290.559590103871, \n-327.436066767257, -147.436066767257, -348.60701241524, -176.689162244968, \n-340.413286984334, -62.1267764365396, -355.118323809515, -242.12677643654, \n-150.835726181628, -236.272600182985, -211.158141864945, -13.2008989303128, \n-308.915970069498, -289.632187536632, -278.887096630962, -128.915970069498, \n-307.425430254133, -127.425430254133, -2.31892936272919, -293.295641026572, \n-110.559590103871, -160.413286984334, -98.8870966309619, -311.133266173703, \n-337.093867711656, -113.295641026572, -175.118323809515, -193.200898930313, \n-270.112144711814, -254.551570017635, -184.228212914633, -356.689162244968, \n-344.025076998768, -164.025076998768, -116.516820542819, -157.093867711656, \n-258.023062517049, -131.133266173703, -296.516820542819, -194.632158331805, \n-353.647234845187, -5.94435093364956, -173.647234845187, -354.47057944274, \n-299.93105205524, -174.47057944274, -338.515646523367, -158.515646523367, \n-222.552685184285, -134.689325320837, -44.1027095779897, -349.898106854639, \n-59.4391589754227, -352.607970321607, -119.93105205524, -42.5526851842851, \n-94.2568492391647, -274.256849239165, -20.597172524&gt;\n\n\nCode\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\np &lt;- plotMetricPerFov(res, correction = \"bordm\", theo = TRUE, x = \"phi\", image_id = 'sample_id')\np\n\n\n\n\n\nThe values of \\(\\phi\\) correspond to the orientation of the original point pattern. The horizontal axis goes from \\(180\\) to \\(0\\) (left to right) and the vertical from \\(90\\) to \\(270\\) (top to bottom)\nan easier representation of the above metric can be plotted as a rose diagram\n\n\nCode\npar(1,3)\n\n\n[[1]]\nNULL\n\n[[2]]\nNULL\n\n\nCode\nlapply(pp, function(x){rose(nnorient(x))})\n\n\n\n\n\n\n\n\n\n\n\n$`-0.09`\nwindow: rectangle = [-0.004850711, 0.004850711] x [-0.004850711, 0.004850711] \nunits\n\n$`0.01`\nwindow: rectangle = [-0.005200848, 0.005200848] x [-0.005200848, 0.005200848] \nunits\n\n$`0.21`\nwindow: rectangle = [-0.004397865, 0.004397865] x [-0.004397865, 0.004397865] \nunits\n\n\nCode\ndev.off()\n\n\nnull device \n          1 \n\n\nThe two plots are complementary and show which are the preferred orientations of the point patterns. Furthermore, they show whether or not the assumption of isotropy (no change in the statistical properties of a point pattern after rotations) is justified or not (Baddeley, Rubak, and Turner 2015, 236 ff.). Isotropy is an assumption that a lot of spatial metrics make and in our example we note, that the point patterns are in fact anisotropic. An option for analysing anisotropic stationary point patterns is to not calculate the metric on the actual point pattern but rather calculating it on the fry plot of the point pattern. This generalises e.g. Ripley’s \\(K\\) function from circles to arbitrary shapes (Baddeley, Rubak, and Turner 2015, 239 ff.).\nNote also that the concepts of spacing are not only usable in point pattern analysis but also more broadly in other spatial contexts (e.g., spacing between shapes instead of points) (Baddeley, Rubak, and Turner 2015, 279 ff.).\n\n\n\nThe same consideration about edge effects as for the \\(K\\) (and related) functions need to be made for the spacing functions; uncorrected estimates are negatively biased estimators. The easiest approach is to draw an artificial border and consider NNs within it. Other approaches are based on sampling. Yet another approach relates to survival analysis, with the idea is that a circle of a point to grows homogeneously with increasing radius until it hits the frame of the window and “dies”. This gives survival distributions similar to censored data, where the Kaplan-Meier estimator is the optimal choice (Baddeley, Rubak, and Turner 2015, 285–92)."
  },
  {
    "objectID": "01-cell-univar-point.html#setup-1",
    "href": "01-cell-univar-point.html#setup-1",
    "title": "Discrete Marks",
    "section": "Setup",
    "text": "Setup\n\n\nCode\n# redefine the pp here to be zstack 0.01\npp &lt;- pp[['0.01']]\nsub &lt;- spe[, spe$sample_id == '0.01']\n\n\nIn spatstat, a mark can basically take any value, discrete (e.g. cell types, as we have seen above) or continuous (e.g., gene expression) (Baddeley, Rubak, and Turner 2015, 637 ff.). In our example, we take the gene expression of some marker genes from Fig. 6 of the original publication (Moffitt et al. 2018). This is a typical numerical mark for points in a biological dataset.\n\n\nCode\n#  Genes from Fig. 6 of Moffitt et al. (2018)\ngenes &lt;- c('Slc18a2', 'Esr1', 'Pgr')\ngex &lt;- assay(sub)[genes,] %&gt;% t %&gt;% as.matrix %&gt;% \n  data.frame %&gt;% set_rownames(NULL)\n# gene expression to marks\ncolData(sub) &lt;- colData(sub) %&gt;% cbind(gex)\nmarks(pp) &lt;- gex\n\n\n\n\nCode\nplot(pp)\n\n\n\n\n\nHere we see spatial distribution of the counts of the three genes Slc18a2, Esr1 and Pgr. The size of the circles indicates the counts of the transcripts at that spot. Since there are really a lot of points, we can’t easily distinguish general patterns of count distributions.\nThe function pairs from spatstat generates a scatterplot of the counts of the marks (in our case the three genes) against each other and against the \\(x\\) and \\(y\\) coordinates. We can add a non-linear smoothing curve to make the general trends a bit more obvious (Baddeley, Rubak, and Turner 2015, 641).\n\n\nCode\npairs(as.data.frame(pp), panel = panel.smooth, pch=\".\")\n\n\n\n\n\nWe find that the counts of the three genes are very evenly distributed along the \\(x\\) and \\(y\\) coordinate, indicating a homogeneous distribution. The counts of Esr1 and Pgr are positively associated, indicating a dependence of these two marks.\nNN interpolations uses the nearest mark to measure the intensity at each spatial location. This is conceptually similar to taking a very small bandwidth for Gaussian kernel smoothing (Baddeley, Rubak, and Turner 2015, 642).\n\n\nCode\nplot(nnmark(pp))\n\n\n\n\n\nWe see that there is e.g. a clear spatial structure in the expression of e.g. Esr1. It shows a half moon shape."
  },
  {
    "objectID": "01-cell-univar-point.html#summary-functions-for-continuous-marks",
    "href": "01-cell-univar-point.html#summary-functions-for-continuous-marks",
    "title": "Discrete Marks",
    "section": "Summary functions for continuous marks",
    "text": "Summary functions for continuous marks\nAs in the discrete case, summary functions assume that the point process is stationary.\n\nMark correlation function\nThe mark correlation function measures the dependence between two marks for two points at distance \\(r\\). It is applicable to stationary point processes with marks. The generalized mark correlation function is given by:\n\\[ k_f(r) = \\frac{\\mathbb{E}[f(m(u),m(v))]}{\\mathbb{E}[f(M,M')]},\\]\nwhere \\(f(m(u),m(v))\\) is a test function with two arguments (representing the two marks at locations \\(u\\) and \\(v\\)) and returns a non-negative value. For continuous non-negative marks, the canonical choice for \\(f\\) is typically \\(f(m(u),m(v))= m(u)m(v)\\). \\(M\\) and \\(M′\\) represent independent, identically distributed random points with the same distribution as the mark of a randomly chosen point. This denominator is chosen such that random marks have a mark correlation of 1 (Baddeley, Rubak, and Turner 2015, 644–45).\n\n\nCode\nres &lt;- calcMetricPerFov(sub, 'OD Mature', subsetby = genes, fun = 'markcorr',  marks = genes, r_seq=NULL, by = c('Animal_ID','sample_id'), continuous = TRUE)\np &lt;- plotMetricPerFov(res, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'gene')\np\n\n\n\n\n\nFrom this plot we show that all genes show a positive correlation at small distances which decline with increasing radius \\(r\\). The association is strongest for the Slc18a2 gene. We can calculate simulation envelopes to estimate the significance of this association. This is not shown for brevity.\n\n\nMark-weighted \\(K\\)-function\nThe mark-weigthed \\(K\\)-function is a generalization of the \\(K\\)-function in which the contribution from each pair of points is weighted by a function of their respective marks. It is given by:\n\\[K_f(r) = \\frac 1  \\lambda \\frac{C_f(r)}{E[ f(M_1, M_2) ]},\\] where:\n\\[ C_f(r) = E \\left[ \\sum_{x \\in X} f(m(u), m(x)) 1\\{0 &lt; ||u - x|| \\le r\\} \\;  \\big| \\; u \\in X \\right], \\]\nis equivalent to the unnormalized mark-weighted \\(K\\)-function. For every point \\(u\\), we sum the euclidean distance \\(||u - x||\\) of all other points \\(x\\) that are within a distance \\(r\\). This sum is weighted by the function \\(f(.,.)\\) of the marks of \\(u\\) and \\(x\\). The function is standardized by the expected value of \\(f(M_1, M_2)\\) where \\(M_1, M_2\\) represent independent, identically distributed random points with the same distribution as the mark of a randomly chosen point (Baddeley, Rubak, and Turner 2015, 646–47).\nIn the scenario of random labeling, so where the marks are distributed randomly, the mark-weighted \\(K\\)-function corresponds to the standard Ripley’s \\(K\\)-function.\nAlso here, the canonical function is: \\(f(m_1, m_2) = m_1 m_2\\). This means we weigh each interaction between points by the product of the continuous marks of both points.\n\n\nCode\nres &lt;- calcMetricPerFov(sub, 'OD Mature', subsetby = genes, fun = 'Kmark',  marks = genes, r_seq=NULL, by = c('Animal_ID','sample_id'), continuous = TRUE) \np &lt;- plotMetricPerFov(res, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'gene')\np\n\n\n\n\n\nIt is important to note that the theoretical value of the \\(K\\)-function is not very informative since it represents the \\(K\\)-function of a Poisson point process and the underlying point process might not be Poisson. Therefore we compare the mark-weighted with its unmarked analogue. Like this, we can assess whether the points weighted by a continuous mark are more or less correlated than their unmarked analogues (Baddeley, Rubak, and Turner 2015, 647).\nHere we will compare the \\(L\\)-functions weighted by the mark of the gene Esr1 and the unmarked \\(L\\)-function.\n\n\nCode\nppEsr1 &lt;- subset(pp, select = 'Esr1')\nL.Esr1L &lt;- Kmark(ppEsr1, function(m1,m2) {m1*m2}, returnL = TRUE)\nLest.ppEsr1 &lt;- Lest(ppEsr1, nlarge=7000)\nplot(eval.fv(L.Esr1L - Lest.ppEsr1))\n\n\n\n\n\nWe note that the difference between \\(L\\)-function weighted by the expression of Esr1 minus the unmarked \\(L\\)-function is positively different to the poisson difference, meaning that the expression of the continuous mark Esr1 is correlated among itself."
  },
  {
    "objectID": "01-cell-univar-point.html#session-info",
    "href": "01-cell-univar-point.html#session-info",
    "title": "Discrete Marks",
    "section": "Session info",
    "text": "Session info\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] spatialFDA_0.99.0              magrittr_2.0.3                \n [3] stringr_1.5.0                  dixon_0.0-8                   \n [5] splancs_2.01-44                spdep_1.2-8                   \n [7] spData_2.3.0                   tmap_3.3-4                    \n [9] scater_1.28.0                  scran_1.28.2                  \n[11] scuttle_1.10.3                 SFEData_1.2.0                 \n[13] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[15] rgeoda_0.0.10-4                digest_0.6.33                 \n[17] ncf_1.3-2                      sf_1.0-16                     \n[19] reshape2_1.4.4                 patchwork_1.2.0               \n[21] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[23] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[25] dbplyr_2.3.4                   RANN_2.6.1                    \n[27] seg_0.5-7                      sp_2.1-1                      \n[29] rlang_1.1.1                    ggplot2_3.5.1                 \n[31] dplyr_1.1.3                    mixR_0.2.0                    \n[33] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[35] spatstat.model_3.2-6           rpart_4.1.19                  \n[37] spatstat.explore_3.2-3         nlme_3.1-162                  \n[39] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[41] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[43] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[45] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[47] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[49] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[51] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] grpreg_3.4.0                  tools_4.3.1                  \n  [7] utf8_1.2.3                    R6_2.5.1                     \n  [9] HDF5Array_1.28.1              mgcv_1.9-1                   \n [11] rhdf5filters_1.12.1           withr_2.5.1                  \n [13] gridExtra_2.3                 leaflet_2.2.0                \n [15] textshaping_0.3.7             leafem_0.2.3                 \n [17] cli_3.6.1                     labeling_0.4.3               \n [19] mvtnorm_1.2-5                 proxy_0.4-27                 \n [21] systemfonts_1.0.5             R.utils_2.12.2               \n [23] dichromat_2.0-0.1             scico_1.5.0                  \n [25] limma_3.56.2                  rstudioapi_0.15.0            \n [27] RSQLite_2.3.1                 generics_0.1.3               \n [29] crosstalk_1.2.0               Matrix_1.5-4.1               \n [31] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [33] abind_1.4-5                   R.methodsS3_1.8.2            \n [35] terra_1.7-55                  lifecycle_1.0.3              \n [37] yaml_2.3.7                    edgeR_3.42.4                 \n [39] rhdf5_2.44.0                  tmaptools_3.1-1              \n [41] grid_4.3.1                    blob_1.2.4                   \n [43] promises_1.2.1                dqrng_0.3.1                  \n [45] crayon_1.5.2                  lattice_0.21-8               \n [47] beachmat_2.16.0               KEGGREST_1.40.1              \n [49] magick_2.8.0                  refund_0.1-35                \n [51] pillar_1.9.0                  knitr_1.44                   \n [53] metapod_1.7.0                 rjson_0.2.21                 \n [55] boot_1.3-28.1                 fda_6.1.8                    \n [57] codetools_0.2-19              wk_0.8.0                     \n [59] glue_1.6.2                    vctrs_0.6.4                  \n [61] png_0.1-8                     gtable_0.3.4                 \n [63] ks_1.14.2                     cachem_1.0.8                 \n [65] xfun_0.40                     S4Arrays_1.0.6               \n [67] mime_0.12                     DropletUtils_1.20.0          \n [69] pracma_2.4.2                  fds_1.8                      \n [71] pcaPP_2.0-4                   pbs_1.1                      \n [73] units_0.8-4                   statmod_1.5.0                \n [75] bluster_1.10.0                interactiveDisplayBase_1.38.0\n [77] ellipsis_0.3.2                bit64_4.0.5                  \n [79] filelock_1.0.2                irlba_2.3.5.1                \n [81] vipor_0.4.5                   KernSmooth_2.23-21           \n [83] colorspace_2.1-0              DBI_1.1.3                    \n [85] raster_3.6-26                 tidyselect_1.2.0             \n [87] bit_4.0.5                     compiler_4.3.1               \n [89] curl_5.1.0                    BiocNeighbors_1.18.0         \n [91] DelayedArray_0.26.7           scales_1.3.0                 \n [93] classInt_0.4-10               rappdirs_0.3.3               \n [95] goftest_1.2-3                 rainbow_3.8                  \n [97] minqa_1.2.7                   fftwtools_0.9-11             \n [99] spatstat.utils_3.0-5          rmarkdown_2.25               \n[101] XVector_0.40.0                htmltools_0.5.6.1            \n[103] pkgconfig_2.0.3               base64enc_0.1-3              \n[105] lme4_1.1-35.4                 sparseMatrixStats_1.12.2     \n[107] fastmap_1.1.1                 htmlwidgets_1.6.2            \n[109] RLRsim_3.1-8                  shiny_1.7.5.1                \n[111] DelayedMatrixStats_1.22.6     farver_2.1.1                 \n[113] jsonlite_1.8.7                mclust_6.1.1                 \n[115] BiocParallel_1.34.2           R.oo_1.25.0                  \n[117] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[119] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[121] Rhdf5lib_1.22.1               munsell_0.5.0                \n[123] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[125] viridis_0.6.4                 stringi_1.7.12               \n[127] leafsync_0.1.0                MASS_7.3-60                  \n[129] zlibbioc_1.46.0               plyr_1.8.9                   \n[131] parallel_4.3.1                ggrepel_0.9.4                \n[133] deldir_1.0-9                  Biostrings_2.68.1            \n[135] stars_0.6-4                   splines_4.3.1                \n[137] tensor_1.5                    locfit_1.5-9.8               \n[139] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[141] magic_1.6-1                   BiocVersion_3.17.1           \n[143] XML_3.99-0.14                 evaluate_0.22                \n[145] BiocManager_1.30.22           deSolve_1.40                 \n[147] nloptr_2.1.1                  httpuv_1.6.11                \n[149] tidyr_1.3.0                   purrr_1.0.2                  \n[151] polyclip_1.10-6               rsvd_1.0.5                   \n[153] lwgeom_0.2-13                 xtable_1.8-4                 \n[155] e1071_1.7-13                  RSpectra_0.16-1              \n[157] later_1.3.1                   ragg_1.2.6                   \n[159] viridisLite_0.4.2             class_7.3-22                 \n[161] tibble_3.2.1                  memoise_2.0.1                \n[163] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[165] gamm4_0.2-6                   cluster_2.1.4                \n[167] hdrcde_3.4"
  },
  {
    "objectID": "03-cell-multivar-point.html",
    "href": "03-cell-multivar-point.html",
    "title": "Discrete Marks",
    "section": "",
    "text": "Code\nsource(\"utils.R\")\n\n\n\n\n\n\n\nCode\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#subset the data to only look at sample ID 0.01, 0.06 and 0.26\n# list(\"-0.29\", \"0.01\", \"0.06\")\n#zstack_list &lt;- list(\"-0.04\", '-0.09', '-0.14', '-0.19', '-0.24', '-0.29', '0.01', '0.06', '0.11', '0.16', '0.21', \"0.26\")\n\n#define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n\n#define the celltype that you want to compare across the stacks - hereby we assume independence across the z-stacks which is an assumption that can be challenged\ncelltype_ls &lt;- \"OD Mature\"\n\nselectZstacks &lt;- function(zstack, spe){\n  sub &lt;- spe[, spe$sample_id == zstack]\n  pp &lt;- .ppp(sub, marks = \"cluster_id\")\n  return(pp)\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe)\nnames(pp_ls) &lt;- zstack_list\n\n\nThe theory of spatial point patterns is discussed in great detail in (Baddeley, Rubak, and Turner 2015). The book has an accompanying package called spatstat which offers great functionality to the theoretical concepts discribed in the book (Baddeley and Turner 2005). This chapter relies heavily on both publications.\n\n\n\n\n\nIn point pattern analysis we assume that the patterns we observe are a realisation of a stochastic process called a point process. The inferences we make about the point pattern are based on the point process. E.g. the pattern can be said to be created by a Poisson point process and thus is evenly distributed in the observation window (Baddeley, Rubak, and Turner 2015, 127).\nWhen considering a pattern with \\(m\\) multiple types, as we do in the (Moffitt et al. 2018) dataset, there are two very closely related concepts. One can view the pattern as a multitype point pattern, where all the points are sampled from the same point process. The other option is to consider the pattern as a multivariate point pattern, where the points come from \\(m\\) distinct point processes. The difference between these two views is that in the multitype framework we assume the points to stem from the same point process. In the multivariate framework we assume that the types stem from distinct point processes and therefore we can consider dependencies of one type alone. Whether or not the patterns stem from the same point process depends on the biological question. If we analyse two celltypes in one slice of a tissue, we should consider them as being sampled from one point process. However, if we consider the distribution of a celltype in two slices of the same tissue we can have grounds to consider them as distinct processes (Baddeley, Rubak, and Turner 2015, 565).\n\n\n\nThe most common set up in point pattern analysis is what we call window sampling. Instead of observing the entire pattern we observe a subset of this pattern in the so called window. In the analysis we try to make inferences on the entire point process based on the observed window. An example could be different small microscopy windows through which a big tissue slice is observed. The windows would be samples of the bigger point process. In this case, it would be wrong to assume the window to be the convex hull around the observed points because they are just a sample of the bigger point pattern (Baddeley, Rubak, and Turner 2015, 143–45).\nThere is another concept called the small world model. It assumes that points can only be observed in a finite small world and not beyond these boundaries. When thinking of an entire tissue, this is a very common scenario. Cells can only be observed within the tissue and not beyond. In this case, it would be correct to not assume a rectangular observation window but to use more conservative methods to estimate an unknown sampling window such as the Ripley-Rasson estimate of a spatial domain (Baddeley, Rubak, and Turner 2015, 144–45).\nIn both cases it is important to understand the direction of the bias. If the unknown window is estimated to be smaller than the true window, we underestimate the window. This then again leads to an overestimation of the density of points and to other characteristics of the pattern. Therefore, an underestimation of the window size is more concerning than a slight overestimation (Baddeley, Rubak, and Turner 2015, 144–45).\n\n\nCode\nsetRiprasWindows &lt;- function(pp){\n  Window(pp) &lt;- ripras(pp)\n  return(pp)\n}\n#the entire point patterns with the ripras windows\npp &lt;- lapply(pp_ls, setRiprasWindows)\n\nseparateMarks &lt;- function(pp){\n  #split the multitype point process into several single type processes\n  ppls &lt;- split(pp)\n  return (ppls)\n}\n#the point patterns separated by their marks\npp_ls &lt;- lapply(pp, separateMarks)\n\n\n\n\n\nComplete spatial randomness (CSR) is often used as the null model for various point patterns. It is the result of a Poisson process. A completely spatial random process is characterised by two properties, homogeneity and independence, as discussed below (Baddeley, Rubak, and Turner 2015, 132).\n\n\n“Homogeneity […] means that the expected number of points falling in a region B should be proportional to its area |B|” (Baddeley, Rubak, and Turner 2015, 132) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) represents the intensity of the process, i.e., the average number of points in a unit area (Baddeley, Rubak, and Turner 2015, 132–33). :\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|.\n\\label{eq:expected_number_points}\n\\]\n\n\n\nIndependence implies that in two (non-overlapping) regions \\(A\\) and \\(B\\), the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are independent random variables. In other words, the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). In addition, the number of points, \\(N = n(X\\cap B)\\), follows a Poisson distribution:\n\\[\n\\mathbb{P}[N=k] = e^{-\\mu}\\frac{\\mu^k}{k!}\\\\\n\\label{eq:poisson_process}\n\\] where \\(k = \\lambda |B|\\) (Baddeley, Rubak, and Turner 2015, 133).\n\n\n\n\nA Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density, \\(\\lambda(u)\\), sometimes known as the intensity function (see below), is a function of the spatial location \\(u\\). In this case, the expected number of points falling into a region \\(B\\), \\(\\mu = n(X\\cap B)\\), is an integration of the intensity function over that region (Baddeley, Rubak, and Turner 2015, 138).\n\\[\n\\mu = \\int_{B} \\lambda(u) du.\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\n\nA point process is called isotropic, if its statistical properties are invariant to rotations; a CSR process is both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 147).\n\n\n\n“A point process is called stationary if, when we view the process through a window W , its statistical properties do not depend on the location of the window in two-dimensional space.” (Baddeley, Rubak, and Turner 2015, 146). This is the case for any homogeneous point process, where the statistical properties of the pattern are unchanged given shifting of the observation window. This means it is stationary in all statistical properties; first-order properties (e.g. intensity) and second-order properties (e.g. correlation) (Baddeley, Rubak, and Turner 2015, 218). Not all metrics assume stationarity in its full sense. Inhomogeneous metrics only assume second-order / correlation stationarity. That means while the intensity function can vary spatially (first-order stationarity is not given), the estimates of correlation functions (e.g. the inhomogeneous K-function) should be the same in parts of the window (Baddeley, Rubak, and Turner 2015, 689).\n\n\n\nIf a process is not correlation stationary, so the estimates of the inhomogeneous metric vary between locations, locally-scaled versions of the metric can be applicable. This means in small subregions, the process is still stationary and isotropic, but there is a rescaling factor that can vary across the total process (Baddeley, Rubak, and Turner 2015, 246–47).\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimated functions between the quadrats. It should be noted that this test depends on the arbitrary definition of the quadrats. Given our chosen patterns are not independent but result as marks from an overall point-pattern, the permutation approach is questionable. Therefore, the interpretation can be difficult (Baddeley, Rubak, and Turner 2015, 689–93).\n\n\nCode\npermutation_test &lt;- function(pp, mark, split, minpoints) {\n  pp_sel &lt;-  subset(pp, marks %in% mark, drop = TRUE)\n  \n  rho_est &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\n  lambda &lt;- predict(rho_est)\n\n  tesselation &lt;- quantess(unmark(pp_sel), \"x\", 3)\n  tesselation_split &lt;- nestsplit(pp_sel, tesselation, ny=split)\n  \n  plot(tesselation_split, main = mark)\n  \n  tesselation_split$inten &lt;- factor(as.integer(tesselation_split$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n  \n  res.scaled &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kscaled,\n                 minpoints = minpoints)\n  \n  res.inhom &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kinhom,\n                 lambda=lambda, minpoints = minpoints)\n  \n  #p-value of the local-scaling test\n  print(paste0(mark,' local scaling test ', res.scaled$p.value))\n  \n  #p-value of the inhomogeneity test\n  print(paste0(mark,' inhomogeneity test ', res.inhom$p.value))\n}\nlapply(c(\"Microglia\", \"OD Mature\", \"Ependymal\"), function(x) permutation_test(pp[['0.01']], x, split = 3, minpoints = 10))\n\n\nThe p-value of the test for local scaling for microglia cells is \\(&lt;0.05\\) which indicates that the assumption of local scaling is rejected. Therefore, the distribution of microglia cells is not a scaled version of an overall distribution pattern. The p-value of the test for inhomogeneity for both microglia cells is \\(&gt;0.05\\) indicating that the assumption of correlation stationarity is not rejected. In this case we can use the inhomogeneous version of the K-function which assumes correlation stationarity.\nFor ependymal and OD mature cells however, the p-values for both the local scaling test and the inhomogeneity test are \\(&gt;0.05\\) which means that both the correlation stationarity assumption and the local scaling assumption can’t be rejected. [ME: Does this make sense? Or is this just an artifact?]\nAs the interpretation of the permutation test is highly dependent on the quadrats, the results should be interpreted with care. Both inhomogeneous and locally scaled versions of the summary functions have support and both offer interesting insights into the spatial pattern. Therefore, we will compare all versions and show what the choice of metrics means for their interpretation.\n\n\n\nIntensity is the expected density of points per unit area. It can be interpreted as the rate of occurrence or the abundance of events recorded. The intensity represents a first order property because it is related to the expected number of points. More formally the average intensity of a point process is defined as:\n\\[\n\\bar{\\lambda} = \\frac{n(x)}{|W|}\n\\label{eq:average_intensity}\n\\]\nAs this is an average over the entire window, it only really makes sense for a homogeneous point process (Baddeley, Rubak, and Turner 2015, 157–60)\n\n\nFor a homogeneous point process, the intensity can be estimated in a simplistic way: summing the individual intensities of the marks (Baddeley, Rubak, and Turner 2015, 161).\n\n\nCode\nintensityPointProcess &lt;- function(pp,mark) if(mark) intensity(pp) else sum(intensity(pp))\n\nintensityPointProcess(pp_ls[['0.01']], mark = FALSE) %&gt;% round(6)\n\n\n[1] 0.001909\n\n\nOtherwise, we can compute the intensity for each mark individually.\n\n\nCode\nintensityPointProcess(pp_ls[['0.01']], mark = TRUE) %&gt;% round(8)\n\n\n  Ambiguous   Astrocyte Endothelial   Ependymal  Excitatory  Inhibitory \n 0.00024151  0.00020183  0.00014653  0.00008373  0.00036867  0.00061393 \n  Microglia OD Immature   OD Mature   Pericytes \n 0.00003031  0.00006249  0.00014278  0.00001750 \n\n\n\n\n\nIn kernel estimation, we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There are a wide variety of kernel estimators (see (Baddeley, Rubak, and Turner 2015, 168)), but a popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth (Baddeley, Rubak, and Turner 2015, 168).\n\n\nCode\npp_sel &lt;-  subset(pp_ls[['0.01']]$`OD Mature`, drop = TRUE)\nDens &lt;- density(pp_sel, sigma = 100)\nplot(Dens, main = 'Kernel Density (OD Mature cells)')\n\n\n\n\n\n\n\n\nIn quadrat counting, all points falling into a given quadrat are counted. This gives an overview on the characteristics of the point pattern, such as correlation stationarity (Baddeley, Rubak, and Turner 2015, 163).\n\n\nCode\nQ5 &lt;- quadratcount(pp_ls[['0.01']], nx=8, ny=8)\nplot(unmark(pp[['0.01']]), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\nUnder independence assumptions, the quadrat counts can be used for testing homogeneity, i.e., whether the points are distributed evenly across the quadrats (Baddeley, Rubak, and Turner 2015, 164–65).\n\n\nCode\nval &lt;- quadrat.test(pp_ls[['0.01']]$`OD Mature`, 5, alternative=\"regular\", method=\"MonteCarlo\")\nval\n\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nX2 = 635.09, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 25 tiles (irregular windows)\n\n\nA p-value of 1 indicates that the null hypothesis of irregularity can not be rejected strongly. Thus, the point pattern of oligodendrocyts is strongly irregular.\nAlternatively, we can inspect departures from the hypothesis that points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types (Buller 2020).\n\n\nCode\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp[['0.01']], marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\n\nWhether or not a point process is completely spatially random (CSR) depends on two characteristics: points need to be distributed homogeneously and they have to be independent of each other (see definitions above). There are various ways to test for CSR, here we show the use-case of the clark-evans test (Baddeley, Rubak, and Turner 2015, 165–66).\n\n\nCode\nclarkevans.test(pp_ls[['0.01']]$`OD Mature`)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nR = 0.77286, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "03-cell-multivar-point.html#dependencies",
    "href": "03-cell-multivar-point.html#dependencies",
    "title": "Discrete Marks",
    "section": "",
    "text": "Code\nsource(\"utils.R\")"
  },
  {
    "objectID": "03-cell-multivar-point.html#setup",
    "href": "03-cell-multivar-point.html#setup",
    "title": "Discrete Marks",
    "section": "",
    "text": "Code\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#subset the data to only look at sample ID 0.01, 0.06 and 0.26\n# list(\"-0.29\", \"0.01\", \"0.06\")\n#zstack_list &lt;- list(\"-0.04\", '-0.09', '-0.14', '-0.19', '-0.24', '-0.29', '0.01', '0.06', '0.11', '0.16', '0.21', \"0.26\")\n\n#define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n\n#define the celltype that you want to compare across the stacks - hereby we assume independence across the z-stacks which is an assumption that can be challenged\ncelltype_ls &lt;- \"OD Mature\"\n\nselectZstacks &lt;- function(zstack, spe){\n  sub &lt;- spe[, spe$sample_id == zstack]\n  pp &lt;- .ppp(sub, marks = \"cluster_id\")\n  return(pp)\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe)\nnames(pp_ls) &lt;- zstack_list\n\n\nThe theory of spatial point patterns is discussed in great detail in (Baddeley, Rubak, and Turner 2015). The book has an accompanying package called spatstat which offers great functionality to the theoretical concepts discribed in the book (Baddeley and Turner 2005). This chapter relies heavily on both publications."
  },
  {
    "objectID": "03-cell-multivar-point.html#concepts-and-definitions-of-point-processes",
    "href": "03-cell-multivar-point.html#concepts-and-definitions-of-point-processes",
    "title": "Discrete Marks",
    "section": "",
    "text": "In point pattern analysis we assume that the patterns we observe are a realisation of a stochastic process called a point process. The inferences we make about the point pattern are based on the point process. E.g. the pattern can be said to be created by a Poisson point process and thus is evenly distributed in the observation window (Baddeley, Rubak, and Turner 2015, 127).\nWhen considering a pattern with \\(m\\) multiple types, as we do in the (Moffitt et al. 2018) dataset, there are two very closely related concepts. One can view the pattern as a multitype point pattern, where all the points are sampled from the same point process. The other option is to consider the pattern as a multivariate point pattern, where the points come from \\(m\\) distinct point processes. The difference between these two views is that in the multitype framework we assume the points to stem from the same point process. In the multivariate framework we assume that the types stem from distinct point processes and therefore we can consider dependencies of one type alone. Whether or not the patterns stem from the same point process depends on the biological question. If we analyse two celltypes in one slice of a tissue, we should consider them as being sampled from one point process. However, if we consider the distribution of a celltype in two slices of the same tissue we can have grounds to consider them as distinct processes (Baddeley, Rubak, and Turner 2015, 565).\n\n\n\nThe most common set up in point pattern analysis is what we call window sampling. Instead of observing the entire pattern we observe a subset of this pattern in the so called window. In the analysis we try to make inferences on the entire point process based on the observed window. An example could be different small microscopy windows through which a big tissue slice is observed. The windows would be samples of the bigger point process. In this case, it would be wrong to assume the window to be the convex hull around the observed points because they are just a sample of the bigger point pattern (Baddeley, Rubak, and Turner 2015, 143–45).\nThere is another concept called the small world model. It assumes that points can only be observed in a finite small world and not beyond these boundaries. When thinking of an entire tissue, this is a very common scenario. Cells can only be observed within the tissue and not beyond. In this case, it would be correct to not assume a rectangular observation window but to use more conservative methods to estimate an unknown sampling window such as the Ripley-Rasson estimate of a spatial domain (Baddeley, Rubak, and Turner 2015, 144–45).\nIn both cases it is important to understand the direction of the bias. If the unknown window is estimated to be smaller than the true window, we underestimate the window. This then again leads to an overestimation of the density of points and to other characteristics of the pattern. Therefore, an underestimation of the window size is more concerning than a slight overestimation (Baddeley, Rubak, and Turner 2015, 144–45).\n\n\nCode\nsetRiprasWindows &lt;- function(pp){\n  Window(pp) &lt;- ripras(pp)\n  return(pp)\n}\n#the entire point patterns with the ripras windows\npp &lt;- lapply(pp_ls, setRiprasWindows)\n\nseparateMarks &lt;- function(pp){\n  #split the multitype point process into several single type processes\n  ppls &lt;- split(pp)\n  return (ppls)\n}\n#the point patterns separated by their marks\npp_ls &lt;- lapply(pp, separateMarks)\n\n\n\n\n\nComplete spatial randomness (CSR) is often used as the null model for various point patterns. It is the result of a Poisson process. A completely spatial random process is characterised by two properties, homogeneity and independence, as discussed below (Baddeley, Rubak, and Turner 2015, 132).\n\n\n“Homogeneity […] means that the expected number of points falling in a region B should be proportional to its area |B|” (Baddeley, Rubak, and Turner 2015, 132) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) represents the intensity of the process, i.e., the average number of points in a unit area (Baddeley, Rubak, and Turner 2015, 132–33). :\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|.\n\\label{eq:expected_number_points}\n\\]\n\n\n\nIndependence implies that in two (non-overlapping) regions \\(A\\) and \\(B\\), the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are independent random variables. In other words, the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). In addition, the number of points, \\(N = n(X\\cap B)\\), follows a Poisson distribution:\n\\[\n\\mathbb{P}[N=k] = e^{-\\mu}\\frac{\\mu^k}{k!}\\\\\n\\label{eq:poisson_process}\n\\] where \\(k = \\lambda |B|\\) (Baddeley, Rubak, and Turner 2015, 133).\n\n\n\n\nA Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density, \\(\\lambda(u)\\), sometimes known as the intensity function (see below), is a function of the spatial location \\(u\\). In this case, the expected number of points falling into a region \\(B\\), \\(\\mu = n(X\\cap B)\\), is an integration of the intensity function over that region (Baddeley, Rubak, and Turner 2015, 138).\n\\[\n\\mu = \\int_{B} \\lambda(u) du.\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\n\nA point process is called isotropic, if its statistical properties are invariant to rotations; a CSR process is both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 147).\n\n\n\n“A point process is called stationary if, when we view the process through a window W , its statistical properties do not depend on the location of the window in two-dimensional space.” (Baddeley, Rubak, and Turner 2015, 146). This is the case for any homogeneous point process, where the statistical properties of the pattern are unchanged given shifting of the observation window. This means it is stationary in all statistical properties; first-order properties (e.g. intensity) and second-order properties (e.g. correlation) (Baddeley, Rubak, and Turner 2015, 218). Not all metrics assume stationarity in its full sense. Inhomogeneous metrics only assume second-order / correlation stationarity. That means while the intensity function can vary spatially (first-order stationarity is not given), the estimates of correlation functions (e.g. the inhomogeneous K-function) should be the same in parts of the window (Baddeley, Rubak, and Turner 2015, 689).\n\n\n\nIf a process is not correlation stationary, so the estimates of the inhomogeneous metric vary between locations, locally-scaled versions of the metric can be applicable. This means in small subregions, the process is still stationary and isotropic, but there is a rescaling factor that can vary across the total process (Baddeley, Rubak, and Turner 2015, 246–47).\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimated functions between the quadrats. It should be noted that this test depends on the arbitrary definition of the quadrats. Given our chosen patterns are not independent but result as marks from an overall point-pattern, the permutation approach is questionable. Therefore, the interpretation can be difficult (Baddeley, Rubak, and Turner 2015, 689–93).\n\n\nCode\npermutation_test &lt;- function(pp, mark, split, minpoints) {\n  pp_sel &lt;-  subset(pp, marks %in% mark, drop = TRUE)\n  \n  rho_est &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\n  lambda &lt;- predict(rho_est)\n\n  tesselation &lt;- quantess(unmark(pp_sel), \"x\", 3)\n  tesselation_split &lt;- nestsplit(pp_sel, tesselation, ny=split)\n  \n  plot(tesselation_split, main = mark)\n  \n  tesselation_split$inten &lt;- factor(as.integer(tesselation_split$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n  \n  res.scaled &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kscaled,\n                 minpoints = minpoints)\n  \n  res.inhom &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kinhom,\n                 lambda=lambda, minpoints = minpoints)\n  \n  #p-value of the local-scaling test\n  print(paste0(mark,' local scaling test ', res.scaled$p.value))\n  \n  #p-value of the inhomogeneity test\n  print(paste0(mark,' inhomogeneity test ', res.inhom$p.value))\n}\nlapply(c(\"Microglia\", \"OD Mature\", \"Ependymal\"), function(x) permutation_test(pp[['0.01']], x, split = 3, minpoints = 10))\n\n\nThe p-value of the test for local scaling for microglia cells is \\(&lt;0.05\\) which indicates that the assumption of local scaling is rejected. Therefore, the distribution of microglia cells is not a scaled version of an overall distribution pattern. The p-value of the test for inhomogeneity for both microglia cells is \\(&gt;0.05\\) indicating that the assumption of correlation stationarity is not rejected. In this case we can use the inhomogeneous version of the K-function which assumes correlation stationarity.\nFor ependymal and OD mature cells however, the p-values for both the local scaling test and the inhomogeneity test are \\(&gt;0.05\\) which means that both the correlation stationarity assumption and the local scaling assumption can’t be rejected. [ME: Does this make sense? Or is this just an artifact?]\nAs the interpretation of the permutation test is highly dependent on the quadrats, the results should be interpreted with care. Both inhomogeneous and locally scaled versions of the summary functions have support and both offer interesting insights into the spatial pattern. Therefore, we will compare all versions and show what the choice of metrics means for their interpretation.\n\n\n\nIntensity is the expected density of points per unit area. It can be interpreted as the rate of occurrence or the abundance of events recorded. The intensity represents a first order property because it is related to the expected number of points. More formally the average intensity of a point process is defined as:\n\\[\n\\bar{\\lambda} = \\frac{n(x)}{|W|}\n\\label{eq:average_intensity}\n\\]\nAs this is an average over the entire window, it only really makes sense for a homogeneous point process (Baddeley, Rubak, and Turner 2015, 157–60)\n\n\nFor a homogeneous point process, the intensity can be estimated in a simplistic way: summing the individual intensities of the marks (Baddeley, Rubak, and Turner 2015, 161).\n\n\nCode\nintensityPointProcess &lt;- function(pp,mark) if(mark) intensity(pp) else sum(intensity(pp))\n\nintensityPointProcess(pp_ls[['0.01']], mark = FALSE) %&gt;% round(6)\n\n\n[1] 0.001909\n\n\nOtherwise, we can compute the intensity for each mark individually.\n\n\nCode\nintensityPointProcess(pp_ls[['0.01']], mark = TRUE) %&gt;% round(8)\n\n\n  Ambiguous   Astrocyte Endothelial   Ependymal  Excitatory  Inhibitory \n 0.00024151  0.00020183  0.00014653  0.00008373  0.00036867  0.00061393 \n  Microglia OD Immature   OD Mature   Pericytes \n 0.00003031  0.00006249  0.00014278  0.00001750 \n\n\n\n\n\nIn kernel estimation, we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There are a wide variety of kernel estimators (see (Baddeley, Rubak, and Turner 2015, 168)), but a popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth (Baddeley, Rubak, and Turner 2015, 168).\n\n\nCode\npp_sel &lt;-  subset(pp_ls[['0.01']]$`OD Mature`, drop = TRUE)\nDens &lt;- density(pp_sel, sigma = 100)\nplot(Dens, main = 'Kernel Density (OD Mature cells)')\n\n\n\n\n\n\n\n\nIn quadrat counting, all points falling into a given quadrat are counted. This gives an overview on the characteristics of the point pattern, such as correlation stationarity (Baddeley, Rubak, and Turner 2015, 163).\n\n\nCode\nQ5 &lt;- quadratcount(pp_ls[['0.01']], nx=8, ny=8)\nplot(unmark(pp[['0.01']]), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\nUnder independence assumptions, the quadrat counts can be used for testing homogeneity, i.e., whether the points are distributed evenly across the quadrats (Baddeley, Rubak, and Turner 2015, 164–65).\n\n\nCode\nval &lt;- quadrat.test(pp_ls[['0.01']]$`OD Mature`, 5, alternative=\"regular\", method=\"MonteCarlo\")\nval\n\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nX2 = 635.09, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 25 tiles (irregular windows)\n\n\nA p-value of 1 indicates that the null hypothesis of irregularity can not be rejected strongly. Thus, the point pattern of oligodendrocyts is strongly irregular.\nAlternatively, we can inspect departures from the hypothesis that points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types (Buller 2020).\n\n\nCode\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp[['0.01']], marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\n\nWhether or not a point process is completely spatially random (CSR) depends on two characteristics: points need to be distributed homogeneously and they have to be independent of each other (see definitions above). There are various ways to test for CSR, here we show the use-case of the clark-evans test (Baddeley, Rubak, and Turner 2015, 165–66).\n\n\nCode\nclarkevans.test(pp_ls[['0.01']]$`OD Mature`)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nR = 0.77286, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "03-cell-multivar-point.html#multitype-and-multivariate-viewpoint",
    "href": "03-cell-multivar-point.html#multitype-and-multivariate-viewpoint",
    "title": "Discrete Marks",
    "section": "Multitype and Multivariate viewpoint",
    "text": "Multitype and Multivariate viewpoint\nA pattern with multiple type of points, e.g. cell types, can be seen in different ways. One the one hand, the multitype approach assumes that the points \\(x\\) were recorded together with with their labels \\(m\\) and that they were generated at the same time. The locations and labels therefore have a joint distribution \\(P(X,M)\\). On the other hand one can assume that the pattern with multiple types of points is a combination of several distinct point patterns, one for each type of point. This is the multivariate approach and the different point patterns \\(A\\) and \\(B\\) form a joint distribution \\(P(A,B)\\). To test if the labels depend on the location one can assume the following null hypotheses (Baddeley, Rubak, and Turner 2015, 565–67):\n\ncomplete spatial randomness and independence (CSRI): the points are distributed at random; the type of each points is randomly allocated; independence between points of different types; allocation of the types independently of the other points and of its location.\nrandom labeling: each point is assigned a type at random independently of its location\nindependence of components: the points of different types are independent of each other.\n\nApart from CSRI is is also important for the analysis if we can assume stationarity, i.e. the statistical properties of the point pattern do not change in the window.\nFor simplicity, we will focus on three cell types of our point pattern: Ependymal, OD Mature and Microglia. This is appropriate if we assume that the point processes are independent. We could also assume that they come from the same process. In this case we have to check the stationarity assumption of the pattern.\n\n\nCode\nmarks(pp) &lt;- factor(marks(pp))\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\n\npp_sel &lt;-  subset(pp, marks %in% selection, drop = TRUE)\n\n\n\n\nCode\npp_sel |&gt; as.data.frame() |&gt; \n  ggplot(aes(x = x, y = y, color = marks)) +\n  geom_point() +\n  theme_minimal() +\n  coord_fixed() +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\nThe summary of pp (point pattern) object returns general properties, plus intensities, combined and per mark type.\n\n\nCode\nsummary(pp)\n\n\nMarked planar point pattern:  6111 points\nAverage intensity 0.001906561 points per square unit\n\nCoordinates are given to 4 decimal places\n\nMultitype:\n            frequency  proportion    intensity\nAmbiguous         773 0.126493200 2.411670e-04\nAstrocyte         646 0.105711000 2.015445e-04\nEndothelial       469 0.076746850 1.463225e-04\nEpendymal         268 0.043855340 8.361288e-05\nExcitatory       1180 0.193094400 3.681463e-04\nInhibitory       1965 0.321551300 6.130571e-04\nMicroglia          97 0.015873020 3.026287e-05\nOD Immature       200 0.032727870 6.239767e-05\nOD Mature         457 0.074783180 1.425787e-04\nPericytes          56 0.009163803 1.747135e-05\n\nWindow: rectangle = [1222.5635, 3012.4248] x [-3993.535, -2202.755] units\n                    (1790 x 1791 units)\nWindow area = 3205250 square units\n\n\nTo get the overall intensity the individual intensities can be summed up. Assuming that the the multitype process is first order stationary (i.e. each sub-process is stationary) the individual intensities sum up to the intensity of the unmarked point process (Baddeley, Rubak, and Turner 2015, 574ff.).\n\n\nCode\nsum(intensity(pp)) == intensity(unmark(pp))\n\n\n[1] TRUE\n\n\nThe stationarity assumption is not appropriate in all cases. To assess first-order stationarity visually, we can plot the kernel density estimates per type.\n\n\nCode\nppls &lt;- split(pp_sel) # split by mark\nplot(density(ppls))\n\n\n\n\n\nEpendymal and OD Mature cells are cleary inhomogeneous, while for Microglia cells it is not so clear and we could assume homogeneity, especially as there are no cells in the bottom middle of the window.\n\n\n\n\n\n\n\nTo further inverstiagte the spatial arrangement of the different cell types we can calculate the relative risk, i.e., the probability of observing a given celltype at a given location. It is calculated using the function relrisk. The bandwidth for smoothing is calculated with bw.relrisk and might need to be adjusted (Baddeley, Rubak, and Turner 2015, 577–83).\nThe relrisk function further gives us the dominant mark for different regions of the tissue of interest. This could be interesting in the annotation of spatial domains. It indicates at each location, which cell type is most likely to occur.\n\n\nCode\nrpd &lt;- relrisk(pp_sel, diggle = TRUE)\ndom &lt;- im.apply(rpd, which.max)\ndom &lt;- eval.im(factor(dom, levels = seq_along(levels(unique(marks(pp_sel)))),\n                      labels = levels(unique(marks(pp_sel)))))\nplot(dom,las=2,main=\"Dominant mark\")"
  },
  {
    "objectID": "03-cell-multivar-point.html#nearest-neighbourhood-contingency",
    "href": "03-cell-multivar-point.html#nearest-neighbourhood-contingency",
    "title": "Discrete Marks",
    "section": "Nearest neighbourhood contingency",
    "text": "Nearest neighbourhood contingency\nTo further investigate the spatial distribution of the marks we can investigate the nearest neighbourhood of each cell type. One possibility is to work with nearest neighborhood contingency tables developed by (Dixon 2002). The statistical tests are implemented in the R package dixon (Cruz 2008).\nThe measure of segregation \\(S\\) is defined in (Dixon 2002) as\n\\[S_{i,j}= \\frac{\\log[(N_{i,j}/(N_i−N_{i,j})]}{[(N_i−1)/(N−N_i)]}\\] where \\(N_i\\) is the number of individuals \\(i\\), \\(N_{i,j}\\) is the number of individuals of type \\(i\\) with a nearest neighbor of type \\(j\\), and \\(N\\) is the total number of individuals.\nA value of \\(S=0\\) is consistent with random labeling. A value larger than 0 indicates that the two types are more segregated than expected by chance, the larger the value the more segregated. Note that segregated means that it is more likely to expect a neigbour of type \\(j\\) than by chance. In the case that the neigbour is of the same type this is equivalent to “clustering”. On the other hand if \\(S&lt;0\\) it indicates that type \\(j\\) is less likely to be a neigbour than by chance. The P-values are calculated using expected numbers of nearest neighbors under the null hypothesis of random labeling using a Monte-Carlo simulation and assumes an asymptotic \\(\\chi^2\\) distribution.\n\n\nCode\nout &lt;- dixon(as.data.frame(pp_sel), nsim = 99)\n\n\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\n\nCode\nout$tablaZ %&gt;% \n  arrange(desc(abs(`Z `))) %&gt;%\n  select(-`  p-val.Nobs`)\n\n\n       From        To     Obs.Count     Exp. Count    S      Z    p-val.Z\n1 Ependymal Ependymal           262          87.16  1.96  20.04    0.0000\n2 Ependymal OD Mature             3         149.18 -2.04 -16.87    0.0000\n3 OD Mature Ependymal             8         149.18 -1.43 -14.26    0.0000\n4 OD Mature OD Mature           380         253.83  0.60  11.43    0.0000\n5 Ependymal Microglia             3          31.66 -1.07  -5.66    0.0000\n6 Microglia Ependymal             9          31.66 -0.68  -4.92    0.0000\n7 Microglia OD Mature            67          53.99  0.25   2.60    0.0094\n8 Microglia Microglia            21          11.34  0.32   2.50    0.0124\n9 OD Mature Microglia            69          53.99  0.12   2.35    0.0190\n\n\nIn this table we see that most Ependymal cells are very clustered, while Microglia are more evenly distributed. Further we see that it is less likely to find a Ependymal cells next to a OD mature cells than by chance.\nOD Mature cells show this interesting characteristic that they are clustered in some parts of the tissue and more evenly distributed in other parts of the structure. This characteristic is not visible in the table. The statistic also considers only the nearest neighbour and ignores neighbours that are further away."
  },
  {
    "objectID": "03-cell-multivar-point.html#summary-functions-for-pairs-of-types",
    "href": "03-cell-multivar-point.html#summary-functions-for-pairs-of-types",
    "title": "Discrete Marks",
    "section": "Summary functions for pairs of types",
    "text": "Summary functions for pairs of types\nSimilar to the simple case without marks, it is possible to estimate summary functions. In particular, summary functions between different marks can be calculated. Note that the canonical functions assume that the multi-type process is stationary.\n\nCross K-function\nThe cross K-function is a summary function that measures the average number of points of type j within a distance r of a point of type i. The formula is given by:\n\\[\nK(r) = \\frac{1}{\\lambda_j} \\mathbb{E} [t(u,r,X^{j})|u \\in X^{i}],\n\\]\nwhere \\(X^{i}\\) is the point pattern of type \\(i\\) and \\(t(u,r,X^{j})\\) is the number of points of type \\(j\\) in a circle of radius \\(r\\) around \\(u\\) (Baddeley, Rubak, and Turner 2015, 594–95). It is important to remember that the homogeneous cross K-function assumes that the multitype process is stationary. If this is not the case, there is a risk in misinterpreting the results. The problem is the confounding between clustering and inhomogeneity, c.f. (Baddeley, Rubak, and Turner 2015, 151–52)\nFirst, we plot an overview over the cross K function for the different types. As we have seen before the assumption of stationarity might be not valid. We will therefore use the inhomogeneous version of the cross K function.\n\n\nCode\nplotCrossAll &lt;- function(ppp, fun, edgecorr){\n  nMarks &lt;- length(unique(marks(ppp)))\n  Fall &lt;- alltypes(ppp, fun)\n  \n  # Create a list of ggplot objects using lapply\n  plot_list &lt;- lapply(Fall[[\"fns\"]], function(res) {\n    ggplot(res, aes(x = r, y = .data[[edgecorr]])) +\n      geom_line(linewidth = 1) +\n      geom_line(aes(x = r, y = theo), \n                linetype = \"dotted\", linewidth = 1) +\n      geom_line() +\n      labs(title = attributes(res)$yexp) +\n      theme_minimal()\n  })\n  \n  p &lt;- wrap_plots(plot_list, ncol = nMarks) + \n    plot_layout(guides = \"collect\") & theme(legend.position='bottom')\n  return(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplotCrossAll(pp_sel, \"Kcross.inhom\", \"iso\")\n\n\n\n\n\n\nThe diagonal of the imhomogeneous cross K-function plot shows the K-function for the different marks (indication of Poisson or non-Poisson point processes). Off-diagonal panels give indication of independence of points when the number of points follows the expected K-function but does not imply that the individual marks follow a Poisson process. If the types are independent, they are also uncorrelated.\nIn the example above, assuming that the process is inhomogeneous, the Ependymals cells appear to be regularly spaced, which seems counter intuitive. However, this is the result of the pattern being inhomogeneous with spatially varying intensity. When accounting for this, the pattern is more regular than expected under an inhomogeneous point process. The estimation of the inhomogeneous cross functions is not straightforward and results change based on the estimation of the local intensity and the edge correction, c.f. (Baddeley, Rubak, and Turner 2015, 605).\nIn this overview, we can see that there is indication that Microglia and OD Mature cells are independent of each other. The other types seem to be dependent on each other. Let’s focus a bit more on the relationship between Ependymal and the other two cell types. We will also calculate confidence intervals for the different cross K-functions. We have already seen that our dataset most likely does not satisfy the assumption of stationarity. For this reason, we will calculate further calculate the inhomogeneous cross K-function.\n\n\nCode\nplotCrossMetric &lt;- function(ppp, fun, from, to, edgecorr){\n  lce &lt;- lohboot(ppp, fun, from = from, to = to)\n  p &lt;- ggplot(lce, aes(x = r, y = .data[[edgecorr]])) +\n    geom_line(size = 1) +\n    geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)+\n    geom_line(aes(x = r, y = theo), linetype = \"dotted\", size = 1) +\n    geom_line() +\n    labs(title = attributes(lce)$yexp) +\n    theme_minimal()\n  return(p)\n}\n\np_epen_od &lt;- plotCrossMetric(pp_sel, \"Kcross.inhom\", \n                             \"Ependymal\", \"OD Mature\", \"iso\")\np_epend_micro &lt;- plotCrossMetric(pp_sel, \"Kcross.inhom\", \n                                 \"Ependymal\", \"Microglia\", \"iso\")\n\n\n\n\nCode\n# fig-width: 10\n# fig-height: 10\np_epen_od + p_epend_micro\n\n\n\n\n\nRemember that the dashed line represents the assumption of a multitype Poisson process. If the line lies above the dotted line, there is indication of clustering while if the line is below the dotted line there is indication of repulsion. In the plot above we can see that there is indication of clustering between Ependymal and OD Mature cells while there is indication of repulsion between Ependymal and Microglia cells.\n\n\nCross L-function\nAlternatively the L cross function with similar interpretation can be calculated using the Lcross function (Baddeley, Rubak, and Turner 2015, 596ff).\n\n\nCode\n# fig-width: 10\n# fig-height: 10\np_epen_od + p_epend_micro\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMark connection function\nThe mark connection function is the cross pair-correlation function, i.e. the generalization of the pair correlation function to a multitype point processes, divided by the unmarked pair-correlation function. It can be interpreted as the conditional probability that two points a distance \\(r\\)apart have labels of type A and of type B, given the presence of those points (Baddeley, Rubak, and Turner 2015, 596–97).\n\n\nCode\nplotCrossAll(pp_sel, \"markconnect\", \"iso\") + \n  scale_y_continuous(limits = c(0, 1))\n\n\n\n\n\n\nThe dashed lines indicate expected values under random labeling. The values measure dependence (or association) between the different labelled points. Positive values indicate that nearby points are more likely to have different types than expected by chance. This positive association between different cell types does not necessarily imply dependence, as it could be influenced by a negative association between cells of the same type, as it it could be the case for the Microglia cells. Furthermore, as the calculation is based on the \\(K\\) function, the mark connection function assumes homogenity.\n\n\nCross F-function (empty space function), cross G-function (Nearest-neighbor function) and cross J-function\nThe cross F-function is the cumulative distribution function of the distance from a location to the nearest point of the same type. For each type \\(i\\), it is defined as:\n\\[F_i(r) = \\mathbb{P}\\{d(u,X^{i}\\leq r\\}.\\]\nThe cross G-function is the cumulative distribution function of the distance from a location to the nearest point of another type and is defined as:\n\\[G_{ij}(r) = \\mathbb{P}\\{d(x,X^{(j)} \\setminus u \\leq r \\mid X^{(i)} \\ \\text{has a point at u}).\\]\nIf the points are independent of each other, the G and F function are identical. Both assume that the process is stationary. There are inhomogenous alternatives, in case the intensity is varying. Then we only assume correlation stationarity.\nThere exists a difference in the interpretation of the theoretical values of the K-cross and the G-cross function. For the K-cross, the theoretical value indicates independence between marks while for the G-cross the theoretical value is consistent with the assumption that the points of type j are Poisson in addition to being independent of the points of type \\(i\\) (Baddeley, Rubak, and Turner 2015, 597 ff).\nThe cross J-function is defined as:\n\\[J_{ij}(r) = \\frac{1-G_{ij}(r)}{1-F_{j}(r)}\\]\nand summarizes the interpoint dependence between type \\(i\\) and \\(j\\). Under the hypothesis of independent components, i.e., that the point processes of each type are independent, the G-function is equivalent to the F-function and the J-function is equal to 1 (Baddeley, Rubak, and Turner 2015, 597 ff).\n\n\n\n\n\n\n\n\n\n\nDot functions\nFor each K-, G- and J- function, there also exist dot functions, which measure distances from points of one type to points of any type. These functions allow us to measure the dependence of one mark with all other marks at once. For expample, the K-dot function represents the expected number of an other point within distance \\(r\\) of a typical point of type \\(i\\) (Baddeley, Rubak, and Turner 2015, 600 ff).\n\n\nCode\nplotCrossAll(pp_sel, \"Kdot.inhom\", \"iso\")\n\n\n\n\n\nThe dot functions are useful summary statistics to analyse the dependence of one mark with all other marks."
  },
  {
    "objectID": "03-cell-multivar-point.html#summary-function-within-and-between-types",
    "href": "03-cell-multivar-point.html#summary-function-within-and-between-types",
    "title": "Discrete Marks",
    "section": "Summary function within and between types",
    "text": "Summary function within and between types\nIn our original dataset, we have a large number of different marks. We picked three: OD mature, Ependymal and Microglia for illustrative purposes. An alternative to looking at all cross summary function combinations, it is possible to compare between and within types (Baddeley, Rubak, and Turner 2015).\n\nMark equality function\nThe Mark or Type Equality function for a stationary multitype point process measures the correlation between types of two points separated by distance r. It is the sum of the mark connection function of all pairs of points of the same type.\nIf k &lt; 1, points at distance r are less likely than expected to be of the same type. If &gt; 1, they are more likely to be of the same type. The value 1 indicates a lack of correlation (Baddeley, Rubak, and Turner 2015, 603 ff).\n\n\nCode\nplotMarkCorr &lt;- function(pp, edgecorr = \"iso\") {\n    me &lt;- markcorr(pp)\n    ggplot(me, aes(x = r, y = .data[[edgecorr]])) +\n        geom_line(size = 1) +\n        geom_line(aes(x = r, y = theo), linetype = \"dotted\", size = 1) +\n        geom_line() +\n        labs(title = attributes(me)$yexp) +\n        theme_minimal()\n}\n\nplotMarkCorr(pp_sel)\n\n\n\n\n\nWe can see that in our dataset that it the more likely it is to find points of the same type at shorter distances. The curve never crosses the dashed line at 1, which means that it is generally more likely to find points of the same type at any distance than expected by chance."
  },
  {
    "objectID": "03-cell-multivar-point.html#testing-random-labelling",
    "href": "03-cell-multivar-point.html#testing-random-labelling",
    "title": "Discrete Marks",
    "section": "Testing random labelling",
    "text": "Testing random labelling\nThe random labeling test is most logical when the marks represents its status, which is not most appropriate assumption when considering cell types. Testing for random labeling can be done using permutation test, in which the labels are randomly permuted. Random labeling can be assumed if the permuted datasets are statistically equivalent to the original dataset (Baddeley, Rubak, and Turner 2015, 609 ff)."
  },
  {
    "objectID": "03-cell-multivar-point.html#testing-the-indepenence-of-components-assumption",
    "href": "03-cell-multivar-point.html#testing-the-indepenence-of-components-assumption",
    "title": "Discrete Marks",
    "section": "Testing the indepenence of components assumption",
    "text": "Testing the indepenence of components assumption\nThe i-to-j functions are useful to test the independence of different subprocesses. If the processes of type i and j are independent, then \\(K_{ij} = \\pi r^2, G_{ij}(r) = F_{j}(r), J_{ij}(r) \\equiv 1\\). Alternatively, randomization tests can be used in which simulated patterns from the dataset are generated and randomly split into subpatterns. These are then compared to the null hypothesis in which all subpatterns should be statistically equivalent to the original. However, this approach assumes stationarity and there is a need to handle edge effects (Baddeley, Rubak, and Turner 2015, 606 ff).\n\n\nCode\nplotEnvCross &lt;- function(pp, i, j, fun, nsim = 39, radius = 150, global = FALSE){\n  pp_scaled &lt;- rescale(pp)\n  E1 &lt;- envelope(pp_scaled, fun, nsim=nsim, i=i, j=j,\n                 simulate=expression(rshift(pp_scaled, radius = radius)), global = global)\n  p &lt;- ggplot(E1, aes(x = r, y = .data[[\"mmean\"]])) +\n    geom_line(size = 1) +\n    geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)+\n    geom_line(aes(x = r, y = obs), linetype = \"dotted\", size = 1) +\n    geom_line() +\n    labs(title = attributes(E1)$yexp) +\n    theme_minimal()\n  return(p)\n}\n\npEnv &lt;- plotEnvCross(pp_sel, fun = \"Kcross.inhom\", \n                     \"Ependymal\", \"OD Mature\", nsim = 39, radius = 150)\n\n\n\n\nCode\npEnv\n\n\n\n\n\n\n\nCode\nplotEnvCross(pp_sel, fun = \"Kcross.inhom\", \n             \"Ependymal\", \"OD Mature\", nsim = 39, radius = 150, global = TRUE)\n\n\nGenerating 78 simulations by evaluating expression (39 to estimate the mean and \n39 to calculate envelopes) ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, \n78.\n\nDone.\n\n\n\n\n\nWe have indication that the independence-of-components assumption should not be rejected. Therefore, we conclude that Ependymal and OD Mature cells are independent."
  },
  {
    "objectID": "03-cell-multivar-point.html#session-info",
    "href": "03-cell-multivar-point.html#session-info",
    "title": "Discrete Marks",
    "section": "Session info",
    "text": "Session info\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-16                      reshape2_1.4.4                \n[19] patchwork_1.1.3                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.4.4                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.2.1                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] fftwtools_0.9-11              spatstat.utils_3.0-3         \n [87] rmarkdown_2.25                XVector_0.40.0               \n [89] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [91] base64enc_0.1-3               sparseMatrixStats_1.12.2     \n [93] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [95] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [97] farver_2.1.1                  jsonlite_1.8.7               \n [99] BiocParallel_1.34.2           R.oo_1.25.0                  \n[101] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[103] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[105] Rhdf5lib_1.22.1               munsell_0.5.0                \n[107] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[109] viridis_0.6.4                 stringi_1.7.12               \n[111] leafsync_0.1.0                zlibbioc_1.46.0              \n[113] plyr_1.8.9                    parallel_4.3.1               \n[115] ggrepel_0.9.4                 deldir_1.0-9                 \n[117] Biostrings_2.68.1             stars_0.6-4                  \n[119] splines_4.3.1                 tensor_1.5                   \n[121] locfit_1.5-9.8                igraph_1.5.1                 \n[123] ScaledMatrix_1.8.1            BiocVersion_3.17.1           \n[125] XML_3.99-0.14                 evaluate_0.22                \n[127] BiocManager_1.30.22           httpuv_1.6.11                \n[129] purrr_1.0.2                   polyclip_1.10-6              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4"
  },
  {
    "objectID": "05-spot-univar-lattice.html",
    "href": "05-spot-univar-lattice.html",
    "title": "Theory – Univariate lattice based analysis",
    "section": "",
    "text": "Code\nsource(\"utils.R\")\ntheme_set(theme_light())\n\n\n\n\n\n\n\nCode\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\n\nCode\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, named Mdk and Ncl (mckellarLargescaleIntegrationSinglecell2021?).\nSpot based data is collected along a regular spaced grid where all sample areas have the same size. Such a grid is also called a regular lattice. In more rigorous terms the data \\(Y\\) is the product of a random process but the sampling locations are fixed along a lattice \\(D\\). The lattice \\(D\\) does not have to regular but in the scope of spot based data it is. The main difference of this type of data in comparison to point patterns is, that the locations of the data are then not results of a stochastic process but rather due to a defined sampling strategy (Zuur, Ieno, and Smith 2007).\nThe lattice is composed of individual spatial units\n\\[D = \\{A_1, A_2,...,A_n\\}\\]\nwhere these units are not supposed to overlap\n\\[A_i \\cap A_j = \\emptyset \\forall i \\neq j\\]\nThe data is then a random variable of the spatial unit along the lattice\n\\[Y_i = Y(A_i)\\]\nMost lattice data analysis technique build on the concept of neighbours. Therefore, the spatial relationship has to be modelled with e.g. a spatial weigth matrix \\(W\\). There are a lot of ways to define a spatial weigth matrix \\(W\\). Here, the units that are adjacent are specified with a one and the ones that are not adjacent with a zero (binary coniguity matrix)\n\\[w_{ij} = \\begin{cases} 1 \\text{ if } A_i \\text{ and } A_j \\text{ are adjacent}\\\\ 0 \\text{ otw} \\end{cases}\\]\nother options to specify the weight matrix \\(W\\) are mentioned in (Zuur, Ieno, and Smith 2007).\n\n\n\nGlobal methods give us an overview over the entire field of view and summarize the spatial distribution of the cells (for a given measurement such as gene expression) in a single value. The most common global measures are Moran’s I and Geary’s C coefficients; these coefficients are a function of the weight matrix and the variables of interest.\nIn general, a global spatial autocorrelation measure has the form of a double sum over all locations\n\\[\\sum_i \\sum_j f(x_i,x_j) w_{ij}.\\]\n\n\nThe global Moran’s I (Moran 1950) coefficient is a measure of spatial autocorrelation, defined as:\n\\[I = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(x_i - \\bar{x})(x_j - \\bar{x})}{\\sum_i (x_i - \\bar{x})^2}.\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\) and \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\). The expected value is close to \\(0\\) for large \\(n\\) (\\(\\mathbb{E}(I) = -1/(n-1)\\)), whereas a value higher than indicates spatial auto-correlation. Negative values indicate negative auto-correlation.\n\n\n\nGeary’s \\(C\\) (Geary 1954) is a different measure of global autocorrelation and is very closely related to Moran’s \\(I\\). However, it focuses on spatial dissimilarity. Geary’s \\(C\\) is defined by\n\\[C = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(x_i-x_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(x_i-\\bar{x})^2}\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\), \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\) and \\(n\\) the total numer of locations. The interpretation is opposite to Moran’s \\(I\\): a value smaller than \\(1\\) indicates positive auto-correlation whereas a value greater than \\(1\\) represents negative auto-correlation.\n\n\n\nThe global \\(G\\) (Getis and Ord 1992) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in the dataset. Formally that is\n\\[G(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j} \\text{s.t } j \\neq i.\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather consider both.\nIt is recommended to use binary weights for this calculation. We will use the spdep package directly to calculate the global \\(G\\) statistic.\n\n\n\n\nUnlike global measures that give an overview over the entire field of view, local measures report information about the statistic at each location (cell). There exist local analogs of Moran’s I and Geary’s C for which the global statistic can be represented as a weighted sum of the local statistics. As above, the local coefficients are based on both the spatial weights matrix and the values of the measurement of interest.\n\n\nThe local Moran’s I coefficient (Anselin 1995) is a measure of spatial autocorrelation on each location of interest. It is defined as:\n\\[I_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\\]\nwhere the index \\(i\\) refers to the location for which the measure is calculated. The interpretation is analogous to the global Moran’s I where a value of \\(I_i\\) higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation; smaller values indicate negative auto-correlation. It is important to note that, as for the global counterpart, the value of local Moran’s I could be a result from both the high or low end of the values. Since we measure and test a large number of locations simultaneously, we need to correct for multiple testing (e.g., using the Benjamini-Hochberg procedure).\n\n\n\nSimilar to local Moran’s I, there is a local Geary’s C (Anselin 1995) coefficient. It is defined as\n\\[C_i = \\sum_{j=1}^n w_{ij}(x_i-x_j)^2\\]\nThe interpretation is analogous to the global Geary’s C (value less than \\(1\\) indicates positive auto-correlation, a value greater than \\(1\\) highlights negative auto-correlation).\nIn this example, we will not plot the local Geary’s C coefficient for gene expression but for features that are associated with an individual cell, e.g., the number of counts or the number of genes expressed. For this, the colDataUnivariate function is used to calculate the local Geary’s C coefficient for such features.\n\n\n\nThe local Getis-Ord \\(G_i\\) (J. K. Ord and Getis 1995; Getis and Ord 1992) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\), according to:\n\\[G_i(d) = \\frac{\\sum_{j \\neq i } w_{ij}(d)x_j}{\\sum_{j \\neq i} x_j}\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\), which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term.\n\n\n\n\nThe local spatial heteroscedasticity (LOSH) is a measure of spatial autocorrelation that is based on the variance of the local neighbourhood. Unlike the other measures, this method does not assume homoscedastic variance over the whole tissue region. LOSH is defined as:\n\\[H_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_i(d), j \\in N(i,d)\\) are the local residuals that are subtracted from the local mean. The power \\(a\\) modulates the interpretation of the residuals (\\(a=1\\): residuals are interpreted as absolute deviations from the local mean; \\(a=2\\): residuals are interpreted as deviations from the local variance).\nThe LOSH should be interpreted in combination with the local Getis-Ord \\(G_i^*\\) statistic. The \\(G_i^*\\) quantifies the local mean of the variable of interest, while \\(H_i\\) quantifies the local variance. This table provided by Ord and Getis (J. Keith Ord and Getis 2012) summarizes the interpretation of the combination of \\(G_i^*\\) and \\(H_i\\).\n\n\n\n\n\n\n\n\n\nhigh \\(H_i\\)\nlow \\(H_i\\)\n\n\n\n\nlarge \\(\\|G_i^*\\|\\)\nA hot spot with heterogeneous local conditions\nA hot spot with similar surrounding areas; the map would indicate whether the affected region is larger than the single “cell”\n\n\nsmall $ |G_i^*| $\nHeterogeneous local conditions but at a low average level (an unlikely event)\nHomogeneous local conditions and a low average level"
  },
  {
    "objectID": "05-spot-univar-lattice.html#dependencies",
    "href": "05-spot-univar-lattice.html#dependencies",
    "title": "Theory – Univariate lattice based analysis",
    "section": "",
    "text": "Code\nsource(\"utils.R\")\ntheme_set(theme_light())"
  },
  {
    "objectID": "05-spot-univar-lattice.html#setup-and-preprocessing",
    "href": "05-spot-univar-lattice.html#setup-and-preprocessing",
    "title": "Theory – Univariate lattice based analysis",
    "section": "",
    "text": "Code\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\n\nCode\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, named Mdk and Ncl (mckellarLargescaleIntegrationSinglecell2021?).\nSpot based data is collected along a regular spaced grid where all sample areas have the same size. Such a grid is also called a regular lattice. In more rigorous terms the data \\(Y\\) is the product of a random process but the sampling locations are fixed along a lattice \\(D\\). The lattice \\(D\\) does not have to regular but in the scope of spot based data it is. The main difference of this type of data in comparison to point patterns is, that the locations of the data are then not results of a stochastic process but rather due to a defined sampling strategy (Zuur, Ieno, and Smith 2007).\nThe lattice is composed of individual spatial units\n\\[D = \\{A_1, A_2,...,A_n\\}\\]\nwhere these units are not supposed to overlap\n\\[A_i \\cap A_j = \\emptyset \\forall i \\neq j\\]\nThe data is then a random variable of the spatial unit along the lattice\n\\[Y_i = Y(A_i)\\]\nMost lattice data analysis technique build on the concept of neighbours. Therefore, the spatial relationship has to be modelled with e.g. a spatial weigth matrix \\(W\\). There are a lot of ways to define a spatial weigth matrix \\(W\\). Here, the units that are adjacent are specified with a one and the ones that are not adjacent with a zero (binary coniguity matrix)\n\\[w_{ij} = \\begin{cases} 1 \\text{ if } A_i \\text{ and } A_j \\text{ are adjacent}\\\\ 0 \\text{ otw} \\end{cases}\\]\nother options to specify the weight matrix \\(W\\) are mentioned in (Zuur, Ieno, and Smith 2007)."
  },
  {
    "objectID": "05-spot-univar-lattice.html#global-methods",
    "href": "05-spot-univar-lattice.html#global-methods",
    "title": "Theory – Univariate lattice based analysis",
    "section": "",
    "text": "Global methods give us an overview over the entire field of view and summarize the spatial distribution of the cells (for a given measurement such as gene expression) in a single value. The most common global measures are Moran’s I and Geary’s C coefficients; these coefficients are a function of the weight matrix and the variables of interest.\nIn general, a global spatial autocorrelation measure has the form of a double sum over all locations\n\\[\\sum_i \\sum_j f(x_i,x_j) w_{ij}.\\]\n\n\nThe global Moran’s I (Moran 1950) coefficient is a measure of spatial autocorrelation, defined as:\n\\[I = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(x_i - \\bar{x})(x_j - \\bar{x})}{\\sum_i (x_i - \\bar{x})^2}.\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\) and \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\). The expected value is close to \\(0\\) for large \\(n\\) (\\(\\mathbb{E}(I) = -1/(n-1)\\)), whereas a value higher than indicates spatial auto-correlation. Negative values indicate negative auto-correlation.\n\n\n\nGeary’s \\(C\\) (Geary 1954) is a different measure of global autocorrelation and is very closely related to Moran’s \\(I\\). However, it focuses on spatial dissimilarity. Geary’s \\(C\\) is defined by\n\\[C = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(x_i-x_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(x_i-\\bar{x})^2}\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\), \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\) and \\(n\\) the total numer of locations. The interpretation is opposite to Moran’s \\(I\\): a value smaller than \\(1\\) indicates positive auto-correlation whereas a value greater than \\(1\\) represents negative auto-correlation.\n\n\n\nThe global \\(G\\) (Getis and Ord 1992) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in the dataset. Formally that is\n\\[G(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j} \\text{s.t } j \\neq i.\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather consider both.\nIt is recommended to use binary weights for this calculation. We will use the spdep package directly to calculate the global \\(G\\) statistic."
  },
  {
    "objectID": "05-spot-univar-lattice.html#local-measures",
    "href": "05-spot-univar-lattice.html#local-measures",
    "title": "Theory – Univariate lattice based analysis",
    "section": "",
    "text": "Unlike global measures that give an overview over the entire field of view, local measures report information about the statistic at each location (cell). There exist local analogs of Moran’s I and Geary’s C for which the global statistic can be represented as a weighted sum of the local statistics. As above, the local coefficients are based on both the spatial weights matrix and the values of the measurement of interest.\n\n\nThe local Moran’s I coefficient (Anselin 1995) is a measure of spatial autocorrelation on each location of interest. It is defined as:\n\\[I_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\\]\nwhere the index \\(i\\) refers to the location for which the measure is calculated. The interpretation is analogous to the global Moran’s I where a value of \\(I_i\\) higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation; smaller values indicate negative auto-correlation. It is important to note that, as for the global counterpart, the value of local Moran’s I could be a result from both the high or low end of the values. Since we measure and test a large number of locations simultaneously, we need to correct for multiple testing (e.g., using the Benjamini-Hochberg procedure).\n\n\n\nSimilar to local Moran’s I, there is a local Geary’s C (Anselin 1995) coefficient. It is defined as\n\\[C_i = \\sum_{j=1}^n w_{ij}(x_i-x_j)^2\\]\nThe interpretation is analogous to the global Geary’s C (value less than \\(1\\) indicates positive auto-correlation, a value greater than \\(1\\) highlights negative auto-correlation).\nIn this example, we will not plot the local Geary’s C coefficient for gene expression but for features that are associated with an individual cell, e.g., the number of counts or the number of genes expressed. For this, the colDataUnivariate function is used to calculate the local Geary’s C coefficient for such features.\n\n\n\nThe local Getis-Ord \\(G_i\\) (J. K. Ord and Getis 1995; Getis and Ord 1992) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\), according to:\n\\[G_i(d) = \\frac{\\sum_{j \\neq i } w_{ij}(d)x_j}{\\sum_{j \\neq i} x_j}\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\), which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term.\n\n\n\n\nThe local spatial heteroscedasticity (LOSH) is a measure of spatial autocorrelation that is based on the variance of the local neighbourhood. Unlike the other measures, this method does not assume homoscedastic variance over the whole tissue region. LOSH is defined as:\n\\[H_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_i(d), j \\in N(i,d)\\) are the local residuals that are subtracted from the local mean. The power \\(a\\) modulates the interpretation of the residuals (\\(a=1\\): residuals are interpreted as absolute deviations from the local mean; \\(a=2\\): residuals are interpreted as deviations from the local variance).\nThe LOSH should be interpreted in combination with the local Getis-Ord \\(G_i^*\\) statistic. The \\(G_i^*\\) quantifies the local mean of the variable of interest, while \\(H_i\\) quantifies the local variance. This table provided by Ord and Getis (J. Keith Ord and Getis 2012) summarizes the interpretation of the combination of \\(G_i^*\\) and \\(H_i\\).\n\n\n\n\n\n\n\n\n\nhigh \\(H_i\\)\nlow \\(H_i\\)\n\n\n\n\nlarge \\(\\|G_i^*\\|\\)\nA hot spot with heterogeneous local conditions\nA hot spot with similar surrounding areas; the map would indicate whether the affected region is larger than the single “cell”\n\n\nsmall $ |G_i^*| $\nHeterogeneous local conditions but at a low average level (an unlikely event)\nHomogeneous local conditions and a low average level"
  },
  {
    "objectID": "05-spot-univar-lattice.html#global-methods-1",
    "href": "05-spot-univar-lattice.html#global-methods-1",
    "title": "Theory – Univariate lattice based analysis",
    "section": "Global Methods",
    "text": "Global Methods\n\nGlobal Moran’s I coefficient\n\nImplementation using VOYAGER\n\n\nCode\nsfe_tissue &lt;-  colDataUnivariate(sfe_tissue, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"visium\", nsim = 1000,\n                                type = \"moran.mc\")\n\nres &lt;- colFeatureData(sfe_tissue)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$moran.mc_statistic_Vis5A\n\n\n[1] 0.5287047 0.3840275\n\n\nCode\n#p-value\nres$moran.mc_p.value_Vis5A\n\n\n[1] 0.000999001 0.000999001\n\n\nCode\nplotMoranMC(sfe_tissue, c(\"nCounts\", \"nGenes\"))\n\n\n\n\n\nThe number of genes per spot shows a Moran’s \\(I\\) of \\(\\sim 0.38\\) which indicates auto-correlation. The number of counts per spot shows a Moran’s \\(I\\) of \\(\\sim 0.53\\).\n\n\n\nGlobal Geary’s C coefficient\n\nImplementation using VOYAGER\n\n\nCode\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\nsfe_tissue &lt;-  colDataUnivariate(sfe_tissue, features = c(\"nCounts\", \"nGenes\"), \n                                colGraphName = \"visium\", nsim = 1000,\n                                type = \"geary.mc\")\n\nres &lt;- colFeatureData(sfe_tissue)[c(\"nCounts\", \"nGenes\"),]\n#value of the metric\nres$geary.mc_statistic_Vis5A\n\n\n[1] 0.4748925 0.6057966\n\n\nCode\n#p-value\nres$geary.mc_p.value_Vis5A\n\n\n[1] 0.000999001 0.000999001\n\n\nThe Geary’s \\(C\\) statistic gives a value of \\(0.47\\) for the number of counts and \\(0.61\\) for the number of genes. The interpretation is that both features show positive auto correlation.\n\n\n\nGlobal Getis-Ord \\(G\\) statistic\n–&gt; weights should be binarised for this test - how to do this?\n\n\nCode\nweights_neighbourhoods &lt;- colGraph(sfe_tissue, \"visium\")\n\nspdep::globalG.test(x = sfe_tissue$nGenes, listw = weights_neighbourhoods)\n\n\n\n    Getis-Ord global G statistic\n\ndata:  sfe_tissue$nGenes \nweights: weights_neighbourhoods \n\nstandard deviate = 20.757, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.185181e-03       1.074114e-03       2.863192e-11 \n\n\nCode\nspdep::globalG.test(x = sfe_tissue$nCounts, listw = weights_neighbourhoods)\n\n\n\n    Getis-Ord global G statistic\n\ndata:  sfe_tissue$nCounts \nweights: weights_neighbourhoods \n\nstandard deviate = 27.797, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.361423e-03       1.074114e-03       1.068346e-10"
  },
  {
    "objectID": "05-spot-univar-lattice.html#local-measures-for-univariate-data",
    "href": "05-spot-univar-lattice.html#local-measures-for-univariate-data",
    "title": "Theory – Univariate lattice based analysis",
    "section": "Local Measures for Univariate Data",
    "text": "Local Measures for Univariate Data\n\nLocal Moran’s I coefficient\n\nImplementation using Voyager\n\n\nCode\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, type = \"localmoran\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localmoran\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0)\n\n\n\n\n\n\n\n\nLocal Geary’s C coefficient\n\nImplementation using Voyager\n\n\nCode\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \"localC_perm\", features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localC_perm\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0)\n\n\n\n\n\n\n\n\nLocal Getis-Ord \\(G_i\\) coefficient\n\nImplementation using Voyager\n\n\nCode\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue, \n                                \"localG\",\n                                features = c(\"nCounts\", \"nGenes\"))\n\nplotLocalResult(sfe_tissue, \"localG\", features = c(\"nCounts\", \"nGenes\"), ncol = 2,\n                colGeometryName = \"spotPoly\", divergent = TRUE, \n                diverge_center = 0)\n\n\n\n\n\n\n\n\nLocal Spatial Heteroscedasticity (LOSH)\n\nImplementation using Voyager\n\n\nCode\n# run localG with permutation test\nsfe_sub &lt;- colDataUnivariate(sfe_tissue,\n                     features = c(\"Mdk\"),\n                     type = \"LOSH\")\n\n\nplotLocalResult(sfe_tissue, \"LOSH\",\n                features = \"Mdk\",\n                colGeometryName = \"centroids\")"
  },
  {
    "objectID": "05-spot-univar-lattice.html#session-info",
    "href": "05-spot-univar-lattice.html#session-info",
    "title": "Theory – Univariate lattice based analysis",
    "section": "Session info",
    "text": "Session info\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-16                      reshape2_1.4.4                \n[19] patchwork_1.1.3                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.4.4                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  dbscan_1.1-11                \n [19] R.utils_2.12.2                dichromat_2.0-0.1            \n [21] scico_1.5.0                   limma_3.56.2                 \n [23] rstudioapi_0.15.0             RSQLite_2.3.1                \n [25] generics_0.1.3                crosstalk_1.2.0              \n [27] Matrix_1.5-4.1                ggbeeswarm_0.7.2             \n [29] fansi_1.0.5                   abind_1.4-5                  \n [31] R.methodsS3_1.8.2             terra_1.7-55                 \n [33] lifecycle_1.0.3               yaml_2.3.7                   \n [35] edgeR_3.42.4                  rhdf5_2.44.0                 \n [37] tmaptools_3.1-1               grid_4.3.1                   \n [39] blob_1.2.4                    promises_1.2.1               \n [41] dqrng_0.3.1                   crayon_1.5.2                 \n [43] lattice_0.21-8                beachmat_2.16.0              \n [45] KEGGREST_1.40.1               magick_2.8.0                 \n [47] pillar_1.9.0                  knitr_1.44                   \n [49] metapod_1.7.0                 rjson_0.2.21                 \n [51] boot_1.3-28.1                 codetools_0.2-19             \n [53] wk_0.8.0                      glue_1.6.2                   \n [55] vctrs_0.6.4                   png_0.1-8                    \n [57] gtable_0.3.4                  cachem_1.0.8                 \n [59] xfun_0.40                     S4Arrays_1.0.6               \n [61] mime_0.12                     DropletUtils_1.20.0          \n [63] units_0.8-4                   statmod_1.5.0                \n [65] bluster_1.10.0                interactiveDisplayBase_1.38.0\n [67] ellipsis_0.3.2                bit64_4.0.5                  \n [69] filelock_1.0.2                irlba_2.3.5.1                \n [71] vipor_0.4.5                   KernSmooth_2.23-21           \n [73] colorspace_2.1-0              DBI_1.1.3                    \n [75] raster_3.6-26                 tidyselect_1.2.0             \n [77] bit_4.0.5                     compiler_4.3.1               \n [79] curl_5.1.0                    BiocNeighbors_1.18.0         \n [81] DelayedArray_0.26.7           scales_1.2.1                 \n [83] classInt_0.4-10               rappdirs_0.3.3               \n [85] goftest_1.2-3                 spatstat.utils_3.0-3         \n [87] rmarkdown_2.25                XVector_0.40.0               \n [89] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [91] base64enc_0.1-3               sparseMatrixStats_1.12.2     \n [93] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [95] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [97] farver_2.1.1                  jsonlite_1.8.7               \n [99] BiocParallel_1.34.2           R.oo_1.25.0                  \n[101] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[103] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[105] Rhdf5lib_1.22.1               munsell_0.5.0                \n[107] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[109] viridis_0.6.4                 stringi_1.7.12               \n[111] leafsync_0.1.0                zlibbioc_1.46.0              \n[113] plyr_1.8.9                    parallel_4.3.1               \n[115] ggrepel_0.9.4                 deldir_1.0-9                 \n[117] Biostrings_2.68.1             stars_0.6-4                  \n[119] splines_4.3.1                 tensor_1.5                   \n[121] locfit_1.5-9.8                igraph_1.5.1                 \n[123] ScaledMatrix_1.8.1            BiocVersion_3.17.1           \n[125] XML_3.99-0.14                 evaluate_0.22                \n[127] BiocManager_1.30.22           httpuv_1.6.11                \n[129] purrr_1.0.2                   polyclip_1.10-6              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4"
  },
  {
    "objectID": "02-cell-univar-lattice.html",
    "href": "02-cell-univar-lattice.html",
    "title": "Theory – Univariate lattice based analysis",
    "section": "",
    "text": "Code\nsource(\"utils.R\")\ntheme_set(theme_minimal())\n\n\nUntil now, we have considered the cells to be represented in a point pattern. However, as cells have a shape and area, this might be an oversimplification in some cases. Alternatively, we can rely on the segmentation of individual cells that are available for various datasets. The outline of each cell is represented by a polygon and the collection of all cells can be seen as an irregular lattice. Unlike a regular lattice (e.g., spot-based spatial transcriptomics data), the sample areas in an irregular lattice can have different sizes and are not necessarily regularly distributed over the sample space.\nFor this representation of the cells we will rely on the SpatialFeatureExperiment package. For preprocessing of the dataset we refer the reader to the vignette of the voyager package (Moses et al. 2023). The voyager package also provides wrapper functions around the package spdep (Pebesma and Bivand 2023) that work directly on the SpatialFeatureExperiment object.\n\n\nCode\n(sfe &lt;- HeNSCLCData())\n\n\nclass: SpatialFeatureExperiment \ndim: 980 100290 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100290): 1_1 1_2 ... 30_4759 30_4760\ncolData names(17): Area AspectRatio ... nCounts nGenes\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n\nCode\n# Empty cells\ncolData(sfe)$is_empty &lt;- colData(sfe)$nCounts &lt; 1\n# Select, sum negative control probes\n(neg_inds &lt;- str_detect(rownames(sfe), \"^NegPrb\")) %&gt;% sum\n\n\n[1] 20\n\n\nCode\ncolData(sfe)$prop_neg &lt;- colSums(counts(sfe)[neg_inds,])/colData(sfe)$nCounts\n# Remove low quality cells\nsfe &lt;- sfe[,!sfe$is_empty & sfe$prop_neg &lt; 0.1]\n# Re-calculate stats\nrowData(sfe)$means &lt;- rowMeans(counts(sfe))\nrowData(sfe)$vars &lt;- rowVars(counts(sfe))\nrowData(sfe)$is_neg &lt;- neg_inds\n# log Counts\nsfe &lt;- logNormCounts(sfe)\n\n\n\nIn this vignette, we will show the metrics related to two marker genes: KRT17 (basal cells) and TAGLN (smooth muscle cells).\n\n\nCode\nplotSpatialFeature(sfe, c(\"KRT17\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()\n\n\n\n\n\nCode\nplotSpatialFeature(sfe, c(\"TAGLN\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()\n\n\n\n\n\n\n\n\nIn general, a spatial autocorrelation measure has the following elements: a function, \\(f(x_i, x_j)\\), of the values of interest at locations \\(i\\) and \\(j\\) and a neighbourhood or weight matrix, \\(w_{ij}\\). The function \\(f\\) relates the measured values \\(x_i\\) and \\(x_j\\) and the neighbourhood matrix \\(w_{ij}\\) builds in the spatial relationship between location \\(i\\) and \\(j\\). If \\(i\\) and \\(j\\) are not neighbours, i.e. we assume they do not have any spatial association, the corresponding element of the weights matrix is 0 (i.e., \\(w_{ij} = 0\\)). In the following we will see that the function \\(f\\) varies between the different spatial autocorrelation measures (Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023).\n\n\n\n\nOne of the challenges when working with (irregular) lattice data is the construction of a neighbourhood graph (Pebesma and Bivand 2023). The main question is, what to consider as neighbours, as this will affect downstream analyses. Various methods exist to create neighbours, such as contiguitiy based neighbours, graph-based neighbours, distance based neighbours or higher order neighbours (Getis 2009; Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023). The documentation of the package spdep gives an overview of the different methods.\nSegmentation of individual cells is challenging (Wang 2019), therefore construction of contiguity-based neighbours based on individual cell segmentation assumes perfect segmentation results. Furthermore it would neglect the influence of more distant, not directly adjacent neighbours, which based on the feature of interest might not be the correct assumption.\nIn the following, we will use a k-nearest neighbours approach from voyager that relies on the spdep package. The approach and in particular the number \\(k\\) is somewhat arbritary.\n\n\n\n\n\nCode\ncolGraph(sfe, \"knn5\") &lt;- findSpatialNeighbors(sfe, method = \"knearneigh\",\n                                                  dist_type = \"idw\", k = 5, \n                                                  style = \"W\")\n\n\n\n\n\nGlobal methods give us an overview over the entire field of view and summarize the spatial distribution of the cells (for a given measurement such as gene expression) in a single value. The most common global measures are Moran’s I and Geary’s C coefficients; these coefficients are a function of the weight matrix and the variables of interest.\nIn general, a global spatial autocorrelation measure has the form of a double sum over all locations\n\\[\\sum_i \\sum_j f(x_i,x_j) w_{ij}.\\]\n\n\nThe global Moran’s I (Moran 1950) coefficient is a measure of spatial autocorrelation, defined as:\n\\[I = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(x_i - \\bar{x})(x_j - \\bar{x})}{\\sum_i (x_i - \\bar{x})^2}.\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\) and \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\). The expected value is close to \\(0\\) for large \\(n\\) (\\(\\mathbb{E}(I) = -1/(n-1)\\)), whereas a value higher than indicates spatial auto-correlation. Negative values indicate negative auto-correlation.\n\n\n\nGeary’s \\(C\\) (Geary 1954) is a different measure of global autocorrelation and is very closely related to Moran’s \\(I\\). However, it focuses on spatial dissimilarity. Geary’s \\(C\\) is defined by\n\\[C = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(x_i-x_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(x_i-\\bar{x})^2}\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\), \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\) and \\(n\\) the total numer of locations. The interpretation is opposite to Moran’s \\(I\\): a value smaller than \\(1\\) indicates positive auto-correlation whereas a value greater than \\(1\\) represents negative auto-correlation.\n\n\n\nThe global \\(G\\) (Getis and Ord 1992) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in the dataset. Formally that is\n\\[G(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j} \\text{s.t } j \\neq i.\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather consider both.\nIt is recommended to use binary weights for this calculation. We will use the spdep package directly to calculate the global \\(G\\) statistic.\n\n\n\n\nUnlike global measures that give an overview over the entire field of view, local measures report information about the statistic at each location (cell). There exist local analogs of Moran’s I and Geary’s C for which the global statistic can be represented as a weighted sum of the local statistics. As above, the local coefficients are based on both the spatial weights matrix and the values of the measurement of interest.\n\n\nThe local Moran’s I coefficient (Anselin 1995) is a measure of spatial autocorrelation on each location of interest. It is defined as:\n\\[I_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\\]\nwhere the index \\(i\\) refers to the location for which the measure is calculated. The interpretation is analogous to the global Moran’s I where a value of \\(I_i\\) higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation; smaller values indicate negative auto-correlation. It is important to note that, as for the global counterpart, the value of local Moran’s I could be a result from both the high or low end of the values. Since we measure and test a large number of locations simultaneously, we need to correct for multiple testing (e.g., using the Benjamini-Hochberg procedure).\n\n\n\nSimilar to local Moran’s I, there is a local Geary’s C (Anselin 1995) coefficient. It is defined as\n\\[C_i = \\sum_{j=1}^n w_{ij}(x_i-x_j)^2\\]\nThe interpretation is analogous to the global Geary’s C (value less than \\(1\\) indicates positive auto-correlation, a value greater than \\(1\\) highlights negative auto-correlation).\nIn this example, we will not plot the local Geary’s C coefficient for gene expression but for features that are associated with an individual cell, e.g., the number of counts or the number of genes expressed. For this, the colDataUnivariate function is used to calculate the local Geary’s C coefficient for such features.\n\n\n\nThe local Getis-Ord \\(G_i\\) (J. K. Ord and Getis 1995; Getis and Ord 1992) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\), according to:\n\\[G_i(d) = \\frac{\\sum_{j \\neq i } w_{ij}(d)x_j}{\\sum_{j \\neq i} x_j}\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\), which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term.\n\n\n\n\nThe local spatial heteroscedasticity (LOSH) is a measure of spatial autocorrelation that is based on the variance of the local neighbourhood. Unlike the other measures, this method does not assume homoscedastic variance over the whole tissue region. LOSH is defined as:\n\\[H_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_i(d), j \\in N(i,d)\\) are the local residuals that are subtracted from the local mean. The power \\(a\\) modulates the interpretation of the residuals (\\(a=1\\): residuals are interpreted as absolute deviations from the local mean; \\(a=2\\): residuals are interpreted as deviations from the local variance).\nThe LOSH should be interpreted in combination with the local Getis-Ord \\(G_i^*\\) statistic. The \\(G_i^*\\) quantifies the local mean of the variable of interest, while \\(H_i\\) quantifies the local variance. This table provided by Ord and Getis (J. Keith Ord and Getis 2012) summarizes the interpretation of the combination of \\(G_i^*\\) and \\(H_i\\).\n\n\n\n\n\n\n\n\n\nhigh \\(H_i\\)\nlow \\(H_i\\)\n\n\n\n\nlarge \\(\\|G_i^*\\|\\)\nA hot spot with heterogeneous local conditions\nA hot spot with similar surrounding areas; the map would indicate whether the affected region is larger than the single “cell”\n\n\nsmall $ |G_i^*| $\nHeterogeneous local conditions but at a low average level (an unlikely event)\nHomogeneous local conditions and a low average level"
  },
  {
    "objectID": "02-cell-univar-lattice.html#dependencies",
    "href": "02-cell-univar-lattice.html#dependencies",
    "title": "Theory – Univariate lattice based analysis",
    "section": "",
    "text": "Code\nsource(\"utils.R\")\ntheme_set(theme_minimal())\n\n\nUntil now, we have considered the cells to be represented in a point pattern. However, as cells have a shape and area, this might be an oversimplification in some cases. Alternatively, we can rely on the segmentation of individual cells that are available for various datasets. The outline of each cell is represented by a polygon and the collection of all cells can be seen as an irregular lattice. Unlike a regular lattice (e.g., spot-based spatial transcriptomics data), the sample areas in an irregular lattice can have different sizes and are not necessarily regularly distributed over the sample space.\nFor this representation of the cells we will rely on the SpatialFeatureExperiment package. For preprocessing of the dataset we refer the reader to the vignette of the voyager package (Moses et al. 2023). The voyager package also provides wrapper functions around the package spdep (Pebesma and Bivand 2023) that work directly on the SpatialFeatureExperiment object.\n\n\nCode\n(sfe &lt;- HeNSCLCData())\n\n\nclass: SpatialFeatureExperiment \ndim: 980 100290 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100290): 1_1 1_2 ... 30_4759 30_4760\ncolData names(17): Area AspectRatio ... nCounts nGenes\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n\nCode\n# Empty cells\ncolData(sfe)$is_empty &lt;- colData(sfe)$nCounts &lt; 1\n# Select, sum negative control probes\n(neg_inds &lt;- str_detect(rownames(sfe), \"^NegPrb\")) %&gt;% sum\n\n\n[1] 20\n\n\nCode\ncolData(sfe)$prop_neg &lt;- colSums(counts(sfe)[neg_inds,])/colData(sfe)$nCounts\n# Remove low quality cells\nsfe &lt;- sfe[,!sfe$is_empty & sfe$prop_neg &lt; 0.1]\n# Re-calculate stats\nrowData(sfe)$means &lt;- rowMeans(counts(sfe))\nrowData(sfe)$vars &lt;- rowVars(counts(sfe))\nrowData(sfe)$is_neg &lt;- neg_inds\n# log Counts\nsfe &lt;- logNormCounts(sfe)\n\n\n\nIn this vignette, we will show the metrics related to two marker genes: KRT17 (basal cells) and TAGLN (smooth muscle cells).\n\n\nCode\nplotSpatialFeature(sfe, c(\"KRT17\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()\n\n\n\n\n\nCode\nplotSpatialFeature(sfe, c(\"TAGLN\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()"
  },
  {
    "objectID": "02-cell-univar-lattice.html#irregular-lattice-and-neighbourhood-matrix",
    "href": "02-cell-univar-lattice.html#irregular-lattice-and-neighbourhood-matrix",
    "title": "Theory – Univariate lattice based analysis",
    "section": "",
    "text": "In general, a spatial autocorrelation measure has the following elements: a function, \\(f(x_i, x_j)\\), of the values of interest at locations \\(i\\) and \\(j\\) and a neighbourhood or weight matrix, \\(w_{ij}\\). The function \\(f\\) relates the measured values \\(x_i\\) and \\(x_j\\) and the neighbourhood matrix \\(w_{ij}\\) builds in the spatial relationship between location \\(i\\) and \\(j\\). If \\(i\\) and \\(j\\) are not neighbours, i.e. we assume they do not have any spatial association, the corresponding element of the weights matrix is 0 (i.e., \\(w_{ij} = 0\\)). In the following we will see that the function \\(f\\) varies between the different spatial autocorrelation measures (Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023)."
  },
  {
    "objectID": "02-cell-univar-lattice.html#neighbourhood-matrix",
    "href": "02-cell-univar-lattice.html#neighbourhood-matrix",
    "title": "Theory – Univariate lattice based analysis",
    "section": "",
    "text": "One of the challenges when working with (irregular) lattice data is the construction of a neighbourhood graph (Pebesma and Bivand 2023). The main question is, what to consider as neighbours, as this will affect downstream analyses. Various methods exist to create neighbours, such as contiguitiy based neighbours, graph-based neighbours, distance based neighbours or higher order neighbours (Getis 2009; Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023). The documentation of the package spdep gives an overview of the different methods.\nSegmentation of individual cells is challenging (Wang 2019), therefore construction of contiguity-based neighbours based on individual cell segmentation assumes perfect segmentation results. Furthermore it would neglect the influence of more distant, not directly adjacent neighbours, which based on the feature of interest might not be the correct assumption.\nIn the following, we will use a k-nearest neighbours approach from voyager that relies on the spdep package. The approach and in particular the number \\(k\\) is somewhat arbritary.\n\n\n\n\n\nCode\ncolGraph(sfe, \"knn5\") &lt;- findSpatialNeighbors(sfe, method = \"knearneigh\",\n                                                  dist_type = \"idw\", k = 5, \n                                                  style = \"W\")"
  },
  {
    "objectID": "02-cell-univar-lattice.html#global-methods",
    "href": "02-cell-univar-lattice.html#global-methods",
    "title": "Theory – Univariate lattice based analysis",
    "section": "",
    "text": "Global methods give us an overview over the entire field of view and summarize the spatial distribution of the cells (for a given measurement such as gene expression) in a single value. The most common global measures are Moran’s I and Geary’s C coefficients; these coefficients are a function of the weight matrix and the variables of interest.\nIn general, a global spatial autocorrelation measure has the form of a double sum over all locations\n\\[\\sum_i \\sum_j f(x_i,x_j) w_{ij}.\\]\n\n\nThe global Moran’s I (Moran 1950) coefficient is a measure of spatial autocorrelation, defined as:\n\\[I = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(x_i - \\bar{x})(x_j - \\bar{x})}{\\sum_i (x_i - \\bar{x})^2}.\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\) and \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\). The expected value is close to \\(0\\) for large \\(n\\) (\\(\\mathbb{E}(I) = -1/(n-1)\\)), whereas a value higher than indicates spatial auto-correlation. Negative values indicate negative auto-correlation.\n\n\n\nGeary’s \\(C\\) (Geary 1954) is a different measure of global autocorrelation and is very closely related to Moran’s \\(I\\). However, it focuses on spatial dissimilarity. Geary’s \\(C\\) is defined by\n\\[C = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(x_i-x_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(x_i-\\bar{x})^2}\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\), \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\) and \\(n\\) the total numer of locations. The interpretation is opposite to Moran’s \\(I\\): a value smaller than \\(1\\) indicates positive auto-correlation whereas a value greater than \\(1\\) represents negative auto-correlation.\n\n\n\nThe global \\(G\\) (Getis and Ord 1992) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in the dataset. Formally that is\n\\[G(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j} \\text{s.t } j \\neq i.\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather consider both.\nIt is recommended to use binary weights for this calculation. We will use the spdep package directly to calculate the global \\(G\\) statistic."
  },
  {
    "objectID": "02-cell-univar-lattice.html#local-measures",
    "href": "02-cell-univar-lattice.html#local-measures",
    "title": "Theory – Univariate lattice based analysis",
    "section": "",
    "text": "Unlike global measures that give an overview over the entire field of view, local measures report information about the statistic at each location (cell). There exist local analogs of Moran’s I and Geary’s C for which the global statistic can be represented as a weighted sum of the local statistics. As above, the local coefficients are based on both the spatial weights matrix and the values of the measurement of interest.\n\n\nThe local Moran’s I coefficient (Anselin 1995) is a measure of spatial autocorrelation on each location of interest. It is defined as:\n\\[I_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\\]\nwhere the index \\(i\\) refers to the location for which the measure is calculated. The interpretation is analogous to the global Moran’s I where a value of \\(I_i\\) higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation; smaller values indicate negative auto-correlation. It is important to note that, as for the global counterpart, the value of local Moran’s I could be a result from both the high or low end of the values. Since we measure and test a large number of locations simultaneously, we need to correct for multiple testing (e.g., using the Benjamini-Hochberg procedure).\n\n\n\nSimilar to local Moran’s I, there is a local Geary’s C (Anselin 1995) coefficient. It is defined as\n\\[C_i = \\sum_{j=1}^n w_{ij}(x_i-x_j)^2\\]\nThe interpretation is analogous to the global Geary’s C (value less than \\(1\\) indicates positive auto-correlation, a value greater than \\(1\\) highlights negative auto-correlation).\nIn this example, we will not plot the local Geary’s C coefficient for gene expression but for features that are associated with an individual cell, e.g., the number of counts or the number of genes expressed. For this, the colDataUnivariate function is used to calculate the local Geary’s C coefficient for such features.\n\n\n\nThe local Getis-Ord \\(G_i\\) (J. K. Ord and Getis 1995; Getis and Ord 1992) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\), according to:\n\\[G_i(d) = \\frac{\\sum_{j \\neq i } w_{ij}(d)x_j}{\\sum_{j \\neq i} x_j}\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\), which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term.\n\n\n\n\nThe local spatial heteroscedasticity (LOSH) is a measure of spatial autocorrelation that is based on the variance of the local neighbourhood. Unlike the other measures, this method does not assume homoscedastic variance over the whole tissue region. LOSH is defined as:\n\\[H_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_i(d), j \\in N(i,d)\\) are the local residuals that are subtracted from the local mean. The power \\(a\\) modulates the interpretation of the residuals (\\(a=1\\): residuals are interpreted as absolute deviations from the local mean; \\(a=2\\): residuals are interpreted as deviations from the local variance).\nThe LOSH should be interpreted in combination with the local Getis-Ord \\(G_i^*\\) statistic. The \\(G_i^*\\) quantifies the local mean of the variable of interest, while \\(H_i\\) quantifies the local variance. This table provided by Ord and Getis (J. Keith Ord and Getis 2012) summarizes the interpretation of the combination of \\(G_i^*\\) and \\(H_i\\).\n\n\n\n\n\n\n\n\n\nhigh \\(H_i\\)\nlow \\(H_i\\)\n\n\n\n\nlarge \\(\\|G_i^*\\|\\)\nA hot spot with heterogeneous local conditions\nA hot spot with similar surrounding areas; the map would indicate whether the affected region is larger than the single “cell”\n\n\nsmall $ |G_i^*| $\nHeterogeneous local conditions but at a low average level (an unlikely event)\nHomogeneous local conditions and a low average level"
  },
  {
    "objectID": "02-cell-univar-lattice.html#global-methods-1",
    "href": "02-cell-univar-lattice.html#global-methods-1",
    "title": "Theory – Univariate lattice based analysis",
    "section": "Global Methods",
    "text": "Global Methods\n\nGlobal Moran’s I coefficient\n\nImplementation using voyager\n\n\nCode\ncalculateMoransI(sfe,\n    features = c(\"KRT17\", \"TAGLN\"),\n    colGraphName = \"knn5\",\n    exprs_values = \"logcounts\"\n)\n\n\nDataFrame with 2 rows and 2 columns\n          moran         K\n      &lt;numeric&gt; &lt;numeric&gt;\nKRT17  0.643978   5.09219\nTAGLN  0.262374   6.55766\n\n\nWe can also use the moran.mc function to calculate the Moran’s I coefficient. This function uses a Monte Carlo simulation to calculate the P-value.\n\n\nCode\nsfe &lt;- runUnivariate(sfe,\n                     features = c(\"KRT17\", \"TAGLN\"),\n                     colGraphName = \"knn5\",\n                     exprs_values = \"logcounts\",\n                     type = \"moran.mc\",\n                     nsim = 200)\n\nres &lt;- rowData(sfe)[c(\"KRT17\", \"TAGLN\"),]\n#value of the metric\nres$moran.mc_statistic_sample01\n\n\n[1] 0.6439784 0.2623738\n\n\nCode\n#P-value\nres$moran.mc_p.value_sample01\n\n\n[1] 0.004975124 0.004975124\n\n\nWe can see both genes have a positive Moran’s I coefficient and a highly significant P-value. The expected value is \\(\\mathbb{E}(I) = -1/(n-1)\\) which is for large \\(N\\) close to 0. Positive and significant values indicate that areas with similar values are clustered. It is important to note that this could be both at the high or low end of the values of interest. Negative values indicate clustering of alternating values, i.e., gives a measure of spatial heterogeneity. Moreover, one should note that the result is dependent on the neighbourhood matrix. Different neighbourhood matrices will give different results. To compare Moran’s I coefficients between different values, we need to use the same neighbourhood matrix.\n\n\n\nGlobal’s Geary’s C coefficient\n\nImplementation using voyager\n\n\nCode\nsfe &lt;- runUnivariate(sfe,\n                     features = c(\"KRT17\", \"TAGLN\"),\n                     colGraphName = \"knn5\", nsim = 200,\n                     type = \"geary.mc\")\n\nres &lt;- rowData(sfe)[c(\"KRT17\", \"TAGLN\"),]\n#value of the metric\nres$geary.mc_statistic_sample01\n\n\n[1] 0.3563510 0.7259396\n\n\nCode\n#P-value\nres$geary.mc_p.value_sample01\n\n\n[1] 0.004975124 0.004975124\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgain, the value of Geary’s \\(C\\) indicates that the genes are spatially auto-correlated.\n\n\n\nGlobal Getis-Ord \\(G\\) statistic\n\nImplementation using spdep\n\n\nCode\n# Get the weight matrix from sfe object\nweights_neighbourhoods_binary &lt;- colGraph(sfe)\n# Change it to binary weights\nweights_neighbourhoods_binary$style &lt;- \"B\" \n# Calculate the global G statistic\nspdep::globalG.test(x = counts(sfe)[\"KRT17\",], \n                    listw = weights_neighbourhoods_binary)\n\n\n\n    Getis-Ord global G statistic\n\ndata:  counts(sfe)[\"KRT17\", ] \nweights: weights_neighbourhoods_binary \n\nstandard deviate = 280.93, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      5.409666e-05       9.990609e-06       2.464848e-14"
  },
  {
    "objectID": "02-cell-univar-lattice.html#a-note-of-caution",
    "href": "02-cell-univar-lattice.html#a-note-of-caution",
    "title": "Theory – Univariate lattice based analysis",
    "section": "A note of caution",
    "text": "A note of caution\nThe local methods presented above should always be interpreted with care, since we face the problem of multiple testing when calculating them for each cell. Moreover, the presented methods should mainly serve as exploratory measures to identify interesting regions in the data. Multiple processes can lead to the same pattern, thus from identifying the pattern we cannot infer the underlying process. Indication of clustering does not explain why this occurs. On the one hand, clustering can be the result of spatial interaction between the variables of interest. We have an accumulation of a gene of interest in one region of the tissue. On the other hand clustering can be the result spatial heterogeneity, when local similarity is created by structural heterogeneity in the tissue, e.g., that cells with uniform expression of a gene of interest are grouped together which then creates the apparent clustering of the gene expression measurement."
  },
  {
    "objectID": "02-cell-univar-lattice.html#session-info",
    "href": "02-cell-univar-lattice.html#session-info",
    "title": "Theory – Univariate lattice based analysis",
    "section": "Session info",
    "text": "Session info\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-16                      reshape2_1.4.4                \n[19] patchwork_1.1.3                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.4.4                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.2.1                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] spatstat.utils_3.0-3          rmarkdown_2.25               \n [87] XVector_0.40.0                htmltools_0.5.6.1            \n [89] pkgconfig_2.0.3               base64enc_0.1-3              \n [91] sparseMatrixStats_1.12.2      fastmap_1.1.1                \n [93] htmlwidgets_1.6.2             shiny_1.7.5.1                \n [95] DelayedMatrixStats_1.22.6     farver_2.1.1                 \n [97] jsonlite_1.8.7                BiocParallel_1.34.2          \n [99] R.oo_1.25.0                   BiocSingular_1.16.0          \n[101] RCurl_1.98-1.12               GenomeInfoDbData_1.2.10      \n[103] s2_1.1.4                      Rhdf5lib_1.22.1              \n[105] munsell_0.5.0                 Rcpp_1.0.11                  \n[107] ggnewscale_0.4.9              viridis_0.6.4                \n[109] stringi_1.7.12                leafsync_0.1.0               \n[111] zlibbioc_1.46.0               plyr_1.8.9                   \n[113] parallel_4.3.1                ggrepel_0.9.4                \n[115] deldir_1.0-9                  Biostrings_2.68.1            \n[117] stars_0.6-4                   splines_4.3.1                \n[119] tensor_1.5                    locfit_1.5-9.8               \n[121] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[123] BiocVersion_3.17.1            XML_3.99-0.14                \n[125] evaluate_0.22                 BiocManager_1.30.22          \n[127] httpuv_1.6.11                 purrr_1.0.2                  \n[129] polyclip_1.10-6               scattermore_1.2              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4"
  },
  {
    "objectID": "04-cell-multivar-lattice.html",
    "href": "04-cell-multivar-lattice.html",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "Code\nsource(\"utils.R\")\ntheme_set(theme_minimal())\n\n\nFor this representation of cells, we will rely on the SpatialFeatureExperiment package. For preprocessing of the dataset, we refer the reader to the vignette of the voyager package.\n\n\nCode\n(sfe &lt;- HeNSCLCData())\n\n# Empty cells\ncolData(sfe)$is_empty &lt;- colData(sfe)$nCounts &lt; 1\n# Select, count negative control probes\n(neg_inds &lt;- str_detect(rownames(sfe), \"^NegPrb\")) %&gt;% sum\n\ncolData(sfe)$prop_neg &lt;- colSums(counts(sfe)[neg_inds,])/colData(sfe)$nCounts\n# Remove low quality cells\nsfe &lt;- sfe[,!sfe$is_empty & sfe$prop_neg &lt; 0.1]\n# Calculate count stats\nrowData(sfe)$means &lt;- rowMeans(counts(sfe))\nrowData(sfe)$vars &lt;- rowVars(counts(sfe))\nrowData(sfe)$is_neg &lt;- neg_inds\n# log Counts\nsfe &lt;- logNormCounts(sfe)\n\n\n\n\nIn this vignette, we will show the metrics related a ligand-receptor pair, CEACAM6 and EGFR which was identified in the original publication of the CosMx dataset (He et al. 2022).\n\n\nCode\nplotSpatialFeature(sfe, c(\"CEACAM6\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()\n\n\n\n\n\nCode\nplotSpatialFeature(sfe, c(\"EGFR\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()\n\n\n\n\n\n\n\n\nIn general, a spatial autocorrelation measure has the following elements: a function, \\(f(x_i, x_j)\\), of the values of interest at locations \\(i\\) and \\(j\\) and a neighbourhood or weight matrix, \\(w_{ij}\\). The function \\(f\\) relates the measured values \\(x_i\\) and \\(x_j\\) and the neighbourhood matrix \\(w_{ij}\\) builds in the spatial relationship between location \\(i\\) and \\(j\\). If \\(i\\) and \\(j\\) are not neighbours, i.e. we assume they do not have any spatial association, the corresponding element of the weights matrix is 0 (i.e., \\(w_{ij} = 0\\)). In the following we will see that the function \\(f\\) varies between the different spatial autocorrelation measures (Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023).\n\n\n\n\nOne of the challenges when working with (irregular) lattice data is the construction of a neighbourhood graph (Pebesma and Bivand 2023). The main question is, what to consider as neighbours, as this will affect downstream analyses. Various methods exist to create neighbours, such as contiguitiy based neighbours, graph-based neighbours, distance based neighbours or higher order neighbours (Getis 2009; Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023). The documentation of the package spdep gives an overview of the different methods.\nSegmentation of individual cells is challenging (Wang 2019), therefore construction of contiguity-based neighbours based on individual cell segmentation assumes perfect segmentation results. Furthermore it would neglect the influence of more distant, not directly adjacent neighbours, which based on the feature of interest might not be the correct assumption.\nIn the following, we will use a k-nearest neighbours approach from voyager that relies on the spdep package. The approach and in particular the number \\(k\\) is somewhat arbritary.\n\n\n\n\n\nCode\ncolGraph(sfe, \"knn5\") &lt;- findSpatialNeighbors(sfe, method = \"knearneigh\",\n                                                  dist_type = \"idw\", k = 5, \n                                                  style = \"W\")\nweights_neighbourhoods &lt;- colGraph(sfe, \"knn5\")\n\n\n\n\n\n\n\nFor two continous observation the global bivariate Moran’s I is defined as (Wartenberg 1985 ; Bivand 2022)\n\\[I_B = \\frac{\\Sigma_i(\\Sigma_j{w_{ij}y_j\\times x_i})}{\\Sigma_i{x_i^2}}\\]\nwhere \\(x_i\\) and \\(y_i\\) are the two variables of interest and \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\).\nThe global bivariate Moran’s I is a measure of autocorrelation of the variables \\(x\\) and \\(y\\) with the spatial lag of \\(y\\). Therefore the result might overestimate the spatial autocorrelation of the variables due to the inherent (non-spatial) correlation of \\(x\\) and \\(y\\) (Bivand 2022).\n\n\n\nLee’s L is a bivariate measure that combines non-spatial pearson correlation with spatial autocorrelation via Moran’s I (Lee 2001). This enables us to asses the spatial dependence of two continuous variables in a single measure. The measure is defined as\n\\[L(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\]\nwhere \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\), \\(x\\) and \\(y\\) the two variables and \\(\\bar{x}\\) and \\(\\bar{y}\\) their means.\n\n\n\n\n\n\nSimilar to the global variant of Lee’s L the local variant (Lee 2001) is defined as\n\\[L_i(x,y) = \\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\] Local Lee’s L is a measure of spatial co-expression, when the variables of interest are gene expression measurements and can also be a metric of co-localization. Unlike the gobal version, the variables are not averaged and show the local contribution to the metric. Positive values indicate colocalization, negative values indicate segregation.\nThis can be interesting in the context of detection of coexpressed ligand-receptor pairs. A method that is based on bivariate Moran’s I and tries to detect such pairs is SpatialDM (Li et al. 2023).\n\n\n\n\n\n\nGeary’s C is a measure of spatial autocorrelation that is based on the difference between a variable and its neighbours. (Anselin 2019) defines it as\n\\[C_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2,\\]\nand can be generalized to \\(k\\) parameters by expanding\n\\[c_{k,i} = \\sum_{v=1}^k c_{v,i}\\]\nwhere \\(c_{v,i}\\) is the local Geary’s C for the \\(v\\)th variable at location \\(i\\). The number of variables that can be used is not fixed, which makes the interpretation a bit more difficult. In general, the metric summarizes similarity in the “multivariate attribute space” (i.e. the gene expression) to its geographic neighbours. The common difficulty in these analyses is the interpretaing the mixture of similarity in the geographic space and similarity in the attribute space."
  },
  {
    "objectID": "04-cell-multivar-lattice.html#dependencies",
    "href": "04-cell-multivar-lattice.html#dependencies",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "Code\nsource(\"utils.R\")\ntheme_set(theme_minimal())\n\n\nFor this representation of cells, we will rely on the SpatialFeatureExperiment package. For preprocessing of the dataset, we refer the reader to the vignette of the voyager package.\n\n\nCode\n(sfe &lt;- HeNSCLCData())\n\n# Empty cells\ncolData(sfe)$is_empty &lt;- colData(sfe)$nCounts &lt; 1\n# Select, count negative control probes\n(neg_inds &lt;- str_detect(rownames(sfe), \"^NegPrb\")) %&gt;% sum\n\ncolData(sfe)$prop_neg &lt;- colSums(counts(sfe)[neg_inds,])/colData(sfe)$nCounts\n# Remove low quality cells\nsfe &lt;- sfe[,!sfe$is_empty & sfe$prop_neg &lt; 0.1]\n# Calculate count stats\nrowData(sfe)$means &lt;- rowMeans(counts(sfe))\nrowData(sfe)$vars &lt;- rowVars(counts(sfe))\nrowData(sfe)$is_neg &lt;- neg_inds\n# log Counts\nsfe &lt;- logNormCounts(sfe)\n\n\n\n\nIn this vignette, we will show the metrics related a ligand-receptor pair, CEACAM6 and EGFR which was identified in the original publication of the CosMx dataset (He et al. 2022).\n\n\nCode\nplotSpatialFeature(sfe, c(\"CEACAM6\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()\n\n\n\n\n\nCode\nplotSpatialFeature(sfe, c(\"EGFR\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()"
  },
  {
    "objectID": "04-cell-multivar-lattice.html#irregular-lattice-and-neighbourhood-matrix",
    "href": "04-cell-multivar-lattice.html#irregular-lattice-and-neighbourhood-matrix",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "In general, a spatial autocorrelation measure has the following elements: a function, \\(f(x_i, x_j)\\), of the values of interest at locations \\(i\\) and \\(j\\) and a neighbourhood or weight matrix, \\(w_{ij}\\). The function \\(f\\) relates the measured values \\(x_i\\) and \\(x_j\\) and the neighbourhood matrix \\(w_{ij}\\) builds in the spatial relationship between location \\(i\\) and \\(j\\). If \\(i\\) and \\(j\\) are not neighbours, i.e. we assume they do not have any spatial association, the corresponding element of the weights matrix is 0 (i.e., \\(w_{ij} = 0\\)). In the following we will see that the function \\(f\\) varies between the different spatial autocorrelation measures (Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023)."
  },
  {
    "objectID": "04-cell-multivar-lattice.html#neighbourhood-matrix",
    "href": "04-cell-multivar-lattice.html#neighbourhood-matrix",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "One of the challenges when working with (irregular) lattice data is the construction of a neighbourhood graph (Pebesma and Bivand 2023). The main question is, what to consider as neighbours, as this will affect downstream analyses. Various methods exist to create neighbours, such as contiguitiy based neighbours, graph-based neighbours, distance based neighbours or higher order neighbours (Getis 2009; Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023). The documentation of the package spdep gives an overview of the different methods.\nSegmentation of individual cells is challenging (Wang 2019), therefore construction of contiguity-based neighbours based on individual cell segmentation assumes perfect segmentation results. Furthermore it would neglect the influence of more distant, not directly adjacent neighbours, which based on the feature of interest might not be the correct assumption.\nIn the following, we will use a k-nearest neighbours approach from voyager that relies on the spdep package. The approach and in particular the number \\(k\\) is somewhat arbritary.\n\n\n\n\n\nCode\ncolGraph(sfe, \"knn5\") &lt;- findSpatialNeighbors(sfe, method = \"knearneigh\",\n                                                  dist_type = \"idw\", k = 5, \n                                                  style = \"W\")\nweights_neighbourhoods &lt;- colGraph(sfe, \"knn5\")"
  },
  {
    "objectID": "04-cell-multivar-lattice.html#global-measures-for-bivariate-data",
    "href": "04-cell-multivar-lattice.html#global-measures-for-bivariate-data",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "For two continous observation the global bivariate Moran’s I is defined as (Wartenberg 1985 ; Bivand 2022)\n\\[I_B = \\frac{\\Sigma_i(\\Sigma_j{w_{ij}y_j\\times x_i})}{\\Sigma_i{x_i^2}}\\]\nwhere \\(x_i\\) and \\(y_i\\) are the two variables of interest and \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\).\nThe global bivariate Moran’s I is a measure of autocorrelation of the variables \\(x\\) and \\(y\\) with the spatial lag of \\(y\\). Therefore the result might overestimate the spatial autocorrelation of the variables due to the inherent (non-spatial) correlation of \\(x\\) and \\(y\\) (Bivand 2022).\n\n\n\nLee’s L is a bivariate measure that combines non-spatial pearson correlation with spatial autocorrelation via Moran’s I (Lee 2001). This enables us to asses the spatial dependence of two continuous variables in a single measure. The measure is defined as\n\\[L(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\]\nwhere \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\), \\(x\\) and \\(y\\) the two variables and \\(\\bar{x}\\) and \\(\\bar{y}\\) their means."
  },
  {
    "objectID": "04-cell-multivar-lattice.html#local-measures-for-bivariate-data",
    "href": "04-cell-multivar-lattice.html#local-measures-for-bivariate-data",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "Similar to the global variant of Lee’s L the local variant (Lee 2001) is defined as\n\\[L_i(x,y) = \\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\] Local Lee’s L is a measure of spatial co-expression, when the variables of interest are gene expression measurements and can also be a metric of co-localization. Unlike the gobal version, the variables are not averaged and show the local contribution to the metric. Positive values indicate colocalization, negative values indicate segregation.\nThis can be interesting in the context of detection of coexpressed ligand-receptor pairs. A method that is based on bivariate Moran’s I and tries to detect such pairs is SpatialDM (Li et al. 2023)."
  },
  {
    "objectID": "04-cell-multivar-lattice.html#local-measures-for-multivariate-data",
    "href": "04-cell-multivar-lattice.html#local-measures-for-multivariate-data",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "Geary’s C is a measure of spatial autocorrelation that is based on the difference between a variable and its neighbours. (Anselin 2019) defines it as\n\\[C_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2,\\]\nand can be generalized to \\(k\\) parameters by expanding\n\\[c_{k,i} = \\sum_{v=1}^k c_{v,i}\\]\nwhere \\(c_{v,i}\\) is the local Geary’s C for the \\(v\\)th variable at location \\(i\\). The number of variables that can be used is not fixed, which makes the interpretation a bit more difficult. In general, the metric summarizes similarity in the “multivariate attribute space” (i.e. the gene expression) to its geographic neighbours. The common difficulty in these analyses is the interpretaing the mixture of similarity in the geographic space and similarity in the attribute space."
  },
  {
    "objectID": "04-cell-multivar-lattice.html#global-measures-for-bivariate-data-1",
    "href": "04-cell-multivar-lattice.html#global-measures-for-bivariate-data-1",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "Global Measures for Bivariate Data",
    "text": "Global Measures for Bivariate Data\n\nGlobal Bivariate Moran’s I\n\n\nImplementation using spded\n\n\nCode\nres_xy &lt;- spdep::moran_bv(x = logcounts(sfe)[\"CEACAM6\",],\n         y = logcounts(sfe)[\"EGFR\",],\n         listw =  colGraph(sfe, \"knn5\"),\n         nsim = 499)\nboot::boot.ci(res_xy, conf = c(0.99, 0.95, 0.9), type = \"basic\")\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 499 bootstrap replicates\n\nCALL : \nboot::boot.ci(boot.out = res_xy, conf = c(0.99, 0.95, 0.9), type = \"basic\")\n\nIntervals : \nLevel      Basic         \n99%   ( 0.1285,  0.1358 )   \n95%   ( 0.1296,  0.1350 )   \n90%   ( 0.1301,  0.1349 )  \nCalculations and Intervals on Original Scale\nSome basic intervals may be unstable\n\n\nCode\nplot(res_xy)\n\n\n\n\n\nFrom the result of the global measure, the overall spatial autocorrelation of the two genes is not significant.\n\n\nGlobal Bivariate Lee’s L\n\nImplementation using voyager\n\n\nCode\nres_lee &lt;- calculateBivariate(sfe, type = \"lee.mc\", \n                   feature1 = \"CEACAM6\", feature2 = \"EGFR\",\n                   nsim = 499)\nres_lee$lee.mc_statistic\n\n\n statistic \n0.06726535 \n\n\nCode\nres_lee$ lee.mc_p.value\n\n\n[1] 0.002\n\n\nThe interpretation of the result is not straightforward, as identical patterns do not have a value of 1 but have a value depending on their spatial arrangement. In general positive values indicate spatial co-occurrence while negative values indicate spatial segregation of the pattern of variables of \\(x\\) and \\(y\\) (Lee 2001)."
  },
  {
    "objectID": "04-cell-multivar-lattice.html#local-measures-for-bivariate-data-1",
    "href": "04-cell-multivar-lattice.html#local-measures-for-bivariate-data-1",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "Local Measures for Bivariate Data",
    "text": "Local Measures for Bivariate Data\n\nBivariate Lee’s L\n\nImplementation using voyager\n\n\nCode\nsfe &lt;- runBivariate(sfe, type = \"locallee\",\n                    feature1 = \"CEACAM6\", feature2 = \"EGFR\")\n\nplotLocalResult(sfe, \"locallee\", \n                features = localResultFeatures(sfe, \"locallee\"),\n                ncol = 2, colGeometryName = \"centroids\",\n                divergent = TRUE, diverge_center = 0)"
  },
  {
    "objectID": "04-cell-multivar-lattice.html#local-measures-for-multivariate-data-1",
    "href": "04-cell-multivar-lattice.html#local-measures-for-multivariate-data-1",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "Local Measures for Multivariate Data",
    "text": "Local Measures for Multivariate Data\n\nMultivariate local Geary’s C\nHere we use the marker genes used in the original paper that study apoptosis (He et al. 2022, Supplementary Table 1) in a subset of the tissue, as the computation is very intensive.\n\n\nCode\napoptosis_genes &lt;- c(\"BAX\", \"BCL2\", \"BCL2L1\", \"BIRC5\", \"CASP3\", \"CASP8\", \"TP53\")\n\n# Subset of the tissue\nbbox_use &lt;- st_as_sfc(st_bbox(c(xmin = 3200, xmax = 15800, ymin = 155200, ymax = 164200)))\nsfe_sub &lt;- sfe[,st_intersects(colGeometries(sfe)$centroids, bbox_use, sparse = FALSE)]\n\nsfe_sub &lt;- runMultivariate(sfe_sub, type = \"localC_multi\",\n                    subset_row = apoptosis_genes)\n\n# Local C mutli is stored in colData so this is a workaround to plot it\nplotSpatialFeature(sfe_sub, \"localC_multi\", colGeometryName = \"centroids\")\n\n\n\n\n\nThe plot indicates regions where the gene expression is more homogeneous (low Geary’s C) and regions where the gene expression is more heterogeneous (large Geary’s C value). Importantly, strong similarity in one or some variables may compensate for dissimilarity in other variables, which makes the interpretation tricky. The local Geary’s C value is not scaled.\nWe can further plot the results of the permutation test. Significant values indicate interesting regions, but should be interpreted with care for various reasons. For example, we are looking for similarity in a combination of multiple values but the exact combination is not known. For further details, see (Anselin 2019).\n(MR: this makes me question how we should present this. SG: Good question, it comes very close to spatial clustering here, maybe we can show this as a preview for other methods that we do not discuss.. From the Anselin 2019 publication: “Overall, however, the statistic indicates a combination of the notion of distance in multi-attribute space with that of geographic neighbors. This is the essence of any spatial autocorrelation statistic. It is also the trade-off encountered in spatially constrained multivariate clustering methods (for a recent discussion, see, e.g., Grubesic, Wei, and Murray 2014).”)\n\n\nCode\nsfe_sub &lt;- runMultivariate(sfe_sub, type = \"localC_perm_multi\",\n                    subset_row = apoptosis_genes,\n                    nsim = 100)\n\n# stored as spatially reduced dim; plot it in this way\nspatialReducedDim(sfe_sub, \"localC_perm_multi\",  c(1, 11))\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt would be interesting to do this not only on the cell level, but also on the domain level."
  },
  {
    "objectID": "04-cell-multivar-lattice.html#local-neighbor-match-test",
    "href": "04-cell-multivar-lattice.html#local-neighbor-match-test",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "Local Neighbor Match Test",
    "text": "Local Neighbor Match Test\nThis test is useful to assess the overlap of the k-nearest neighbours from physical distances (tissue space) with the k-nearest neighbours from the gene expression measurements (attribute space).\n[MR: how are the KNNs calculated in the attribute space?]\n\n\nCode\nsf &lt;- colGeometries(sfe)$cellSeg\nsf &lt;- cbind(sf,  t(as.matrix(logcounts(sfe)[c(apoptosis_genes),])))\n\nnbr_test &lt;- neighbor_match_test(sf[c(apoptosis_genes)], k = 20)\n\nsf$Probability &lt;- nbr_test$Probability\nsf$Cardinality &lt;- nbr_test$Cardinality\n\ntm_shape(sf) + tm_fill(col = 'Probability')  \n\n\n\n\n\nCode\ntm_shape(sf) + tm_fill(col = 'Cardinality')  \n\n\n\n\n\nCardinality is a measure of how many neighbours of each cell are in common. Some regions show high cardinality with low probability. On the cellular level, this might not be very informative and lead to regions with high similarity. We only see very few cells with a cardinality greater than 0. The problem might come from the imperfect segmentation of the cells, which can result in a poor reconstruction of the “geographical” tissue neighbourhood graph. In addition, as the number of dimensions increase, the empty space between observations also increases; this is known as the empty space problem.\nAgain, this analysis should probably be performed on a structure level instead of a single cell level.\n[MR: should we do the analysis at the structure/domain level then?]"
  },
  {
    "objectID": "04-cell-multivar-lattice.html#session-info",
    "href": "04-cell-multivar-lattice.html#session-info",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "Session info",
    "text": "Session info\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-16                      reshape2_1.4.4                \n[19] patchwork_1.1.3                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.4.4                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.2.1                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] spatstat.utils_3.0-3          rmarkdown_2.25               \n [87] XVector_0.40.0                htmltools_0.5.6.1            \n [89] pkgconfig_2.0.3               base64enc_0.1-3              \n [91] sparseMatrixStats_1.12.2      fastmap_1.1.1                \n [93] htmlwidgets_1.6.2             shiny_1.7.5.1                \n [95] DelayedMatrixStats_1.22.6     farver_2.1.1                 \n [97] jsonlite_1.8.7                BiocParallel_1.34.2          \n [99] R.oo_1.25.0                   BiocSingular_1.16.0          \n[101] RCurl_1.98-1.12               GenomeInfoDbData_1.2.10      \n[103] s2_1.1.4                      Rhdf5lib_1.22.1              \n[105] munsell_0.5.0                 Rcpp_1.0.11                  \n[107] ggnewscale_0.4.9              viridis_0.6.4                \n[109] stringi_1.7.12                leafsync_0.1.0               \n[111] zlibbioc_1.46.0               plyr_1.8.9                   \n[113] parallel_4.3.1                ggrepel_0.9.4                \n[115] deldir_1.0-9                  Biostrings_2.68.1            \n[117] stars_0.6-4                   splines_4.3.1                \n[119] tensor_1.5                    locfit_1.5-9.8               \n[121] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[123] BiocVersion_3.17.1            XML_3.99-0.14                \n[125] evaluate_0.22                 BiocManager_1.30.22          \n[127] httpuv_1.6.11                 purrr_1.0.2                  \n[129] polyclip_1.10-6               scattermore_1.2              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4"
  },
  {
    "objectID": "06-spot-multivar-lattice.html",
    "href": "06-spot-multivar-lattice.html",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "Code\nsource(\"utils.R\")\ntheme_set(theme_light())\n\n\n\n\n\n\n\nCode\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\n\nCode\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\nweights_neighbourhoods &lt;- colGraph(sfe_tissue, \"visium\")\n\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, named Mdkand Ncl[7].\n\n\nCode\nMdK &lt;- \"ENSMUSG00000027239\"\nNcI &lt;- \"ENSMUSG00000026234\"\n\n\nSpot based data is collected along a regular spaced grid where all sample areas have the same size. Such a grid is also called a regular lattice. In more rigorous terms the data \\(Y\\) is the product of a random process but the sampling locations are fixed along a lattice \\(D\\). The lattice \\(D\\) does not have to regular but in the scope of spot based data it is. The main difference of this type of data in comparison to point patterns is, that the locations of the data are then not results of a stochastic process but rather due to a defined sampling strategy (Zuur, Ieno, and Smith 2007).\nThe lattice is composed of individual spatial units\n\\[D = \\{A_1, A_2,...,A_n\\}\\]\nwhere these units are not supposed to overlap\n\\[A_i \\cap A_j = \\emptyset \\forall i \\neq j\\]\nThe data is then a random variable of the spatial unit along the lattice\n\\[Y_i = Y(A_i)\\]\nMost lattice data analysis technique build on the concept of neighbours. Therefore, the spatial relationship has to be modelled with e.g. a spatial weigth matrix \\(W\\). There are a lot of ways to define a spatial weigth matrix \\(W\\). Here, the units that are adjacent are specified with a one and the ones that are not adjacent with a zero (binary coniguity matrix)\n\\[w_{ij} = \\begin{cases} 1 \\text{ if } A_i \\text{ and } A_j \\text{ are adjacent}\\\\ 0 \\text{ otw} \\end{cases}\\]\nother options to specify the weight matrix \\(W\\) are mentioned in (Zuur, Ieno, and Smith 2007).\n\n\n\n\n\nFor two continous observation the global bivariate Moran’s I is defined as (Wartenberg 1985 ; Bivand 2022)\n\\[I_B = \\frac{\\Sigma_i(\\Sigma_j{w_{ij}y_j\\times x_i})}{\\Sigma_i{x_i^2}}\\]\nwhere \\(x_i\\) and \\(y_i\\) are the two variables of interest and \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\).\nThe global bivariate Moran’s I is a measure of autocorrelation of the variables \\(x\\) and \\(y\\) with the spatial lag of \\(y\\). Therefore the result might overestimate the spatial autocorrelation of the variables due to the inherent (non-spatial) correlation of \\(x\\) and \\(y\\) (Bivand 2022).\n\n\n\nLee’s L is a bivariate measure that combines non-spatial pearson correlation with spatial autocorrelation via Moran’s I (Lee 2001). This enables us to asses the spatial dependence of two continuous variables in a single measure. The measure is defined as\n\\[L(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\]\nwhere \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\), \\(x\\) and \\(y\\) the two variables and \\(\\bar{x}\\) and \\(\\bar{y}\\) their means.\n\n\n\n\n\n\nSimilar to the global variant of Lee’s L the local variant (Lee 2001) is defined as\n\\[L_i(x,y) = \\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\] Local Lee’s L is a measure of spatial co-expression, when the variables of interest are gene expression measurements and can also be a metric of co-localization. Unlike the gobal version, the variables are not averaged and show the local contribution to the metric. Positive values indicate colocalization, negative values indicate segregation.\nThis can be interesting in the context of detection of coexpressed ligand-receptor pairs. A method that is based on bivariate Moran’s I and tries to detect such pairs is SpatialDM (Li et al. 2023).\n\n\n\n\n\n\nGeary’s C is a measure of spatial autocorrelation that is based on the difference between a variable and its neighbours. (Anselin 2019) defines it as\n\\[C_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2,\\]\nand can be generalized to \\(k\\) parameters by expanding\n\\[c_{k,i} = \\sum_{v=1}^k c_{v,i}\\]\nwhere \\(c_{v,i}\\) is the local Geary’s C for the \\(v\\)th variable at location \\(i\\). The number of variables that can be used is not fixed, which makes the interpretation a bit more difficult. In general, the metric summarizes similarity in the “multivariate attribute space” (i.e. the gene expression) to its geographic neighbours. The common difficulty in these analyses is the interpretaing the mixture of similarity in the geographic space and similarity in the attribute space."
  },
  {
    "objectID": "06-spot-multivar-lattice.html#dependencies",
    "href": "06-spot-multivar-lattice.html#dependencies",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "Code\nsource(\"utils.R\")\ntheme_set(theme_light())"
  },
  {
    "objectID": "06-spot-multivar-lattice.html#setup-and-preprocessing",
    "href": "06-spot-multivar-lattice.html#setup-and-preprocessing",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "Code\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe &lt;- mirrorImg(sfe, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe\n\n\nclass: SpatialFeatureExperiment \ndim: 15123 4992 \nmetadata(0):\nassays(1): counts\nrownames(15123): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(4992): AAACAACGAATAGTTC AAACAAGTATCTCCCA ... TTGTTTGTATTACACG\n  TTGTTTGTGTAAATTC\ncolData names(12): barcode col ... prop_mito in_tissue\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\n\nCode\nsfe_tissue &lt;- sfe[,colData(sfe)$in_tissue]\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0,]\n\n#perform normalisation \nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\nweights_neighbourhoods &lt;- colGraph(sfe_tissue, \"visium\")\n\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, named Mdkand Ncl[7].\n\n\nCode\nMdK &lt;- \"ENSMUSG00000027239\"\nNcI &lt;- \"ENSMUSG00000026234\"\n\n\nSpot based data is collected along a regular spaced grid where all sample areas have the same size. Such a grid is also called a regular lattice. In more rigorous terms the data \\(Y\\) is the product of a random process but the sampling locations are fixed along a lattice \\(D\\). The lattice \\(D\\) does not have to regular but in the scope of spot based data it is. The main difference of this type of data in comparison to point patterns is, that the locations of the data are then not results of a stochastic process but rather due to a defined sampling strategy (Zuur, Ieno, and Smith 2007).\nThe lattice is composed of individual spatial units\n\\[D = \\{A_1, A_2,...,A_n\\}\\]\nwhere these units are not supposed to overlap\n\\[A_i \\cap A_j = \\emptyset \\forall i \\neq j\\]\nThe data is then a random variable of the spatial unit along the lattice\n\\[Y_i = Y(A_i)\\]\nMost lattice data analysis technique build on the concept of neighbours. Therefore, the spatial relationship has to be modelled with e.g. a spatial weigth matrix \\(W\\). There are a lot of ways to define a spatial weigth matrix \\(W\\). Here, the units that are adjacent are specified with a one and the ones that are not adjacent with a zero (binary coniguity matrix)\n\\[w_{ij} = \\begin{cases} 1 \\text{ if } A_i \\text{ and } A_j \\text{ are adjacent}\\\\ 0 \\text{ otw} \\end{cases}\\]\nother options to specify the weight matrix \\(W\\) are mentioned in (Zuur, Ieno, and Smith 2007)."
  },
  {
    "objectID": "06-spot-multivar-lattice.html#global-measures-for-bivariate-data",
    "href": "06-spot-multivar-lattice.html#global-measures-for-bivariate-data",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "For two continous observation the global bivariate Moran’s I is defined as (Wartenberg 1985 ; Bivand 2022)\n\\[I_B = \\frac{\\Sigma_i(\\Sigma_j{w_{ij}y_j\\times x_i})}{\\Sigma_i{x_i^2}}\\]\nwhere \\(x_i\\) and \\(y_i\\) are the two variables of interest and \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\).\nThe global bivariate Moran’s I is a measure of autocorrelation of the variables \\(x\\) and \\(y\\) with the spatial lag of \\(y\\). Therefore the result might overestimate the spatial autocorrelation of the variables due to the inherent (non-spatial) correlation of \\(x\\) and \\(y\\) (Bivand 2022).\n\n\n\nLee’s L is a bivariate measure that combines non-spatial pearson correlation with spatial autocorrelation via Moran’s I (Lee 2001). This enables us to asses the spatial dependence of two continuous variables in a single measure. The measure is defined as\n\\[L(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\]\nwhere \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\), \\(x\\) and \\(y\\) the two variables and \\(\\bar{x}\\) and \\(\\bar{y}\\) their means."
  },
  {
    "objectID": "06-spot-multivar-lattice.html#local-measures-for-bivariate-data",
    "href": "06-spot-multivar-lattice.html#local-measures-for-bivariate-data",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "Similar to the global variant of Lee’s L the local variant (Lee 2001) is defined as\n\\[L_i(x,y) = \\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\] Local Lee’s L is a measure of spatial co-expression, when the variables of interest are gene expression measurements and can also be a metric of co-localization. Unlike the gobal version, the variables are not averaged and show the local contribution to the metric. Positive values indicate colocalization, negative values indicate segregation.\nThis can be interesting in the context of detection of coexpressed ligand-receptor pairs. A method that is based on bivariate Moran’s I and tries to detect such pairs is SpatialDM (Li et al. 2023)."
  },
  {
    "objectID": "06-spot-multivar-lattice.html#local-measures-for-multivariate-data",
    "href": "06-spot-multivar-lattice.html#local-measures-for-multivariate-data",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "",
    "text": "Geary’s C is a measure of spatial autocorrelation that is based on the difference between a variable and its neighbours. (Anselin 2019) defines it as\n\\[C_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2,\\]\nand can be generalized to \\(k\\) parameters by expanding\n\\[c_{k,i} = \\sum_{v=1}^k c_{v,i}\\]\nwhere \\(c_{v,i}\\) is the local Geary’s C for the \\(v\\)th variable at location \\(i\\). The number of variables that can be used is not fixed, which makes the interpretation a bit more difficult. In general, the metric summarizes similarity in the “multivariate attribute space” (i.e. the gene expression) to its geographic neighbours. The common difficulty in these analyses is the interpretaing the mixture of similarity in the geographic space and similarity in the attribute space."
  },
  {
    "objectID": "06-spot-multivar-lattice.html#global-measures-for-bivariate-data-1",
    "href": "06-spot-multivar-lattice.html#global-measures-for-bivariate-data-1",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "Global Measures for Bivariate Data",
    "text": "Global Measures for Bivariate Data\n\nGlobal Bivariate Moran’s I\n\n\nImplementation using spded\n\n\nCode\nres_xy &lt;- spdep::moran_bv(x = logcounts(sfe_tissue)[MdK,],\n         y = logcounts(sfe_tissue)[NcI,],\n         listw =  colGraph(sfe_tissue, \"visium\"),\n         nsim = 499)\nboot::boot.ci(res_xy, conf = c(0.99, 0.95, 0.9), type = \"basic\")\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 499 bootstrap replicates\n\nCALL : \nboot::boot.ci(boot.out = res_xy, conf = c(0.99, 0.95, 0.9), type = \"basic\")\n\nIntervals : \nLevel      Basic         \n99%   (-0.0099,  0.0675 )   \n95%   ( 0.0046,  0.0583 )   \n90%   ( 0.0087,  0.0550 )  \nCalculations and Intervals on Original Scale\nSome basic intervals may be unstable\n\n\nCode\nplot(res_xy)\n\n\n\n\n\nFrom the result of the global measure, the overall spatial autocorrelation of the two genes is not significant.\n\n\nGlobal Bivariate Lee’s L\n\nImplementation using voyager\n\n\nCode\nres_lee &lt;- calculateBivariate(sfe_tissue, type = \"lee.mc\", \n                   feature1 = MdK, feature2 = NcI,\n                   nsim = 499)\nres_lee$lee.mc_statistic\n\n\nstatistic \n0.0213312 \n\n\nCode\nres_lee$ lee.mc_p.value\n\n\n[1] 0.008\n\n\nThe interpretation of the result is not straightforward, as identical patterns do not have a value of 1 but have a value depending on their spatial arrangement. In general positive values indicate spatial co-occurrence while negative values indicate spatial segregation of the pattern of variables of \\(x\\) and \\(y\\) (Lee 2001)."
  },
  {
    "objectID": "06-spot-multivar-lattice.html#local-measures-for-bivariate-data-1",
    "href": "06-spot-multivar-lattice.html#local-measures-for-bivariate-data-1",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "Local Measures for Bivariate Data",
    "text": "Local Measures for Bivariate Data\n\nBivariate Lee’s L\n\nImplementation using voyager\n\n\nCode\nsfe_tissue &lt;- runBivariate(sfe_tissue, type = \"locallee\",\n                    feature1 = MdK, feature2 = NcI)\n\nplotLocalResult(sfe_tissue, \"locallee\", \n                features = localResultFeatures(sfe_tissue, \"locallee\"),\n                ncol = 2, divergent = TRUE, diverge_center = 0,\n                colGeometryName = \"spotPoly\")"
  },
  {
    "objectID": "06-spot-multivar-lattice.html#local-measures-for-multivariate-data-1",
    "href": "06-spot-multivar-lattice.html#local-measures-for-multivariate-data-1",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "Local Measures for Multivariate Data",
    "text": "Local Measures for Multivariate Data\n\nMultivariate local Geary’s C\nHere we use the marker genes used in the original paper that study apoptosis (He et al. 2022, Supplementary Table 1) in a subset of the tissue, as the computation is very intensive.\n\n\nCode\nhvgs &lt;- getTopHVGs(sfe_tissue, fdr.threshold = 0.01)\n\n# Subset of the tissue\nsfe_tissue &lt;- runMultivariate(sfe_tissue, type = \"localC_multi\",\n                    subset_row = hvgs)\n\n# Local C mutli is stored in colData so this is a workaround to plot it\nplotSpatialFeature(sfe_tissue, \"localC_multi\")\n\n\n\n\n\nWe can further plot the results of the permutation test. Significant values indicate interesting regions, but should be interpreted with care for various reasons. For example, we are looking for similarity in a combination of multiple values but the exact combination is not known. For further details, see (Anselin 2019).\n(MR: this makes me question how we should present this. SG: Good question, it comes very close to spatial clustering here, maybe we can show this as a preview for other methods that we do not discuss.. From the Anselin 2019 publication: “Overall, however, the statistic indicates a combination of the notion of distance in multi-attribute space with that of geographic neighbors. This is the essence of any spatial autocorrelation statistic. It is also the trade-off encountered in spatially constrained multivariate clustering methods (for a recent discussion, see, e.g., Grubesic, Wei, and Murray 2014).”)\n\n\nCode\nsfe_tissue &lt;- runMultivariate(sfe_tissue, type = \"localC_perm_multi\",\n                    subset_row = hvgs,\n                    nsim = 100)\n\n# stored as spatially reduced dim; plot it in this way\nspatialReducedDim(sfe_tissue, \"localC_perm_multi\",  c(1, 11))\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt would be interesting to do this not only on the cell level, but also on the domain level."
  },
  {
    "objectID": "06-spot-multivar-lattice.html#local-neighbor-match-test",
    "href": "06-spot-multivar-lattice.html#local-neighbor-match-test",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "Local Neighbor Match Test",
    "text": "Local Neighbor Match Test\nThis test is useful to assess the overlap of the k-nearest neighbours from physical distances (tissue space) with the k-nearest neighbours from the gene expression measurements (attribute space).\n[MR: how are the KNNs calculated in the attribute space?]\n\n\nCode\nsf &lt;- colGeometries(sfe_tissue)$spotPoly\nsf &lt;- cbind(sf,  t(as.matrix(logcounts(sfe_tissue)[hvgs,])))\n\nnbr_test &lt;- neighbor_match_test(sf[c(hvgs)], k = 20)\n\nsf$Probability &lt;- nbr_test$Probability\nsf$Cardinality &lt;- nbr_test$Cardinality\n\ntm_shape(sf) + tm_fill(col = 'Probability')  \n\n\n\n\n\nCode\ntm_shape(sf) + tm_fill(col = 'Cardinality')  \n\n\n\n\n\nCardinality is a measure of how many neighbours of each cell are in common. Some regions show high cardinality with low probability. On the cellular level, this might not be very informative and lead to regions with high similarity. We only see very few cells with a cardinality greater than 0. In addition, as the number of dimensions increase, the empty space between observations also increases; this is known as the empty space problem.\nAgain, this analysis should probably be performed on a structure level instead of a single cell level.\n[MR: should we do the analysis at the structure/domain level then?]"
  },
  {
    "objectID": "06-spot-multivar-lattice.html#session-info",
    "href": "06-spot-multivar-lattice.html#session-info",
    "title": "Theory – Multivariate lattice based analysis",
    "section": "Session info",
    "text": "Session info\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-16                      reshape2_1.4.4                \n[19] patchwork_1.1.3                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.4.4                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.8-42                   rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  dbscan_1.1-11                \n [19] R.utils_2.12.2                dichromat_2.0-0.1            \n [21] scico_1.5.0                   limma_3.56.2                 \n [23] rstudioapi_0.15.0             RSQLite_2.3.1                \n [25] generics_0.1.3                crosstalk_1.2.0              \n [27] Matrix_1.5-4.1                ggbeeswarm_0.7.2             \n [29] fansi_1.0.5                   abind_1.4-5                  \n [31] R.methodsS3_1.8.2             terra_1.7-55                 \n [33] lifecycle_1.0.3               yaml_2.3.7                   \n [35] edgeR_3.42.4                  rhdf5_2.44.0                 \n [37] tmaptools_3.1-1               grid_4.3.1                   \n [39] blob_1.2.4                    promises_1.2.1               \n [41] dqrng_0.3.1                   crayon_1.5.2                 \n [43] lattice_0.21-8                beachmat_2.16.0              \n [45] KEGGREST_1.40.1               magick_2.8.0                 \n [47] pillar_1.9.0                  knitr_1.44                   \n [49] metapod_1.7.0                 rjson_0.2.21                 \n [51] boot_1.3-28.1                 codetools_0.2-19             \n [53] wk_0.8.0                      glue_1.6.2                   \n [55] vctrs_0.6.4                   png_0.1-8                    \n [57] gtable_0.3.4                  cachem_1.0.8                 \n [59] xfun_0.40                     S4Arrays_1.0.6               \n [61] mime_0.12                     DropletUtils_1.20.0          \n [63] units_0.8-4                   statmod_1.5.0                \n [65] bluster_1.10.0                interactiveDisplayBase_1.38.0\n [67] ellipsis_0.3.2                bit64_4.0.5                  \n [69] filelock_1.0.2                irlba_2.3.5.1                \n [71] vipor_0.4.5                   KernSmooth_2.23-21           \n [73] colorspace_2.1-0              DBI_1.1.3                    \n [75] raster_3.6-26                 tidyselect_1.2.0             \n [77] bit_4.0.5                     compiler_4.3.1               \n [79] curl_5.1.0                    BiocNeighbors_1.18.0         \n [81] DelayedArray_0.26.7           scales_1.2.1                 \n [83] classInt_0.4-10               rappdirs_0.3.3               \n [85] goftest_1.2-3                 spatstat.utils_3.0-3         \n [87] rmarkdown_2.25                XVector_0.40.0               \n [89] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [91] base64enc_0.1-3               sparseMatrixStats_1.12.2     \n [93] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [95] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [97] farver_2.1.1                  jsonlite_1.8.7               \n [99] BiocParallel_1.34.2           R.oo_1.25.0                  \n[101] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[103] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[105] Rhdf5lib_1.22.1               munsell_0.5.0                \n[107] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[109] viridis_0.6.4                 stringi_1.7.12               \n[111] leafsync_0.1.0                zlibbioc_1.46.0              \n[113] plyr_1.8.9                    parallel_4.3.1               \n[115] ggrepel_0.9.4                 deldir_1.0-9                 \n[117] Biostrings_2.68.1             stars_0.6-4                  \n[119] splines_4.3.1                 tensor_1.5                   \n[121] locfit_1.5-9.8                igraph_1.5.1                 \n[123] ScaledMatrix_1.8.1            BiocVersion_3.17.1           \n[125] XML_3.99-0.14                 evaluate_0.22                \n[127] BiocManager_1.30.22           httpuv_1.6.11                \n[129] purrr_1.0.2                   polyclip_1.10-6              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4"
  },
  {
    "objectID": "08-highlights-point-pattern-analysis.html",
    "href": "08-highlights-point-pattern-analysis.html",
    "title": "Point Pattenr Analysis – Summary",
    "section": "",
    "text": "Cells (or transcripts) can be approximated as points given their location.\n\n\nThe central package to analyse point patterns in R is called spatstat (Baddeley and Turner 2005). The main data object to compute on is called a ppp object. ppp objects describe point patterns in two dimensional space, ppx objects create multidimensional point patterns. A ppp object is is made up of three specifications (Baddeley and Turner 2005):\n\nThe locations of the points in question (\\(x\\),\\(y\\) and, optionally, \\(z\\) coordinates)\nThe observation window\nThe associated marks to each point in the pattern\n\nOn this central object, various spatstat metrics can be calculated.\n\n\n\n\n\n\nStructure of a SpatialExperiment object as introduced by Righelli et al.\n\n\nOften, the starting point in spatial omics data analysis is a SpatialExperiment (or similar) object. This is a central data structure in the BioConductor framework to store spatial omics data. The data we consider here is a MERFISH assay of a mouse preoptic hypothalamus (Chen et al. 2015; Moffitt et al. 2018).\n\n\nCode\nsuppressPackageStartupMessages({\n  library(SpatialExperiment)\n  library(spatstat.geom)\n  library(spatstat.explore)\n  library(dplyr)\n  library(ggplot2)\n  library(patchwork)\n  library(reshape2)\n  library(stringr)\n  library(tidyr)\n  library(magrittr)\n})\n\n\n\n\nCode\n# load the data from ExperimentHub\nsource(\"../code/load_data.R\")\n# source some helper functions\nsource(\"../code/utils.R\")\nlibrary('spatialFDA')\ntheme_set(theme_light())\n# load the SpatialExperiment object\nspe &lt;- readRDS(\"../data/spe.rds\")\nspe\n\n\nclass: SpatialExperiment \ndim: 161 73655 \nmetadata(0):\nassays(1): exprs\nrownames(161): Ace2 Adora2a ... Ucn3 Vgf\nrowData names(0):\ncolnames(73655): 6749ccb4-2ed1-4029-968f-820a287f43c8\n  6cac74bd-4ea7-4701-8701-42563cc65eb8 ...\n  6b666f81-7b73-4100-9e02-b5381b39f0f3\n  fdcddd97-7701-462a-b48f-979111245bd5\ncolData names(7): Animal_ID Animal_sex ... Neuron_cluster_ID cluster_id\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : x y\nimgData names(0):\n\n\nWe see that we have an object of class SpatialExperiment with \\(161\\) genes (rows) and \\(73655\\) cells. This object is very similar to a SingleCellExperiment object except it has the added spatialCoords slot. One slot in the colData is called sample_id which defines the so called z-slices. The three dimensional tissue is cut in the z-axis into consecutive two dimensional slices (Righelli et al. 2022).\nNext, we want to extract three slices of this SpatialExperiment object and convert the 2D slices into ppp objects.\n\n\nCode\n# define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n# small helper function to extract the z-slices and convert them to `ppp` objects\nselectZstacks &lt;- function(zstack, spe) {\n  spe[, spe$sample_id == zstack] |&gt; \n    .ppp(marks = \"cluster_id\")\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe) |&gt;\n  setNames(zstack_list)\n\npp_ls\n\n\n$`-0.09`\nMarked planar point pattern: 6185 points\nMultitype, with levels = \n   Ambiguous Astrocyte Endothelial Ependymal Excitatory Inhibitory Microglia OD \nImmature OD Mature Pericytes\nwindow: rectangle = [1307.7716, 3097.8543] x [2114.368, 3903.386] units\n\n$`0.01`\nMarked planar point pattern: 6111 points\nMultitype, with levels = \n   Ambiguous Astrocyte Endothelial Ependymal Excitatory Inhibitory Microglia OD \nImmature OD Mature Pericytes\nwindow: rectangle = [1222.5635, 3012.4248] x [-3993.535, -2202.755] units\n\n$`0.21`\nMarked planar point pattern: 5578 points\nMultitype, with levels = \n   Ambiguous Astrocyte Endothelial Ependymal Excitatory Inhibitory Microglia OD \nImmature OD Mature Pericytes\nwindow: rectangle = [1328.6103, 3124.2492] x [2199.257, 3993.499] units\n\n\nWe see that we obtain a list of three ppp objects for the three z-slices \\(-0.09, 0.01, 0.21\\).\nWe can plot one of these slices, e.g. slice \\(-0.09\\) with ggplot\n\n\nCode\n# create a dataframe from the point pattern\npp_df &lt;- pp_ls$`-0.09` %&gt;% as.data.frame\n# plot with ggplot\nggplot(pp_df, aes(x, y, colour = marks)) +\n  geom_point(size = 1) +\n  coord_equal()\n\n\n\n\n\n\n\n\nAs stated above, one important aspect of a point pattern is the observation window. It represents the region in which a pattern is observed or e.g. a survey was conducted (Baddeley, Rubak, and Turner 2015, 85). In most microscopy use cases we encounter window sampling. Window sampling describes the case where we don’t observe the entire point pattern in a window but just a sample (Baddeley, Rubak, and Turner 2015, 143–45).\nThe window of a point pattern does not need to be rectangular; we can receive round biopsies or calculate convex hulls around our sample (Baddeley, Rubak, and Turner 2015, 143–45).\nLet’s investigate the observation window for the slice \\(-0.09\\).\n\n\nCode\n# subset point pattern list\npp_sub &lt;- pp_ls$`-0.09`\n# base R plot of all marks\npp_sub |&gt; plot()\n\n\n\n\n\nHere, we have a rectangular window around all points.\nLet’s investigate what a round window would look like:\n\n\nCode\npp_sub_round &lt;- pp_sub\n# calculate circle with radius 850 µm and a center at the centroid of the window would look like\nw &lt;- disc(r = 850, centroid.owin(Window(pp_sub)))\nWindow(pp_sub_round) &lt;- w\npp_sub_round |&gt; plot()\n\n\n\n\n\nCorrectly assigning windows is very important. The window should represent the space where points are expected. This means, in window sampling, one should not restrict the window. This would lead to a false underestimation of the area where the points can be potentially observed. This problem of where we can observe points and where not (beyond the boundary of the window) leads to a range of problems collectively called edge effects (Baddeley, Rubak, and Turner 2015, 143–45). We will discuss these later.\n\n\n\nThe next concept that defines a point pattern is that marks can be associated with the points. The points can also have no mark, which we would call an unmarked point pattern\n\n\nCode\nunmark(pp_sub) |&gt; plot()\n\n\n\n\n\nMarks can be univariate or multivariate variables that are associated with the points (Baddeley, Rubak, and Turner 2015, 147). In the context of cell biology we can distinguish between discrete marks (e.g. cell types) or continuous marks (e.g. gene expression).\n\n\nIn our example, we have a multitype point pattern, meaning there are different cell types that serve as marks for the point pattern. Multitype means that we consider all marks together. The opposite is multivariate, where we consider the marks independently (Baddeley, Rubak, and Turner 2015, 564 ff.).\nFirst the multitype case:\n\n\nCode\npp_sub |&gt; plot()\n\n\n\n\n\nThen splitting the point pattern and plotting a multivariate view on the same pattern.\n\n\nCode\npp_sub |&gt;\n  split() |&gt;\n  plot()\n\n\n\n\n\n\n\n\nMarks can as well be continuous as in the case of gene expression. We choose some genes from the original paper and look at their distribution (Baddeley, Rubak, and Turner 2015, 637; Moffitt et al. 2018).\n\n\nCode\n# subset the original SpatialExperiment to our example slide -0.09\nsub &lt;- spe[, spe$sample_id == \"-0.09\"]\n#  Genes from Fig. 6 of Moffitt et al. (2018)\ngenes &lt;- c(\"Slc18a2\", \"Esr1\", \"Pgr\")\ngex &lt;- assay(sub)[genes, ] %&gt;%\n  t() %&gt;%\n  as.matrix() %&gt;%\n  data.frame() %&gt;%\n  set_rownames(NULL)\n# gene expression to marks\nmarks(pp_sub) &lt;- gex\n\n\nNow that we have points with multivariate continuous marks\n\n\nCode\n# create a dataframe in long format for plotting\npp_df &lt;- pp_sub %&gt;%\n  as.data.frame() %&gt;%\n  pivot_longer(cols = 3:5)\n\nggplot(pp_df, aes(x, y, colour = log(value + 1))) +\n  geom_point(size = 0.5) +\n  facet_wrap(~name) +\n  coord_equal() +\n  scale_color_continuous(type = \"viridis\")\n\n\n\n\n\nWe note that the expression of the genes Pgr and Slc18a2 is very evenly distributed with some elevations in the middle of the structure. Esr1 shows a half-circle like structure in expression. Note that the expression is here log transformed counts offset by one (to avoid problems with log of zero).\n\n\n\nWe can compare patterns between marks of the same type. This is referred to as a within mark comparison in our vignette. We can compare discrete marks, so the distribution of one single mark, e.g. a cell type.\n\n\nCode\n# create a dataframe from the point pattern\npp_df_discrete &lt;- lapply(zstack_list, function(x) {\n  df &lt;- pp_ls[[x]] %&gt;% as.data.frame()\n  df$stack &lt;- x\n  return(df)\n}) %&gt;% bind_rows()\n\n# select OD Mature cells\npp_df_odmature &lt;- pp_df_discrete[pp_df_discrete$marks == \"OD Mature\", ]\n\nggplot(pp_df_odmature, aes(x, y, colour = marks)) +\n  geom_point(size = 0.5) +\n  facet_wrap(~stack, scales = \"free\") +\n  theme(aspect.ratio = 1)\n\n\n\n\n\nHere, we plot the distribution of mature oligodendrocytes across three slices of one 3D brain sample.\nContinuous marks can be compared as well, e.g. the expression of a gene across slices of a tissue\n\n\nCode\npp_df &lt;- lapply(zstack_list, function(x) {\n  # subset the original SpatialExperiment to our example slide -0.09\n  sub &lt;- spe[, spe$sample_id == x]\n  #  Genes from Fig. 6 of Moffitt et al. (2018)\n  genes &lt;- c(\"Slc18a2\", \"Esr1\", \"Pgr\")\n  gex &lt;- assay(sub)[genes, ] %&gt;%\n    t() %&gt;%\n    as.matrix() %&gt;%\n    data.frame() %&gt;%\n    set_rownames(NULL)\n  # gene expression to marks\n  marks(pp_ls[[x]]) &lt;- gex\n  df &lt;- pp_ls[[x]] %&gt;% as.data.frame()\n  df$stack &lt;- x\n  return(df)\n}) %&gt;% bind_rows()\n\nggplot(pp_df, aes(x, y, colour = log(Esr1 + 1))) +\n  geom_point(size = 0.5) +\n  facet_wrap(~stack, scales = \"free\") +\n  theme(aspect.ratio = 1) +\n  scale_color_continuous(type = \"viridis\")\n\n\n\n\n\nWe note that the gene Esr1 is differentially distributed across the slices of the 3D sample.\n\n\n\nCorrelation is a second order quantity that measures the dependence between points (Baddeley, Rubak, and Turner 2015, 199). A famous way to measure this is with Ripley’s \\(K\\), which is a cumulative function that quantifies the “number of \\(r\\)-neighbours of a typical random point” (Baddeley, Rubak, and Turner 2015, 204; Ripley 1976).\n\n\nGlobal correlation measures quantify the correlation in the entire window. Global Ripley’s \\(K\\) is defined as:\n\\[\n\\hat{K}(r) = \\frac{|W|}{n(n-1)}\\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n\\{d_{ij}\\leq r\\} e_{ij}(r)\n\\]\nIn the formula above we note a few things:\n\nThe function is normalised by the number of points \\(n\\) and the window size \\(|W|\\)\nthe term \\(e_{ij}(r)\\) is an edge correction - see the section on border corrections further down in the vignette (Baddeley, Rubak, and Turner 2015, 204).\n\nRipley’s \\(K\\) function can be variance stabilised, which is referred to as Besag’s \\(L\\) (Canete et al. 2022; Besag 1977). The idea behind variance stabilisation is to “uncouple” the relationship between mean and variance. By taking the square root of the function in question, the variance is nearly constant across the function (Bartlett 1947).\n\\[\nL(r) = \\sqrt{\\frac{K(r)}{\\pi}}\n\\]\n\n\nCode\nres_ls &lt;- lapply(list('Kest', 'Lest'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')})\n\n\n\n\nCode\nwrap_plots(p_ls, guides = 'collect')\n\n\n\n\n\nThe strongest estimate of association between oligodendrocytes is found for the slices \\(0.01\\). Slice \\(0.21\\) does not show such a high degree of association at radii \\(\\leq300\\) as the other two slices. This means that the apparent clustering we see in the distribution of points is mainly due to an overall higher number of cells in slide \\(0.21\\) and not a higher degree of association per se. The black line indicates the expected \\(K\\) respectively \\(L\\) function for a completely spatially random poisson process (Baddeley, Rubak, and Turner 2015, 132 ff.).\nSame can be done for the arrangement of Microglia cells across these three sections.\n\n\nCode\nres &lt;- calcMetricPerFov(spe, 'Microglia', subsetby = 'sample_id', fun = 'Lest', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\n\nplotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')\n\n\nWe note that the Microglia cells are distributed close to a Poisson Process across the different slices.\nA similar analysis can be performed for continuous marks. As an exercise, try to calculated a mark weighted correlation function markcorr. You get more information on this function by typing ?markcorr. The mark weighted correlation function is defined as:\n\\[\nk_f(r) =  \\frac{\\mathbb{E}[f(m(u),m(v))|u,v \\in X]}{\\mathbb{E}[f(M,M')]}\n\\]\nwhere the numerator is the conditional expectation of the marks at location \\(u,v\\) separated by a radius \\(r\\) and \\(f\\) can be any function linking the two marks. The denominator is the expectation of two random marks \\(M,M'\\) (Baddeley, Rubak, and Turner 2015, 603).\n\n\nCode\ngenes &lt;- c(\"Slc18a2\", \"Esr1\", \"Pgr\")\ngex &lt;- assay(spe)[genes,] %&gt;% t %&gt;% as.matrix %&gt;% \n  data.frame %&gt;% set_rownames(NULL)\n# gene expression to marks\ncolData(spe) &lt;- colData(spe) %&gt;% cbind(gex)\n\nres &lt;- calcMetricPerFov(spe, selection = 'Esr1', subsetby = 'sample_id', fun = 'markcorr',  marks = 'Esr1', r_seq=NULL, by = c('Animal_ID', 'sample_id'), continuous = TRUE)\n\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\n  \np &lt;- plotMetricPerFov(res, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'sample_id')\np\n\n\n\n\n\nWe note that at very small radii the expression of the gene Esr1 shows a high association with itself. Later on, the association is less pronounced than in the slices \\(-0.09\\) and \\(0.01\\).\n\n\n\nNext to observation window metrics, we can calculate point level statistics as well. One such option is the local indicators of spatial association (LISA). This gives one curve per point in the field of view (Baddeley, Rubak, and Turner 2015, 247–48).\n\n\nCode\npp &lt;- subset(pp_ls[[\"0.01\"]], marks %in% \"OD Mature\")\nL_odmature_lisa &lt;- localL(pp)\n\ndf &lt;- as.data.frame(L_odmature_lisa)\ndfm &lt;- reshape2::melt(df, \"r\")\n\nget_sel &lt;- dfm %&gt;%\n  dplyr::filter(r &gt; 200.5630 & r &lt; 201.4388, variable != \"theo\") %&gt;%\n  dplyr::mutate(sel = value) %&gt;%\n  dplyr::select(variable, sel)\n\ndfm &lt;- dfm %&gt;% left_join(get_sel)\n\np &lt;- ggplot(dfm, aes(x = r, y = value, group = variable, colour = sel)) +\n  geom_line(linewidth = 1) +\n  scale_color_continuous(type = \"viridis\") +\n  geom_vline(xintercept = 200) +\n  theme(legend.position = \"none\") +\n  ggtitle(\"LISA curves of slice 0.01\")\n\n\n\n\nCode\np\n\n\n\n\n\nThese curves could be analysed using tools from functional data analysis such as functional PCA (Baddeley, Rubak, and Turner 2015, 247–48; Ramsay and Silverman 2005).\n\n\n\n\n\nThe same analyses as above can be performed between two celltypes. The corresponding functions are called cross functions (Baddeley, Rubak, and Turner 2015, 594 ff.). As an exercise, try to implement (similar to the analyses above) a cross comparison between two cell types of interest. With the provided functions this is possible, just give a function you like as input and a vector with two cell types you wish to compare. You can look at functions in the documentation of spatstat.explore. We provide an example below:\n\n\nCode\n# select OD Mature and Microglia cells\npp_df_odmature_microglia &lt;- pp_df_discrete[pp_df_discrete$marks %in% c(\"OD Mature\", \"Microglia\"), ]\n\nggplot(pp_df_odmature_microglia, aes(x, y, colour = marks)) +\n  geom_point(size = 0.5) +\n  facet_wrap(~stack, scales = \"free\") +\n  theme(aspect.ratio = 1)\n\n\n\n\n\n\n\nCode\nres &lt;- calcMetricPerFov(spe, c(\"OD Mature\", \"Microglia\"), subsetby = 'sample_id', fun = 'Lcross', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\n\np &lt;- plotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')\n\n\n\n\nCode\np\n\n\n\n\n\nWe note that there is not a very strong co-localisation indicated by the \\(L\\) curves between mature oligodendrocytes and microglia cells. If we look at their spatial distribution that makes sense since microglia cells are distributed more or less homogeneously in the respective slices.\n\n\n\nEdge effects describe the phenomenon that not the entire point process is observed, but rather only the part within the window \\(W\\). This means the value of various statistics could be biased along the edges (Baddeley, Rubak, and Turner 2015, 213).\nThere are many corrections for edge effects that are briefly listed here (Baddeley, Rubak, and Turner 2015, 214–19):\nBorder correction:\n\nIn border correction the summation of data points is restricted to \\(x_i\\) for which \\(b(x_i,r)\\) is completely in the window \\(W\\).\n\nIsotropic correction:\n\nWe can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.\n\nTranslation correction:\n\nA stationary point process \\(X\\) is invariant to translations. So the entire point process can be shifted by a vector \\(s\\) to be at the position \\(X+s\\).\n\n\n\n\n\n\nPoint patterns are realisations of a point process. In the analysis we make inferences about the point process.\nA point process assumes stochasticity. Therefore, HTS-based approaches are not suitable for point pattern analysis.\nThere are global metrics for the comparison within a celltype or between celltypes.\nThere are corresponding metrics for single cells and their interactions.\nPoint pattern analysis allows for the analysis of continuous gene expression marks as well.\n\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] spatialFDA_0.99.0              dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.10.3                 SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-16                     \n[17] STexampleData_1.8.0            RANN_2.6.1                    \n[19] seg_0.5-7                      sp_2.1-1                      \n[21] rlang_1.1.1                    mixR_0.2.0                    \n[23] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[25] spatstat.model_3.2-6           rpart_4.1.19                  \n[27] MerfishData_1.2.0              EBImage_4.42.0                \n[29] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[31] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[33] magrittr_2.0.3                 tidyr_1.3.0                   \n[35] stringr_1.5.0                  reshape2_1.4.4                \n[37] patchwork_1.2.0                ggplot2_3.5.1                 \n[39] dplyr_1.1.3                    spatstat.explore_3.2-3        \n[41] nlme_3.1-162                   spatstat.random_3.1-6         \n[43] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[45] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[47] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[49] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[51] IRanges_2.34.1                 S4Vectors_0.38.2              \n[53] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[55] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.9-1                    rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.3.0                  classInt_0.4-10              \n [83] rappdirs_0.3.3                tiff_0.1-11                  \n [85] goftest_1.2-3                 fftwtools_0.9-11             \n [87] spatstat.utils_3.0-5          rmarkdown_2.25               \n [89] XVector_0.40.0                base64enc_0.1-3              \n [91] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [93] jpeg_0.1-10                   sparseMatrixStats_1.12.2     \n [95] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [97] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [99] farver_2.1.1                  jsonlite_1.8.7               \n[101] BiocParallel_1.34.2           R.oo_1.25.0                  \n[103] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[105] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[107] Rhdf5lib_1.22.1               munsell_0.5.0                \n[109] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[111] viridis_0.6.4                 stringi_1.7.12               \n[113] leafsync_0.1.0                zlibbioc_1.46.0              \n[115] plyr_1.8.9                    parallel_4.3.1               \n[117] ggrepel_0.9.4                 deldir_1.0-9                 \n[119] Biostrings_2.68.1             stars_0.6-4                  \n[121] splines_4.3.1                 tensor_1.5                   \n[123] locfit_1.5-9.8                igraph_1.5.1                 \n[125] ScaledMatrix_1.8.1            XML_3.99-0.14                \n[127] BiocVersion_3.17.1            evaluate_0.22                \n[129] BiocManager_1.30.22           httpuv_1.6.11                \n[131] purrr_1.0.2                   polyclip_1.10-6              \n[133] rsvd_1.0.5                    lwgeom_0.2-13                \n[135] xtable_1.8-4                  e1071_1.7-13                 \n[137] RSpectra_0.16-1               later_1.3.1                  \n[139] viridisLite_0.4.2             class_7.3-22                 \n[141] tibble_3.2.1                  memoise_2.0.1                \n[143] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[145] cluster_2.1.4                 BiocStyle_2.28.1"
  },
  {
    "objectID": "08-highlights-point-pattern-analysis.html#introduction",
    "href": "08-highlights-point-pattern-analysis.html#introduction",
    "title": "Point Pattenr Analysis – Summary",
    "section": "",
    "text": "Cells (or transcripts) can be approximated as points given their location.\n\n\nThe central package to analyse point patterns in R is called spatstat (Baddeley and Turner 2005). The main data object to compute on is called a ppp object. ppp objects describe point patterns in two dimensional space, ppx objects create multidimensional point patterns. A ppp object is is made up of three specifications (Baddeley and Turner 2005):\n\nThe locations of the points in question (\\(x\\),\\(y\\) and, optionally, \\(z\\) coordinates)\nThe observation window\nThe associated marks to each point in the pattern\n\nOn this central object, various spatstat metrics can be calculated.\n\n\n\n\n\n\nStructure of a SpatialExperiment object as introduced by Righelli et al.\n\n\nOften, the starting point in spatial omics data analysis is a SpatialExperiment (or similar) object. This is a central data structure in the BioConductor framework to store spatial omics data. The data we consider here is a MERFISH assay of a mouse preoptic hypothalamus (Chen et al. 2015; Moffitt et al. 2018).\n\n\nCode\nsuppressPackageStartupMessages({\n  library(SpatialExperiment)\n  library(spatstat.geom)\n  library(spatstat.explore)\n  library(dplyr)\n  library(ggplot2)\n  library(patchwork)\n  library(reshape2)\n  library(stringr)\n  library(tidyr)\n  library(magrittr)\n})\n\n\n\n\nCode\n# load the data from ExperimentHub\nsource(\"../code/load_data.R\")\n# source some helper functions\nsource(\"../code/utils.R\")\nlibrary('spatialFDA')\ntheme_set(theme_light())\n# load the SpatialExperiment object\nspe &lt;- readRDS(\"../data/spe.rds\")\nspe\n\n\nclass: SpatialExperiment \ndim: 161 73655 \nmetadata(0):\nassays(1): exprs\nrownames(161): Ace2 Adora2a ... Ucn3 Vgf\nrowData names(0):\ncolnames(73655): 6749ccb4-2ed1-4029-968f-820a287f43c8\n  6cac74bd-4ea7-4701-8701-42563cc65eb8 ...\n  6b666f81-7b73-4100-9e02-b5381b39f0f3\n  fdcddd97-7701-462a-b48f-979111245bd5\ncolData names(7): Animal_ID Animal_sex ... Neuron_cluster_ID cluster_id\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : x y\nimgData names(0):\n\n\nWe see that we have an object of class SpatialExperiment with \\(161\\) genes (rows) and \\(73655\\) cells. This object is very similar to a SingleCellExperiment object except it has the added spatialCoords slot. One slot in the colData is called sample_id which defines the so called z-slices. The three dimensional tissue is cut in the z-axis into consecutive two dimensional slices (Righelli et al. 2022).\nNext, we want to extract three slices of this SpatialExperiment object and convert the 2D slices into ppp objects.\n\n\nCode\n# define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n# small helper function to extract the z-slices and convert them to `ppp` objects\nselectZstacks &lt;- function(zstack, spe) {\n  spe[, spe$sample_id == zstack] |&gt; \n    .ppp(marks = \"cluster_id\")\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe) |&gt;\n  setNames(zstack_list)\n\npp_ls\n\n\n$`-0.09`\nMarked planar point pattern: 6185 points\nMultitype, with levels = \n   Ambiguous Astrocyte Endothelial Ependymal Excitatory Inhibitory Microglia OD \nImmature OD Mature Pericytes\nwindow: rectangle = [1307.7716, 3097.8543] x [2114.368, 3903.386] units\n\n$`0.01`\nMarked planar point pattern: 6111 points\nMultitype, with levels = \n   Ambiguous Astrocyte Endothelial Ependymal Excitatory Inhibitory Microglia OD \nImmature OD Mature Pericytes\nwindow: rectangle = [1222.5635, 3012.4248] x [-3993.535, -2202.755] units\n\n$`0.21`\nMarked planar point pattern: 5578 points\nMultitype, with levels = \n   Ambiguous Astrocyte Endothelial Ependymal Excitatory Inhibitory Microglia OD \nImmature OD Mature Pericytes\nwindow: rectangle = [1328.6103, 3124.2492] x [2199.257, 3993.499] units\n\n\nWe see that we obtain a list of three ppp objects for the three z-slices \\(-0.09, 0.01, 0.21\\).\nWe can plot one of these slices, e.g. slice \\(-0.09\\) with ggplot\n\n\nCode\n# create a dataframe from the point pattern\npp_df &lt;- pp_ls$`-0.09` %&gt;% as.data.frame\n# plot with ggplot\nggplot(pp_df, aes(x, y, colour = marks)) +\n  geom_point(size = 1) +\n  coord_equal()\n\n\n\n\n\n\n\n\nAs stated above, one important aspect of a point pattern is the observation window. It represents the region in which a pattern is observed or e.g. a survey was conducted (Baddeley, Rubak, and Turner 2015, 85). In most microscopy use cases we encounter window sampling. Window sampling describes the case where we don’t observe the entire point pattern in a window but just a sample (Baddeley, Rubak, and Turner 2015, 143–45).\nThe window of a point pattern does not need to be rectangular; we can receive round biopsies or calculate convex hulls around our sample (Baddeley, Rubak, and Turner 2015, 143–45).\nLet’s investigate the observation window for the slice \\(-0.09\\).\n\n\nCode\n# subset point pattern list\npp_sub &lt;- pp_ls$`-0.09`\n# base R plot of all marks\npp_sub |&gt; plot()\n\n\n\n\n\nHere, we have a rectangular window around all points.\nLet’s investigate what a round window would look like:\n\n\nCode\npp_sub_round &lt;- pp_sub\n# calculate circle with radius 850 µm and a center at the centroid of the window would look like\nw &lt;- disc(r = 850, centroid.owin(Window(pp_sub)))\nWindow(pp_sub_round) &lt;- w\npp_sub_round |&gt; plot()\n\n\n\n\n\nCorrectly assigning windows is very important. The window should represent the space where points are expected. This means, in window sampling, one should not restrict the window. This would lead to a false underestimation of the area where the points can be potentially observed. This problem of where we can observe points and where not (beyond the boundary of the window) leads to a range of problems collectively called edge effects (Baddeley, Rubak, and Turner 2015, 143–45). We will discuss these later.\n\n\n\nThe next concept that defines a point pattern is that marks can be associated with the points. The points can also have no mark, which we would call an unmarked point pattern\n\n\nCode\nunmark(pp_sub) |&gt; plot()\n\n\n\n\n\nMarks can be univariate or multivariate variables that are associated with the points (Baddeley, Rubak, and Turner 2015, 147). In the context of cell biology we can distinguish between discrete marks (e.g. cell types) or continuous marks (e.g. gene expression).\n\n\nIn our example, we have a multitype point pattern, meaning there are different cell types that serve as marks for the point pattern. Multitype means that we consider all marks together. The opposite is multivariate, where we consider the marks independently (Baddeley, Rubak, and Turner 2015, 564 ff.).\nFirst the multitype case:\n\n\nCode\npp_sub |&gt; plot()\n\n\n\n\n\nThen splitting the point pattern and plotting a multivariate view on the same pattern.\n\n\nCode\npp_sub |&gt;\n  split() |&gt;\n  plot()\n\n\n\n\n\n\n\n\nMarks can as well be continuous as in the case of gene expression. We choose some genes from the original paper and look at their distribution (Baddeley, Rubak, and Turner 2015, 637; Moffitt et al. 2018).\n\n\nCode\n# subset the original SpatialExperiment to our example slide -0.09\nsub &lt;- spe[, spe$sample_id == \"-0.09\"]\n#  Genes from Fig. 6 of Moffitt et al. (2018)\ngenes &lt;- c(\"Slc18a2\", \"Esr1\", \"Pgr\")\ngex &lt;- assay(sub)[genes, ] %&gt;%\n  t() %&gt;%\n  as.matrix() %&gt;%\n  data.frame() %&gt;%\n  set_rownames(NULL)\n# gene expression to marks\nmarks(pp_sub) &lt;- gex\n\n\nNow that we have points with multivariate continuous marks\n\n\nCode\n# create a dataframe in long format for plotting\npp_df &lt;- pp_sub %&gt;%\n  as.data.frame() %&gt;%\n  pivot_longer(cols = 3:5)\n\nggplot(pp_df, aes(x, y, colour = log(value + 1))) +\n  geom_point(size = 0.5) +\n  facet_wrap(~name) +\n  coord_equal() +\n  scale_color_continuous(type = \"viridis\")\n\n\n\n\n\nWe note that the expression of the genes Pgr and Slc18a2 is very evenly distributed with some elevations in the middle of the structure. Esr1 shows a half-circle like structure in expression. Note that the expression is here log transformed counts offset by one (to avoid problems with log of zero).\n\n\n\nWe can compare patterns between marks of the same type. This is referred to as a within mark comparison in our vignette. We can compare discrete marks, so the distribution of one single mark, e.g. a cell type.\n\n\nCode\n# create a dataframe from the point pattern\npp_df_discrete &lt;- lapply(zstack_list, function(x) {\n  df &lt;- pp_ls[[x]] %&gt;% as.data.frame()\n  df$stack &lt;- x\n  return(df)\n}) %&gt;% bind_rows()\n\n# select OD Mature cells\npp_df_odmature &lt;- pp_df_discrete[pp_df_discrete$marks == \"OD Mature\", ]\n\nggplot(pp_df_odmature, aes(x, y, colour = marks)) +\n  geom_point(size = 0.5) +\n  facet_wrap(~stack, scales = \"free\") +\n  theme(aspect.ratio = 1)\n\n\n\n\n\nHere, we plot the distribution of mature oligodendrocytes across three slices of one 3D brain sample.\nContinuous marks can be compared as well, e.g. the expression of a gene across slices of a tissue\n\n\nCode\npp_df &lt;- lapply(zstack_list, function(x) {\n  # subset the original SpatialExperiment to our example slide -0.09\n  sub &lt;- spe[, spe$sample_id == x]\n  #  Genes from Fig. 6 of Moffitt et al. (2018)\n  genes &lt;- c(\"Slc18a2\", \"Esr1\", \"Pgr\")\n  gex &lt;- assay(sub)[genes, ] %&gt;%\n    t() %&gt;%\n    as.matrix() %&gt;%\n    data.frame() %&gt;%\n    set_rownames(NULL)\n  # gene expression to marks\n  marks(pp_ls[[x]]) &lt;- gex\n  df &lt;- pp_ls[[x]] %&gt;% as.data.frame()\n  df$stack &lt;- x\n  return(df)\n}) %&gt;% bind_rows()\n\nggplot(pp_df, aes(x, y, colour = log(Esr1 + 1))) +\n  geom_point(size = 0.5) +\n  facet_wrap(~stack, scales = \"free\") +\n  theme(aspect.ratio = 1) +\n  scale_color_continuous(type = \"viridis\")\n\n\n\n\n\nWe note that the gene Esr1 is differentially distributed across the slices of the 3D sample.\n\n\n\nCorrelation is a second order quantity that measures the dependence between points (Baddeley, Rubak, and Turner 2015, 199). A famous way to measure this is with Ripley’s \\(K\\), which is a cumulative function that quantifies the “number of \\(r\\)-neighbours of a typical random point” (Baddeley, Rubak, and Turner 2015, 204; Ripley 1976).\n\n\nGlobal correlation measures quantify the correlation in the entire window. Global Ripley’s \\(K\\) is defined as:\n\\[\n\\hat{K}(r) = \\frac{|W|}{n(n-1)}\\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n\\{d_{ij}\\leq r\\} e_{ij}(r)\n\\]\nIn the formula above we note a few things:\n\nThe function is normalised by the number of points \\(n\\) and the window size \\(|W|\\)\nthe term \\(e_{ij}(r)\\) is an edge correction - see the section on border corrections further down in the vignette (Baddeley, Rubak, and Turner 2015, 204).\n\nRipley’s \\(K\\) function can be variance stabilised, which is referred to as Besag’s \\(L\\) (Canete et al. 2022; Besag 1977). The idea behind variance stabilisation is to “uncouple” the relationship between mean and variance. By taking the square root of the function in question, the variance is nearly constant across the function (Bartlett 1947).\n\\[\nL(r) = \\sqrt{\\frac{K(r)}{\\pi}}\n\\]\n\n\nCode\nres_ls &lt;- lapply(list('Kest', 'Lest'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')})\n\n\n\n\nCode\nwrap_plots(p_ls, guides = 'collect')\n\n\n\n\n\nThe strongest estimate of association between oligodendrocytes is found for the slices \\(0.01\\). Slice \\(0.21\\) does not show such a high degree of association at radii \\(\\leq300\\) as the other two slices. This means that the apparent clustering we see in the distribution of points is mainly due to an overall higher number of cells in slide \\(0.21\\) and not a higher degree of association per se. The black line indicates the expected \\(K\\) respectively \\(L\\) function for a completely spatially random poisson process (Baddeley, Rubak, and Turner 2015, 132 ff.).\nSame can be done for the arrangement of Microglia cells across these three sections.\n\n\nCode\nres &lt;- calcMetricPerFov(spe, 'Microglia', subsetby = 'sample_id', fun = 'Lest', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\n\nplotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')\n\n\nWe note that the Microglia cells are distributed close to a Poisson Process across the different slices.\nA similar analysis can be performed for continuous marks. As an exercise, try to calculated a mark weighted correlation function markcorr. You get more information on this function by typing ?markcorr. The mark weighted correlation function is defined as:\n\\[\nk_f(r) =  \\frac{\\mathbb{E}[f(m(u),m(v))|u,v \\in X]}{\\mathbb{E}[f(M,M')]}\n\\]\nwhere the numerator is the conditional expectation of the marks at location \\(u,v\\) separated by a radius \\(r\\) and \\(f\\) can be any function linking the two marks. The denominator is the expectation of two random marks \\(M,M'\\) (Baddeley, Rubak, and Turner 2015, 603).\n\n\nCode\ngenes &lt;- c(\"Slc18a2\", \"Esr1\", \"Pgr\")\ngex &lt;- assay(spe)[genes,] %&gt;% t %&gt;% as.matrix %&gt;% \n  data.frame %&gt;% set_rownames(NULL)\n# gene expression to marks\ncolData(spe) &lt;- colData(spe) %&gt;% cbind(gex)\n\nres &lt;- calcMetricPerFov(spe, selection = 'Esr1', subsetby = 'sample_id', fun = 'markcorr',  marks = 'Esr1', r_seq=NULL, by = c('Animal_ID', 'sample_id'), continuous = TRUE)\n\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\n  \np &lt;- plotMetricPerFov(res, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'sample_id')\np\n\n\n\n\n\nWe note that at very small radii the expression of the gene Esr1 shows a high association with itself. Later on, the association is less pronounced than in the slices \\(-0.09\\) and \\(0.01\\).\n\n\n\nNext to observation window metrics, we can calculate point level statistics as well. One such option is the local indicators of spatial association (LISA). This gives one curve per point in the field of view (Baddeley, Rubak, and Turner 2015, 247–48).\n\n\nCode\npp &lt;- subset(pp_ls[[\"0.01\"]], marks %in% \"OD Mature\")\nL_odmature_lisa &lt;- localL(pp)\n\ndf &lt;- as.data.frame(L_odmature_lisa)\ndfm &lt;- reshape2::melt(df, \"r\")\n\nget_sel &lt;- dfm %&gt;%\n  dplyr::filter(r &gt; 200.5630 & r &lt; 201.4388, variable != \"theo\") %&gt;%\n  dplyr::mutate(sel = value) %&gt;%\n  dplyr::select(variable, sel)\n\ndfm &lt;- dfm %&gt;% left_join(get_sel)\n\np &lt;- ggplot(dfm, aes(x = r, y = value, group = variable, colour = sel)) +\n  geom_line(linewidth = 1) +\n  scale_color_continuous(type = \"viridis\") +\n  geom_vline(xintercept = 200) +\n  theme(legend.position = \"none\") +\n  ggtitle(\"LISA curves of slice 0.01\")\n\n\n\n\nCode\np\n\n\n\n\n\nThese curves could be analysed using tools from functional data analysis such as functional PCA (Baddeley, Rubak, and Turner 2015, 247–48; Ramsay and Silverman 2005).\n\n\n\n\n\nThe same analyses as above can be performed between two celltypes. The corresponding functions are called cross functions (Baddeley, Rubak, and Turner 2015, 594 ff.). As an exercise, try to implement (similar to the analyses above) a cross comparison between two cell types of interest. With the provided functions this is possible, just give a function you like as input and a vector with two cell types you wish to compare. You can look at functions in the documentation of spatstat.explore. We provide an example below:\n\n\nCode\n# select OD Mature and Microglia cells\npp_df_odmature_microglia &lt;- pp_df_discrete[pp_df_discrete$marks %in% c(\"OD Mature\", \"Microglia\"), ]\n\nggplot(pp_df_odmature_microglia, aes(x, y, colour = marks)) +\n  geom_point(size = 0.5) +\n  facet_wrap(~stack, scales = \"free\") +\n  theme(aspect.ratio = 1)\n\n\n\n\n\n\n\nCode\nres &lt;- calcMetricPerFov(spe, c(\"OD Mature\", \"Microglia\"), subsetby = 'sample_id', fun = 'Lcross', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\n\np &lt;- plotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')\n\n\n\n\nCode\np\n\n\n\n\n\nWe note that there is not a very strong co-localisation indicated by the \\(L\\) curves between mature oligodendrocytes and microglia cells. If we look at their spatial distribution that makes sense since microglia cells are distributed more or less homogeneously in the respective slices.\n\n\n\nEdge effects describe the phenomenon that not the entire point process is observed, but rather only the part within the window \\(W\\). This means the value of various statistics could be biased along the edges (Baddeley, Rubak, and Turner 2015, 213).\nThere are many corrections for edge effects that are briefly listed here (Baddeley, Rubak, and Turner 2015, 214–19):\nBorder correction:\n\nIn border correction the summation of data points is restricted to \\(x_i\\) for which \\(b(x_i,r)\\) is completely in the window \\(W\\).\n\nIsotropic correction:\n\nWe can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.\n\nTranslation correction:\n\nA stationary point process \\(X\\) is invariant to translations. So the entire point process can be shifted by a vector \\(s\\) to be at the position \\(X+s\\)."
  },
  {
    "objectID": "08-highlights-point-pattern-analysis.html#summary-and-considerations",
    "href": "08-highlights-point-pattern-analysis.html#summary-and-considerations",
    "title": "Point Pattenr Analysis – Summary",
    "section": "",
    "text": "Point patterns are realisations of a point process. In the analysis we make inferences about the point process.\nA point process assumes stochasticity. Therefore, HTS-based approaches are not suitable for point pattern analysis.\nThere are global metrics for the comparison within a celltype or between celltypes.\nThere are corresponding metrics for single cells and their interactions.\nPoint pattern analysis allows for the analysis of continuous gene expression marks as well.\n\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] spatialFDA_0.99.0              dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.10.3                 SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-16                     \n[17] STexampleData_1.8.0            RANN_2.6.1                    \n[19] seg_0.5-7                      sp_2.1-1                      \n[21] rlang_1.1.1                    mixR_0.2.0                    \n[23] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[25] spatstat.model_3.2-6           rpart_4.1.19                  \n[27] MerfishData_1.2.0              EBImage_4.42.0                \n[29] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[31] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[33] magrittr_2.0.3                 tidyr_1.3.0                   \n[35] stringr_1.5.0                  reshape2_1.4.4                \n[37] patchwork_1.2.0                ggplot2_3.5.1                 \n[39] dplyr_1.1.3                    spatstat.explore_3.2-3        \n[41] nlme_3.1-162                   spatstat.random_3.1-6         \n[43] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[45] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[47] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[49] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[51] IRanges_2.34.1                 S4Vectors_0.38.2              \n[53] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[55] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.9-1                    rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.3.0                  classInt_0.4-10              \n [83] rappdirs_0.3.3                tiff_0.1-11                  \n [85] goftest_1.2-3                 fftwtools_0.9-11             \n [87] spatstat.utils_3.0-5          rmarkdown_2.25               \n [89] XVector_0.40.0                base64enc_0.1-3              \n [91] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [93] jpeg_0.1-10                   sparseMatrixStats_1.12.2     \n [95] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [97] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [99] farver_2.1.1                  jsonlite_1.8.7               \n[101] BiocParallel_1.34.2           R.oo_1.25.0                  \n[103] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[105] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[107] Rhdf5lib_1.22.1               munsell_0.5.0                \n[109] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[111] viridis_0.6.4                 stringi_1.7.12               \n[113] leafsync_0.1.0                zlibbioc_1.46.0              \n[115] plyr_1.8.9                    parallel_4.3.1               \n[117] ggrepel_0.9.4                 deldir_1.0-9                 \n[119] Biostrings_2.68.1             stars_0.6-4                  \n[121] splines_4.3.1                 tensor_1.5                   \n[123] locfit_1.5-9.8                igraph_1.5.1                 \n[125] ScaledMatrix_1.8.1            XML_3.99-0.14                \n[127] BiocVersion_3.17.1            evaluate_0.22                \n[129] BiocManager_1.30.22           httpuv_1.6.11                \n[131] purrr_1.0.2                   polyclip_1.10-6              \n[133] rsvd_1.0.5                    lwgeom_0.2-13                \n[135] xtable_1.8-4                  e1071_1.7-13                 \n[137] RSpectra_0.16-1               later_1.3.1                  \n[139] viridisLite_0.4.2             class_7.3-22                 \n[141] tibble_3.2.1                  memoise_2.0.1                \n[143] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[145] cluster_2.1.4                 BiocStyle_2.28.1"
  },
  {
    "objectID": "01-imaging-univar-ppSOD.html",
    "href": "01-imaging-univar-ppSOD.html",
    "title": "Discrete Marks",
    "section": "",
    "text": "Show the code\nsource(\"utils.R\")\n\n\n\n\n\n\n\nShow the code\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n\n#define the celltype that you want to compare across the stacks - hereby we assume independence across the z-stacks which is an assumption that can be challenged\ncelltype_ls &lt;- \"OD Mature\"\n\nselectZstacks &lt;- function(zstack, spe){\n  sub &lt;- spe[, spe$sample_id == zstack]\n  pp &lt;- .ppp(sub, marks = \"cluster_id\")\n  return(pp)\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe)\nnames(pp_ls) &lt;- zstack_list\n\n\nThe theory of spatial point patterns is discussed in great detail in (Baddeley, Rubak, and Turner 2015). The book has an accompanying package called spatstat which offers great functionality to the theoretical concepts described in the book (Baddeley and Turner 2005). This chapter relies heavily on both publications.\n\n\n\n\n\nIn point pattern analysis we assume that the patterns we observe are a realisation of a stochastic process called a point process. The inferences we make about the point pattern are based on the point process. For example, if a pattern is created by a Poisson point process it will be evenly distributed in the observation window (Baddeley, Rubak, and Turner 2015, 127).\nWhen considering a pattern with \\(m\\) multiple types, as we do in the (Moffitt et al. 2018) dataset, there are two very closely related concepts. One can view the pattern as a multitype point pattern, where all the points are sampled from the same point process. The other option is to consider the pattern as a multivariate point pattern, where the points come from \\(m\\) distinct point processes. The difference between these two views is that in the multitype framework we assume the points to stem from the same point process. In the multivariate framework we assume that the types stem from distinct point processes and therefore we can consider dependencies of one type alone. Whether or not the patterns stem from the same point process depends on the biological question. If we analyse two cell types in one slice of a tissue, we should consider them as being sampled from one point process. However, if we consider the distribution of a cell type in two slices of the same tissue we can have grounds to consider them as distinct processes (Baddeley, Rubak, and Turner 2015, 564–65).\n\n\n\nThe most common set up in point pattern analysis is what we call window sampling. Instead of observing the entire pattern we observe a subset of this pattern in the so called window. An example could be different small microscopy windows through which a big tissue slice is observed. In this case, it would be wrong to assume the window to be the convex hull around the observed points because they are just a sample of the bigger point pattern (Baddeley, Rubak, and Turner 2015, 143–45).\nThere is another concept called the small world model. It assumes that points can only be observed in a finite small world and not beyond these boundaries. When thinking of an entire tissue, this is a very common scenario. Cells can only be observed within the tissue and not beyond. In this case, it would be correct to not assume a rectangular observation window but to use methods to estimate an unknown sampling window such as the Ripley-Rasson estimate of a spatial region (Baddeley, Rubak, and Turner 2015, 144–45; Ripley and Rasson 1977).\n\n\nShow the code\nsetRiprasWindows &lt;- function(pp){\n  Window(pp) &lt;- ripras(pp)\n  return(pp)\n}\n#the entire point patterns with the ripras windows\npp &lt;- lapply(pp_ls, setRiprasWindows)\n\nseparateMarks &lt;- function(pp){\n  #split the multitype point process into several single type processes\n  ppls &lt;- split(pp)\n  return (ppls)\n}\n#the point patterns separated by their marks\npp_ls &lt;- lapply(pp, separateMarks)\n\n\n\n\n\nComplete spatial randomness (CSR) is often used as the null model for various point patterns. It is the result of a Poisson process. A completely spatial random process is characterised by two properties, homogeneity and independence, as discussed below (Baddeley, Rubak, and Turner 2015, 132).\n\n\n“Homogeneity […] means that the expected number of points falling in a region B should be proportional to its area |B|” (Baddeley, Rubak, and Turner 2015, 132) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) represents the intensity of the process, i.e., the average number of points in a unit area (Baddeley, Rubak, and Turner 2015, 132–33). :\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|.\n\\label{eq:expected_number_points}\n\\]\n\n\n\nIndependence implies that in two (non-overlapping) regions \\(A\\) and \\(B\\), the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are independent random variables. In other words, the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). (Baddeley, Rubak, and Turner 2015, 133).\n\n\n\n\nA Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density, \\(\\lambda(u)\\), sometimes known as the intensity function (see below), is a function of the spatial location \\(u\\). In this case, the expected number of points falling into a region \\(B\\), \\(\\mu = n(X\\cap B)\\), is an integration of the intensity function over that region (Baddeley, Rubak, and Turner 2015, 138).\n\\[\n\\mu = \\int_{B} \\lambda(u) du.\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\n\nA point process is called isotropic, if its statistical properties are invariant to rotations; a CSR process is both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 147).\n\n\n\n“A point process is called stationary if, when we view the process through a window W , its statistical properties do not depend on the location of the window in two-dimensional space.” (Baddeley, Rubak, and Turner 2015, 146). This is the case for any homogeneous point process, where the statistical properties of the pattern are unchanged given shifting of the observation window. This means it is stationary in all statistical properties; first-order properties (e.g. intensity) and second-order properties (e.g. correlation) (Baddeley, Rubak, and Turner 2015, 218). Not all metrics assume stationarity in its full sense. Inhomogeneous metrics only assume second-order / correlation stationarity. That means while the intensity function can vary spatially (first-order stationarity is not given), the estimates of correlation functions (e.g. the inhomogeneous K-function) should be the same in parts of the window (Baddeley, Rubak, and Turner 2015, 689 ff.).\n\n\n\nIf a process is not correlation stationary, so the estimates of the inhomogeneous metric vary between locations, locally-scaled versions of the metric can be applicable. This means in subregions, the process is still stationary and isotropic, but there is a rescaling factor that can vary across the total process (Baddeley, Rubak, and Turner 2015, 246–47).\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimated functions between the quadrats. It should be noted that this test depends on the arbitrary definition of the quadrats. Given our chosen patterns are not independent but result as marks from an overall point-pattern, the permutation approach is questionable (Baddeley, Rubak, and Turner 2015, 689–93).\n\n\nShow the code\npermutation_test &lt;- function(pp, mark, split, minpoints) {\n  pp_sel &lt;-  subset(pp, marks %in% mark, drop = TRUE)\n  \n  rho_est &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\n  lambda &lt;- predict(rho_est)\n\n  tesselation &lt;- quantess(unmark(pp_sel), \"x\", 3)\n  tesselation_split &lt;- nestsplit(pp_sel, tesselation, ny=split)\n  \n  plot(tesselation_split, main = mark)\n  \n  tesselation_split$inten &lt;- factor(as.integer(tesselation_split$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n  \n  res.scaled &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kscaled,\n                 minpoints = minpoints)\n  \n  res.inhom &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kinhom,\n                 lambda=lambda, minpoints = minpoints)\n  \n  #p-value of the local-scaling test\n  print(paste0(mark,' local scaling test ', res.scaled$p.value))\n  \n  #p-value of the inhomogeneity test\n  print(paste0(mark,' inhomogeneity test ', res.inhom$p.value))\n}\nlapply(c(\"Microglia\", \"OD Mature\", \"Ependymal\"), function(x) permutation_test(pp[['0.01']], x, split = 3, minpoints = 10))\n\n\nThe p-value of the test for local scaling for microglia cells is \\(&lt;0.05\\) which indicates that the assumption of local scaling is rejected. Therefore, the distribution of microglia cells is not a scaled version of an overall distribution pattern. The p-value of the test for inhomogeneity for both microglia cells is \\(&gt;0.05\\) indicating that the assumption of correlation stationarity is not rejected. In this case we can use the inhomogeneous version of the K-function which assumes correlation stationarity.\nFor ependymal and OD mature cells however, the p-values for both the local scaling test and the inhomogeneity test are \\(&gt;0.05\\) which means that for this choice of quadrats both the correlation stationarity assumption and the local scaling assumption can’t be rejected.\nAs the interpretation of the permutation test is highly dependent on the quadrats, the results should be interpreted with care. Both inhomogeneous and locally scaled versions of the summary functions have support and both offer interesting insights into the spatial pattern. Therefore, we will compare all versions and show what the choice of metrics means for their interpretation.\n\n\n\nIntensity is the expected density of points per unit area. It can be interpreted as the rate of occurrence or the abundance of events. The intensity represents a first order property because it is related to the expected number of points. More formally the average intensity of a point process is defined as:\n\\[\n\\bar{\\lambda} = \\frac{n(x)}{|W|}\n\\label{eq:average_intensity}\n\\]\nAs this is an average over the entire window, it is a good estimate for a homogeneous point process (Baddeley, Rubak, and Turner 2015, 157–60)\n\n\nFor a homogeneous point process, the intensity can be estimated in a simplistic way: summing the individual intensities of the marks (Baddeley, Rubak, and Turner 2015, 161).\n\n\nShow the code\nintensityPointProcess &lt;- function(pp,mark) if(mark) intensity(pp) else sum(intensity(pp))\n\nintensityPointProcess(pp_ls[['0.01']], mark = FALSE) %&gt;% round(6)\n\n\n[1] 0.001909\n\n\nOtherwise, we can compute the intensity for each mark individually.\n\n\nShow the code\nintensityPointProcess(pp_ls[['0.01']], mark = TRUE) %&gt;% round(8)\n\n\n  Ambiguous   Astrocyte Endothelial   Ependymal  Excitatory  Inhibitory \n 0.00024151  0.00020183  0.00014653  0.00008373  0.00036867  0.00061393 \n  Microglia OD Immature   OD Mature   Pericytes \n 0.00003031  0.00006249  0.00014278  0.00001750 \n\n\n\n\n\nIn kernel estimation, we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There is a wide variety of kernel estimators (see (Baddeley, Rubak, and Turner 2015, 168)), but a popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth (Baddeley, Rubak, and Turner 2015, 168).\n\n\nShow the code\npp_sel &lt;-  subset(pp_ls[['0.01']]$`OD Mature`, drop = TRUE)\nDens &lt;- density(pp_sel, sigma = 100)\nplot(Dens, main = 'Kernel Density (OD Mature cells)')\n\n\n\n\n\n\n\n\n\n\n\n\nIn quadrat counting, all points falling into a given quadrat are counted. This gives an overview on the characteristics of the point pattern, such as correlation stationarity (Baddeley, Rubak, and Turner 2015, 163).\n\n\nShow the code\nQ5 &lt;- quadratcount(pp_ls[['0.01']], nx=8, ny=8)\nplot(unmark(pp[['0.01']]), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\nUnder independence assumptions, the quadrat counts can be used for testing homogeneity, i.e., whether the points are distributed evenly across the quadrats (Baddeley, Rubak, and Turner 2015, 164–65).\n\n\nShow the code\nval &lt;- quadrat.test(pp_ls[['0.01']]$`OD Mature`, 5, alternative=\"regular\", method=\"MonteCarlo\")\nval\n\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nX2 = 635.09, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 25 tiles (irregular windows)\n\n\nA p-value of 1 indicates that the null hypothesis of irregularity can not be rejected strongly. Thus, the point pattern of oligodendrocyts is strongly irregular.\nAlternatively, we can inspect departures from the hypothesis that points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types (Buller 2020).\n\n\nShow the code\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp[['0.01']], marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhether or not a point process is completely spatially random (CSR) depends on two characteristics: points need to be distributed homogeneously and they have to be independent of each other (see definitions above). There are various ways to test for CSR, here we show the use-case of the clark-evans test (Baddeley, Rubak, and Turner 2015, 165–66).\n\n\nShow the code\nclarkevans.test(pp_ls[['0.01']]$`OD Mature`)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nR = 0.77286, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\n\nIn the following document we will often compare the distribution of mature oligodendrocytes (OD mature cells) across different z-slices of the same tissue. We assume these slices to be enough apart to be considered as generated by different point processes. Since we consider the dependence of one mark among itself, we are in a within cell type setting per slide. We compare several curves along different z-slices, which is in turn a multivariate comparison (Baddeley, Rubak, and Turner 2015, 564 ff.).\nIn our example dataset we analyse the mouse preoptic hypothalamus (Moffitt et al. 2018). The lower boundary is the end of the tissue whereas the upper three boundaries are a technical boundary. Therefore, our example is a mixture between window sampling and the small world model. In order to decrease the bias of the tissue border, we use the Ripley-Rasson estimate of a spatial domain to estimate the sampling window (Baddeley, Rubak, and Turner 2015, 55; Ripley and Rasson 1977).\n\n\nShow the code\nlibrary('spatialFDA')\npar(mfrow=c(1,3))\n#Plot the marks separately \nlapply(zstack_list, function(zstack){\n  plot(pp_ls[[zstack]][[celltype_ls]], main = zstack, legend = FALSE)\n})\n\n\n\n\n\n\n\n\n\n[[1]]\nSymbol map with constant values\ncols: #000000E4\n\n[[2]]\nSymbol map with constant values\ncols: #000000C2\n\n[[3]]\nSymbol map with constant values\ncols: #0000007B\n\n\nShow the code\ndev.off()\n\n\nnull device \n          1 \n\n\nShow the code\npls &lt;- lapply(zstack_list, function(zstack){\n  pp_sel &lt;- pp_ls[[zstack]][[celltype_ls]]\n  p &lt;- pp_sel |&gt; as.data.frame() |&gt; \n  ggplot(aes(x = x, y = y, alpha = 0.3)) +\n  geom_point(size=0.75) +\n  theme_minimal() +\n  coord_fixed() +\n  ggtitle(zstack)\n  return(p)\n})\nwrap_plots(pls, guides = 'collect')\n\n\n\n\n\nCorrelation, or more generally covariance, represents a second-order summary statistic and measures dependence between data points (Baddeley, Rubak, and Turner 2015, 199 ff.).\n\n\n\n\nWith Ripley’s \\(K\\) we measure “the average number of \\(r\\)-neighbours of a typical random point” (Baddeley, Rubak, and Turner 2015, 204). This number is still dependent on the size of the observation window so we can normalise it by the number of points \\(n\\) and the window size, \\(|W|\\). We then obtain the empirical Ripley’s \\(K\\) function (Baddeley, Rubak, and Turner 2015, 204; Ripley 1977, 1976):\n\\[\n\\hat{K}(r) = \\frac{|W|}{n(n-1)}\\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n\\{d_{ij}\\leq r\\} e_{ij}(r)\n\\]\nThe standardisation makes it possible to compare point patterns with different observation windows and with different numbers of points. However, using the empirical \\(K\\) function assumes that the point process has homogeneous intensity, which is often not the case for biological tissue (Baddeley, Rubak, and Turner 2015, 204–5). We will return to this issue below in the Correcting for Inhomogeneity. The term \\(e_{ij}(r)\\) is an edge correction. We will briefly cover this in Edge effects and their corrections for spatial metrics\n\n\n\nEdge effects describe the phenomenon that not the entire point process is observed, but rather only the part within the window \\(W\\). This means the value of various statistics could be biased along the edges (Baddeley, Rubak, and Turner 2015, 213 ff.).\nThere are many corrections for edge effects that are briefly listed here (Baddeley, Rubak, and Turner 2015, 214–19):\nBorder correction:\nIn border correction the summation of data points is restricted to \\(x_i\\) for which \\(b(x_i,r)\\) is completely in the window \\(W\\).\nIsotropic correction:\nWe can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.\nTranslation correction:\nA stationary point process \\(X\\) is invariant to translations. So the entire point process can be shifted by a vector \\(s\\) to be at the position \\(X+s\\).\n\n\n\n\nThe \\(K\\)-function can be ``centered’’, which is then referred to as Besag’s \\(L\\)-function. The \\(L\\)-function is a variance-stabilising version of the \\(K\\)-function (Canete et al. 2022; Besag 1977, 1977):\n\\[\nL(r) = \\sqrt{\\frac{K(r)}{\\pi}}.\n\\]\nBy taking the square root the variance is approximately constant across the domain (Bartlett 1947).\n\n\n\nWe have seen above that the \\(K\\)-function is cumulative. That is, the contributions of all distances smaller equal to \\(r\\) are considered. An alternative is to take the derivative of the \\(K\\)-function in order to obtain contributions of distances between points equal to \\(r\\), according to:\n\\[\ng(r) = \\frac{K'(r)}{2\\pi r},\n\\]\nwhere the derivative of the \\(K\\) function divided by the probability of a Poisson process at this radius (Baddeley, Rubak, and Turner 2015, 225 ff.).\n\n\nShow the code\nres_ls &lt;- lapply(list('Kest', 'Lest', 'pcf'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')})\n\n\n\n\n\n\nShow the code\np_homo &lt;- wrap_plots(p_ls, guides = 'collect')\np_homo\n\n\n\n\n\n\n\n\n\nIn the homogeneous case we see that all slices are above the Poisson line, indicating positive association for all slices. The association is strongest for slice $-0.09$ followed by $0.01$ and $0.21$. Interestingly, at radii \\(r&gt;300\\) the \\(K\\) curve for slice \\(0.21\\) crosses the other two curves.\n\n\n\n\n\nIn the case that a spatial pattern is known or suspected to be inhomogeneous, we have to take this into account in the analysis. Inhomogeneous alternatives can be estimated via:\n\\[\n\\hat{K}_{inhom}(r) = \\frac{1}{D^p|W|}\\sum_i\\sum_{j \\neq i} \\frac{\\mathbb{1}\\{||u-x_j||\\leq r\\}}{\\hat{\\lambda}(x_j)\\hat{\\lambda}(x_i)}e(x_j,x_i;r),\n\\]\nwhere \\(e(u,v;r)\\) is an edge correction weight and \\(\\hat{\\lambda}(x_i)\\) is an estimator of the intensity at point \\(x_i\\). The estimation of the local intensities can happen in a data-dependent manner via kernel-smoothing. As this is the same data to then calculate the metric on, this can lead to biases. However, if the local intensities are known, the inhomogeneous \\(K\\) function is an unbiased estimator (Baddeley, Rubak, and Turner 2015, 242–46).\n\n\nShow the code\nres_ls &lt;- lapply(list('Kinhom', 'Linhom'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\nres_pcf &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = 'pcfinhom', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id')) \nres_pcf &lt;- subset(res_pcf, sample_id %in% c('-0.09', '0.01', '0.21'))\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"border\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\np &lt;- plotMetricPerFov(res_pcf, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'sample_id')\n\n\n\n\nShow the code\np_inhomo &lt;- wrap_plots(p_ls, guides = 'collect')\np_inhomo &lt;- wrap_plots(p_inhomo, p, guides = 'collect', widths=c(2,1))\np_inhomo\n\n\n\n\n\n\n\n\n\nThe inhomogeneous \\(K\\)-function indicates that the oligodendrocytes of slice 0.21 are close to a Poisson process (dashed line) and can therefore be assumed to be randomly distributed and not clustered. The two other slices show a slightly stronger association among the oligodendrocytes than the slice 0.21.\nThe \\(L\\) function is complementary to the \\(K\\) function in this example.\nThe pair correlation function is the derivative of the \\(K\\)-function. The pcf plot gives similar information as before: Oligodendrocytes show the strongest association at \\(\\sim r = 25\\) whereas the association is weaker in slice 0.21.\nInterestingly, the curves for the inhomogeneous functions of slices -0.09 and 0.01 cross the Poisson line at \\(r\\sim350\\). This means that the inhomogeneous functions find repulsion of slices past a radius of \\(350\\).\n\n\n\n\n\n\nIn the inhomogeneous \\(K\\)-function approach above, we assume that the intensities can vary locally but the scale of the point process is not changed. This means that while the intensities might vary in the parts of the point pattern, the pattern in one subquadrat is not just a scaled version of another subquadrat (Baddeley, Rubak, and Turner 2015, 246–47; Prokešová, Hahn, and Jensen 2006).\nTo account for this local scaling, we can assume that the process is subdivided into small regions. In these small regions, the point process is a scaled version of a template process. This template process needs to be both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 246–47).\n\n\n\nSince the \\(L\\)-function is simply a transformation of the \\(K\\)-function, the same local scaling framework can be applied to the \\(L\\)-function (Baddeley, Rubak, and Turner 2015, 246–47).\n\n\nShow the code\nres_ls &lt;- lapply(list('Kscaled', 'Lscaled'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\n\n\n\n\nShow the code\np_scaled &lt;- wrap_plots(p_ls, guides = 'collect')\np_scaled\n\n\n\n\n\n\n\n\n\nWe see, that in slice 0.01 oligodendrocytes are far from the Poisson process line, indicating a strong association. The other two slices show a less strong association.\n\n\nShow the code\np &lt;- wrap_plots(list(p_homo, p_inhomo, p_scaled), nrow = 3, guides = 'collect') + plot_annotation(tag_levels = 'A')\np\n\n\n\n\n\n\n\n\n\nShow the code\nggsave('pp_function_comparison.pdf', plot = p, width = 8, height = 9)\n\n\nIn the plot above we see all variants of the correlation metrics. The assumptions of either homogeneity (first row), inhomogeneity (second row) and local scaling (third row) change the interpretation of these example point patterns. In summary, in this example homogeneous variants show a positive association for all slices whereas inhomogeneity infered a Poisson distribution for slice \\(0.21\\). Furthermore, the inhomogeneous variant estimated repulsion for slices \\(-0.09\\) and \\(0.01\\), whereas homogeneous variants estimated clustering for all radii, whereas slice \\(0.21\\) became stronger than the other two slices past \\(r&gt;350\\). The locally scaled version showed positive associations for all slices and no crossing of curves over the radii.\nDeciding whether a pattern is homogeneous or inhomogeneous depends on the biological question. We provide some recommendations in the “Getting started” vignettes.\n\n\n\nIt is worth noting that the \\(K\\)- and \\(L\\)-functions described above are summary statistics over the entire pattern (i.e., averaged over all points). However, if we know that there are different regions in our point pattern, an alternative strategy is to compute `local` contributions to these patterns, i.e., local \\(K\\)- ,\\(L\\)- or pair-correlation functions. Baddeley et. al. propose to compare these \\(n\\) functions with so-called functional principal component analysis (see below). We will show here the example of the LISA version of the \\(L\\)-function (Baddeley, Rubak, and Turner 2015, 247–48).\n\n\n\n\nShow the code\nL_odmature_lisa &lt;- localL(pp_ls[['0.01']]$`OD Mature`)      \n\ndf &lt;- as.data.frame(L_odmature_lisa)\ndfm &lt;- reshape2::melt(df, \"r\")\n\nget_sel &lt;- dfm %&gt;% filter(r &gt; 200.5630 & r &lt; 201.4388, variable != \"theo\") %&gt;%\n  mutate(sel = value) %&gt;% select(variable, sel)\n\ndfm &lt;- dfm %&gt;% left_join(get_sel)\n\np &lt;- ggplot(dfm, aes(x=r, y=value, group=variable, colour=sel)) +\n  geom_line() + \n  scale_color_continuous(type = \"viridis\") +\n  geom_vline(xintercept = 200) +\n  theme(legend.position = \"none\") +\n  theme_light() +\n  ggtitle(\"LISA curves of slice 0.01\")\n\nppdf &lt;- as.data.frame(pp[['0.01']]) %&gt;% filter(marks==\"OD Mature\")\nppdf$sel &lt;- get_sel$sel # assume they are in same order\n\nq &lt;- ggplot(ppdf, aes(x=x, y=y, colour=sel)) + \n  geom_point(size=0.75) +\n  scale_color_continuous(type = \"viridis\") +\n  theme(legend.position = \"none\") +\n  theme_light()+\n  ggtitle(\"Points coloured by LISA value at r ~ 200\")\n\n\n\n\nShow the code\np|q\n\n\n\n\n\n\n\n\n\nIn the case of the OD mature cells, we obtain further information with this plot. We note that there are two distinct populations of curves: those that are clearly above the mean LISA curve in black and others that are around/underneath. This indicates that there are two different kinds of interactions in the OD mature cells. Stronger and less clustered regions.\nThere are inhomogeneous versions of these (e.g. localLinhom) that are not shown here for brevity.\n\n\n\nWe apply functional PCA to retrieve the main trends in these individual curves. The idea of functional PCA is the same as for ordinary PCA but applied to functional data (i.e., each observation is a function). For the \\(n\\) functions above, functional PCA will recover the main trends in the data (Ramsay and Silverman 2005). We use the R package refund to perform functional PCA (Xiao et al. 2016).\n\n\nShow the code\n#normalise the data\ndf_fdob &lt;- asinh(df %&gt;% as.matrix / 50) %&gt;% as.data.frame()\n# extract the functional response matrix\nmat &lt;- df_fdob %&gt;%\n   select(!c(r,theo)) %&gt;%\n  t()\n# create a dataframe as required by pffr\ndat &lt;- data.frame(ID = rownames(mat))\ndat$Y &lt;- mat \ndat$sel &lt;- get_sel$sel\n\n# perform functional PCA\nres &lt;- functionalPCA(dat = dat, r = df_fdob$r |&gt; unique(), knots = 30, pve = 0.99)\n# extract the scores\nscores_df &lt;- res$scores %&gt;% as.data.frame()\n# plot a biplot\np_biplot &lt;- ggplot(scores_df, aes(scores_df[, 1], scores_df[, 2], colour = (dat[['sel']]))) +\n        geom_point() +\n        coord_equal() +\n        theme_light() +\n        scale_color_continuous(type = \"viridis\") +\n        xlab('PC1') +\n        ylab('PC2')\n\n\n\n\nShow the code\np_biplot\n\n\n\n\n\n\n\n\n\n\n\nShow the code\np1 &lt;- ggplot(ppdf, aes(x=x, y=y, colour = res$scores[,1])) + \n  scale_color_continuous(type = \"viridis\", name = 'loading PC1') +\n  theme_light() +\n  geom_point(size=0.75)\n\np2 &lt;- ggplot(ppdf, aes(x=x, y=y, colour = res$scores[,2])) + \n  scale_color_continuous(type = \"viridis\", name = 'loading PC2') +\n  theme_light() +\n  geom_point(size=0.75)\n\n\n\n\nShow the code\np1|p2\n\n\n\n\n\n\n\n\n\nThe biplot shows the distribution of the first two loadings of the functional PCA. The points are coloured as they were in the plots of the LISA \\(L\\)-curves. The first principal component clearly separates the two populations. In the last plot we project the loadings of the fPCs back onto the biological slices and find the same separation.\n\n\n\n\n\nSo far we have considered first- and second-order summary statistics and local (or inhomogeneous) adaptations of them. In the second order, one considers (counts of) pairs (e.g., \\(K\\) function). In a third-order setting, we would count triplets of points. A triplet is counted as the normalised expected value of triangles where all edges are smaller than the radius \\(r\\) (Baddeley, Rubak, and Turner 2015, 249).\n\n\n\n\n\nSo far, most approaches considered intensity and correlation as measures to assess a point pattern. Next, we will look at measures of spacing and shortest-distances to assess spatial arrangements (Baddeley, Rubak, and Turner 2015, 255).\nBaddeley et al. summarises three basic distances:\n\npairwise distance: \\(d_{i,j} = ||x_i-x_j||\\)\nNN distances: \\(d_i = \\min_{j \\neq i}d_{ij}\\)\nempty-space distance: \\(d(u) = \\min_j||u-x_j||\\)\n\nNote also that there are tests of CSR that are based on spacing, including the Clark-Evans and Hopkins-Skellam Index tests that were discussed above ``Testing for CSR’’.\n\n\nNearest neighbour (NN) methods are based on the notion of “nearness”. In particular, we introduce nndist from spatstat, a method to calculate the distances until \\(k\\) NN are found. This function returns a density for each specified \\(k\\) for the \\(k\\) neighbour distances. We can for instance collapse the \\(k\\) curves into a mean curve per point pattern. This information of the mean nearest neighbour distance (MMND) can be summarised as a density. Note, that these distances are “raw” nearest-neighbour distances which are not corrected for edge effects. Edge correction for the nearest neighbour distance (\\(k = 1\\)) is implemented in the function Gest below (Baddeley, Rubak, and Turner 2015, 256) (Baddeley and Turner 2005).\n\n\nShow the code\nnndistance &lt;- function(pp, nk){\n  xy &lt;- cbind(pp$x, pp$y)\n  nndistances_k15 &lt;- nndist(xy, k = nk) \n  nndistances_mean &lt;- rowMeans(nndistances_k15)\n  return(nndistances_mean)\n}\n\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricRes_nndist &lt;- function(ppls, celltype, fun){\n  metric.res &lt;- list(res = do.call(fun, args = list(pp=ppls[[celltype]], nk = seq(1:15))))\n  metric.res$type = celltype\n  return(metric.res)\n}\n# [MR: again, this function looks again like those before and maybe could be done as an all-in-one wrapper.]\ncelltypes &lt;- c(\"Ependymal\", \"OD Mature\", \"Microglia\")\n#go through all defined celltypes and calculate the nearest-neighbour distance\nres_ls &lt;- lapply(celltypes, metricRes_nndist, fun = nndistance, ppls = pp_ls[['0.01']])\n#initialise a dataframe for the metric values and the type information\nres_df &lt;- data.frame(metric = numeric(0), type = character(0))\n# Loop through the res_ls list and combine the metric values with their corresponding type - ChatGPT\nfor (i in 1:length(res_ls)) {\n  metric_values &lt;- res_ls[[i]]$res\n  metric_type &lt;- rep(res_ls[[i]]$type, length(metric_values))\n  df &lt;- data.frame(metric = metric_values, type = metric_type)\n  res_df &lt;- rbind(res_df, df)\n}\n#plot the densities\np &lt;- ggplot(res_df, aes(x=metric, col= type))+\n    geom_density(linewidth=1)+\n    scale_x_sqrt() +\n    theme_light() +\n    ggtitle('Sqrt of the Mean Nearest-Neighbour Distance')\np\n\n\n\n\n\n\n\n\n\nIn the MNND empirical distribution, the ependymal cells show the shortest NN distances, a reflection of their clustering. The OD mature cells have larger NN distances as well as a bimodal distribution, indicating a mix of shorter and longer distances (as visible in the LISA \\(L\\)-functions). Microglia cells show the widest distances and the symmetry of the curve indicates similar distances throughout the field of view.\n\n\n\n\n\nIn a stationary spatial point process, the empty-space distance is defined as:\n\\[\nd(u,X) = \\min\\{||u-x_i||: x_i \\in X\\}\n\\]\nNote that this is an edge-corrected distribution function of the nearest-neighbour distance above.\nThe empty space function is then the cumulative distribution function of the empty-space distances defined above:\n\\[\nF(r) = \\mathbb{P}\\{d(u,X)\\leq r\\}.\n\\]\nThe NN distance is defined as:\n\\[\nd_i = \\min_{j\\neq i}||x_j-x_i||.\n\\]\nThe NN distance distribution function \\(G(r)\\) is then defined as:\n\\[\nG(r) = \\mathbb{P}\\{d(x,X\\backslash u \\leq r |X\\ has\\ a\\ point\\ at\\ u\\}.\n\\]\nFor a homogeneous Poisson process, the NN distance distribution is identical to the empty-space function of the same process:\n\\[\nG_{pois} \\equiv F_{pois}.\n\\]\nFor a general point process, the \\(F\\) and \\(G\\) functions are different (Baddeley, Rubak, and Turner 2015, 261–67).\n\n\n\n\nThe \\(F\\) and \\(G\\) functions are, like the \\(K\\) function, cumulative. The same disadvantages as with the \\(K\\) function occur here too, namely their cumulative nature. Therefore, an analogue to the pair-correlation function would make sense to consider. For practical reasons, this is no longer the derivative of the \\(F\\) function but rather a hazard rate:\n\\[\nh(r) = \\frac{f(r)}{1-F(r)}.\n\\]\n(Baddeley, Rubak, and Turner 2015, 271–74).\n\n\n\nThe concepts of the empty-space function \\(F\\) and the NN function \\(G\\) are complementary. If one decreases, the other increases.\nThus, the \\(J\\) function is a combination of both functions:\n\\[\nJ(r) = \\frac{1-G(r)}{1-F(r)}.\n\\]\nFor a CSR process, \\(J_{pois} \\equiv 1\\), whereas values of \\(J(r) &gt; 1\\) are consistent with a regular (e.g., repelling) pattern, and $J(r) &lt; 1 represents a clustered process (Baddeley, Rubak, and Turner 2015, 275–77).\n\n\nShow the code\nres_ls &lt;- lapply(list('Gest', 'Fest', 'Jest'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"rs\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\n\n\n\n\nShow the code\nwrap_plots(p_ls, guides = 'collect')\n\n\n\n\n\n\n\n\n\n\n\n\nThere are inhomogeneous variants of the spacing functions explained above (Baddeley, Rubak, and Turner 2015, 277–78)\n\n\nShow the code\nres_ls &lt;- lapply(list('Ginhom', 'Finhom', 'Jinhom'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"bord\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\n\n\n\n\nShow the code\nwrap_plots(p_ls, guides = 'collect')\n\n\n\n\n\n\n\n\n\nThe inhomogeneous curves look different to their homogeneous counterparts but the relative ordering is of the curves per plot is the same.\n\n\n\nNext to the NN distance, we can estimate the orientation of the neighbours, which gives an indication of the orientation of the spacing. It works by taking the angle between each point and its \\(k^{th}\\) nearest neighbour. The angle is anticlockwise from the x-axis (Baddeley, Rubak, and Turner 2015, 278–79) (Baddeley and Turner 2005).\n\n\nShow the code\nres &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = 'nnorient', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\np &lt;- plotMetricPerFov(res, correction = \"bordm\", theo = TRUE, x = \"phi\", image_id = 'sample_id')\n\n\n\n\nShow the code\np\n\n\n\n\n\n\n\n\n\nThe values of \\(\\phi\\) correspond to the orientation of the original point pattern. The horizontal axis goes from \\(180\\) to \\(0\\) (left to right) and the vertical from \\(90\\) to \\(270\\) (top to bottom)\nan easier representation of the above metric can be plotted as a rose diagram\n\n\nShow the code\npar(1,3)\n\n\n[[1]]\nNULL\n\n[[2]]\nNULL\n\n\nShow the code\nlapply(pp, function(x){rose(nnorient(x))})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n$`-0.09`\nwindow: rectangle = [-0.004850711, 0.004850711] x [-0.004850711, 0.004850711] \nunits\n\n$`0.01`\nwindow: rectangle = [-0.005200848, 0.005200848] x [-0.005200848, 0.005200848] \nunits\n\n$`0.21`\nwindow: rectangle = [-0.004397865, 0.004397865] x [-0.004397865, 0.004397865] \nunits\n\n\nShow the code\ndev.off()\n\n\nnull device \n          1 \n\n\nThe two plots are complementary and show which are the preferred orientations of the point patterns. Furthermore, they show whether or not the assumption of isotropy (no change in the statistical properties of a point pattern after rotations) is justified or not (Baddeley, Rubak, and Turner 2015, 236 ff.). Isotropy is an assumption that a lot of spatial metrics make and in our example we note, that the point patterns are in fact anisotropic. An option for analysing anisotropic stationary point patterns is to not calculate the metric on the actual point pattern but rather calculating it on the fry plot of the point pattern. This generalises e.g. Ripley’s \\(K\\) function from circles to arbitrary shapes (Baddeley, Rubak, and Turner 2015, 239 ff.).\nNote also that the concepts of spacing are not only usable in point pattern analysis but also more broadly in other spatial contexts (e.g., spacing between shapes instead of points) (Baddeley, Rubak, and Turner 2015, 279 ff.).\n\n\n\nThe same consideration about edge effects as for the \\(K\\) (and related) functions need to be made for the spacing functions; uncorrected estimates are negatively biased estimators. The easiest approach is to draw an artificial border and consider NNs within it. Other approaches are based on sampling. Yet another approach relates to survival analysis, with the idea is that a circle of a point to grows homogeneously with increasing radius until it hits the frame of the window and “dies”. This gives survival distributions similar to censored data, where the Kaplan-Meier estimator is the optimal choice (Baddeley, Rubak, and Turner 2015, 285–92).\n©2024 The pasta authors. Content is published under Creative Commons CC-BY-4.0 License for the text and GPL-3 License for any code.",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "01-imaging-univar-ppSOD.html#dependencies",
    "href": "01-imaging-univar-ppSOD.html#dependencies",
    "title": "Discrete Marks",
    "section": "",
    "text": "Show the code\nsource(\"utils.R\")",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "01-imaging-univar-ppSOD.html#setup",
    "href": "01-imaging-univar-ppSOD.html#setup",
    "title": "Discrete Marks",
    "section": "",
    "text": "Show the code\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n\n#define the celltype that you want to compare across the stacks - hereby we assume independence across the z-stacks which is an assumption that can be challenged\ncelltype_ls &lt;- \"OD Mature\"\n\nselectZstacks &lt;- function(zstack, spe){\n  sub &lt;- spe[, spe$sample_id == zstack]\n  pp &lt;- .ppp(sub, marks = \"cluster_id\")\n  return(pp)\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe)\nnames(pp_ls) &lt;- zstack_list\n\n\nThe theory of spatial point patterns is discussed in great detail in (Baddeley, Rubak, and Turner 2015). The book has an accompanying package called spatstat which offers great functionality to the theoretical concepts described in the book (Baddeley and Turner 2005). This chapter relies heavily on both publications.",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "01-imaging-univar-ppSOD.html#concepts-and-definitions-of-point-processes",
    "href": "01-imaging-univar-ppSOD.html#concepts-and-definitions-of-point-processes",
    "title": "Discrete Marks",
    "section": "",
    "text": "In point pattern analysis we assume that the patterns we observe are a realisation of a stochastic process called a point process. The inferences we make about the point pattern are based on the point process. For example, if a pattern is created by a Poisson point process it will be evenly distributed in the observation window (Baddeley, Rubak, and Turner 2015, 127).\nWhen considering a pattern with \\(m\\) multiple types, as we do in the (Moffitt et al. 2018) dataset, there are two very closely related concepts. One can view the pattern as a multitype point pattern, where all the points are sampled from the same point process. The other option is to consider the pattern as a multivariate point pattern, where the points come from \\(m\\) distinct point processes. The difference between these two views is that in the multitype framework we assume the points to stem from the same point process. In the multivariate framework we assume that the types stem from distinct point processes and therefore we can consider dependencies of one type alone. Whether or not the patterns stem from the same point process depends on the biological question. If we analyse two cell types in one slice of a tissue, we should consider them as being sampled from one point process. However, if we consider the distribution of a cell type in two slices of the same tissue we can have grounds to consider them as distinct processes (Baddeley, Rubak, and Turner 2015, 564–65).\n\n\n\nThe most common set up in point pattern analysis is what we call window sampling. Instead of observing the entire pattern we observe a subset of this pattern in the so called window. An example could be different small microscopy windows through which a big tissue slice is observed. In this case, it would be wrong to assume the window to be the convex hull around the observed points because they are just a sample of the bigger point pattern (Baddeley, Rubak, and Turner 2015, 143–45).\nThere is another concept called the small world model. It assumes that points can only be observed in a finite small world and not beyond these boundaries. When thinking of an entire tissue, this is a very common scenario. Cells can only be observed within the tissue and not beyond. In this case, it would be correct to not assume a rectangular observation window but to use methods to estimate an unknown sampling window such as the Ripley-Rasson estimate of a spatial region (Baddeley, Rubak, and Turner 2015, 144–45; Ripley and Rasson 1977).\n\n\nShow the code\nsetRiprasWindows &lt;- function(pp){\n  Window(pp) &lt;- ripras(pp)\n  return(pp)\n}\n#the entire point patterns with the ripras windows\npp &lt;- lapply(pp_ls, setRiprasWindows)\n\nseparateMarks &lt;- function(pp){\n  #split the multitype point process into several single type processes\n  ppls &lt;- split(pp)\n  return (ppls)\n}\n#the point patterns separated by their marks\npp_ls &lt;- lapply(pp, separateMarks)\n\n\n\n\n\nComplete spatial randomness (CSR) is often used as the null model for various point patterns. It is the result of a Poisson process. A completely spatial random process is characterised by two properties, homogeneity and independence, as discussed below (Baddeley, Rubak, and Turner 2015, 132).\n\n\n“Homogeneity […] means that the expected number of points falling in a region B should be proportional to its area |B|” (Baddeley, Rubak, and Turner 2015, 132) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) represents the intensity of the process, i.e., the average number of points in a unit area (Baddeley, Rubak, and Turner 2015, 132–33). :\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|.\n\\label{eq:expected_number_points}\n\\]\n\n\n\nIndependence implies that in two (non-overlapping) regions \\(A\\) and \\(B\\), the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are independent random variables. In other words, the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). (Baddeley, Rubak, and Turner 2015, 133).\n\n\n\n\nA Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density, \\(\\lambda(u)\\), sometimes known as the intensity function (see below), is a function of the spatial location \\(u\\). In this case, the expected number of points falling into a region \\(B\\), \\(\\mu = n(X\\cap B)\\), is an integration of the intensity function over that region (Baddeley, Rubak, and Turner 2015, 138).\n\\[\n\\mu = \\int_{B} \\lambda(u) du.\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\n\nA point process is called isotropic, if its statistical properties are invariant to rotations; a CSR process is both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 147).\n\n\n\n“A point process is called stationary if, when we view the process through a window W , its statistical properties do not depend on the location of the window in two-dimensional space.” (Baddeley, Rubak, and Turner 2015, 146). This is the case for any homogeneous point process, where the statistical properties of the pattern are unchanged given shifting of the observation window. This means it is stationary in all statistical properties; first-order properties (e.g. intensity) and second-order properties (e.g. correlation) (Baddeley, Rubak, and Turner 2015, 218). Not all metrics assume stationarity in its full sense. Inhomogeneous metrics only assume second-order / correlation stationarity. That means while the intensity function can vary spatially (first-order stationarity is not given), the estimates of correlation functions (e.g. the inhomogeneous K-function) should be the same in parts of the window (Baddeley, Rubak, and Turner 2015, 689 ff.).\n\n\n\nIf a process is not correlation stationary, so the estimates of the inhomogeneous metric vary between locations, locally-scaled versions of the metric can be applicable. This means in subregions, the process is still stationary and isotropic, but there is a rescaling factor that can vary across the total process (Baddeley, Rubak, and Turner 2015, 246–47).\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimated functions between the quadrats. It should be noted that this test depends on the arbitrary definition of the quadrats. Given our chosen patterns are not independent but result as marks from an overall point-pattern, the permutation approach is questionable (Baddeley, Rubak, and Turner 2015, 689–93).\n\n\nShow the code\npermutation_test &lt;- function(pp, mark, split, minpoints) {\n  pp_sel &lt;-  subset(pp, marks %in% mark, drop = TRUE)\n  \n  rho_est &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\n  lambda &lt;- predict(rho_est)\n\n  tesselation &lt;- quantess(unmark(pp_sel), \"x\", 3)\n  tesselation_split &lt;- nestsplit(pp_sel, tesselation, ny=split)\n  \n  plot(tesselation_split, main = mark)\n  \n  tesselation_split$inten &lt;- factor(as.integer(tesselation_split$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n  \n  res.scaled &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kscaled,\n                 minpoints = minpoints)\n  \n  res.inhom &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kinhom,\n                 lambda=lambda, minpoints = minpoints)\n  \n  #p-value of the local-scaling test\n  print(paste0(mark,' local scaling test ', res.scaled$p.value))\n  \n  #p-value of the inhomogeneity test\n  print(paste0(mark,' inhomogeneity test ', res.inhom$p.value))\n}\nlapply(c(\"Microglia\", \"OD Mature\", \"Ependymal\"), function(x) permutation_test(pp[['0.01']], x, split = 3, minpoints = 10))\n\n\nThe p-value of the test for local scaling for microglia cells is \\(&lt;0.05\\) which indicates that the assumption of local scaling is rejected. Therefore, the distribution of microglia cells is not a scaled version of an overall distribution pattern. The p-value of the test for inhomogeneity for both microglia cells is \\(&gt;0.05\\) indicating that the assumption of correlation stationarity is not rejected. In this case we can use the inhomogeneous version of the K-function which assumes correlation stationarity.\nFor ependymal and OD mature cells however, the p-values for both the local scaling test and the inhomogeneity test are \\(&gt;0.05\\) which means that for this choice of quadrats both the correlation stationarity assumption and the local scaling assumption can’t be rejected.\nAs the interpretation of the permutation test is highly dependent on the quadrats, the results should be interpreted with care. Both inhomogeneous and locally scaled versions of the summary functions have support and both offer interesting insights into the spatial pattern. Therefore, we will compare all versions and show what the choice of metrics means for their interpretation.\n\n\n\nIntensity is the expected density of points per unit area. It can be interpreted as the rate of occurrence or the abundance of events. The intensity represents a first order property because it is related to the expected number of points. More formally the average intensity of a point process is defined as:\n\\[\n\\bar{\\lambda} = \\frac{n(x)}{|W|}\n\\label{eq:average_intensity}\n\\]\nAs this is an average over the entire window, it is a good estimate for a homogeneous point process (Baddeley, Rubak, and Turner 2015, 157–60)\n\n\nFor a homogeneous point process, the intensity can be estimated in a simplistic way: summing the individual intensities of the marks (Baddeley, Rubak, and Turner 2015, 161).\n\n\nShow the code\nintensityPointProcess &lt;- function(pp,mark) if(mark) intensity(pp) else sum(intensity(pp))\n\nintensityPointProcess(pp_ls[['0.01']], mark = FALSE) %&gt;% round(6)\n\n\n[1] 0.001909\n\n\nOtherwise, we can compute the intensity for each mark individually.\n\n\nShow the code\nintensityPointProcess(pp_ls[['0.01']], mark = TRUE) %&gt;% round(8)\n\n\n  Ambiguous   Astrocyte Endothelial   Ependymal  Excitatory  Inhibitory \n 0.00024151  0.00020183  0.00014653  0.00008373  0.00036867  0.00061393 \n  Microglia OD Immature   OD Mature   Pericytes \n 0.00003031  0.00006249  0.00014278  0.00001750 \n\n\n\n\n\nIn kernel estimation, we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There is a wide variety of kernel estimators (see (Baddeley, Rubak, and Turner 2015, 168)), but a popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth (Baddeley, Rubak, and Turner 2015, 168).\n\n\nShow the code\npp_sel &lt;-  subset(pp_ls[['0.01']]$`OD Mature`, drop = TRUE)\nDens &lt;- density(pp_sel, sigma = 100)\nplot(Dens, main = 'Kernel Density (OD Mature cells)')\n\n\n\n\n\n\n\n\n\n\n\n\nIn quadrat counting, all points falling into a given quadrat are counted. This gives an overview on the characteristics of the point pattern, such as correlation stationarity (Baddeley, Rubak, and Turner 2015, 163).\n\n\nShow the code\nQ5 &lt;- quadratcount(pp_ls[['0.01']], nx=8, ny=8)\nplot(unmark(pp[['0.01']]), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\nUnder independence assumptions, the quadrat counts can be used for testing homogeneity, i.e., whether the points are distributed evenly across the quadrats (Baddeley, Rubak, and Turner 2015, 164–65).\n\n\nShow the code\nval &lt;- quadrat.test(pp_ls[['0.01']]$`OD Mature`, 5, alternative=\"regular\", method=\"MonteCarlo\")\nval\n\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nX2 = 635.09, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 25 tiles (irregular windows)\n\n\nA p-value of 1 indicates that the null hypothesis of irregularity can not be rejected strongly. Thus, the point pattern of oligodendrocyts is strongly irregular.\nAlternatively, we can inspect departures from the hypothesis that points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types (Buller 2020).\n\n\nShow the code\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp[['0.01']], marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhether or not a point process is completely spatially random (CSR) depends on two characteristics: points need to be distributed homogeneously and they have to be independent of each other (see definitions above). There are various ways to test for CSR, here we show the use-case of the clark-evans test (Baddeley, Rubak, and Turner 2015, 165–66).\n\n\nShow the code\nclarkevans.test(pp_ls[['0.01']]$`OD Mature`)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nR = 0.77286, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "01-imaging-univar-ppSOD.html#univariate-viewpoint",
    "href": "01-imaging-univar-ppSOD.html#univariate-viewpoint",
    "title": "Discrete Marks",
    "section": "",
    "text": "In the following document we will often compare the distribution of mature oligodendrocytes (OD mature cells) across different z-slices of the same tissue. We assume these slices to be enough apart to be considered as generated by different point processes. Since we consider the dependence of one mark among itself, we are in a within cell type setting per slide. We compare several curves along different z-slices, which is in turn a multivariate comparison (Baddeley, Rubak, and Turner 2015, 564 ff.).\nIn our example dataset we analyse the mouse preoptic hypothalamus (Moffitt et al. 2018). The lower boundary is the end of the tissue whereas the upper three boundaries are a technical boundary. Therefore, our example is a mixture between window sampling and the small world model. In order to decrease the bias of the tissue border, we use the Ripley-Rasson estimate of a spatial domain to estimate the sampling window (Baddeley, Rubak, and Turner 2015, 55; Ripley and Rasson 1977).\n\n\nShow the code\nlibrary('spatialFDA')\npar(mfrow=c(1,3))\n#Plot the marks separately \nlapply(zstack_list, function(zstack){\n  plot(pp_ls[[zstack]][[celltype_ls]], main = zstack, legend = FALSE)\n})\n\n\n\n\n\n\n\n\n\n[[1]]\nSymbol map with constant values\ncols: #000000E4\n\n[[2]]\nSymbol map with constant values\ncols: #000000C2\n\n[[3]]\nSymbol map with constant values\ncols: #0000007B\n\n\nShow the code\ndev.off()\n\n\nnull device \n          1 \n\n\nShow the code\npls &lt;- lapply(zstack_list, function(zstack){\n  pp_sel &lt;- pp_ls[[zstack]][[celltype_ls]]\n  p &lt;- pp_sel |&gt; as.data.frame() |&gt; \n  ggplot(aes(x = x, y = y, alpha = 0.3)) +\n  geom_point(size=0.75) +\n  theme_minimal() +\n  coord_fixed() +\n  ggtitle(zstack)\n  return(p)\n})\nwrap_plots(pls, guides = 'collect')",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "01-imaging-univar-ppSOD.html#correlation",
    "href": "01-imaging-univar-ppSOD.html#correlation",
    "title": "Discrete Marks",
    "section": "",
    "text": "Correlation, or more generally covariance, represents a second-order summary statistic and measures dependence between data points (Baddeley, Rubak, and Turner 2015, 199 ff.).\n\n\n\n\nWith Ripley’s \\(K\\) we measure “the average number of \\(r\\)-neighbours of a typical random point” (Baddeley, Rubak, and Turner 2015, 204). This number is still dependent on the size of the observation window so we can normalise it by the number of points \\(n\\) and the window size, \\(|W|\\). We then obtain the empirical Ripley’s \\(K\\) function (Baddeley, Rubak, and Turner 2015, 204; Ripley 1977, 1976):\n\\[\n\\hat{K}(r) = \\frac{|W|}{n(n-1)}\\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n\\{d_{ij}\\leq r\\} e_{ij}(r)\n\\]\nThe standardisation makes it possible to compare point patterns with different observation windows and with different numbers of points. However, using the empirical \\(K\\) function assumes that the point process has homogeneous intensity, which is often not the case for biological tissue (Baddeley, Rubak, and Turner 2015, 204–5). We will return to this issue below in the Correcting for Inhomogeneity. The term \\(e_{ij}(r)\\) is an edge correction. We will briefly cover this in Edge effects and their corrections for spatial metrics\n\n\n\nEdge effects describe the phenomenon that not the entire point process is observed, but rather only the part within the window \\(W\\). This means the value of various statistics could be biased along the edges (Baddeley, Rubak, and Turner 2015, 213 ff.).\nThere are many corrections for edge effects that are briefly listed here (Baddeley, Rubak, and Turner 2015, 214–19):\nBorder correction:\nIn border correction the summation of data points is restricted to \\(x_i\\) for which \\(b(x_i,r)\\) is completely in the window \\(W\\).\nIsotropic correction:\nWe can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.\nTranslation correction:\nA stationary point process \\(X\\) is invariant to translations. So the entire point process can be shifted by a vector \\(s\\) to be at the position \\(X+s\\).\n\n\n\n\nThe \\(K\\)-function can be ``centered’’, which is then referred to as Besag’s \\(L\\)-function. The \\(L\\)-function is a variance-stabilising version of the \\(K\\)-function (Canete et al. 2022; Besag 1977, 1977):\n\\[\nL(r) = \\sqrt{\\frac{K(r)}{\\pi}}.\n\\]\nBy taking the square root the variance is approximately constant across the domain (Bartlett 1947).\n\n\n\nWe have seen above that the \\(K\\)-function is cumulative. That is, the contributions of all distances smaller equal to \\(r\\) are considered. An alternative is to take the derivative of the \\(K\\)-function in order to obtain contributions of distances between points equal to \\(r\\), according to:\n\\[\ng(r) = \\frac{K'(r)}{2\\pi r},\n\\]\nwhere the derivative of the \\(K\\) function divided by the probability of a Poisson process at this radius (Baddeley, Rubak, and Turner 2015, 225 ff.).\n\n\nShow the code\nres_ls &lt;- lapply(list('Kest', 'Lest', 'pcf'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')})\n\n\n\n\n\n\nShow the code\np_homo &lt;- wrap_plots(p_ls, guides = 'collect')\np_homo\n\n\n\n\n\n\n\n\n\nIn the homogeneous case we see that all slices are above the Poisson line, indicating positive association for all slices. The association is strongest for slice $-0.09$ followed by $0.01$ and $0.21$. Interestingly, at radii \\(r&gt;300\\) the \\(K\\) curve for slice \\(0.21\\) crosses the other two curves.\n\n\n\n\n\nIn the case that a spatial pattern is known or suspected to be inhomogeneous, we have to take this into account in the analysis. Inhomogeneous alternatives can be estimated via:\n\\[\n\\hat{K}_{inhom}(r) = \\frac{1}{D^p|W|}\\sum_i\\sum_{j \\neq i} \\frac{\\mathbb{1}\\{||u-x_j||\\leq r\\}}{\\hat{\\lambda}(x_j)\\hat{\\lambda}(x_i)}e(x_j,x_i;r),\n\\]\nwhere \\(e(u,v;r)\\) is an edge correction weight and \\(\\hat{\\lambda}(x_i)\\) is an estimator of the intensity at point \\(x_i\\). The estimation of the local intensities can happen in a data-dependent manner via kernel-smoothing. As this is the same data to then calculate the metric on, this can lead to biases. However, if the local intensities are known, the inhomogeneous \\(K\\) function is an unbiased estimator (Baddeley, Rubak, and Turner 2015, 242–46).\n\n\nShow the code\nres_ls &lt;- lapply(list('Kinhom', 'Linhom'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\nres_pcf &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = 'pcfinhom', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id')) \nres_pcf &lt;- subset(res_pcf, sample_id %in% c('-0.09', '0.01', '0.21'))\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"border\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\np &lt;- plotMetricPerFov(res_pcf, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'sample_id')\n\n\n\n\nShow the code\np_inhomo &lt;- wrap_plots(p_ls, guides = 'collect')\np_inhomo &lt;- wrap_plots(p_inhomo, p, guides = 'collect', widths=c(2,1))\np_inhomo\n\n\n\n\n\n\n\n\n\nThe inhomogeneous \\(K\\)-function indicates that the oligodendrocytes of slice 0.21 are close to a Poisson process (dashed line) and can therefore be assumed to be randomly distributed and not clustered. The two other slices show a slightly stronger association among the oligodendrocytes than the slice 0.21.\nThe \\(L\\) function is complementary to the \\(K\\) function in this example.\nThe pair correlation function is the derivative of the \\(K\\)-function. The pcf plot gives similar information as before: Oligodendrocytes show the strongest association at \\(\\sim r = 25\\) whereas the association is weaker in slice 0.21.\nInterestingly, the curves for the inhomogeneous functions of slices -0.09 and 0.01 cross the Poisson line at \\(r\\sim350\\). This means that the inhomogeneous functions find repulsion of slices past a radius of \\(350\\).\n\n\n\n\n\n\nIn the inhomogeneous \\(K\\)-function approach above, we assume that the intensities can vary locally but the scale of the point process is not changed. This means that while the intensities might vary in the parts of the point pattern, the pattern in one subquadrat is not just a scaled version of another subquadrat (Baddeley, Rubak, and Turner 2015, 246–47; Prokešová, Hahn, and Jensen 2006).\nTo account for this local scaling, we can assume that the process is subdivided into small regions. In these small regions, the point process is a scaled version of a template process. This template process needs to be both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 246–47).\n\n\n\nSince the \\(L\\)-function is simply a transformation of the \\(K\\)-function, the same local scaling framework can be applied to the \\(L\\)-function (Baddeley, Rubak, and Turner 2015, 246–47).\n\n\nShow the code\nres_ls &lt;- lapply(list('Kscaled', 'Lscaled'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\n\n\n\n\nShow the code\np_scaled &lt;- wrap_plots(p_ls, guides = 'collect')\np_scaled\n\n\n\n\n\n\n\n\n\nWe see, that in slice 0.01 oligodendrocytes are far from the Poisson process line, indicating a strong association. The other two slices show a less strong association.\n\n\nShow the code\np &lt;- wrap_plots(list(p_homo, p_inhomo, p_scaled), nrow = 3, guides = 'collect') + plot_annotation(tag_levels = 'A')\np\n\n\n\n\n\n\n\n\n\nShow the code\nggsave('pp_function_comparison.pdf', plot = p, width = 8, height = 9)\n\n\nIn the plot above we see all variants of the correlation metrics. The assumptions of either homogeneity (first row), inhomogeneity (second row) and local scaling (third row) change the interpretation of these example point patterns. In summary, in this example homogeneous variants show a positive association for all slices whereas inhomogeneity infered a Poisson distribution for slice \\(0.21\\). Furthermore, the inhomogeneous variant estimated repulsion for slices \\(-0.09\\) and \\(0.01\\), whereas homogeneous variants estimated clustering for all radii, whereas slice \\(0.21\\) became stronger than the other two slices past \\(r&gt;350\\). The locally scaled version showed positive associations for all slices and no crossing of curves over the radii.\nDeciding whether a pattern is homogeneous or inhomogeneous depends on the biological question. We provide some recommendations in the “Getting started” vignettes.\n\n\n\nIt is worth noting that the \\(K\\)- and \\(L\\)-functions described above are summary statistics over the entire pattern (i.e., averaged over all points). However, if we know that there are different regions in our point pattern, an alternative strategy is to compute `local` contributions to these patterns, i.e., local \\(K\\)- ,\\(L\\)- or pair-correlation functions. Baddeley et. al. propose to compare these \\(n\\) functions with so-called functional principal component analysis (see below). We will show here the example of the LISA version of the \\(L\\)-function (Baddeley, Rubak, and Turner 2015, 247–48).\n\n\n\n\nShow the code\nL_odmature_lisa &lt;- localL(pp_ls[['0.01']]$`OD Mature`)      \n\ndf &lt;- as.data.frame(L_odmature_lisa)\ndfm &lt;- reshape2::melt(df, \"r\")\n\nget_sel &lt;- dfm %&gt;% filter(r &gt; 200.5630 & r &lt; 201.4388, variable != \"theo\") %&gt;%\n  mutate(sel = value) %&gt;% select(variable, sel)\n\ndfm &lt;- dfm %&gt;% left_join(get_sel)\n\np &lt;- ggplot(dfm, aes(x=r, y=value, group=variable, colour=sel)) +\n  geom_line() + \n  scale_color_continuous(type = \"viridis\") +\n  geom_vline(xintercept = 200) +\n  theme(legend.position = \"none\") +\n  theme_light() +\n  ggtitle(\"LISA curves of slice 0.01\")\n\nppdf &lt;- as.data.frame(pp[['0.01']]) %&gt;% filter(marks==\"OD Mature\")\nppdf$sel &lt;- get_sel$sel # assume they are in same order\n\nq &lt;- ggplot(ppdf, aes(x=x, y=y, colour=sel)) + \n  geom_point(size=0.75) +\n  scale_color_continuous(type = \"viridis\") +\n  theme(legend.position = \"none\") +\n  theme_light()+\n  ggtitle(\"Points coloured by LISA value at r ~ 200\")\n\n\n\n\nShow the code\np|q\n\n\n\n\n\n\n\n\n\nIn the case of the OD mature cells, we obtain further information with this plot. We note that there are two distinct populations of curves: those that are clearly above the mean LISA curve in black and others that are around/underneath. This indicates that there are two different kinds of interactions in the OD mature cells. Stronger and less clustered regions.\nThere are inhomogeneous versions of these (e.g. localLinhom) that are not shown here for brevity.\n\n\n\nWe apply functional PCA to retrieve the main trends in these individual curves. The idea of functional PCA is the same as for ordinary PCA but applied to functional data (i.e., each observation is a function). For the \\(n\\) functions above, functional PCA will recover the main trends in the data (Ramsay and Silverman 2005). We use the R package refund to perform functional PCA (Xiao et al. 2016).\n\n\nShow the code\n#normalise the data\ndf_fdob &lt;- asinh(df %&gt;% as.matrix / 50) %&gt;% as.data.frame()\n# extract the functional response matrix\nmat &lt;- df_fdob %&gt;%\n   select(!c(r,theo)) %&gt;%\n  t()\n# create a dataframe as required by pffr\ndat &lt;- data.frame(ID = rownames(mat))\ndat$Y &lt;- mat \ndat$sel &lt;- get_sel$sel\n\n# perform functional PCA\nres &lt;- functionalPCA(dat = dat, r = df_fdob$r |&gt; unique(), knots = 30, pve = 0.99)\n# extract the scores\nscores_df &lt;- res$scores %&gt;% as.data.frame()\n# plot a biplot\np_biplot &lt;- ggplot(scores_df, aes(scores_df[, 1], scores_df[, 2], colour = (dat[['sel']]))) +\n        geom_point() +\n        coord_equal() +\n        theme_light() +\n        scale_color_continuous(type = \"viridis\") +\n        xlab('PC1') +\n        ylab('PC2')\n\n\n\n\nShow the code\np_biplot\n\n\n\n\n\n\n\n\n\n\n\nShow the code\np1 &lt;- ggplot(ppdf, aes(x=x, y=y, colour = res$scores[,1])) + \n  scale_color_continuous(type = \"viridis\", name = 'loading PC1') +\n  theme_light() +\n  geom_point(size=0.75)\n\np2 &lt;- ggplot(ppdf, aes(x=x, y=y, colour = res$scores[,2])) + \n  scale_color_continuous(type = \"viridis\", name = 'loading PC2') +\n  theme_light() +\n  geom_point(size=0.75)\n\n\n\n\nShow the code\np1|p2\n\n\n\n\n\n\n\n\n\nThe biplot shows the distribution of the first two loadings of the functional PCA. The points are coloured as they were in the plots of the LISA \\(L\\)-curves. The first principal component clearly separates the two populations. In the last plot we project the loadings of the fPCs back onto the biological slices and find the same separation.\n\n\n\n\n\nSo far we have considered first- and second-order summary statistics and local (or inhomogeneous) adaptations of them. In the second order, one considers (counts of) pairs (e.g., \\(K\\) function). In a third-order setting, we would count triplets of points. A triplet is counted as the normalised expected value of triangles where all edges are smaller than the radius \\(r\\) (Baddeley, Rubak, and Turner 2015, 249).",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "01-imaging-univar-ppSOD.html#spacing",
    "href": "01-imaging-univar-ppSOD.html#spacing",
    "title": "Discrete Marks",
    "section": "",
    "text": "So far, most approaches considered intensity and correlation as measures to assess a point pattern. Next, we will look at measures of spacing and shortest-distances to assess spatial arrangements (Baddeley, Rubak, and Turner 2015, 255).\nBaddeley et al. summarises three basic distances:\n\npairwise distance: \\(d_{i,j} = ||x_i-x_j||\\)\nNN distances: \\(d_i = \\min_{j \\neq i}d_{ij}\\)\nempty-space distance: \\(d(u) = \\min_j||u-x_j||\\)\n\nNote also that there are tests of CSR that are based on spacing, including the Clark-Evans and Hopkins-Skellam Index tests that were discussed above ``Testing for CSR’’.\n\n\nNearest neighbour (NN) methods are based on the notion of “nearness”. In particular, we introduce nndist from spatstat, a method to calculate the distances until \\(k\\) NN are found. This function returns a density for each specified \\(k\\) for the \\(k\\) neighbour distances. We can for instance collapse the \\(k\\) curves into a mean curve per point pattern. This information of the mean nearest neighbour distance (MMND) can be summarised as a density. Note, that these distances are “raw” nearest-neighbour distances which are not corrected for edge effects. Edge correction for the nearest neighbour distance (\\(k = 1\\)) is implemented in the function Gest below (Baddeley, Rubak, and Turner 2015, 256) (Baddeley and Turner 2005).\n\n\nShow the code\nnndistance &lt;- function(pp, nk){\n  xy &lt;- cbind(pp$x, pp$y)\n  nndistances_k15 &lt;- nndist(xy, k = nk) \n  nndistances_mean &lt;- rowMeans(nndistances_k15)\n  return(nndistances_mean)\n}\n\n#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate\n#POST: result of the metric\nmetricRes_nndist &lt;- function(ppls, celltype, fun){\n  metric.res &lt;- list(res = do.call(fun, args = list(pp=ppls[[celltype]], nk = seq(1:15))))\n  metric.res$type = celltype\n  return(metric.res)\n}\n# [MR: again, this function looks again like those before and maybe could be done as an all-in-one wrapper.]\ncelltypes &lt;- c(\"Ependymal\", \"OD Mature\", \"Microglia\")\n#go through all defined celltypes and calculate the nearest-neighbour distance\nres_ls &lt;- lapply(celltypes, metricRes_nndist, fun = nndistance, ppls = pp_ls[['0.01']])\n#initialise a dataframe for the metric values and the type information\nres_df &lt;- data.frame(metric = numeric(0), type = character(0))\n# Loop through the res_ls list and combine the metric values with their corresponding type - ChatGPT\nfor (i in 1:length(res_ls)) {\n  metric_values &lt;- res_ls[[i]]$res\n  metric_type &lt;- rep(res_ls[[i]]$type, length(metric_values))\n  df &lt;- data.frame(metric = metric_values, type = metric_type)\n  res_df &lt;- rbind(res_df, df)\n}\n#plot the densities\np &lt;- ggplot(res_df, aes(x=metric, col= type))+\n    geom_density(linewidth=1)+\n    scale_x_sqrt() +\n    theme_light() +\n    ggtitle('Sqrt of the Mean Nearest-Neighbour Distance')\np\n\n\n\n\n\n\n\n\n\nIn the MNND empirical distribution, the ependymal cells show the shortest NN distances, a reflection of their clustering. The OD mature cells have larger NN distances as well as a bimodal distribution, indicating a mix of shorter and longer distances (as visible in the LISA \\(L\\)-functions). Microglia cells show the widest distances and the symmetry of the curve indicates similar distances throughout the field of view.\n\n\n\n\n\nIn a stationary spatial point process, the empty-space distance is defined as:\n\\[\nd(u,X) = \\min\\{||u-x_i||: x_i \\in X\\}\n\\]\nNote that this is an edge-corrected distribution function of the nearest-neighbour distance above.\nThe empty space function is then the cumulative distribution function of the empty-space distances defined above:\n\\[\nF(r) = \\mathbb{P}\\{d(u,X)\\leq r\\}.\n\\]\nThe NN distance is defined as:\n\\[\nd_i = \\min_{j\\neq i}||x_j-x_i||.\n\\]\nThe NN distance distribution function \\(G(r)\\) is then defined as:\n\\[\nG(r) = \\mathbb{P}\\{d(x,X\\backslash u \\leq r |X\\ has\\ a\\ point\\ at\\ u\\}.\n\\]\nFor a homogeneous Poisson process, the NN distance distribution is identical to the empty-space function of the same process:\n\\[\nG_{pois} \\equiv F_{pois}.\n\\]\nFor a general point process, the \\(F\\) and \\(G\\) functions are different (Baddeley, Rubak, and Turner 2015, 261–67).\n\n\n\n\nThe \\(F\\) and \\(G\\) functions are, like the \\(K\\) function, cumulative. The same disadvantages as with the \\(K\\) function occur here too, namely their cumulative nature. Therefore, an analogue to the pair-correlation function would make sense to consider. For practical reasons, this is no longer the derivative of the \\(F\\) function but rather a hazard rate:\n\\[\nh(r) = \\frac{f(r)}{1-F(r)}.\n\\]\n(Baddeley, Rubak, and Turner 2015, 271–74).\n\n\n\nThe concepts of the empty-space function \\(F\\) and the NN function \\(G\\) are complementary. If one decreases, the other increases.\nThus, the \\(J\\) function is a combination of both functions:\n\\[\nJ(r) = \\frac{1-G(r)}{1-F(r)}.\n\\]\nFor a CSR process, \\(J_{pois} \\equiv 1\\), whereas values of \\(J(r) &gt; 1\\) are consistent with a regular (e.g., repelling) pattern, and $J(r) &lt; 1 represents a clustered process (Baddeley, Rubak, and Turner 2015, 275–77).\n\n\nShow the code\nres_ls &lt;- lapply(list('Gest', 'Fest', 'Jest'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"rs\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\n\n\n\n\nShow the code\nwrap_plots(p_ls, guides = 'collect')\n\n\n\n\n\n\n\n\n\n\n\n\nThere are inhomogeneous variants of the spacing functions explained above (Baddeley, Rubak, and Turner 2015, 277–78)\n\n\nShow the code\nres_ls &lt;- lapply(list('Ginhom', 'Finhom', 'Jinhom'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, correction = \"bord\", theo = TRUE, x = \"r\", image_id = 'sample_id')})\n\n\n\n\nShow the code\nwrap_plots(p_ls, guides = 'collect')\n\n\n\n\n\n\n\n\n\nThe inhomogeneous curves look different to their homogeneous counterparts but the relative ordering is of the curves per plot is the same.\n\n\n\nNext to the NN distance, we can estimate the orientation of the neighbours, which gives an indication of the orientation of the spacing. It works by taking the angle between each point and its \\(k^{th}\\) nearest neighbour. The angle is anticlockwise from the x-axis (Baddeley, Rubak, and Turner 2015, 278–79) (Baddeley and Turner 2005).\n\n\nShow the code\nres &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = 'nnorient', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\np &lt;- plotMetricPerFov(res, correction = \"bordm\", theo = TRUE, x = \"phi\", image_id = 'sample_id')\n\n\n\n\nShow the code\np\n\n\n\n\n\n\n\n\n\nThe values of \\(\\phi\\) correspond to the orientation of the original point pattern. The horizontal axis goes from \\(180\\) to \\(0\\) (left to right) and the vertical from \\(90\\) to \\(270\\) (top to bottom)\nan easier representation of the above metric can be plotted as a rose diagram\n\n\nShow the code\npar(1,3)\n\n\n[[1]]\nNULL\n\n[[2]]\nNULL\n\n\nShow the code\nlapply(pp, function(x){rose(nnorient(x))})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n$`-0.09`\nwindow: rectangle = [-0.004850711, 0.004850711] x [-0.004850711, 0.004850711] \nunits\n\n$`0.01`\nwindow: rectangle = [-0.005200848, 0.005200848] x [-0.005200848, 0.005200848] \nunits\n\n$`0.21`\nwindow: rectangle = [-0.004397865, 0.004397865] x [-0.004397865, 0.004397865] \nunits\n\n\nShow the code\ndev.off()\n\n\nnull device \n          1 \n\n\nThe two plots are complementary and show which are the preferred orientations of the point patterns. Furthermore, they show whether or not the assumption of isotropy (no change in the statistical properties of a point pattern after rotations) is justified or not (Baddeley, Rubak, and Turner 2015, 236 ff.). Isotropy is an assumption that a lot of spatial metrics make and in our example we note, that the point patterns are in fact anisotropic. An option for analysing anisotropic stationary point patterns is to not calculate the metric on the actual point pattern but rather calculating it on the fry plot of the point pattern. This generalises e.g. Ripley’s \\(K\\) function from circles to arbitrary shapes (Baddeley, Rubak, and Turner 2015, 239 ff.).\nNote also that the concepts of spacing are not only usable in point pattern analysis but also more broadly in other spatial contexts (e.g., spacing between shapes instead of points) (Baddeley, Rubak, and Turner 2015, 279 ff.).\n\n\n\nThe same consideration about edge effects as for the \\(K\\) (and related) functions need to be made for the spacing functions; uncorrected estimates are negatively biased estimators. The easiest approach is to draw an artificial border and consider NNs within it. Other approaches are based on sampling. Yet another approach relates to survival analysis, with the idea is that a circle of a point to grows homogeneously with increasing radius until it hits the frame of the window and “dies”. This gives survival distributions similar to censored data, where the Kaplan-Meier estimator is the optimal choice (Baddeley, Rubak, and Turner 2015, 285–92).",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "01-imaging-univar-ppSOD.html#setup-1",
    "href": "01-imaging-univar-ppSOD.html#setup-1",
    "title": "Discrete Marks",
    "section": "Setup",
    "text": "Setup\n\n\nShow the code\n# redefine the pp here to be zstack 0.01\npp &lt;- pp[['0.01']]\nsub &lt;- spe[, spe$sample_id == '0.01']\n\n\nIn spatstat, a mark can basically take any value, discrete (e.g. cell types, as we have seen above) or continuous (e.g., gene expression) (Baddeley, Rubak, and Turner 2015, 637 ff.). In our example, we take the gene expression of some marker genes from Fig. 6 of the original publication (Moffitt et al. 2018). This is a typical numerical mark for points in a biological dataset.\n\n\nShow the code\n#  Genes from Fig. 6 of Moffitt et al. (2018)\ngenes &lt;- c('Slc18a2', 'Esr1', 'Pgr')\ngex &lt;- assay(sub)[genes,] %&gt;% t %&gt;% as.matrix %&gt;% \n  data.frame %&gt;% set_rownames(NULL)\n# gene expression to marks\ncolData(sub) &lt;- colData(sub) %&gt;% cbind(gex)\nmarks(pp) &lt;- gex\n\n\n\n\nShow the code\nplot(pp)\n\n\n\n\n\n\n\n\n\nHere we see spatial distribution of the counts of the three genes Slc18a2, Esr1 and Pgr. The size of the circles indicates the counts of the transcripts at that spot. Since there are really a lot of points, we can’t easily distinguish general patterns of count distributions.\nThe function pairs from spatstat generates a scatterplot of the counts of the marks (in our case the three genes) against each other and against the \\(x\\) and \\(y\\) coordinates. We can add a non-linear smoothing curve to make the general trends a bit more obvious (Baddeley, Rubak, and Turner 2015, 641).\n\n\nShow the code\npairs(as.data.frame(pp), panel = panel.smooth, pch=\".\")\n\n\n\n\n\n\n\n\n\nWe find that the counts of the three genes are very evenly distributed along the \\(x\\) and \\(y\\) coordinate, indicating a homogeneous distribution. The counts of Esr1 and Pgr are positively associated, indicating a dependence of these two marks.\nNN interpolations uses the nearest mark to measure the intensity at each spatial location. This is conceptually similar to taking a very small bandwidth for Gaussian kernel smoothing (Baddeley, Rubak, and Turner 2015, 642).\n\n\nShow the code\nplot(nnmark(pp))\n\n\n\n\n\n\n\n\n\nWe see that there is e.g. a clear spatial structure in the expression of e.g. Esr1. It shows a half moon shape.",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "01-imaging-univar-ppSOD.html#summary-functions-for-continuous-marks",
    "href": "01-imaging-univar-ppSOD.html#summary-functions-for-continuous-marks",
    "title": "Discrete Marks",
    "section": "Summary functions for continuous marks",
    "text": "Summary functions for continuous marks\nAs in the discrete case, summary functions assume that the point process is stationary.\n\nMark correlation function\nThe mark correlation function measures the dependence between two marks for two points at distance \\(r\\). It is applicable to stationary point processes with marks. The generalized mark correlation function is given by:\n\\[ k_f(r) = \\frac{\\mathbb{E}[f(m(u),m(v))]}{\\mathbb{E}[f(M,M')]},\\]\nwhere \\(f(m(u),m(v))\\) is a test function with two arguments (representing the two marks at locations \\(u\\) and \\(v\\)) and returns a non-negative value. For continuous non-negative marks, the canonical choice for \\(f\\) is typically \\(f(m(u),m(v))= m(u)m(v)\\). \\(M\\) and \\(M′\\) represent independent, identically distributed random points with the same distribution as the mark of a randomly chosen point. This denominator is chosen such that random marks have a mark correlation of 1 (Baddeley, Rubak, and Turner 2015, 644–45).\n\n\nShow the code\nres &lt;- calcMetricPerFov(sub, 'OD Mature', subsetby = genes, fun = 'markcorr',  marks = genes, r_seq=NULL, by = c('Animal_ID','sample_id'), continuous = TRUE)\np &lt;- plotMetricPerFov(res, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'gene')\np\n\n\n\n\n\n\n\n\n\nFrom this plot we show that all genes show a positive correlation at small distances which decline with increasing radius \\(r\\). The association is strongest for the Slc18a2 gene. We can calculate simulation envelopes to estimate the significance of this association. This is not shown for brevity.\n\n\nMark-weighted \\(K\\)-function\nThe mark-weigthed \\(K\\)-function is a generalization of the \\(K\\)-function in which the contribution from each pair of points is weighted by a function of their respective marks. It is given by:\n\\[K_f(r) = \\frac 1  \\lambda \\frac{C_f(r)}{E[ f(M_1, M_2) ]},\\] where:\n\\[ C_f(r) = E \\left[ \\sum_{x \\in X} f(m(u), m(x)) 1\\{0 &lt; ||u - x|| \\le r\\} \\;  \\big| \\; u \\in X \\right], \\]\nis equivalent to the unnormalized mark-weighted \\(K\\)-function. For every point \\(u\\), we sum the euclidean distance \\(||u - x||\\) of all other points \\(x\\) that are within a distance \\(r\\). This sum is weighted by the function \\(f(.,.)\\) of the marks of \\(u\\) and \\(x\\). The function is standardized by the expected value of \\(f(M_1, M_2)\\) where \\(M_1, M_2\\) represent independent, identically distributed random points with the same distribution as the mark of a randomly chosen point (Baddeley, Rubak, and Turner 2015, 646–47).\nIn the scenario of random labeling, so where the marks are distributed randomly, the mark-weighted \\(K\\)-function corresponds to the standard Ripley’s \\(K\\)-function.\nAlso here, the canonical function is: \\(f(m_1, m_2) = m_1 m_2\\). This means we weigh each interaction between points by the product of the continuous marks of both points.\n\n\nShow the code\nres &lt;- calcMetricPerFov(sub, 'OD Mature', subsetby = genes, fun = 'Kmark',  marks = genes, r_seq=NULL, by = c('Animal_ID','sample_id'), continuous = TRUE) \np &lt;- plotMetricPerFov(res, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'gene')\np\n\n\n\n\n\n\n\n\n\nIt is important to note that the theoretical value of the \\(K\\)-function is not very informative since it represents the \\(K\\)-function of a Poisson point process and the underlying point process might not be Poisson. Therefore we compare the mark-weighted with its unmarked analogue. Like this, we can assess whether the points weighted by a continuous mark are more or less correlated than their unmarked analogues (Baddeley, Rubak, and Turner 2015, 647).\nHere we will compare the \\(L\\)-functions weighted by the mark of the gene Esr1 and the unmarked \\(L\\)-function.\n\n\nShow the code\nppEsr1 &lt;- subset(pp, select = 'Esr1')\nL.Esr1L &lt;- Kmark(ppEsr1, function(m1,m2) {m1*m2}, returnL = TRUE)\nLest.ppEsr1 &lt;- Lest(ppEsr1, nlarge=7000)\nplot(eval.fv(L.Esr1L - Lest.ppEsr1))\n\n\n\n\n\n\n\n\n\nWe note that the difference between \\(L\\)-function weighted by the expression of Esr1 minus the unmarked \\(L\\)-function is positively different to the poisson difference, meaning that the expression of the continuous mark Esr1 is correlated among itself.",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "01-imaging-univar-ppSOD.html#session-info",
    "href": "01-imaging-univar-ppSOD.html#session-info",
    "title": "Discrete Marks",
    "section": "Session info",
    "text": "Session info\n\n\nShow the code\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] spatialFDA_0.99.0              magrittr_2.0.3                \n [3] stringr_1.5.0                  dixon_0.0-8                   \n [5] splancs_2.01-44                spdep_1.2-8                   \n [7] spData_2.3.0                   tmap_3.3-4                    \n [9] scater_1.28.0                  scran_1.28.2                  \n[11] scuttle_1.10.3                 SFEData_1.2.0                 \n[13] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[15] rgeoda_0.0.10-4                digest_0.6.33                 \n[17] ncf_1.3-2                      sf_1.0-16                     \n[19] reshape2_1.4.4                 patchwork_1.2.0               \n[21] STexampleData_1.8.0            ExperimentHub_2.8.1           \n[23] AnnotationHub_3.8.0            BiocFileCache_2.8.0           \n[25] dbplyr_2.3.4                   RANN_2.6.1                    \n[27] seg_0.5-7                      sp_2.1-1                      \n[29] rlang_1.1.1                    ggplot2_3.5.1                 \n[31] dplyr_1.1.3                    mixR_0.2.0                    \n[33] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[35] spatstat.model_3.2-6           rpart_4.1.19                  \n[37] spatstat.explore_3.2-3         nlme_3.1-162                  \n[39] spatstat.random_3.1-6          spatstat.geom_3.2-5           \n[41] spatstat.data_3.0-1            SpatialExperiment_1.10.0      \n[43] SingleCellExperiment_1.22.0    SummarizedExperiment_1.30.2   \n[45] Biobase_2.60.0                 GenomicRanges_1.52.1          \n[47] GenomeInfoDb_1.36.4            IRanges_2.34.1                \n[49] S4Vectors_0.38.2               BiocGenerics_0.46.0           \n[51] MatrixGenerics_1.12.3          matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] grpreg_3.4.0                  tools_4.3.1                  \n  [7] utf8_1.2.3                    R6_2.5.1                     \n  [9] HDF5Array_1.28.1              mgcv_1.9-1                   \n [11] rhdf5filters_1.12.1           withr_2.5.1                  \n [13] gridExtra_2.3                 leaflet_2.2.0                \n [15] textshaping_0.3.7             leafem_0.2.3                 \n [17] cli_3.6.1                     labeling_0.4.3               \n [19] mvtnorm_1.2-5                 proxy_0.4-27                 \n [21] systemfonts_1.0.5             R.utils_2.12.2               \n [23] dichromat_2.0-0.1             scico_1.5.0                  \n [25] limma_3.56.2                  rstudioapi_0.15.0            \n [27] RSQLite_2.3.1                 generics_0.1.3               \n [29] crosstalk_1.2.0               Matrix_1.5-4.1               \n [31] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [33] abind_1.4-5                   R.methodsS3_1.8.2            \n [35] terra_1.7-55                  lifecycle_1.0.3              \n [37] yaml_2.3.7                    edgeR_3.42.4                 \n [39] rhdf5_2.44.0                  tmaptools_3.1-1              \n [41] grid_4.3.1                    blob_1.2.4                   \n [43] promises_1.2.1                dqrng_0.3.1                  \n [45] crayon_1.5.2                  lattice_0.21-8               \n [47] beachmat_2.16.0               KEGGREST_1.40.1              \n [49] magick_2.8.0                  refund_0.1-35                \n [51] pillar_1.9.0                  knitr_1.44                   \n [53] metapod_1.7.0                 rjson_0.2.21                 \n [55] boot_1.3-28.1                 fda_6.1.8                    \n [57] codetools_0.2-19              wk_0.8.0                     \n [59] glue_1.6.2                    vctrs_0.6.4                  \n [61] png_0.1-8                     gtable_0.3.4                 \n [63] ks_1.14.2                     cachem_1.0.8                 \n [65] xfun_0.40                     S4Arrays_1.0.6               \n [67] mime_0.12                     DropletUtils_1.20.0          \n [69] pracma_2.4.2                  fds_1.8                      \n [71] pcaPP_2.0-4                   pbs_1.1                      \n [73] units_0.8-4                   statmod_1.5.0                \n [75] bluster_1.10.0                interactiveDisplayBase_1.38.0\n [77] ellipsis_0.3.2                bit64_4.0.5                  \n [79] filelock_1.0.2                irlba_2.3.5.1                \n [81] vipor_0.4.5                   KernSmooth_2.23-21           \n [83] colorspace_2.1-0              DBI_1.1.3                    \n [85] raster_3.6-26                 tidyselect_1.2.0             \n [87] bit_4.0.5                     compiler_4.3.1               \n [89] curl_5.1.0                    BiocNeighbors_1.18.0         \n [91] DelayedArray_0.26.7           scales_1.3.0                 \n [93] classInt_0.4-10               rappdirs_0.3.3               \n [95] goftest_1.2-3                 rainbow_3.8                  \n [97] minqa_1.2.7                   fftwtools_0.9-11             \n [99] spatstat.utils_3.0-5          rmarkdown_2.25               \n[101] XVector_0.40.0                htmltools_0.5.6.1            \n[103] pkgconfig_2.0.3               base64enc_0.1-3              \n[105] lme4_1.1-35.4                 sparseMatrixStats_1.12.2     \n[107] fastmap_1.1.1                 htmlwidgets_1.6.2            \n[109] RLRsim_3.1-8                  shiny_1.7.5.1                \n[111] DelayedMatrixStats_1.22.6     farver_2.1.1                 \n[113] jsonlite_1.8.7                mclust_6.1.1                 \n[115] BiocParallel_1.34.2           R.oo_1.25.0                  \n[117] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[119] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[121] Rhdf5lib_1.22.1               munsell_0.5.0                \n[123] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[125] viridis_0.6.4                 stringi_1.7.12               \n[127] leafsync_0.1.0                MASS_7.3-60                  \n[129] zlibbioc_1.46.0               plyr_1.8.9                   \n[131] parallel_4.3.1                ggrepel_0.9.4                \n[133] deldir_1.0-9                  Biostrings_2.68.1            \n[135] stars_0.6-4                   splines_4.3.1                \n[137] tensor_1.5                    locfit_1.5-9.8               \n[139] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[141] magic_1.6-1                   BiocVersion_3.17.1           \n[143] XML_3.99-0.14                 evaluate_0.22                \n[145] BiocManager_1.30.22           deSolve_1.40                 \n[147] nloptr_2.1.1                  httpuv_1.6.11                \n[149] tidyr_1.3.0                   purrr_1.0.2                  \n[151] polyclip_1.10-6               rsvd_1.0.5                   \n[153] lwgeom_0.2-13                 xtable_1.8-4                 \n[155] e1071_1.7-13                  RSpectra_0.16-1              \n[157] later_1.3.1                   ragg_1.2.6                   \n[159] viridisLite_0.4.2             class_7.3-22                 \n[161] tibble_3.2.1                  memoise_2.0.1                \n[163] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[165] gamm4_0.2-6                   cluster_2.1.4                \n[167] hdrcde_3.4",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "02-imaging-univar-latSOD.html",
    "href": "02-imaging-univar-latSOD.html",
    "title": "Irregular Lattices",
    "section": "",
    "text": "Show the code\nsource(\"utils.R\")\ntheme_set(theme_minimal())\n\n\nUntil now, we have considered the cells to be represented in a point pattern. However, as cells have a shape and area, this might be an oversimplification in some cases. Alternatively, we can rely on the segmentation of individual cells that are available for various datasets. The outline of each cell is represented by a polygon and the collection of all cells can be seen as an irregular lattice. Unlike a regular lattice (e.g., spot-based spatial transcriptomics data), the sample areas in an irregular lattice can have different sizes and are not necessarily regularly distributed over the sample space.\nFor this representation of the cells we will rely on the SpatialFeatureExperiment package. For preprocessing of the dataset we refer the reader to the vignette of the voyager package (Moses et al. 2023). The voyager package also provides wrapper functions around the package spdep (Pebesma and Bivand 2023) that work directly on the SpatialFeatureExperiment object.\n\n\nShow the code\n#taken from https://pachterlab.github.io/voyager/articles/vig4_cosmx.html\n(sfe &lt;- HeNSCLCData())\n\n\nclass: SpatialFeatureExperiment \ndim: 980 100290 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100290): 1_1 1_2 ... 30_4759 30_4760\ncolData names(17): Area AspectRatio ... nCounts nGenes\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n\nShow the code\n# Empty cells\ncolData(sfe)$is_empty &lt;- colData(sfe)$nCounts &lt; 1\n# Select, sum negative control probes\n(neg_inds &lt;- str_detect(rownames(sfe), \"^NegPrb\")) %&gt;% sum\n\n\n[1] 20\n\n\nShow the code\ncolData(sfe)$prop_neg &lt;- colSums(counts(sfe)[neg_inds,])/colData(sfe)$nCounts\n# Remove low quality cells\nsfe &lt;- sfe[,!sfe$is_empty & sfe$prop_neg &lt; 0.1]\n# Re-calculate stats\nrowData(sfe)$is_neg &lt;- neg_inds\n# log Counts\nsfe &lt;- logNormCounts(sfe)\n\n\nFor some examples we will show a subset of the tissue.\n\n\nShow the code\nbbox_use &lt;- st_as_sfc(st_bbox(c(xmin = 3500, xmax = 14000, ymin = 157200, ymax = 162200)))\n\n\n\n\nShow the code\nsfe &lt;- sfe[,st_intersects(colGeometries(sfe)$centroids, bbox_use, sparse = FALSE)]\n\n\n\nIn this vignette, we will show the metrics related to two marker genes: KRT17 (basal cells) and TAGLN (smooth muscle cells).\n\n\nShow the code\nplotSpatialFeature(sfe, c(\"KRT17\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()\n\n\n\n\n\n\n\n\n\nShow the code\nplotSpatialFeature(sfe, c(\"TAGLN\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the challenges when working with (irregular) lattice data is the construction of a neighbourhood graph (Pebesma and Bivand 2023). The main question is, what to consider as neighbours, as this will affect downstream analyses. Various methods exist to create neighbours, such as contiguitiy based neighbours (neighbours in direct contact), graph-based neighbours (e.g., \\(k\\)-nearest neighbours), distance based neighbours or higher order neighbours (Getis 2009; Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023). The documentation of the package spdep gives an overview of the different methods.\nSegmentation of individual cells is challenging (Wang 2019) and construction of contiguity-based neighbours based on individual cell segmentation assumes very accurate segmentation results. Furthermore it would neglect the influence of more distant, not directly adjacent neighbours, which based on the feature of interest might not be the correct assumption.\nIn an irregular lattice, the task of finding a spatial weight matrix is more complex, as different options exist. One option is to base the neighbourhood graph on neighbours that are in direct contact with each other (contiguous), as implemented in the poly2nb method. As cell segmentation is notoriously imperfect, we add a snap value, which means that we consider all cells with distance 20 or less as contiguous.\n\n\nShow the code\ncolGraph(sfe, \"poly2nb\") &lt;-\n  findSpatialNeighbors(sfe,\n    type = \"cellSeg\",\n    method = \"poly2nb\", # wraps the spdep function with the same name\n    style = \"W\",\n    snap = 20 # all cells with less distance  apart are considered contiguous\n  )\n\n\n\n\nShow the code\np1 &lt;- plotColGraph(sfe,\n  colGraphName = \"poly2nb\",\n  colGeometryName = \"cellSeg\",\n  bbox =  c(xmin = 3500, xmax = 10000, ymin = 157200, ymax = 162200)\n) + theme_void()\n\n\nAlternatively, we can use a k-nearest neighbours approach. The the number \\(k\\) is somewhat arbitrary.\n\n\nShow the code\ncolGraph(sfe, \"knn5\") &lt;-\n  findSpatialNeighbors(sfe,\n    method = \"knearneigh\", # wraps the spdep function with the same name\n    k = 5,\n    zero.policy = TRUE\n  )\n\n\n\n\nShow the code\np2 &lt;- plotColGraph(sfe,\n  colGraphName = \"knn5\",\n  colGeometryName = \"cellSeg\",\n  bbox = c(xmin = 3500, xmax = 10000, ymin = 157200, ymax = 162200)\n) + theme_void()\n\n\nThe graphs below show noticeable differences. In the contiguous neighbour graph on the left (neighbours in direct contact), we can see the formation of distinct patches that are not connected to the rest of the tissue. In addition some cells don’t have any direct neighbours. In contrast, the k-nearest neighbours (kNN) graph on the right reveals that these patches tend to be connected to the rest of the structure.\n\n\nShow the code\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\nHere we set the arguments for the examples below.\n\n\nShow the code\nfeatures &lt;- c(\"KRT17\", \"TAGLN\")\ncolGraphName &lt;- \"knn5\"\ncolGeometryName &lt;- \"centroids\"\n\n\n\n\n\nGlobal methods give us an overview over the entire field-of-view and summarize the spatial autocorrelation metric to a single value. The metrics are a function of the weight matrix and the variables of interest. The variables of interest can be gene expression, intensity of a marker or the area of the cell. The global measures can be seen as a weighted average of the local metric, as explained below.\nIn general, a global spatial autocorrelation measure has the form of a double sum over all locations \\(i,j\\)\n\\[\\sum_i \\sum_j f(x_i,x_j) w_{ij}\\]\nwhere \\(f(x_i,x_j)\\) is the measure of association between features of interest and \\(w_{ij}\\) scales the relationship by a spatial weight as defined in the weight matrix \\(W\\). If \\(i\\) and \\(j\\) are not neighbours, i.e. we assume they do not have any spatial association, the corresponding element of the weights matrix is 0 (i.e., \\(w_{ij} = 0\\)). In the following we will see that the function \\(f\\) varies between the different spatial autocorrelation measures (Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023).\n\n\nThe global Moran’s I (Moran 1950) coefficient is a measure of spatial autocorrelation, defined as:\n\\[I = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(x_i - \\bar{x})(x_j - \\bar{x})}{\\sum_i (x_i - \\bar{x})^2}.\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\) and \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\). The expected value is close to \\(0\\) for large \\(n\\) (\\(\\mathbb{E}(I) = -1/(n-1)\\)), whereas a value higher than indicates spatial auto-correlation. Negative values indicate negative auto-correlation.\n\n\n\n\nShow the code\ncalculateMoransI(\n  sfe,\n  features = features,\n  colGraphName = colGraphName,\n  exprs_values = \"logcounts\"\n)\n\n\nDataFrame with 2 rows and 2 columns\n          moran         K\n      &lt;numeric&gt; &lt;numeric&gt;\nKRT17  0.725630   3.79983\nTAGLN  0.282208   7.98489\n\n\nWe can also use the moran.mc function to calculate the Moran’s I coefficient. This function uses a Monte Carlo simulation to calculate the p-value.\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     colGraphName = colGraphName,\n                     exprs_values = \"logcounts\",\n                     type = \"moran.mc\",\n                     nsim = 200)\n\nres &lt;- rowData(sfe)[features,]\nres\n\n\nDataFrame with 2 rows and 10 columns\n          means      vars       cv2    is_neg moran.mc_statistic_sample01\n      &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;logical&gt;                   &lt;numeric&gt;\nKRT17  1.378333  14.67222   7.72303     FALSE                    0.725630\nTAGLN  0.714079   3.76205   7.37788     FALSE                    0.282208\n      moran.mc_parameter_sample01 moran.mc_p.value_sample01\n                        &lt;numeric&gt;                 &lt;numeric&gt;\nKRT17                         201                0.00497512\nTAGLN                         201                0.00497512\n      moran.mc_alternative_sample01 moran.mc_method_sample01\n                        &lt;character&gt;              &lt;character&gt;\nKRT17                       greater   Monte-Carlo simulati..\nTAGLN                       greater   Monte-Carlo simulati..\n                        moran.mc_res_sample01\n                                       &lt;list&gt;\nKRT17 -0.00403813, 0.01123295, 0.00700654,...\nTAGLN -0.00331296,-0.00455799,-0.00374588,...\n\n\nShow the code\n#value of the metric\nres[,7]\n\n\n[1] 0.004975124 0.004975124\n\n\nShow the code\n#p-value\nres[,9]\n\n\n[1] \"Monte-Carlo simulation of Moran I\" \"Monte-Carlo simulation of Moran I\"\n\n\nWe can see both genes have a positive Moran’s I coefficient and a highly significant p-value. The expected value is \\(\\mathbb{E}(I) = -1/(n-1)\\) which is for large \\(N\\) close to 0. Positive and significant values indicate that areas with similar values are clustered. It is important to note that this could be both at the high or low end of the values of interest. Negative values indicate clustering of alternating values, i.e., gives a measure of spatial heterogeneity. Moreover, one should note that the result is dependent on the weight matrix. Different weight matrices will give different results. To compare Moran’s I coefficients between different values, we need to use the same weight matrix.\n\n\n\n\nGeary’s \\(C\\) (Geary 1954) is a different measure of global autocorrelation and is very closely related to Moran’s \\(I\\). However, it focuses on spatial dissimilarity. Geary’s \\(C\\) is defined by\n\\[C = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(x_i-x_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(x_i-\\bar{x})^2}\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\), \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\) and \\(n\\) the total numer of locations. The interpretation is opposite to Moran’s \\(I\\): a value smaller than \\(1\\) indicates positive auto-correlation whereas a value greater than \\(1\\) represents negative auto-correlation.\n\n\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     colGraphName = colGraphName,\n                     nsim = 200,\n                     type = \"geary.mc\")\n\nres &lt;- rowData(sfe)[features,]\nres\n\n\nDataFrame with 2 rows and 16 columns\n          means      vars       cv2    is_neg moran.mc_statistic_sample01\n      &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;logical&gt;                   &lt;numeric&gt;\nKRT17  1.378333  14.67222   7.72303     FALSE                    0.725630\nTAGLN  0.714079   3.76205   7.37788     FALSE                    0.282208\n      moran.mc_parameter_sample01 moran.mc_p.value_sample01\n                        &lt;numeric&gt;                 &lt;numeric&gt;\nKRT17                         201                0.00497512\nTAGLN                         201                0.00497512\n      moran.mc_alternative_sample01 moran.mc_method_sample01\n                        &lt;character&gt;              &lt;character&gt;\nKRT17                       greater   Monte-Carlo simulati..\nTAGLN                       greater   Monte-Carlo simulati..\n                        moran.mc_res_sample01 geary.mc_statistic_sample01\n                                       &lt;list&gt;                   &lt;numeric&gt;\nKRT17 -0.00403813, 0.01123295, 0.00700654,...                    0.270655\nTAGLN -0.00331296,-0.00455799,-0.00374588,...                    0.713507\n      geary.mc_parameter_sample01 geary.mc_p.value_sample01\n                        &lt;numeric&gt;                 &lt;numeric&gt;\nKRT17                           1                0.00497512\nTAGLN                           1                0.00497512\n      geary.mc_alternative_sample01 geary.mc_method_sample01\n                        &lt;character&gt;              &lt;character&gt;\nKRT17                       greater   Monte-Carlo simulati..\nTAGLN                       greater   Monte-Carlo simulati..\n               geary.mc_res_sample01\n                              &lt;list&gt;\nKRT17 1.008629,0.987882,0.992398,...\nTAGLN    1.00121,1.00322,0.99916,...\n\n\nShow the code\n#value of the metric\nres[,7]\n\n\n[1] 0.004975124 0.004975124\n\n\nShow the code\n#p-value\nres[,9]\n\n\n[1] \"Monte-Carlo simulation of Moran I\" \"Monte-Carlo simulation of Moran I\"\n\n\nAgain, the value of Geary’s \\(C\\) indicates that the genes are spatially auto-correlated.\n\n\n\n\nThe global \\(G\\) (Getis and Ord 1992) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in the dataset. Formally that is\n\\[G(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j} \\text{s.t } j \\neq i.\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather consider both.\nIt is recommended to use binary weights for this calculation. We will use the spdep package directly to calculate the global \\(G\\) statistic.\n\n\nShow the code\n# Get the weight matrix from sfe object\nweights_neighbourhoods_binary &lt;- colGraph(sfe, colGraphName)\n# Change it to binary weights\nweights_neighbourhoods_binary$style &lt;- \"B\" \n# Calculate the global G statistic\nspdep::globalG.test(x = counts(sfe)[features[1],], \n                    listw = weights_neighbourhoods_binary)\n\n\n\n    Getis-Ord global G statistic\n\ndata:  counts(sfe)[features[1], ] \nweights: weights_neighbourhoods_binary \n\nstandard deviate = 93.537, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      4.138026e-04       9.725734e-05       1.145260e-11 \n\n\n\n\n\n\nUnlike global measures that give an overview over the entire field of view, local measures report information about the statistic at each location (cell). There exist local analogs of Moran’s I and Geary’s C for which the global statistic can be represented as a weighted sum of the local statistics. As above, the local coefficients are based on both the spatial weights matrix and the values of the measurement of interest.\n\n\nThe local Moran’s I coefficient (Anselin 1995) is a measure of spatial autocorrelation on each location of interest. It is defined as:\n\\[I_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\\]\nwhere the index \\(i\\) refers to the location for which the measure is calculated. The interpretation is analogous to the global Moran’s I where a value of \\(I_i\\) higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation; smaller values indicate negative auto-correlation. It is important to note that, as for the global counterpart, the value of local Moran’s I could be a result from both the high or low end of the values. Since we measure and test a large number of locations simultaneously, we need to correct for multiple testing (e.g., using the Benjamini-Hochberg procedure).\n\n\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     colGraphName = colGraphName,\n                     type = \"localmoran\")\n\nplotLocalResult(sfe, \"localmoran\",\n                features = features, ncol = 2,\n                colGeometryName = colGeometryName)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimilar to local Moran’s I, there is a local Geary’s C (Anselin 1995) coefficient. It is defined as\n\\[C_i = \\sum_{j=1}^n w_{ij}(x_i-x_j)^2\\]\nThe interpretation is analogous to the global Geary’s C (value less than \\(1\\) indicates positive auto-correlation, a value greater than \\(1\\) highlights negative auto-correlation).\nIn this example, we will not plot the local Geary’s C coefficient for gene expression but for features that are associated with an individual cell, e.g., the number of counts or the number of genes expressed. For this, the colDataUnivariate function is used to calculate the local Geary’s C coefficient for such features.\n\n\n\n\nShow the code\nsfe &lt;- colDataUnivariate(sfe, \"localC_perm\",\n                         features = c(\"nCounts\", \"nGenes\"),\n                         colGraphName = colGraphName)\n\nplotLocalResult(\n  sfe,\n  \"localC_perm\",\n  features = c(\"nCounts\", \"nGenes\"),\n  ncol = 2,\n  colGeometryName = colGeometryName,\n  divergent = TRUE,\n  diverge_center = 0\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe local Getis-Ord \\(G_i\\) (J. K. Ord and Getis 1995; Getis and Ord 1992) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\), according to:\n\\[G_i(d) = \\frac{\\sum_{j \\neq i } w_{ij}(d)x_j}{\\sum_{j \\neq i} x_j}\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\), which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term.\n\n\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     #include_self = TRUE, # this would specify G_i^*(d),\n                     colGraphName = colGraphName,\n                     type = \"localG\")\n\nplotLocalResult(sfe, \"localG\",\n                features = features,\n                ncol = 2,\n                colGeometryName = colGeometryName)\n\n\n\n\n\n\n\n\n\nThe results above gives an estimate of the local Getis-Ord statistic for each cell, but no significance value. This can be done by using a permutation approach using the localG_perm argument.\nPositive values indicate clustering of high values, i.e., hot spots, and negative values indicate clustering of low values, i.e., cold spots. The method does not detect outlier values because, unlike in local Moran’s I, there is no cross-product between \\(i\\) and \\(j\\). But unlike local Moran’s I, we know the type of interaction (high-high or low-low) between \\(i\\) and \\(j\\).\n\n\n\n\n\nThe local spatial heteroscedasticity (LOSH) is a measure of spatial autocorrelation that is based on the variance of the local neighbourhood. Unlike the other measures, this method does not assume homoscedastic variance over the whole tissue region. LOSH is defined as:\n\\[H_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_i(d), j \\in N(i,d)\\) are the local residuals that are subtracted from the local mean. The power \\(a\\) modulates the interpretation of the residuals (\\(a=1\\): residuals are interpreted as absolute deviations from the local mean; \\(a=2\\): residuals are interpreted as deviations from the local variance).\nThe LOSH should be interpreted in combination with the local Getis-Ord \\(G_i^*\\) statistic. The \\(G_i^*\\) quantifies the local mean of the variable of interest, while \\(H_i\\) quantifies the local variance. This table provided by Ord and Getis (J. Keith Ord and Getis 2012) summarizes the interpretation of the combination of \\(G_i^*\\) and \\(H_i\\).\n\n\n\n\n\n\n\n\n\nhigh \\(H_i\\)\nlow \\(H_i\\)\n\n\n\n\nlarge \\(\\|G_i^*\\|\\)\nA hot spot with heterogeneous local conditions\nA hot spot with similar surrounding areas; the map would indicate whether the affected region is larger than the single “cell”\n\n\nsmall $ |G_i^*| $\nHeterogeneous local conditions but at a low average level (an unlikely event)\nHomogeneous local conditions and a low average level\n\n\n\n\n\n\n\nShow the code\n# run localG with permutation test\nsfe &lt;- runUnivariate(sfe,\n                     features = features[1],\n                     colGraphName = colGraphName,\n                     type = \"LOSH\")\n\n\nplotLocalResult(sfe, \"LOSH\",\n                features = features[1],\n                colGeometryName = colGeometryName)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe local methods presented above should always be interpreted with care, since we face the problem of multiple testing when calculating them for each cell. Moreover, the presented methods should mainly serve as exploratory measures to identify interesting regions in the data. Multiple processes can lead to the same pattern, thus from identifying the pattern we cannot infer the underlying process. Indication of clustering does not explain why this occurs. On the one hand, clustering can be the result of spatial interaction between the variables of interest. We have an accumulation of a gene of interest in one region of the tissue. On the other hand clustering can be the result spatial heterogeneity, when local similarity is created by structural heterogeneity in the tissue, e.g., that cells with uniform expression of a gene of interest are grouped together which then creates the apparent clustering of the gene expression measurement.\n©2024 The pasta authors. Content is published under Creative Commons CC-BY-4.0 License for the text and GPL-3 License for any code.",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "02-imaging-univar-latSOD.html#dependencies",
    "href": "02-imaging-univar-latSOD.html#dependencies",
    "title": "Irregular Lattices",
    "section": "",
    "text": "Show the code\nsource(\"utils.R\")\ntheme_set(theme_minimal())\n\n\nUntil now, we have considered the cells to be represented in a point pattern. However, as cells have a shape and area, this might be an oversimplification in some cases. Alternatively, we can rely on the segmentation of individual cells that are available for various datasets. The outline of each cell is represented by a polygon and the collection of all cells can be seen as an irregular lattice. Unlike a regular lattice (e.g., spot-based spatial transcriptomics data), the sample areas in an irregular lattice can have different sizes and are not necessarily regularly distributed over the sample space.\nFor this representation of the cells we will rely on the SpatialFeatureExperiment package. For preprocessing of the dataset we refer the reader to the vignette of the voyager package (Moses et al. 2023). The voyager package also provides wrapper functions around the package spdep (Pebesma and Bivand 2023) that work directly on the SpatialFeatureExperiment object.\n\n\nShow the code\n#taken from https://pachterlab.github.io/voyager/articles/vig4_cosmx.html\n(sfe &lt;- HeNSCLCData())\n\n\nclass: SpatialFeatureExperiment \ndim: 980 100290 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100290): 1_1 1_2 ... 30_4759 30_4760\ncolData names(17): Area AspectRatio ... nCounts nGenes\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n\nShow the code\n# Empty cells\ncolData(sfe)$is_empty &lt;- colData(sfe)$nCounts &lt; 1\n# Select, sum negative control probes\n(neg_inds &lt;- str_detect(rownames(sfe), \"^NegPrb\")) %&gt;% sum\n\n\n[1] 20\n\n\nShow the code\ncolData(sfe)$prop_neg &lt;- colSums(counts(sfe)[neg_inds,])/colData(sfe)$nCounts\n# Remove low quality cells\nsfe &lt;- sfe[,!sfe$is_empty & sfe$prop_neg &lt; 0.1]\n# Re-calculate stats\nrowData(sfe)$is_neg &lt;- neg_inds\n# log Counts\nsfe &lt;- logNormCounts(sfe)\n\n\nFor some examples we will show a subset of the tissue.\n\n\nShow the code\nbbox_use &lt;- st_as_sfc(st_bbox(c(xmin = 3500, xmax = 14000, ymin = 157200, ymax = 162200)))\n\n\n\n\nShow the code\nsfe &lt;- sfe[,st_intersects(colGeometries(sfe)$centroids, bbox_use, sparse = FALSE)]\n\n\n\nIn this vignette, we will show the metrics related to two marker genes: KRT17 (basal cells) and TAGLN (smooth muscle cells).\n\n\nShow the code\nplotSpatialFeature(sfe, c(\"KRT17\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()\n\n\n\n\n\n\n\n\n\nShow the code\nplotSpatialFeature(sfe, c(\"TAGLN\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "02-imaging-univar-latSOD.html#spatial-weight-matrix",
    "href": "02-imaging-univar-latSOD.html#spatial-weight-matrix",
    "title": "Irregular Lattices",
    "section": "",
    "text": "One of the challenges when working with (irregular) lattice data is the construction of a neighbourhood graph (Pebesma and Bivand 2023). The main question is, what to consider as neighbours, as this will affect downstream analyses. Various methods exist to create neighbours, such as contiguitiy based neighbours (neighbours in direct contact), graph-based neighbours (e.g., \\(k\\)-nearest neighbours), distance based neighbours or higher order neighbours (Getis 2009; Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023). The documentation of the package spdep gives an overview of the different methods.\nSegmentation of individual cells is challenging (Wang 2019) and construction of contiguity-based neighbours based on individual cell segmentation assumes very accurate segmentation results. Furthermore it would neglect the influence of more distant, not directly adjacent neighbours, which based on the feature of interest might not be the correct assumption.\nIn an irregular lattice, the task of finding a spatial weight matrix is more complex, as different options exist. One option is to base the neighbourhood graph on neighbours that are in direct contact with each other (contiguous), as implemented in the poly2nb method. As cell segmentation is notoriously imperfect, we add a snap value, which means that we consider all cells with distance 20 or less as contiguous.\n\n\nShow the code\ncolGraph(sfe, \"poly2nb\") &lt;-\n  findSpatialNeighbors(sfe,\n    type = \"cellSeg\",\n    method = \"poly2nb\", # wraps the spdep function with the same name\n    style = \"W\",\n    snap = 20 # all cells with less distance  apart are considered contiguous\n  )\n\n\n\n\nShow the code\np1 &lt;- plotColGraph(sfe,\n  colGraphName = \"poly2nb\",\n  colGeometryName = \"cellSeg\",\n  bbox =  c(xmin = 3500, xmax = 10000, ymin = 157200, ymax = 162200)\n) + theme_void()\n\n\nAlternatively, we can use a k-nearest neighbours approach. The the number \\(k\\) is somewhat arbitrary.\n\n\nShow the code\ncolGraph(sfe, \"knn5\") &lt;-\n  findSpatialNeighbors(sfe,\n    method = \"knearneigh\", # wraps the spdep function with the same name\n    k = 5,\n    zero.policy = TRUE\n  )\n\n\n\n\nShow the code\np2 &lt;- plotColGraph(sfe,\n  colGraphName = \"knn5\",\n  colGeometryName = \"cellSeg\",\n  bbox = c(xmin = 3500, xmax = 10000, ymin = 157200, ymax = 162200)\n) + theme_void()\n\n\nThe graphs below show noticeable differences. In the contiguous neighbour graph on the left (neighbours in direct contact), we can see the formation of distinct patches that are not connected to the rest of the tissue. In addition some cells don’t have any direct neighbours. In contrast, the k-nearest neighbours (kNN) graph on the right reveals that these patches tend to be connected to the rest of the structure.\n\n\nShow the code\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\nHere we set the arguments for the examples below.\n\n\nShow the code\nfeatures &lt;- c(\"KRT17\", \"TAGLN\")\ncolGraphName &lt;- \"knn5\"\ncolGeometryName &lt;- \"centroids\"",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "02-imaging-univar-latSOD.html#global-measures",
    "href": "02-imaging-univar-latSOD.html#global-measures",
    "title": "Irregular Lattices",
    "section": "",
    "text": "Global methods give us an overview over the entire field-of-view and summarize the spatial autocorrelation metric to a single value. The metrics are a function of the weight matrix and the variables of interest. The variables of interest can be gene expression, intensity of a marker or the area of the cell. The global measures can be seen as a weighted average of the local metric, as explained below.\nIn general, a global spatial autocorrelation measure has the form of a double sum over all locations \\(i,j\\)\n\\[\\sum_i \\sum_j f(x_i,x_j) w_{ij}\\]\nwhere \\(f(x_i,x_j)\\) is the measure of association between features of interest and \\(w_{ij}\\) scales the relationship by a spatial weight as defined in the weight matrix \\(W\\). If \\(i\\) and \\(j\\) are not neighbours, i.e. we assume they do not have any spatial association, the corresponding element of the weights matrix is 0 (i.e., \\(w_{ij} = 0\\)). In the following we will see that the function \\(f\\) varies between the different spatial autocorrelation measures (Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023).\n\n\nThe global Moran’s I (Moran 1950) coefficient is a measure of spatial autocorrelation, defined as:\n\\[I = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(x_i - \\bar{x})(x_j - \\bar{x})}{\\sum_i (x_i - \\bar{x})^2}.\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\) and \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\). The expected value is close to \\(0\\) for large \\(n\\) (\\(\\mathbb{E}(I) = -1/(n-1)\\)), whereas a value higher than indicates spatial auto-correlation. Negative values indicate negative auto-correlation.\n\n\n\n\nShow the code\ncalculateMoransI(\n  sfe,\n  features = features,\n  colGraphName = colGraphName,\n  exprs_values = \"logcounts\"\n)\n\n\nDataFrame with 2 rows and 2 columns\n          moran         K\n      &lt;numeric&gt; &lt;numeric&gt;\nKRT17  0.725630   3.79983\nTAGLN  0.282208   7.98489\n\n\nWe can also use the moran.mc function to calculate the Moran’s I coefficient. This function uses a Monte Carlo simulation to calculate the p-value.\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     colGraphName = colGraphName,\n                     exprs_values = \"logcounts\",\n                     type = \"moran.mc\",\n                     nsim = 200)\n\nres &lt;- rowData(sfe)[features,]\nres\n\n\nDataFrame with 2 rows and 10 columns\n          means      vars       cv2    is_neg moran.mc_statistic_sample01\n      &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;logical&gt;                   &lt;numeric&gt;\nKRT17  1.378333  14.67222   7.72303     FALSE                    0.725630\nTAGLN  0.714079   3.76205   7.37788     FALSE                    0.282208\n      moran.mc_parameter_sample01 moran.mc_p.value_sample01\n                        &lt;numeric&gt;                 &lt;numeric&gt;\nKRT17                         201                0.00497512\nTAGLN                         201                0.00497512\n      moran.mc_alternative_sample01 moran.mc_method_sample01\n                        &lt;character&gt;              &lt;character&gt;\nKRT17                       greater   Monte-Carlo simulati..\nTAGLN                       greater   Monte-Carlo simulati..\n                        moran.mc_res_sample01\n                                       &lt;list&gt;\nKRT17 -0.00403813, 0.01123295, 0.00700654,...\nTAGLN -0.00331296,-0.00455799,-0.00374588,...\n\n\nShow the code\n#value of the metric\nres[,7]\n\n\n[1] 0.004975124 0.004975124\n\n\nShow the code\n#p-value\nres[,9]\n\n\n[1] \"Monte-Carlo simulation of Moran I\" \"Monte-Carlo simulation of Moran I\"\n\n\nWe can see both genes have a positive Moran’s I coefficient and a highly significant p-value. The expected value is \\(\\mathbb{E}(I) = -1/(n-1)\\) which is for large \\(N\\) close to 0. Positive and significant values indicate that areas with similar values are clustered. It is important to note that this could be both at the high or low end of the values of interest. Negative values indicate clustering of alternating values, i.e., gives a measure of spatial heterogeneity. Moreover, one should note that the result is dependent on the weight matrix. Different weight matrices will give different results. To compare Moran’s I coefficients between different values, we need to use the same weight matrix.\n\n\n\n\nGeary’s \\(C\\) (Geary 1954) is a different measure of global autocorrelation and is very closely related to Moran’s \\(I\\). However, it focuses on spatial dissimilarity. Geary’s \\(C\\) is defined by\n\\[C = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(x_i-x_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(x_i-\\bar{x})^2}\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\), \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\) and \\(n\\) the total numer of locations. The interpretation is opposite to Moran’s \\(I\\): a value smaller than \\(1\\) indicates positive auto-correlation whereas a value greater than \\(1\\) represents negative auto-correlation.\n\n\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     colGraphName = colGraphName,\n                     nsim = 200,\n                     type = \"geary.mc\")\n\nres &lt;- rowData(sfe)[features,]\nres\n\n\nDataFrame with 2 rows and 16 columns\n          means      vars       cv2    is_neg moran.mc_statistic_sample01\n      &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;logical&gt;                   &lt;numeric&gt;\nKRT17  1.378333  14.67222   7.72303     FALSE                    0.725630\nTAGLN  0.714079   3.76205   7.37788     FALSE                    0.282208\n      moran.mc_parameter_sample01 moran.mc_p.value_sample01\n                        &lt;numeric&gt;                 &lt;numeric&gt;\nKRT17                         201                0.00497512\nTAGLN                         201                0.00497512\n      moran.mc_alternative_sample01 moran.mc_method_sample01\n                        &lt;character&gt;              &lt;character&gt;\nKRT17                       greater   Monte-Carlo simulati..\nTAGLN                       greater   Monte-Carlo simulati..\n                        moran.mc_res_sample01 geary.mc_statistic_sample01\n                                       &lt;list&gt;                   &lt;numeric&gt;\nKRT17 -0.00403813, 0.01123295, 0.00700654,...                    0.270655\nTAGLN -0.00331296,-0.00455799,-0.00374588,...                    0.713507\n      geary.mc_parameter_sample01 geary.mc_p.value_sample01\n                        &lt;numeric&gt;                 &lt;numeric&gt;\nKRT17                           1                0.00497512\nTAGLN                           1                0.00497512\n      geary.mc_alternative_sample01 geary.mc_method_sample01\n                        &lt;character&gt;              &lt;character&gt;\nKRT17                       greater   Monte-Carlo simulati..\nTAGLN                       greater   Monte-Carlo simulati..\n               geary.mc_res_sample01\n                              &lt;list&gt;\nKRT17 1.008629,0.987882,0.992398,...\nTAGLN    1.00121,1.00322,0.99916,...\n\n\nShow the code\n#value of the metric\nres[,7]\n\n\n[1] 0.004975124 0.004975124\n\n\nShow the code\n#p-value\nres[,9]\n\n\n[1] \"Monte-Carlo simulation of Moran I\" \"Monte-Carlo simulation of Moran I\"\n\n\nAgain, the value of Geary’s \\(C\\) indicates that the genes are spatially auto-correlated.\n\n\n\n\nThe global \\(G\\) (Getis and Ord 1992) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in the dataset. Formally that is\n\\[G(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j} \\text{s.t } j \\neq i.\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather consider both.\nIt is recommended to use binary weights for this calculation. We will use the spdep package directly to calculate the global \\(G\\) statistic.\n\n\nShow the code\n# Get the weight matrix from sfe object\nweights_neighbourhoods_binary &lt;- colGraph(sfe, colGraphName)\n# Change it to binary weights\nweights_neighbourhoods_binary$style &lt;- \"B\" \n# Calculate the global G statistic\nspdep::globalG.test(x = counts(sfe)[features[1],], \n                    listw = weights_neighbourhoods_binary)\n\n\n\n    Getis-Ord global G statistic\n\ndata:  counts(sfe)[features[1], ] \nweights: weights_neighbourhoods_binary \n\nstandard deviate = 93.537, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      4.138026e-04       9.725734e-05       1.145260e-11",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "02-imaging-univar-latSOD.html#local-measures",
    "href": "02-imaging-univar-latSOD.html#local-measures",
    "title": "Irregular Lattices",
    "section": "",
    "text": "Unlike global measures that give an overview over the entire field of view, local measures report information about the statistic at each location (cell). There exist local analogs of Moran’s I and Geary’s C for which the global statistic can be represented as a weighted sum of the local statistics. As above, the local coefficients are based on both the spatial weights matrix and the values of the measurement of interest.\n\n\nThe local Moran’s I coefficient (Anselin 1995) is a measure of spatial autocorrelation on each location of interest. It is defined as:\n\\[I_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\\]\nwhere the index \\(i\\) refers to the location for which the measure is calculated. The interpretation is analogous to the global Moran’s I where a value of \\(I_i\\) higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation; smaller values indicate negative auto-correlation. It is important to note that, as for the global counterpart, the value of local Moran’s I could be a result from both the high or low end of the values. Since we measure and test a large number of locations simultaneously, we need to correct for multiple testing (e.g., using the Benjamini-Hochberg procedure).\n\n\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     colGraphName = colGraphName,\n                     type = \"localmoran\")\n\nplotLocalResult(sfe, \"localmoran\",\n                features = features, ncol = 2,\n                colGeometryName = colGeometryName)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimilar to local Moran’s I, there is a local Geary’s C (Anselin 1995) coefficient. It is defined as\n\\[C_i = \\sum_{j=1}^n w_{ij}(x_i-x_j)^2\\]\nThe interpretation is analogous to the global Geary’s C (value less than \\(1\\) indicates positive auto-correlation, a value greater than \\(1\\) highlights negative auto-correlation).\nIn this example, we will not plot the local Geary’s C coefficient for gene expression but for features that are associated with an individual cell, e.g., the number of counts or the number of genes expressed. For this, the colDataUnivariate function is used to calculate the local Geary’s C coefficient for such features.\n\n\n\n\nShow the code\nsfe &lt;- colDataUnivariate(sfe, \"localC_perm\",\n                         features = c(\"nCounts\", \"nGenes\"),\n                         colGraphName = colGraphName)\n\nplotLocalResult(\n  sfe,\n  \"localC_perm\",\n  features = c(\"nCounts\", \"nGenes\"),\n  ncol = 2,\n  colGeometryName = colGeometryName,\n  divergent = TRUE,\n  diverge_center = 0\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe local Getis-Ord \\(G_i\\) (J. K. Ord and Getis 1995; Getis and Ord 1992) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\), according to:\n\\[G_i(d) = \\frac{\\sum_{j \\neq i } w_{ij}(d)x_j}{\\sum_{j \\neq i} x_j}\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\), which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term.\n\n\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     #include_self = TRUE, # this would specify G_i^*(d),\n                     colGraphName = colGraphName,\n                     type = \"localG\")\n\nplotLocalResult(sfe, \"localG\",\n                features = features,\n                ncol = 2,\n                colGeometryName = colGeometryName)\n\n\n\n\n\n\n\n\n\nThe results above gives an estimate of the local Getis-Ord statistic for each cell, but no significance value. This can be done by using a permutation approach using the localG_perm argument.\nPositive values indicate clustering of high values, i.e., hot spots, and negative values indicate clustering of low values, i.e., cold spots. The method does not detect outlier values because, unlike in local Moran’s I, there is no cross-product between \\(i\\) and \\(j\\). But unlike local Moran’s I, we know the type of interaction (high-high or low-low) between \\(i\\) and \\(j\\).\n\n\n\n\n\nThe local spatial heteroscedasticity (LOSH) is a measure of spatial autocorrelation that is based on the variance of the local neighbourhood. Unlike the other measures, this method does not assume homoscedastic variance over the whole tissue region. LOSH is defined as:\n\\[H_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_i(d), j \\in N(i,d)\\) are the local residuals that are subtracted from the local mean. The power \\(a\\) modulates the interpretation of the residuals (\\(a=1\\): residuals are interpreted as absolute deviations from the local mean; \\(a=2\\): residuals are interpreted as deviations from the local variance).\nThe LOSH should be interpreted in combination with the local Getis-Ord \\(G_i^*\\) statistic. The \\(G_i^*\\) quantifies the local mean of the variable of interest, while \\(H_i\\) quantifies the local variance. This table provided by Ord and Getis (J. Keith Ord and Getis 2012) summarizes the interpretation of the combination of \\(G_i^*\\) and \\(H_i\\).\n\n\n\n\n\n\n\n\n\nhigh \\(H_i\\)\nlow \\(H_i\\)\n\n\n\n\nlarge \\(\\|G_i^*\\|\\)\nA hot spot with heterogeneous local conditions\nA hot spot with similar surrounding areas; the map would indicate whether the affected region is larger than the single “cell”\n\n\nsmall $ |G_i^*| $\nHeterogeneous local conditions but at a low average level (an unlikely event)\nHomogeneous local conditions and a low average level\n\n\n\n\n\n\n\nShow the code\n# run localG with permutation test\nsfe &lt;- runUnivariate(sfe,\n                     features = features[1],\n                     colGraphName = colGraphName,\n                     type = \"LOSH\")\n\n\nplotLocalResult(sfe, \"LOSH\",\n                features = features[1],\n                colGeometryName = colGeometryName)",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "02-imaging-univar-latSOD.html#a-note-of-caution",
    "href": "02-imaging-univar-latSOD.html#a-note-of-caution",
    "title": "Irregular Lattices",
    "section": "",
    "text": "The local methods presented above should always be interpreted with care, since we face the problem of multiple testing when calculating them for each cell. Moreover, the presented methods should mainly serve as exploratory measures to identify interesting regions in the data. Multiple processes can lead to the same pattern, thus from identifying the pattern we cannot infer the underlying process. Indication of clustering does not explain why this occurs. On the one hand, clustering can be the result of spatial interaction between the variables of interest. We have an accumulation of a gene of interest in one region of the tissue. On the other hand clustering can be the result spatial heterogeneity, when local similarity is created by structural heterogeneity in the tissue, e.g., that cells with uniform expression of a gene of interest are grouped together which then creates the apparent clustering of the gene expression measurement.",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "02-imaging-univar-latSOD.html#session-info",
    "href": "02-imaging-univar-latSOD.html#session-info",
    "title": "Irregular Lattices",
    "section": "Session info",
    "text": "Session info\n\n\nShow the code\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-16                      reshape2_1.4.4                \n[19] patchwork_1.2.0                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.5.1                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.9-1                    rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.3.0                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] spatstat.utils_3.0-5          rmarkdown_2.25               \n [87] XVector_0.40.0                htmltools_0.5.6.1            \n [89] pkgconfig_2.0.3               base64enc_0.1-3              \n [91] sparseMatrixStats_1.12.2      fastmap_1.1.1                \n [93] htmlwidgets_1.6.2             shiny_1.7.5.1                \n [95] DelayedMatrixStats_1.22.6     farver_2.1.1                 \n [97] jsonlite_1.8.7                BiocParallel_1.34.2          \n [99] R.oo_1.25.0                   BiocSingular_1.16.0          \n[101] RCurl_1.98-1.12               GenomeInfoDbData_1.2.10      \n[103] s2_1.1.4                      Rhdf5lib_1.22.1              \n[105] munsell_0.5.0                 Rcpp_1.0.11                  \n[107] ggnewscale_0.4.9              viridis_0.6.4                \n[109] stringi_1.7.12                leafsync_0.1.0               \n[111] zlibbioc_1.46.0               plyr_1.8.9                   \n[113] parallel_4.3.1                ggrepel_0.9.4                \n[115] deldir_1.0-9                  Biostrings_2.68.1            \n[117] stars_0.6-4                   splines_4.3.1                \n[119] tensor_1.5                    locfit_1.5-9.8               \n[121] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[123] BiocVersion_3.17.1            XML_3.99-0.14                \n[125] evaluate_0.22                 BiocManager_1.30.22          \n[127] httpuv_1.6.11                 purrr_1.0.2                  \n[129] polyclip_1.10-6               scattermore_1.2              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "00-overview-latSOD.html#dependencies",
    "href": "00-overview-latSOD.html#dependencies",
    "title": "Lattice data analysis – Summary",
    "section": "Dependencies",
    "text": "Dependencies\n\n\nShow the code\nsuppressPackageStartupMessages({\n  library(dplyr)\n  library(ggplot2)\n  library(patchwork)\n  library(Voyager)\n  library(SpatialFeatureExperiment)\n  library(SFEData)\n  library(spdep)\n  library(sf)\n  library(stringr)\n  library(tidyr)\n  library(magrittr)\n  library(scater)\n})\n\ntheme_set(theme_light())",
    "crumbs": [
      "Overview Lattice-based Methods"
    ]
  },
  {
    "objectID": "00-overview-latSOD.html#setup-and-preprocessing",
    "href": "00-overview-latSOD.html#setup-and-preprocessing",
    "title": "Lattice data analysis – Summary",
    "section": "Setup and Preprocessing",
    "text": "Setup and Preprocessing\nWe will load a dataset generated by (McKellar et al. 2021) using the Visium technology (Ståhl et al. 2016). The data shows a sample taken from the tibialis anterior muscle of a mouse.\n\n\nShow the code\n# Load the dataset\nsfe &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n# Take spots that are covered with tissue\nsfe_tissue &lt;- sfe[, colData(sfe)$in_tissue]\n# Filter out genes with no counts\nsfe_tissue &lt;- sfe_tissue[rowSums(counts(sfe_tissue)) &gt; 0, ]\n# Convert counts log-transformed normalized expression values\nsfe_tissue &lt;- scater::logNormCounts(sfe_tissue)\n\n\nSpatialFeatureExperiment (Moses et al. 2023) objects are an extension of the SpatialExperiment object (Righelli et al. 2022). It additionally contains geometric annotations that are encoded as simple features of the sf library (Pebesma and Bivand 2023).\n\n\nShow the code\nsfe_tissue\n\n\nclass: SpatialFeatureExperiment \ndim: 15043 932 \nmetadata(0):\nassays(2): counts logcounts\nrownames(15043): ENSMUSG00000025902 ENSMUSG00000096126 ...\n  ENSMUSG00000064368 ENSMUSG00000064370\nrowData names(6): Ensembl symbol ... vars cv2\ncolnames(932): AAACATTTCCCGGATT AAACCTAAGCAGCCGG ... TTGTGTTTCCCGAAAG\n  TTGTTGTGTGTCAAGA\ncolData names(13): barcode col ... in_tissue sizeFactor\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : imageX imageY\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: spotPoly (POLYGON) \nannotGeometries: tissueBoundary (POLYGON), myofiber_full (POLYGON), myofiber_simplified (POLYGON), nuclei (POLYGON), nuclei_centroid (POINT) \n\nGraphs:\nVis5A: \n\n\nFor example, the spots of the Visium dataset are stored as a simple feature collection.\n\n\nShow the code\ncolGeometry(sfe_tissue, \"spotPoly\") |&gt; head()\n\n\nSimple feature collection with 6 features and 0 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 5857.695 ymin: 4126.151 xmax: 10206.53 ymax: 11789.24\nCRS:           NA\n                        geometry\n1 POLYGON ((6037.973 5430.826...\n2 POLYGON ((7977.344 4461.467...\n3 POLYGON ((8547.633 11699.1,...\n4 POLYGON ((6867.944 4463.856...\n5 POLYGON ((9779.598 4216.29,...\n6 POLYGON ((10206.53 9282.577...",
    "crumbs": [
      "Overview Lattice-based Methods"
    ]
  },
  {
    "objectID": "00-overview-latSOD.html#definition",
    "href": "00-overview-latSOD.html#definition",
    "title": "Lattice data analysis – Summary",
    "section": "Definition",
    "text": "Definition\nLattice data refers to spatial data collected at locations arranged in a regular or irregular grid (lattice). Each location has a defined spatial unit, and the sampling locations are fixed rather than random. This approach contrasts with point pattern analysis, where we assume that the locations were generated by a stochastic process (Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023).\nAs can be seen below, the Visium dataset is a regular lattice. The color shows the number of counts detected in each Visium spot. In contrast, the outlines of individual cells after segmentation (e.g., from a higher resolution spatial omics assay) could be seen as an irregular lattice. As this dataset also contains (manual) segmentations of myofibers (muscle cells stored as myofiber_simplified) we will illustrate calculations based on irregular lattice on the myofiber segmentations.\n\n\nShow the code\n# A plot using the plotSpatialFeature from Voyager\np &lt;- plotSpatialFeature(sfe_tissue,\n  \"nCounts\",\n  annotGeometryName = \"myofiber_simplified\"\n)\n\n# This extracts the segmented cells\ncells &lt;- annotGeometry(sfe_tissue, \"myofiber_simplified\") |&gt;\n  st_geometry()\n\n# We can also use ggplot and geom_sf to plot sf objects\nq &lt;- ggplot() +\n  geom_sf(data = cells, fill = NA) +\n  theme_void()\n\n# Using `patchwork` to combine the plots\np | q",
    "crumbs": [
      "Overview Lattice-based Methods"
    ]
  },
  {
    "objectID": "00-overview-latSOD.html#spatial-weight-matrix",
    "href": "00-overview-latSOD.html#spatial-weight-matrix",
    "title": "Lattice data analysis – Summary",
    "section": "Spatial weight matrix",
    "text": "Spatial weight matrix\nIn lattice data analysis, a key concept is the spatial weight matrix, which models the spatial relationships between units in the lattice (i.e., spots or cells). Various methods exist for constructing this matrix, such as contiguity-based (direct neighbors), graph-based, or distance-based methods. (Getis 2009; Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023). The documentation of the package spdep gives an overview of the different methods.\nFor Visium, the most straightforward way is to take the direct neighbours of each spot. This is done using the function findVisiumGraph.\n\n\nShow the code\ncolGraph(sfe_tissue, \"visium\") &lt;- findVisiumGraph(sfe_tissue)\n\n\n\n\nShow the code\nplotColGraph(sfe_tissue,\n  colGraphName = \"visium\",\n  colGeometryName = \"spotPoly\"\n) + theme_void()\n\n\n\n\n\n\n\n\n\nIn an irregular lattice, the task of finding a spatial weight matrix is more complex, as different options exist. One option is to base the neighbourhood graph on neighbours that are in direct contact with each other (contiguous), as implemented in the poly2nb method.\n\n\nShow the code\nannotGraph(sfe_tissue, \"myofiber_poly2nb\") &lt;-\n  findSpatialNeighbors(sfe_tissue,\n    type = \"myofiber_simplified\",\n    MARGIN = 3,\n    method = \"poly2nb\", # wraps spdep function with same name\n    zero.policy = TRUE\n  )\n\n\n\n\nShow the code\np1 &lt;- plotAnnotGraph(sfe_tissue,\n  annotGraphName = \"myofiber_poly2nb\",\n  annotGeometryName = \"myofiber_simplified\"\n) + theme_void()\n\n\nAlternatively, we could take the five nearest neighbours of each cell.\n\n\nShow the code\nannotGraph(sfe_tissue, \"knn5\") &lt;-\n  findSpatialNeighbors(sfe_tissue,\n    type = \"myofiber_simplified\",\n    MARGIN = 3, # to use the annotation geometry\n    method = \"knearneigh\", # wraps the spdep function with the same name\n    k = 5,\n    zero.policy = TRUE\n  )\n\n\n\n\nShow the code\np2 &lt;- plotAnnotGraph(sfe_tissue,\n  annotGraphName = \"knn5\",\n  annotGeometryName = \"myofiber_simplified\"\n) + theme_void()\n\n\nAs we can see below, the graphs look quite distinct. On the left side, in the contiguous neigbhbour graph (neighbours in direct contact) we can notice the formation of patches, while in the knn graph isolated patches are interconnected.\n\n\nShow the code\np1 + p2",
    "crumbs": [
      "Overview Lattice-based Methods"
    ]
  },
  {
    "objectID": "00-overview-latSOD.html#global-measures",
    "href": "00-overview-latSOD.html#global-measures",
    "title": "Lattice data analysis – Summary",
    "section": "Global Measures",
    "text": "Global Measures\nGlobal methods give us an overview over the entire field-of-view and summarize the spatial autocorrelation metric to a single value. The metrics are a function of the weight matrix and the variables of interest. The variables of interest can be gene expression, intensity of a marker or the area of a cell. The global measures can be seen as a weighted average of the local metric, as explained below.\nIn general, a global spatial autocorrelation measure has the form of a double sum over all locations \\(i,j\\)\n\\[\\sum_i \\sum_j f(x_i,x_j) w_{ij}\\]\nwhere \\(f(x_i,x_j)\\) is the measure of association between features of interest and \\(w_{ij}\\) scales the relationship by a spatial weight as defined in the weight matrix \\(W\\) (Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023).\n\nMoran’s I\nMoran’s I is the most prominent measure of spatial autocorrelation. The values are bounded by \\(-1\\) and \\(1\\). The expected value is close to \\(0\\) for large \\(n\\), the exact value is given by \\(\\mathbb{E}(I) = -1/(n-1)\\). A value higher than the expected value indicates spatial auto-correlation. Negative values indicate negative auto-correlation. Spatial auto-correlation means that similar values tend to be found together in the tissue. In fact, Moran’s I can be interpreted as the Pearson correlation between the value at location \\(i\\) and the averages value of the neigbours of \\(i\\), (neighbours as defined in the weight matrix \\(W\\)) (Moran 1950).\nIn the first example we will calculate Moran’s I for the number of counts and genes measured in the Visium dataset. First, we have a look at the distribution by eye.\n\n\nShow the code\nplotSpatialFeature(sfe_tissue,\n  features = c(\"nCounts\", \"nGenes\"),\n  colGeometryName = \"spotPoly\",\n  swap_rownames = \"symbol\"\n)\n\n\n\n\n\n\n\n\n\nBased on these values we can calculate Moran’s I\n\n\nShow the code\ncalculateUnivariate(t(colData(sfe_tissue)[, c(\"nCounts\", \"nGenes\")]),\n  type = \"moran\",\n  listw = colGraph(sfe_tissue, \"visium\")\n)\n\n\nDataFrame with 2 rows and 2 columns\n            moran         K\n        &lt;numeric&gt; &lt;numeric&gt;\nnCounts  0.528705   3.00082\nnGenes   0.384028   3.88036\n\n\nWe can further use permutation testing to get a significance of our estimates.\n\n\nShow the code\nsfe_tissue &lt;- colDataUnivariate(sfe_tissue,\n  features = c(\"nCounts\", \"nGenes\"),\n  colGraphName = \"visium\", nsim = 1000,\n  type = \"moran.mc\"\n)\nplotMoranMC(sfe_tissue, c(\"nCounts\", \"nGenes\"),\n  linewidth = 2\n)\n\n\n\n\n\n\n\n\n\nHere we can see the Moran’s I values for the number of counts and genes that were identified in the Visium dataset and a permutation-based null distribution. As we can see, the Moran’s I values both indicate positive spatial autocorrelation and are highly significant. This means that regions with similar count and number of measured gene values tend to cluster together. This is an interesting finding and was observed in other spatial transcriptomic datasets, see (Bhuva et al. 2024).",
    "crumbs": [
      "Overview Lattice-based Methods"
    ]
  },
  {
    "objectID": "00-overview-latSOD.html#local-measures-for-univariate-data",
    "href": "00-overview-latSOD.html#local-measures-for-univariate-data",
    "title": "Lattice data analysis – Summary",
    "section": "Local Measures for Univariate Data",
    "text": "Local Measures for Univariate Data\nOften a global measure is not enough. One number determining e.g. the spatial autocorrelation over an entire tissue slice might not be reflective of tissue heterogeneity. Therefore, local indicators of spatial associations have been developed (Pebesma and Bivand 2023).\n\nLocal Moran’s I\nLocal Moran’s I provides a measure of spatial autocorrelation at each location, highlighting local clusters of similarity or dissimilarity (Anselin 1995). It is defined as:\n\\[I_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\\]\nwhere the index \\(i\\) refers to the location for which the measure is calculated. The interpretation is analogous to the global Moran’s I where a value of \\(I_i\\) higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation; smaller values indicate negative auto-correlation. It is important to note that, as for the global counterpart, the value of local Moran’s I could be a result from both the high or low end of the values. Here we will calculate the local Moran’s I value for the measurement of muscle fiber marker gene Myh2:\n\n\nShow the code\nsfe_tissue &lt;- runUnivariate(sfe_tissue,\n  type = \"localmoran\",\n  features = \"Myh2\",\n  colGraphName = \"visium\",\n  swap_rownames = \"symbol\"\n)\n\n# plot the expression values\npExp &lt;- plotSpatialFeature(sfe_tissue,\n  features = c(\"Myh2\"), colGeometryName = \"spotPoly\",\n  swap_rownames = \"symbol\"\n)\n\n# plot the local Moran's I values\npLi &lt;- plotLocalResult(sfe_tissue, \"localmoran\",\n  features = c(\"Myh2\"),\n  colGeometryName = \"spotPoly\", swap_rownames = \"symbol\",\n  divergent = TRUE, diverge_center = 0\n) + labs(fill = \"li(Myh2)\") # specify legend\n\n\n# plot the local Moran's I p-values\npPval &lt;- plotLocalResult(sfe_tissue, \"localmoran\",\n  features = c(\"Myh2\"), \"-log10p_adj\",\n  colGeometryName = \"spotPoly\", swap_rownames = \"symbol\",\n  divergent = TRUE, diverge_center = -log10(0.05)\n) + labs(fill = \"-log10(p.adj)\") # specify legend\n\n# please note that the\npExp + pLi + pPval\n\n\n\n\n\n\n\n\n\nIn the local version of Moran’s I, the interpretation is the same as the global version. When interpreting local autocorrelation measures, it is important to consider both the effect size estimates and the significance level. Since the significance level is calculated for each spot separately, it is recommended to adjust for multiple testing. By default, runUnivariate uses the Benjamini & Hochberg correction. The local Moran’s I statistics reveal locations in the tissue that have similar values to their neighbours (c.f., the lower part of the tissue).\n\n\nMultivariate measures – Bivariate Moran’s I\nThere exists a bivariate version of Moran’s I as well. The package spatialDM (Li et al. 2023) uses an adapted version of bivariate Moran’s I to identify ligand-receptor pairs.\nFor two continous observations the global bivariate Moran’s I is defined as (Wartenberg 1985; Bivand 2022)\n\\[I_B = \\frac{\\Sigma_i(\\Sigma_j{w_{ij}b_j\\times a_i})}{\\Sigma_i{b_i^2}}\\]\nwhere \\(a_i\\) and \\(b_i\\) are the two variables of interest and \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\). It is a measure of the correlation of the variables \\(a\\) with the the average of the neighboring values for variable \\(b\\) (also called the spatial lag of \\(b\\)).\nThere exists a local version that we will explore here. Note that the results are not symmetric, but very similar to each other.\n\n\nShow the code\nsfe_tissue &lt;- runBivariate(sfe_tissue, \"localmoran_bv\", # wraps the method from spdep\n  c(\"Myh1\", \"Myh2\"),\n  swap_rownames = \"symbol\", nsim = 1000\n)\n\n# this command gives all results of localmoran_bv\nlocalResultFeatures(sfe_tissue, \"localmoran_bv\")\n\n\n[1] \"Myh1__Myh1\" \"Myh2__Myh1\" \"Myh1__Myh2\" \"Myh2__Myh2\"\n\n\nShow the code\nplotLocalResult(sfe_tissue, \"localmoran_bv\", c(\"Myh1__Myh2\", \"Myh2__Myh1\"),\n  colGeometryName = \"spotPoly\", divergent = TRUE, diverge_center = 0\n)\n\n\n\n\n\n\n\n\n\nPlease note that the result might overestimate the spatial autocorrelation of the variables due to the inherent (non-spatial) correlation of \\(x\\) and \\(y\\) (Bivand 2022).",
    "crumbs": [
      "Overview Lattice-based Methods"
    ]
  },
  {
    "objectID": "00-overview-latSOD.html#impact-of-neighbourhood-on-autocorrelation-measures",
    "href": "00-overview-latSOD.html#impact-of-neighbourhood-on-autocorrelation-measures",
    "title": "Lattice data analysis – Summary",
    "section": "Impact of neighbourhood on autocorrelation measures",
    "text": "Impact of neighbourhood on autocorrelation measures\nLet’s compare the impact of different spatial weight matrices on local autocorrelation analysis. In this Visium dataset we do not have gene expression information for each cell because of the resolution of the spots. We will instead calculate the autocorrelation measures on the area of the segmented cells. This could be helpful when looking at local cell densities in a tissue.\nFirst, we base the spatial weight matrix on contiguous neighbours.\n\n\nShow the code\nsfe_tissue &lt;- annotGeometryUnivariate(sfe_tissue, \"localmoran\", \"area\",\n  annotGeometryName = \"myofiber_simplified\",\n  annotGraphName = \"myofiber_poly2nb\",\n  include_self = FALSE, zero.policy = TRUE,\n  name = \"myofiber_poly2nb\"\n)\n\npPoly &lt;- plotLocalResult(sfe_tissue, \"myofiber_poly2nb\", \"area\",\n  annotGeometryName = \"myofiber_simplified\",\n  annotGraphName = \"myofiber_poly2nb\",\n  divergent = TRUE, diverge_center = 0\n) + labs(title = \"Local Moran's I (li)\\nContiguous Neighbours\", \n         fill = \"li(area)\")\n\n\nAs an alternative, we also base the spatial weight matrix on the 5 nearest neighbours.\n\n\nShow the code\nsfe_tissue &lt;- annotGeometryUnivariate(sfe_tissue, \"localmoran\", \"area\",\n  annotGeometryName = \"myofiber_simplified\",\n  annotGraphName = \"knn5\",\n  include_self = FALSE, zero.policy = TRUE,\n  name = \"knn5\"\n)\n\npKnn5 &lt;- plotLocalResult(sfe_tissue, \"knn5\", \"area\",\n  annotGeometryName = \"myofiber_simplified\",\n  annotGraphName = \"knn5\",\n  divergent = TRUE, diverge_center = 0\n) + labs(title = \"Local Moran's I (li)\\n5 Nearest Neighbours\", \n         fill = \"li(area)\")\n\n\n\n\nShow the code\npPoly + pKnn5\n\n\n\n\n\n\n\n\n\nWhat happens if we base the spatial weight matrix on 10 nearest neighbours?\n\n\nShow the code\nannotGraph(sfe_tissue, \"knn10\") &lt;-\n  findSpatialNeighbors(sfe_tissue,\n    type = \"myofiber_simplified\",\n    MARGIN = 3, # to use the annotation geometry\n    method = \"knearneigh\", # wraps the spdep function with the same name\n    k = 10,\n    zero.policy = TRUE\n  )\n\nsfe_tissue &lt;- annotGeometryUnivariate(sfe_tissue, \"localmoran\", \"area\",\n  annotGeometryName = \"myofiber_simplified\",\n  annotGraphName = \"knn10\",\n  include_self = FALSE, zero.policy = TRUE,\n  name = \"knn10\"\n)\n\npKnn10 &lt;- plotLocalResult(sfe_tissue, \"knn10\", \"area\",\n  annotGeometryName = \"myofiber_simplified\",\n  annotGraphName = \"knn10\",\n  divergent = TRUE, diverge_center = 0\n) + labs(title = \"Local Moran's I (li)\\n10 Nearest Neighbours\", \n         fill = \"li(area)\")\n\n\n\n\nShow the code\npPoly + pKnn5 + pKnn10\n\n\n\n\n\n\n\n\n\nThe overall pattern of spatial autocorrelation is similar across the different weight matrices. However, locally there are some differences, as well as in the scale of the autocorrelation (note that the same color in the different plots does not correspond to the same value between the plots). There is a trend of smoothing of the value, the larger the neighbourhood in consideration.",
    "crumbs": [
      "Overview Lattice-based Methods"
    ]
  },
  {
    "objectID": "00-overview-ppSOD.html",
    "href": "00-overview-ppSOD.html",
    "title": "Point Pattern Analysis – Summary",
    "section": "",
    "text": "Cells (or transcripts) can be approximated as points given their location.\n\n\nThe central package to analyse point patterns in R is called spatstat (Baddeley and Turner 2005). The main data object to compute on is called a ppp object. ppp objects describe point patterns in two dimensional space, ppx objects create multidimensional point patterns. A ppp object is made up of three specifications (Baddeley and Turner 2005):\n\nThe locations of the points in question (\\(x\\),\\(y\\) and, optionally, \\(z\\) coordinates)\nThe observation window\nThe associated marks to each point in the pattern\n\nOn this central object, various spatstat metrics can be calculated.\n\n\n\n\n\n\nStructure of a SpatialExperiment object as introduced by Righelli et al.\n\n\nOften, the starting point in spatial omics data analysis is a SpatialExperiment (or similar) object. This is a central data structure in the BioConductor framework to store spatial omics data. The data we consider here is a MERFISH assay of a mouse preoptic hypothalamus (Chen et al. 2015; Moffitt et al. 2018).\n\n\nShow the code\nsuppressPackageStartupMessages({\n  library(SpatialExperiment)\n  library(spatstat.geom)\n  library(spatstat.explore)\n  library(dplyr)\n  library(ggplot2)\n  library(patchwork)\n  library(reshape2)\n  library(stringr)\n  library(tidyr)\n  library(magrittr)\n})\n\n\n\n\nShow the code\n# load the data from ExperimentHub\nsource(\"../code/load_data.R\")\n# source some helper functions\nsource(\"../code/utils.R\")\nlibrary('spatialFDA')\ntheme_set(theme_light())\n# load the SpatialExperiment object\nspe &lt;- readRDS(\"../data/spe.rds\")\nspe\n\n\nclass: SpatialExperiment \ndim: 161 73655 \nmetadata(0):\nassays(1): exprs\nrownames(161): Ace2 Adora2a ... Ucn3 Vgf\nrowData names(0):\ncolnames(73655): 6749ccb4-2ed1-4029-968f-820a287f43c8\n  6cac74bd-4ea7-4701-8701-42563cc65eb8 ...\n  6b666f81-7b73-4100-9e02-b5381b39f0f3\n  fdcddd97-7701-462a-b48f-979111245bd5\ncolData names(7): Animal_ID Animal_sex ... Neuron_cluster_ID cluster_id\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : x y\nimgData names(0):\n\n\nWe see that we have an object of class SpatialExperiment with \\(161\\) genes (rows) and \\(73655\\) cells. This object is very similar to a SingleCellExperiment object except it has the added spatialCoords slot. One slot in the colData is called sample_id which defines the so called z-slices. The three dimensional tissue is cut in the z-axis into consecutive two dimensional slices (Righelli et al. 2022).\nNext, we want to extract three slices of this SpatialExperiment object and convert the 2D slices into ppp objects.\n\n\nShow the code\n# define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n# small helper function to extract the z-slices and convert them to `ppp` objects\nselectZstacks &lt;- function(zstack, spe) {\n  spe[, spe$sample_id == zstack] |&gt; \n    .ppp(marks = \"cluster_id\")\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe) |&gt;\n  setNames(zstack_list)\n\npp_ls\n\n\n$`-0.09`\nMarked planar point pattern: 6185 points\nMultitype, with levels = \n   Ambiguous Astrocyte Endothelial Ependymal Excitatory Inhibitory Microglia OD \nImmature OD Mature Pericytes\nwindow: rectangle = [1307.7716, 3097.8543] x [2114.368, 3903.386] units\n\n$`0.01`\nMarked planar point pattern: 6111 points\nMultitype, with levels = \n   Ambiguous Astrocyte Endothelial Ependymal Excitatory Inhibitory Microglia OD \nImmature OD Mature Pericytes\nwindow: rectangle = [1222.5635, 3012.4248] x [-3993.535, -2202.755] units\n\n$`0.21`\nMarked planar point pattern: 5578 points\nMultitype, with levels = \n   Ambiguous Astrocyte Endothelial Ependymal Excitatory Inhibitory Microglia OD \nImmature OD Mature Pericytes\nwindow: rectangle = [1328.6103, 3124.2492] x [2199.257, 3993.499] units\n\n\nWe see that we obtain a list of three ppp objects for the three z-slices \\(-0.09, 0.01, 0.21\\).\nWe can plot one of these slices, e.g. slice \\(-0.09\\) with ggplot\n\n\nShow the code\n# create a dataframe from the point pattern\npp_df &lt;- pp_ls$`-0.09` %&gt;% as.data.frame\n# plot with ggplot\nggplot(pp_df, aes(x, y, colour = marks)) +\n  geom_point(size = 1) +\n  coord_equal()\n\n\n\n\n\n\n\n\n\n\n\n\nAs stated above, one important aspect of a point pattern is the observation window. It represents the region in which a pattern is observed or e.g. a survey was conducted (Baddeley, Rubak, and Turner 2015, 85). In most microscopy use cases we encounter window sampling. Window sampling describes the case where we don’t observe the entire point pattern in a window but just a sample (Baddeley, Rubak, and Turner 2015, 143–45).\nThe window of a point pattern does not need to be rectangular; we can receive round biopsies or calculate convex hulls around our sample (Baddeley, Rubak, and Turner 2015, 143–45).\nLet’s investigate the observation window for the slice \\(-0.09\\).\n\n\nShow the code\n# subset point pattern list\npp_sub &lt;- pp_ls$`-0.09`\n# base R plot of all marks\npp_sub |&gt; plot()\n\n\n\n\n\n\n\n\n\nHere, we have a rectangular window around all points.\nLet’s investigate what a round window would look like:\n\n\nShow the code\npp_sub_round &lt;- pp_sub\n# calculate circle with radius 850 µm and a center at the centroid of the window would look like\nw &lt;- disc(r = 850, centroid.owin(Window(pp_sub)))\nWindow(pp_sub_round) &lt;- w\npp_sub_round |&gt; plot()\n\n\n\n\n\n\n\n\n\nCorrectly assigning windows is very important. The window should represent the space where points are expected. This means, in window sampling, one should not restrict the window. This would lead to a false underestimation of the area where the points can be potentially observed. This problem of where we can observe points and where not (beyond the boundary of the window) leads to a range of problems collectively called edge effects (Baddeley, Rubak, and Turner 2015, 143–45). We will discuss these later.\n\n\n\nThe next concept that defines a point pattern is that marks can be associated with the points. The points can also have no mark, which we would call an unmarked point pattern\n\n\nShow the code\nunmark(pp_sub) |&gt; plot()\n\n\n\n\n\n\n\n\n\nMarks can be univariate or multivariate variables that are associated with the points (Baddeley, Rubak, and Turner 2015, 147). In the context of cell biology we can distinguish between discrete marks (e.g. cell types) or continuous marks (e.g. gene expression).\n\n\nIn our example, we have a multitype point pattern, meaning there are different cell types that serve as marks for the point pattern. Multitype means that we consider all marks together. The opposite is multivariate, where we consider the marks independently (Baddeley, Rubak, and Turner 2015, 564 ff.).\nFirst the multitype case:\n\n\nShow the code\npp_sub |&gt; plot()\n\n\n\n\n\n\n\n\n\nThen splitting the point pattern and plotting a multivariate view on the same pattern.\n\n\nShow the code\npp_sub |&gt;\n  split() |&gt;\n  plot()\n\n\n\n\n\n\n\n\n\n\n\n\nMarks can as well be continuous as in the case of gene expression. We choose some genes from the original paper and look at their distribution (Baddeley, Rubak, and Turner 2015, 637; Moffitt et al. 2018).\n\n\nShow the code\n# subset the original SpatialExperiment to our example slide -0.09\nsub &lt;- spe[, spe$sample_id == \"-0.09\"]\n#  Genes from Fig. 6 of Moffitt et al. (2018)\ngenes &lt;- c(\"Slc18a2\", \"Esr1\", \"Pgr\")\ngex &lt;- assay(sub)[genes, ] %&gt;%\n  t() %&gt;%\n  as.matrix() %&gt;%\n  data.frame() %&gt;%\n  set_rownames(NULL)\n# gene expression to marks\nmarks(pp_sub) &lt;- gex\n\n\nNow that we have points with multivariate continuous marks\n\n\nShow the code\n# create a dataframe in long format for plotting\npp_df &lt;- pp_sub %&gt;%\n  as.data.frame() %&gt;%\n  pivot_longer(cols = 3:5)\n\nggplot(pp_df, aes(x, y, colour = log(value + 1))) +\n  geom_point(size = 0.5) +\n  facet_wrap(~name) +\n  coord_equal() +\n  scale_color_continuous(type = \"viridis\")\n\n\n\n\n\n\n\n\n\nWe note that the expression of the genes Pgr and Slc18a2 is very evenly distributed with some elevations in the middle of the structure. Esr1 shows a half-circle like structure in expression. Note that the expression is here log transformed counts offset by one (to avoid problems with log of zero).\n\n\n\nWe can compare patterns between marks of the same type. This is referred to as a within mark comparison in our vignette. We can compare discrete marks, so the distribution of one single mark, e.g. a cell type.\n\n\nShow the code\n# create a dataframe from the point pattern\npp_df_discrete &lt;- lapply(zstack_list, function(x) {\n  df &lt;- pp_ls[[x]] %&gt;% as.data.frame()\n  df$stack &lt;- x\n  return(df)\n}) %&gt;% bind_rows()\n\n# select OD Mature cells\npp_df_odmature &lt;- pp_df_discrete[pp_df_discrete$marks == \"OD Mature\", ]\n\nggplot(pp_df_odmature, aes(x, y, colour = marks)) +\n  geom_point(size = 0.5) +\n  facet_wrap(~stack, scales = \"free\") +\n  theme(aspect.ratio = 1)\n\n\n\n\n\n\n\n\n\nHere, we plot the distribution of mature oligodendrocytes across three slices of one 3D brain sample.\nContinuous marks can be compared as well, e.g. the expression of a gene across slices of a tissue\n\n\nShow the code\npp_df &lt;- lapply(zstack_list, function(x) {\n  # subset the original SpatialExperiment to our example slide -0.09\n  sub &lt;- spe[, spe$sample_id == x]\n  #  Genes from Fig. 6 of Moffitt et al. (2018)\n  genes &lt;- c(\"Slc18a2\", \"Esr1\", \"Pgr\")\n  gex &lt;- assay(sub)[genes, ] %&gt;%\n    t() %&gt;%\n    as.matrix() %&gt;%\n    data.frame() %&gt;%\n    set_rownames(NULL)\n  # gene expression to marks\n  marks(pp_ls[[x]]) &lt;- gex\n  df &lt;- pp_ls[[x]] %&gt;% as.data.frame()\n  df$stack &lt;- x\n  return(df)\n}) %&gt;% bind_rows()\n\nggplot(pp_df, aes(x, y, colour = log(Esr1 + 1))) +\n  geom_point(size = 0.5) +\n  facet_wrap(~stack, scales = \"free\") +\n  theme(aspect.ratio = 1) +\n  scale_color_continuous(type = \"viridis\")\n\n\n\n\n\n\n\n\n\nWe note that the gene Esr1 is differentially distributed across the slices of the 3D sample.\n\n\n\nCorrelation is a second order quantity that measures the dependence between points (Baddeley, Rubak, and Turner 2015, 199). A famous way to measure this is with Ripley’s \\(K\\), which is a cumulative function that quantifies the “number of \\(r\\)-neighbours of a typical random point” (Baddeley, Rubak, and Turner 2015, 204; Ripley 1976).\n\n\nGlobal correlation measures quantify the correlation in the entire window. Global Ripley’s \\(K\\) is defined as:\n\\[\n\\hat{K}(r) = \\frac{|W|}{n(n-1)}\\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n\\{d_{ij}\\leq r\\} e_{ij}(r)\n\\]\nIn the formula above we note a few things:\n\nThe function is normalised by the number of points \\(n\\) and the window size \\(|W|\\)\nthe term \\(e_{ij}(r)\\) is an edge correction - see the section on border corrections further down in the vignette (Baddeley, Rubak, and Turner 2015, 204).\n\nRipley’s \\(K\\) function can be variance stabilised, which is referred to as Besag’s \\(L\\) (Canete et al. 2022; Besag 1977). The idea behind variance stabilisation is to “uncouple” the relationship between mean and variance. By taking the square root of the function in question, the variance is nearly constant across the function (Bartlett 1947).\n\\[\nL(r) = \\sqrt{\\frac{K(r)}{\\pi}}\n\\]\n\n\nShow the code\nres_ls &lt;- lapply(list('Kest', 'Lest'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')})\n\n\n\n\nShow the code\nwrap_plots(p_ls, guides = 'collect')\n\n\n\n\n\n\n\n\n\nThe strongest estimate of association between oligodendrocytes is found for the slices \\(0.01\\). Slice \\(0.21\\) does not show such a high degree of association at radii \\(\\leq300\\) as the other two slices. This means that the apparent clustering we see in the distribution of points is mainly due to an overall higher number of cells in slide \\(0.21\\) and not a higher degree of association per se. The black line indicates the expected \\(K\\) respectively \\(L\\) function for a completely spatially random poisson process (Baddeley, Rubak, and Turner 2015, 132 ff.).\nSame can be done for the arrangement of Microglia cells across these three sections.\n\n\nShow the code\nres &lt;- calcMetricPerFov(spe, 'Microglia', subsetby = 'sample_id', fun = 'Lest', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\n\nplotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')\n\n\nWe note that the Microglia cells are distributed close to a Poisson Process across the different slices.\nA similar analysis can be performed for continuous marks. As an exercise, try to calculated a mark weighted correlation function markcorr. You get more information on this function by typing ?markcorr. The mark weighted correlation function is defined as:\n\\[\nk_f(r) =  \\frac{\\mathbb{E}[f(m(u),m(v))|u,v \\in X]}{\\mathbb{E}[f(M,M')]}\n\\]\nwhere the numerator is the conditional expectation of the marks at location \\(u,v\\) separated by a radius \\(r\\) and \\(f\\) can be any function linking the two marks. The denominator is the expectation of two random marks \\(M,M'\\) (Baddeley, Rubak, and Turner 2015, 603).\n\n\nShow the code\ngenes &lt;- c(\"Slc18a2\", \"Esr1\", \"Pgr\")\ngex &lt;- assay(spe)[genes,] %&gt;% t %&gt;% as.matrix %&gt;% \n  data.frame %&gt;% set_rownames(NULL)\n# gene expression to marks\ncolData(spe) &lt;- colData(spe) %&gt;% cbind(gex)\n\nres &lt;- calcMetricPerFov(spe, selection = 'Esr1', subsetby = 'sample_id', fun = 'markcorr',  marks = 'Esr1', r_seq=NULL, by = c('Animal_ID', 'sample_id'), continuous = TRUE)\n\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\n  \np &lt;- plotMetricPerFov(res, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'sample_id')\np\n\n\n\n\n\n\n\n\n\nWe note that at very small radii the expression of the gene Esr1 shows a high association with itself. Later on, the association is less pronounced than in the slices \\(-0.09\\) and \\(0.01\\).\n\n\n\nNext to observation window metrics, we can calculate point level statistics as well. One such option is the local indicators of spatial association (LISA). This gives one curve per point in the field of view (Baddeley, Rubak, and Turner 2015, 247–48).\n\n\nShow the code\npp &lt;- subset(pp_ls[[\"0.01\"]], marks %in% \"OD Mature\")\nL_odmature_lisa &lt;- localL(pp)\n\ndf &lt;- as.data.frame(L_odmature_lisa)\ndfm &lt;- reshape2::melt(df, \"r\")\n\nget_sel &lt;- dfm %&gt;%\n  dplyr::filter(r &gt; 200.5630 & r &lt; 201.4388, variable != \"theo\") %&gt;%\n  dplyr::mutate(sel = value) %&gt;%\n  dplyr::select(variable, sel)\n\ndfm &lt;- dfm %&gt;% left_join(get_sel)\n\np &lt;- ggplot(dfm, aes(x = r, y = value, group = variable, colour = sel)) +\n  geom_line(linewidth = 1) +\n  scale_color_continuous(type = \"viridis\") +\n  geom_vline(xintercept = 200) +\n  theme(legend.position = \"none\") +\n  ggtitle(\"LISA curves of slice 0.01\")\n\n\n\n\nShow the code\np\n\n\n\n\n\n\n\n\n\nThese curves could be analysed using tools from functional data analysis such as functional PCA (Baddeley, Rubak, and Turner 2015, 247–48; Ramsay and Silverman 2005).\n\n\n\n\n\nThe same analyses as above can be performed between two cell types. The corresponding functions are called cross functions (Baddeley, Rubak, and Turner 2015, 594 ff.). As an exercise, try to implement (similar to the analyses above) a cross comparison between two cell types of interest. With the provided functions this is possible, just give a function you like as input and a vector with two cell types you wish to compare. You can look at functions in the documentation of spatstat.explore. We provide an example below:\n\n\nShow the code\n# select OD Mature and Microglia cells\npp_df_odmature_microglia &lt;- pp_df_discrete[pp_df_discrete$marks %in% c(\"OD Mature\", \"Microglia\"), ]\n\nggplot(pp_df_odmature_microglia, aes(x, y, colour = marks)) +\n  geom_point(size = 0.5) +\n  facet_wrap(~stack, scales = \"free\") +\n  theme(aspect.ratio = 1)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres &lt;- calcMetricPerFov(spe, c(\"OD Mature\", \"Microglia\"), subsetby = 'sample_id', fun = 'Lcross', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\n\np &lt;- plotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')\n\n\n\n\nShow the code\np\n\n\n\n\n\n\n\n\n\nWe note that there is not a very strong co-localisation indicated by the \\(L\\) curves between mature oligodendrocytes and microglia cells. If we look at their spatial distribution that makes sense since microglia cells are distributed more or less homogeneously in the respective slices.\n\n\n\nEdge effects describe the phenomenon that not the entire point process is observed, but rather only the part within the window \\(W\\). This means the value of various statistics could be biased along the edges (Baddeley, Rubak, and Turner 2015, 213).\nThere are many corrections for edge effects that are briefly listed here (Baddeley, Rubak, and Turner 2015, 214–19):\nBorder correction:\n\nIn border correction the summation of data points is restricted to \\(x_i\\) for which \\(b(x_i,r)\\) is completely in the window \\(W\\).\n\nIsotropic correction:\n\nWe can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.\n\nTranslation correction:\n\nA stationary point process \\(X\\) is invariant to translations. So the entire point process can be shifted by a vector \\(s\\) to be at the position \\(X+s\\).\n\n\n\n\n\n\nPoint patterns are realisations of a point process. In the analysis we make inferences about the point process.\nA point process assumes stochasticity. Therefore, HTS-based approaches are not suitable for point pattern analysis.\nThere are global metrics for the comparison within a celltype or between celltypes.\nThere are corresponding metrics for single cells and their interactions.\nPoint pattern analysis allows for the analysis of continuous gene expression marks as well.\n\n\n\nShow the code\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] spatialFDA_0.99.0              dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.10.3                 SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-16                     \n[17] STexampleData_1.8.0            RANN_2.6.1                    \n[19] seg_0.5-7                      sp_2.1-1                      \n[21] rlang_1.1.1                    mixR_0.2.0                    \n[23] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[25] spatstat.model_3.2-6           rpart_4.1.19                  \n[27] MerfishData_1.2.0              EBImage_4.42.0                \n[29] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[31] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[33] magrittr_2.0.3                 tidyr_1.3.0                   \n[35] stringr_1.5.0                  reshape2_1.4.4                \n[37] patchwork_1.2.0                ggplot2_3.5.1                 \n[39] dplyr_1.1.3                    spatstat.explore_3.2-3        \n[41] nlme_3.1-162                   spatstat.random_3.1-6         \n[43] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[45] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[47] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[49] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[51] IRanges_2.34.1                 S4Vectors_0.38.2              \n[53] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[55] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.9-1                    rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.3.0                  classInt_0.4-10              \n [83] rappdirs_0.3.3                tiff_0.1-11                  \n [85] goftest_1.2-3                 fftwtools_0.9-11             \n [87] spatstat.utils_3.0-5          rmarkdown_2.25               \n [89] XVector_0.40.0                base64enc_0.1-3              \n [91] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [93] jpeg_0.1-10                   sparseMatrixStats_1.12.2     \n [95] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [97] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [99] farver_2.1.1                  jsonlite_1.8.7               \n[101] BiocParallel_1.34.2           R.oo_1.25.0                  \n[103] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[105] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[107] Rhdf5lib_1.22.1               munsell_0.5.0                \n[109] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[111] viridis_0.6.4                 stringi_1.7.12               \n[113] leafsync_0.1.0                zlibbioc_1.46.0              \n[115] plyr_1.8.9                    parallel_4.3.1               \n[117] ggrepel_0.9.4                 deldir_1.0-9                 \n[119] Biostrings_2.68.1             stars_0.6-4                  \n[121] splines_4.3.1                 tensor_1.5                   \n[123] locfit_1.5-9.8                igraph_1.5.1                 \n[125] ScaledMatrix_1.8.1            XML_3.99-0.14                \n[127] BiocVersion_3.17.1            evaluate_0.22                \n[129] BiocManager_1.30.22           httpuv_1.6.11                \n[131] purrr_1.0.2                   polyclip_1.10-6              \n[133] rsvd_1.0.5                    lwgeom_0.2-13                \n[135] xtable_1.8-4                  e1071_1.7-13                 \n[137] RSpectra_0.16-1               later_1.3.1                  \n[139] viridisLite_0.4.2             class_7.3-22                 \n[141] tibble_3.2.1                  memoise_2.0.1                \n[143] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[145] cluster_2.1.4                 BiocStyle_2.28.1\n©2024 The pasta authors. Content is published under Creative Commons CC-BY-4.0 License for the text and GPL-3 License for any code.",
    "crumbs": [
      "Overview Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "00-overview-ppSOD.html#introduction",
    "href": "00-overview-ppSOD.html#introduction",
    "title": "Point Pattern Analysis – Summary",
    "section": "",
    "text": "Cells (or transcripts) can be approximated as points given their location.\n\n\nThe central package to analyse point patterns in R is called spatstat (Baddeley and Turner 2005). The main data object to compute on is called a ppp object. ppp objects describe point patterns in two dimensional space, ppx objects create multidimensional point patterns. A ppp object is made up of three specifications (Baddeley and Turner 2005):\n\nThe locations of the points in question (\\(x\\),\\(y\\) and, optionally, \\(z\\) coordinates)\nThe observation window\nThe associated marks to each point in the pattern\n\nOn this central object, various spatstat metrics can be calculated.\n\n\n\n\n\n\nStructure of a SpatialExperiment object as introduced by Righelli et al.\n\n\nOften, the starting point in spatial omics data analysis is a SpatialExperiment (or similar) object. This is a central data structure in the BioConductor framework to store spatial omics data. The data we consider here is a MERFISH assay of a mouse preoptic hypothalamus (Chen et al. 2015; Moffitt et al. 2018).\n\n\nShow the code\nsuppressPackageStartupMessages({\n  library(SpatialExperiment)\n  library(spatstat.geom)\n  library(spatstat.explore)\n  library(dplyr)\n  library(ggplot2)\n  library(patchwork)\n  library(reshape2)\n  library(stringr)\n  library(tidyr)\n  library(magrittr)\n})\n\n\n\n\nShow the code\n# load the data from ExperimentHub\nsource(\"../code/load_data.R\")\n# source some helper functions\nsource(\"../code/utils.R\")\nlibrary('spatialFDA')\ntheme_set(theme_light())\n# load the SpatialExperiment object\nspe &lt;- readRDS(\"../data/spe.rds\")\nspe\n\n\nclass: SpatialExperiment \ndim: 161 73655 \nmetadata(0):\nassays(1): exprs\nrownames(161): Ace2 Adora2a ... Ucn3 Vgf\nrowData names(0):\ncolnames(73655): 6749ccb4-2ed1-4029-968f-820a287f43c8\n  6cac74bd-4ea7-4701-8701-42563cc65eb8 ...\n  6b666f81-7b73-4100-9e02-b5381b39f0f3\n  fdcddd97-7701-462a-b48f-979111245bd5\ncolData names(7): Animal_ID Animal_sex ... Neuron_cluster_ID cluster_id\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : x y\nimgData names(0):\n\n\nWe see that we have an object of class SpatialExperiment with \\(161\\) genes (rows) and \\(73655\\) cells. This object is very similar to a SingleCellExperiment object except it has the added spatialCoords slot. One slot in the colData is called sample_id which defines the so called z-slices. The three dimensional tissue is cut in the z-axis into consecutive two dimensional slices (Righelli et al. 2022).\nNext, we want to extract three slices of this SpatialExperiment object and convert the 2D slices into ppp objects.\n\n\nShow the code\n# define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n# small helper function to extract the z-slices and convert them to `ppp` objects\nselectZstacks &lt;- function(zstack, spe) {\n  spe[, spe$sample_id == zstack] |&gt; \n    .ppp(marks = \"cluster_id\")\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe) |&gt;\n  setNames(zstack_list)\n\npp_ls\n\n\n$`-0.09`\nMarked planar point pattern: 6185 points\nMultitype, with levels = \n   Ambiguous Astrocyte Endothelial Ependymal Excitatory Inhibitory Microglia OD \nImmature OD Mature Pericytes\nwindow: rectangle = [1307.7716, 3097.8543] x [2114.368, 3903.386] units\n\n$`0.01`\nMarked planar point pattern: 6111 points\nMultitype, with levels = \n   Ambiguous Astrocyte Endothelial Ependymal Excitatory Inhibitory Microglia OD \nImmature OD Mature Pericytes\nwindow: rectangle = [1222.5635, 3012.4248] x [-3993.535, -2202.755] units\n\n$`0.21`\nMarked planar point pattern: 5578 points\nMultitype, with levels = \n   Ambiguous Astrocyte Endothelial Ependymal Excitatory Inhibitory Microglia OD \nImmature OD Mature Pericytes\nwindow: rectangle = [1328.6103, 3124.2492] x [2199.257, 3993.499] units\n\n\nWe see that we obtain a list of three ppp objects for the three z-slices \\(-0.09, 0.01, 0.21\\).\nWe can plot one of these slices, e.g. slice \\(-0.09\\) with ggplot\n\n\nShow the code\n# create a dataframe from the point pattern\npp_df &lt;- pp_ls$`-0.09` %&gt;% as.data.frame\n# plot with ggplot\nggplot(pp_df, aes(x, y, colour = marks)) +\n  geom_point(size = 1) +\n  coord_equal()\n\n\n\n\n\n\n\n\n\n\n\n\nAs stated above, one important aspect of a point pattern is the observation window. It represents the region in which a pattern is observed or e.g. a survey was conducted (Baddeley, Rubak, and Turner 2015, 85). In most microscopy use cases we encounter window sampling. Window sampling describes the case where we don’t observe the entire point pattern in a window but just a sample (Baddeley, Rubak, and Turner 2015, 143–45).\nThe window of a point pattern does not need to be rectangular; we can receive round biopsies or calculate convex hulls around our sample (Baddeley, Rubak, and Turner 2015, 143–45).\nLet’s investigate the observation window for the slice \\(-0.09\\).\n\n\nShow the code\n# subset point pattern list\npp_sub &lt;- pp_ls$`-0.09`\n# base R plot of all marks\npp_sub |&gt; plot()\n\n\n\n\n\n\n\n\n\nHere, we have a rectangular window around all points.\nLet’s investigate what a round window would look like:\n\n\nShow the code\npp_sub_round &lt;- pp_sub\n# calculate circle with radius 850 µm and a center at the centroid of the window would look like\nw &lt;- disc(r = 850, centroid.owin(Window(pp_sub)))\nWindow(pp_sub_round) &lt;- w\npp_sub_round |&gt; plot()\n\n\n\n\n\n\n\n\n\nCorrectly assigning windows is very important. The window should represent the space where points are expected. This means, in window sampling, one should not restrict the window. This would lead to a false underestimation of the area where the points can be potentially observed. This problem of where we can observe points and where not (beyond the boundary of the window) leads to a range of problems collectively called edge effects (Baddeley, Rubak, and Turner 2015, 143–45). We will discuss these later.\n\n\n\nThe next concept that defines a point pattern is that marks can be associated with the points. The points can also have no mark, which we would call an unmarked point pattern\n\n\nShow the code\nunmark(pp_sub) |&gt; plot()\n\n\n\n\n\n\n\n\n\nMarks can be univariate or multivariate variables that are associated with the points (Baddeley, Rubak, and Turner 2015, 147). In the context of cell biology we can distinguish between discrete marks (e.g. cell types) or continuous marks (e.g. gene expression).\n\n\nIn our example, we have a multitype point pattern, meaning there are different cell types that serve as marks for the point pattern. Multitype means that we consider all marks together. The opposite is multivariate, where we consider the marks independently (Baddeley, Rubak, and Turner 2015, 564 ff.).\nFirst the multitype case:\n\n\nShow the code\npp_sub |&gt; plot()\n\n\n\n\n\n\n\n\n\nThen splitting the point pattern and plotting a multivariate view on the same pattern.\n\n\nShow the code\npp_sub |&gt;\n  split() |&gt;\n  plot()\n\n\n\n\n\n\n\n\n\n\n\n\nMarks can as well be continuous as in the case of gene expression. We choose some genes from the original paper and look at their distribution (Baddeley, Rubak, and Turner 2015, 637; Moffitt et al. 2018).\n\n\nShow the code\n# subset the original SpatialExperiment to our example slide -0.09\nsub &lt;- spe[, spe$sample_id == \"-0.09\"]\n#  Genes from Fig. 6 of Moffitt et al. (2018)\ngenes &lt;- c(\"Slc18a2\", \"Esr1\", \"Pgr\")\ngex &lt;- assay(sub)[genes, ] %&gt;%\n  t() %&gt;%\n  as.matrix() %&gt;%\n  data.frame() %&gt;%\n  set_rownames(NULL)\n# gene expression to marks\nmarks(pp_sub) &lt;- gex\n\n\nNow that we have points with multivariate continuous marks\n\n\nShow the code\n# create a dataframe in long format for plotting\npp_df &lt;- pp_sub %&gt;%\n  as.data.frame() %&gt;%\n  pivot_longer(cols = 3:5)\n\nggplot(pp_df, aes(x, y, colour = log(value + 1))) +\n  geom_point(size = 0.5) +\n  facet_wrap(~name) +\n  coord_equal() +\n  scale_color_continuous(type = \"viridis\")\n\n\n\n\n\n\n\n\n\nWe note that the expression of the genes Pgr and Slc18a2 is very evenly distributed with some elevations in the middle of the structure. Esr1 shows a half-circle like structure in expression. Note that the expression is here log transformed counts offset by one (to avoid problems with log of zero).\n\n\n\nWe can compare patterns between marks of the same type. This is referred to as a within mark comparison in our vignette. We can compare discrete marks, so the distribution of one single mark, e.g. a cell type.\n\n\nShow the code\n# create a dataframe from the point pattern\npp_df_discrete &lt;- lapply(zstack_list, function(x) {\n  df &lt;- pp_ls[[x]] %&gt;% as.data.frame()\n  df$stack &lt;- x\n  return(df)\n}) %&gt;% bind_rows()\n\n# select OD Mature cells\npp_df_odmature &lt;- pp_df_discrete[pp_df_discrete$marks == \"OD Mature\", ]\n\nggplot(pp_df_odmature, aes(x, y, colour = marks)) +\n  geom_point(size = 0.5) +\n  facet_wrap(~stack, scales = \"free\") +\n  theme(aspect.ratio = 1)\n\n\n\n\n\n\n\n\n\nHere, we plot the distribution of mature oligodendrocytes across three slices of one 3D brain sample.\nContinuous marks can be compared as well, e.g. the expression of a gene across slices of a tissue\n\n\nShow the code\npp_df &lt;- lapply(zstack_list, function(x) {\n  # subset the original SpatialExperiment to our example slide -0.09\n  sub &lt;- spe[, spe$sample_id == x]\n  #  Genes from Fig. 6 of Moffitt et al. (2018)\n  genes &lt;- c(\"Slc18a2\", \"Esr1\", \"Pgr\")\n  gex &lt;- assay(sub)[genes, ] %&gt;%\n    t() %&gt;%\n    as.matrix() %&gt;%\n    data.frame() %&gt;%\n    set_rownames(NULL)\n  # gene expression to marks\n  marks(pp_ls[[x]]) &lt;- gex\n  df &lt;- pp_ls[[x]] %&gt;% as.data.frame()\n  df$stack &lt;- x\n  return(df)\n}) %&gt;% bind_rows()\n\nggplot(pp_df, aes(x, y, colour = log(Esr1 + 1))) +\n  geom_point(size = 0.5) +\n  facet_wrap(~stack, scales = \"free\") +\n  theme(aspect.ratio = 1) +\n  scale_color_continuous(type = \"viridis\")\n\n\n\n\n\n\n\n\n\nWe note that the gene Esr1 is differentially distributed across the slices of the 3D sample.\n\n\n\nCorrelation is a second order quantity that measures the dependence between points (Baddeley, Rubak, and Turner 2015, 199). A famous way to measure this is with Ripley’s \\(K\\), which is a cumulative function that quantifies the “number of \\(r\\)-neighbours of a typical random point” (Baddeley, Rubak, and Turner 2015, 204; Ripley 1976).\n\n\nGlobal correlation measures quantify the correlation in the entire window. Global Ripley’s \\(K\\) is defined as:\n\\[\n\\hat{K}(r) = \\frac{|W|}{n(n-1)}\\sum_{i=1}^n\\sum_{j=1 \\\\j \\neq i}^n\\{d_{ij}\\leq r\\} e_{ij}(r)\n\\]\nIn the formula above we note a few things:\n\nThe function is normalised by the number of points \\(n\\) and the window size \\(|W|\\)\nthe term \\(e_{ij}(r)\\) is an edge correction - see the section on border corrections further down in the vignette (Baddeley, Rubak, and Turner 2015, 204).\n\nRipley’s \\(K\\) function can be variance stabilised, which is referred to as Besag’s \\(L\\) (Canete et al. 2022; Besag 1977). The idea behind variance stabilisation is to “uncouple” the relationship between mean and variance. By taking the square root of the function in question, the variance is nearly constant across the function (Bartlett 1947).\n\\[\nL(r) = \\sqrt{\\frac{K(r)}{\\pi}}\n\\]\n\n\nShow the code\nres_ls &lt;- lapply(list('Kest', 'Lest'), function(fun){\n  res &lt;- calcMetricPerFov(spe, 'OD Mature', subsetby = 'sample_id', fun = fun, marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\n  res &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\nreturn(res)\n})\n\np_ls &lt;- lapply(res_ls, function(res){plotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')})\n\n\n\n\nShow the code\nwrap_plots(p_ls, guides = 'collect')\n\n\n\n\n\n\n\n\n\nThe strongest estimate of association between oligodendrocytes is found for the slices \\(0.01\\). Slice \\(0.21\\) does not show such a high degree of association at radii \\(\\leq300\\) as the other two slices. This means that the apparent clustering we see in the distribution of points is mainly due to an overall higher number of cells in slide \\(0.21\\) and not a higher degree of association per se. The black line indicates the expected \\(K\\) respectively \\(L\\) function for a completely spatially random poisson process (Baddeley, Rubak, and Turner 2015, 132 ff.).\nSame can be done for the arrangement of Microglia cells across these three sections.\n\n\nShow the code\nres &lt;- calcMetricPerFov(spe, 'Microglia', subsetby = 'sample_id', fun = 'Lest', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\n\nplotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')\n\n\nWe note that the Microglia cells are distributed close to a Poisson Process across the different slices.\nA similar analysis can be performed for continuous marks. As an exercise, try to calculated a mark weighted correlation function markcorr. You get more information on this function by typing ?markcorr. The mark weighted correlation function is defined as:\n\\[\nk_f(r) =  \\frac{\\mathbb{E}[f(m(u),m(v))|u,v \\in X]}{\\mathbb{E}[f(M,M')]}\n\\]\nwhere the numerator is the conditional expectation of the marks at location \\(u,v\\) separated by a radius \\(r\\) and \\(f\\) can be any function linking the two marks. The denominator is the expectation of two random marks \\(M,M'\\) (Baddeley, Rubak, and Turner 2015, 603).\n\n\nShow the code\ngenes &lt;- c(\"Slc18a2\", \"Esr1\", \"Pgr\")\ngex &lt;- assay(spe)[genes,] %&gt;% t %&gt;% as.matrix %&gt;% \n  data.frame %&gt;% set_rownames(NULL)\n# gene expression to marks\ncolData(spe) &lt;- colData(spe) %&gt;% cbind(gex)\n\nres &lt;- calcMetricPerFov(spe, selection = 'Esr1', subsetby = 'sample_id', fun = 'markcorr',  marks = 'Esr1', r_seq=NULL, by = c('Animal_ID', 'sample_id'), continuous = TRUE)\n\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\n  \np &lt;- plotMetricPerFov(res, correction = \"iso\", theo = TRUE, x = \"r\", image_id = 'sample_id')\np\n\n\n\n\n\n\n\n\n\nWe note that at very small radii the expression of the gene Esr1 shows a high association with itself. Later on, the association is less pronounced than in the slices \\(-0.09\\) and \\(0.01\\).\n\n\n\nNext to observation window metrics, we can calculate point level statistics as well. One such option is the local indicators of spatial association (LISA). This gives one curve per point in the field of view (Baddeley, Rubak, and Turner 2015, 247–48).\n\n\nShow the code\npp &lt;- subset(pp_ls[[\"0.01\"]], marks %in% \"OD Mature\")\nL_odmature_lisa &lt;- localL(pp)\n\ndf &lt;- as.data.frame(L_odmature_lisa)\ndfm &lt;- reshape2::melt(df, \"r\")\n\nget_sel &lt;- dfm %&gt;%\n  dplyr::filter(r &gt; 200.5630 & r &lt; 201.4388, variable != \"theo\") %&gt;%\n  dplyr::mutate(sel = value) %&gt;%\n  dplyr::select(variable, sel)\n\ndfm &lt;- dfm %&gt;% left_join(get_sel)\n\np &lt;- ggplot(dfm, aes(x = r, y = value, group = variable, colour = sel)) +\n  geom_line(linewidth = 1) +\n  scale_color_continuous(type = \"viridis\") +\n  geom_vline(xintercept = 200) +\n  theme(legend.position = \"none\") +\n  ggtitle(\"LISA curves of slice 0.01\")\n\n\n\n\nShow the code\np\n\n\n\n\n\n\n\n\n\nThese curves could be analysed using tools from functional data analysis such as functional PCA (Baddeley, Rubak, and Turner 2015, 247–48; Ramsay and Silverman 2005).\n\n\n\n\n\nThe same analyses as above can be performed between two cell types. The corresponding functions are called cross functions (Baddeley, Rubak, and Turner 2015, 594 ff.). As an exercise, try to implement (similar to the analyses above) a cross comparison between two cell types of interest. With the provided functions this is possible, just give a function you like as input and a vector with two cell types you wish to compare. You can look at functions in the documentation of spatstat.explore. We provide an example below:\n\n\nShow the code\n# select OD Mature and Microglia cells\npp_df_odmature_microglia &lt;- pp_df_discrete[pp_df_discrete$marks %in% c(\"OD Mature\", \"Microglia\"), ]\n\nggplot(pp_df_odmature_microglia, aes(x, y, colour = marks)) +\n  geom_point(size = 0.5) +\n  facet_wrap(~stack, scales = \"free\") +\n  theme(aspect.ratio = 1)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres &lt;- calcMetricPerFov(spe, c(\"OD Mature\", \"Microglia\"), subsetby = 'sample_id', fun = 'Lcross', marks = 'cluster_id', r_seq=NULL, by = c('Animal_ID','sample_id'))\nres &lt;- subset(res, sample_id %in% c('-0.09', '0.01', '0.21'))\n\np &lt;- plotMetricPerFov(res, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')\n\n\n\n\nShow the code\np\n\n\n\n\n\n\n\n\n\nWe note that there is not a very strong co-localisation indicated by the \\(L\\) curves between mature oligodendrocytes and microglia cells. If we look at their spatial distribution that makes sense since microglia cells are distributed more or less homogeneously in the respective slices.\n\n\n\nEdge effects describe the phenomenon that not the entire point process is observed, but rather only the part within the window \\(W\\). This means the value of various statistics could be biased along the edges (Baddeley, Rubak, and Turner 2015, 213).\nThere are many corrections for edge effects that are briefly listed here (Baddeley, Rubak, and Turner 2015, 214–19):\nBorder correction:\n\nIn border correction the summation of data points is restricted to \\(x_i\\) for which \\(b(x_i,r)\\) is completely in the window \\(W\\).\n\nIsotropic correction:\n\nWe can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.\n\nTranslation correction:\n\nA stationary point process \\(X\\) is invariant to translations. So the entire point process can be shifted by a vector \\(s\\) to be at the position \\(X+s\\).",
    "crumbs": [
      "Overview Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "00-overview-ppSOD.html#summary-and-considerations",
    "href": "00-overview-ppSOD.html#summary-and-considerations",
    "title": "Point Pattern Analysis – Summary",
    "section": "",
    "text": "Point patterns are realisations of a point process. In the analysis we make inferences about the point process.\nA point process assumes stochasticity. Therefore, HTS-based approaches are not suitable for point pattern analysis.\nThere are global metrics for the comparison within a celltype or between celltypes.\nThere are corresponding metrics for single cells and their interactions.\nPoint pattern analysis allows for the analysis of continuous gene expression marks as well.\n\n\n\nShow the code\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] spatialFDA_0.99.0              dixon_0.0-8                   \n [3] splancs_2.01-44                spdep_1.2-8                   \n [5] spData_2.3.0                   tmap_3.3-4                    \n [7] scater_1.28.0                  scran_1.28.2                  \n [9] scuttle_1.10.3                 SFEData_1.2.0                 \n[11] SpatialFeatureExperiment_1.2.3 Voyager_1.2.7                 \n[13] rgeoda_0.0.10-4                digest_0.6.33                 \n[15] ncf_1.3-2                      sf_1.0-16                     \n[17] STexampleData_1.8.0            RANN_2.6.1                    \n[19] seg_0.5-7                      sp_2.1-1                      \n[21] rlang_1.1.1                    mixR_0.2.0                    \n[23] spatstat_3.0-6                 spatstat.linnet_3.1-1         \n[25] spatstat.model_3.2-6           rpart_4.1.19                  \n[27] MerfishData_1.2.0              EBImage_4.42.0                \n[29] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[31] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[33] magrittr_2.0.3                 tidyr_1.3.0                   \n[35] stringr_1.5.0                  reshape2_1.4.4                \n[37] patchwork_1.2.0                ggplot2_3.5.1                 \n[39] dplyr_1.1.3                    spatstat.explore_3.2-3        \n[41] nlme_3.1-162                   spatstat.random_3.1-6         \n[43] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[45] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[47] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[49] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[51] IRanges_2.34.1                 S4Vectors_0.38.2              \n[53] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[55] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.9-1                    rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.3.0                  classInt_0.4-10              \n [83] rappdirs_0.3.3                tiff_0.1-11                  \n [85] goftest_1.2-3                 fftwtools_0.9-11             \n [87] spatstat.utils_3.0-5          rmarkdown_2.25               \n [89] XVector_0.40.0                base64enc_0.1-3              \n [91] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [93] jpeg_0.1-10                   sparseMatrixStats_1.12.2     \n [95] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [97] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [99] farver_2.1.1                  jsonlite_1.8.7               \n[101] BiocParallel_1.34.2           R.oo_1.25.0                  \n[103] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[105] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[107] Rhdf5lib_1.22.1               munsell_0.5.0                \n[109] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[111] viridis_0.6.4                 stringi_1.7.12               \n[113] leafsync_0.1.0                zlibbioc_1.46.0              \n[115] plyr_1.8.9                    parallel_4.3.1               \n[117] ggrepel_0.9.4                 deldir_1.0-9                 \n[119] Biostrings_2.68.1             stars_0.6-4                  \n[121] splines_4.3.1                 tensor_1.5                   \n[123] locfit_1.5-9.8                igraph_1.5.1                 \n[125] ScaledMatrix_1.8.1            XML_3.99-0.14                \n[127] BiocVersion_3.17.1            evaluate_0.22                \n[129] BiocManager_1.30.22           httpuv_1.6.11                \n[131] purrr_1.0.2                   polyclip_1.10-6              \n[133] rsvd_1.0.5                    lwgeom_0.2-13                \n[135] xtable_1.8-4                  e1071_1.7-13                 \n[137] RSpectra_0.16-1               later_1.3.1                  \n[139] viridisLite_0.4.2             class_7.3-22                 \n[141] tibble_3.2.1                  memoise_2.0.1                \n[143] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[145] cluster_2.1.4                 BiocStyle_2.28.1",
    "crumbs": [
      "Overview Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "03-imaging-multivar-ppSOD.html",
    "href": "03-imaging-multivar-ppSOD.html",
    "title": "Multitype point process",
    "section": "",
    "text": "Show the code\nsource(\"utils.R\")\n©2024 The pasta authors. Content is published under Creative Commons CC-BY-4.0 License for the text and GPL-3 License for any code.",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "03-imaging-multivar-ppSOD.html#dependencies",
    "href": "03-imaging-multivar-ppSOD.html#dependencies",
    "title": "Multitype point process",
    "section": "",
    "text": "Show the code\nsource(\"utils.R\")",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "03-imaging-multivar-ppSOD.html#setup",
    "href": "03-imaging-multivar-ppSOD.html#setup",
    "title": "Multitype point process",
    "section": "Setup",
    "text": "Setup\n\n\nShow the code\nspe &lt;- readRDS(\"../data/spe.rds\")\n\n#define the Z-stacks that you want to compare\nzstack_list &lt;- list(\"-0.09\", \"0.01\", \"0.21\")\n\n#define the celltype that you want to compare across the stacks - hereby we assume independence across the z-stacks which is an assumption that can be challenged\ncelltype_ls &lt;- \"OD Mature\"\n\nselectZstacks &lt;- function(zstack, spe){\n  sub &lt;- spe[, spe$sample_id == zstack]\n  pp &lt;- .ppp(sub, marks = \"cluster_id\")\n  return(pp)\n}\npp_ls &lt;- lapply(zstack_list, selectZstacks, spe)\nnames(pp_ls) &lt;- zstack_list\n\n\nThe theory of spatial point patterns is discussed in great detail in (Baddeley, Rubak, and Turner 2015). The book has an accompanying package called spatstat which offers great functionality to the theoretical concepts described in the book (Baddeley and Turner 2005). This chapter relies heavily on both publications.",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "03-imaging-multivar-ppSOD.html#concepts-and-definitions-of-point-processes",
    "href": "03-imaging-multivar-ppSOD.html#concepts-and-definitions-of-point-processes",
    "title": "Multitype point process",
    "section": "Concepts and Definitions of Point Processes",
    "text": "Concepts and Definitions of Point Processes\n\nPoint Process\nIn point pattern analysis we assume that the patterns we observe are a realisation of a stochastic process called a point process. The inferences we make about the point pattern are based on the point process. For example, if a pattern is created by a Poisson point process it will be evenly distributed in the observation window (Baddeley, Rubak, and Turner 2015, 127).\nWhen considering a pattern with \\(m\\) multiple types, as we do in the (Moffitt et al. 2018) dataset, there are two very closely related concepts. One can view the pattern as a multitype point pattern, where all the points are sampled from the same point process. The other option is to consider the pattern as a multivariate point pattern, where the points come from \\(m\\) distinct point processes. The difference between these two views is that in the multitype framework we assume the points to stem from the same point process. In the multivariate framework we assume that the types stem from distinct point processes and therefore we can consider dependencies of one type alone. Whether or not the patterns stem from the same point process depends on the biological question. If we analyse two cell types in one slice of a tissue, we should consider them as being sampled from one point process. However, if we consider the distribution of a cell type in two slices of the same tissue we can have grounds to consider them as distinct processes (Baddeley, Rubak, and Turner 2015, 564–65).\n\n\nObservation Windows\nThe most common set up in point pattern analysis is what we call window sampling. Instead of observing the entire pattern we observe a subset of this pattern in the so called window. An example could be different small microscopy windows through which a big tissue slice is observed. In this case, it would be wrong to assume the window to be the convex hull around the observed points because they are just a sample of the bigger point pattern (Baddeley, Rubak, and Turner 2015, 143–45).\nThere is another concept called the small world model. It assumes that points can only be observed in a finite small world and not beyond these boundaries. When thinking of an entire tissue, this is a very common scenario. Cells can only be observed within the tissue and not beyond. In this case, it would be correct to not assume a rectangular observation window but to use methods to estimate an unknown sampling window such as the Ripley-Rasson estimate of a spatial region (Baddeley, Rubak, and Turner 2015, 144–45; Ripley and Rasson 1977).\n\n\nShow the code\nsetRiprasWindows &lt;- function(pp){\n  Window(pp) &lt;- ripras(pp)\n  return(pp)\n}\n#the entire point patterns with the ripras windows\npp &lt;- lapply(pp_ls, setRiprasWindows)\n\nseparateMarks &lt;- function(pp){\n  #split the multitype point process into several single type processes\n  ppls &lt;- split(pp)\n  return (ppls)\n}\n#the point patterns separated by their marks\npp_ls &lt;- lapply(pp, separateMarks)\n\n\n\n\nComplete Spatial Randomness\nComplete spatial randomness (CSR) is often used as the null model for various point patterns. It is the result of a Poisson process. A completely spatial random process is characterised by two properties, homogeneity and independence, as discussed below (Baddeley, Rubak, and Turner 2015, 132).\n\nHomogeneity\n“Homogeneity […] means that the expected number of points falling in a region B should be proportional to its area |B|” (Baddeley, Rubak, and Turner 2015, 132) given a proportionality constant \\(\\lambda\\). The constant \\(\\lambda\\) represents the intensity of the process, i.e., the average number of points in a unit area (Baddeley, Rubak, and Turner 2015, 132–33). :\n\\[\n\\mathbb{E}[X\\cap B] = \\lambda |B|.\n\\label{eq:expected_number_points}\n\\]\n\n\nIndependence\nIndependence implies that in two (non-overlapping) regions \\(A\\) and \\(B\\), the number of points \\(n(X\\cap A)\\) and \\(n(X\\cap B)\\) are independent random variables. In other words, the number of points in region \\(A\\) does not affect the number of points in region \\(B\\). (Baddeley, Rubak, and Turner 2015, 133).\n\n\n\nInhomogeneous Poisson Process\nA Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the average density, \\(\\lambda(u)\\), sometimes known as the intensity function (see below), is a function of the spatial location \\(u\\). In this case, the expected number of points falling into a region \\(B\\), \\(\\mu = n(X\\cap B)\\), is an integration of the intensity function over that region (Baddeley, Rubak, and Turner 2015, 138).\n\\[\n\\mu = \\int_{B} \\lambda(u) du.\n\\label{eq:expected_number_inhomogeneous}\n\\]\n\n\nIsotropy\nA point process is called isotropic, if its statistical properties are invariant to rotations; a CSR process is both stationary and isotropic (Baddeley, Rubak, and Turner 2015, 147).\n\n\nStationarity\n“A point process is called stationary if, when we view the process through a window W , its statistical properties do not depend on the location of the window in two-dimensional space.” (Baddeley, Rubak, and Turner 2015, 146). This is the case for any homogeneous point process, where the statistical properties of the pattern are unchanged given shifting of the observation window. This means it is stationary in all statistical properties; first-order properties (e.g. intensity) and second-order properties (e.g. correlation) (Baddeley, Rubak, and Turner 2015, 218). Not all metrics assume stationarity in its full sense. Inhomogeneous metrics only assume second-order / correlation stationarity. That means while the intensity function can vary spatially (first-order stationarity is not given), the estimates of correlation functions (e.g. the inhomogeneous K-function) should be the same in parts of the window (Baddeley, Rubak, and Turner 2015, 689 ff.).\n\n\nLocal scaling\nIf a process is not correlation stationary, so the estimates of the inhomogeneous metric vary between locations, locally-scaled versions of the metric can be applicable. This means in subregions, the process is still stationary and isotropic, but there is a rescaling factor that can vary across the total process (Baddeley, Rubak, and Turner 2015, 246–47).\nWe can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimated functions between the quadrats. It should be noted that this test depends on the arbitrary definition of the quadrats. Given our chosen patterns are not independent but result as marks from an overall point-pattern, the permutation approach is questionable (Baddeley, Rubak, and Turner 2015, 689–93).\n\n\nShow the code\npermutation_test &lt;- function(pp, mark, split, minpoints) {\n  pp_sel &lt;-  subset(pp, marks %in% mark, drop = TRUE)\n  \n  rho_est &lt;- rhohat(unmark(pp_sel), \"x\", method=\"tr\")\n  lambda &lt;- predict(rho_est)\n\n  tesselation &lt;- quantess(unmark(pp_sel), \"x\", 3)\n  tesselation_split &lt;- nestsplit(pp_sel, tesselation, ny=split)\n  \n  plot(tesselation_split, main = mark)\n  \n  tesselation_split$inten &lt;- factor(as.integer(tesselation_split$f1) &lt;= 1, labels=c(\"Hi\",\"Lo\"))\n  \n  res.scaled &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kscaled,\n                 minpoints = minpoints)\n  \n  res.inhom &lt;- studpermu.test(tesselation_split, pts ~ inten, summaryfunction=Kinhom,\n                 lambda=lambda, minpoints = minpoints)\n  \n  #p-value of the local-scaling test\n  print(paste0(mark,' local scaling test ', res.scaled$p.value))\n  \n  #p-value of the inhomogeneity test\n  print(paste0(mark,' inhomogeneity test ', res.inhom$p.value))\n}\nlapply(c(\"Microglia\", \"OD Mature\", \"Ependymal\"), function(x) permutation_test(pp[['0.01']], x, split = 3, minpoints = 10))\n\n\nThe p-value of the test for local scaling for microglia cells is \\(&lt;0.05\\) which indicates that the assumption of local scaling is rejected. Therefore, the distribution of microglia cells is not a scaled version of an overall distribution pattern. The p-value of the test for inhomogeneity for both microglia cells is \\(&gt;0.05\\) indicating that the assumption of correlation stationarity is not rejected. In this case we can use the inhomogeneous version of the K-function which assumes correlation stationarity.\nFor ependymal and OD mature cells however, the p-values for both the local scaling test and the inhomogeneity test are \\(&gt;0.05\\) which means that for this choice of quadrats both the correlation stationarity assumption and the local scaling assumption can’t be rejected.\nAs the interpretation of the permutation test is highly dependent on the quadrats, the results should be interpreted with care. Both inhomogeneous and locally scaled versions of the summary functions have support and both offer interesting insights into the spatial pattern. Therefore, we will compare all versions and show what the choice of metrics means for their interpretation.\n\n\nIntensity\nIntensity is the expected density of points per unit area. It can be interpreted as the rate of occurrence or the abundance of events. The intensity represents a first order property because it is related to the expected number of points. More formally the average intensity of a point process is defined as:\n\\[\n\\bar{\\lambda} = \\frac{n(x)}{|W|}\n\\label{eq:average_intensity}\n\\]\nAs this is an average over the entire window, it is a good estimate for a homogeneous point process (Baddeley, Rubak, and Turner 2015, 157–60)\n\nEstimating Intensity\nFor a homogeneous point process, the intensity can be estimated in a simplistic way: summing the individual intensities of the marks (Baddeley, Rubak, and Turner 2015, 161).\n\n\nShow the code\nintensityPointProcess &lt;- function(pp,mark) if(mark) intensity(pp) else sum(intensity(pp))\n\nintensityPointProcess(pp_ls[['0.01']], mark = FALSE) %&gt;% round(6)\n\n\n[1] 0.001909\n\n\nOtherwise, we can compute the intensity for each mark individually.\n\n\nShow the code\nintensityPointProcess(pp_ls[['0.01']], mark = TRUE) %&gt;% round(8)\n\n\n  Ambiguous   Astrocyte Endothelial   Ependymal  Excitatory  Inhibitory \n 0.00024151  0.00020183  0.00014653  0.00008373  0.00036867  0.00061393 \n  Microglia OD Immature   OD Mature   Pericytes \n 0.00003031  0.00006249  0.00014278  0.00001750 \n\n\n\n\nKernel Estimation\nIn kernel estimation, we try to estimate the intensity function \\(\\lambda(u)\\) of the point process. There is a wide variety of kernel estimators (see (Baddeley, Rubak, and Turner 2015, 168)), but a popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth (Baddeley, Rubak, and Turner 2015, 168).\n\n\nShow the code\npp_sel &lt;-  subset(pp_ls[['0.01']]$`OD Mature`, drop = TRUE)\nDens &lt;- density(pp_sel, sigma = 100)\nplot(Dens, main = 'Kernel Density (OD Mature cells)')\n\n\n\n\n\n\n\n\n\n\n\nQuadrat Counting\nIn quadrat counting, all points falling into a given quadrat are counted. This gives an overview on the characteristics of the point pattern, such as correlation stationarity (Baddeley, Rubak, and Turner 2015, 163).\n\n\nShow the code\nQ5 &lt;- quadratcount(pp_ls[['0.01']], nx=8, ny=8)\nplot(unmark(pp[['0.01']]), main='Unmarked Point Pattern Quadrats')\nplot(Q5, col='black', add=TRUE)\n\n\nUnder independence assumptions, the quadrat counts can be used for testing homogeneity, i.e., whether the points are distributed evenly across the quadrats (Baddeley, Rubak, and Turner 2015, 164–65).\n\n\nShow the code\nval &lt;- quadrat.test(pp_ls[['0.01']]$`OD Mature`, 5, alternative=\"regular\", method=\"MonteCarlo\")\nval\n\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nX2 = 635.09, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 25 tiles (irregular windows)\n\n\nA p-value of 1 indicates that the null hypothesis of irregularity can not be rejected strongly. Thus, the point pattern of oligodendrocyts is strongly irregular.\nAlternatively, we can inspect departures from the hypothesis that points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the relrisk function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types (Buller 2020).\n\n\nShow the code\n# select marks\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\npp_sel &lt;-  subset(pp[['0.01']], marks %in% selection, drop = TRUE)\n\nf1 &lt;- pValuesHotspotMarks(pp_sel)\n\n# Plot significant p-values\nplot(f1$p, main = \"Significant difference\\n to Poisson process alpha = 0.05\")\n\n\n\n\n\n\n\n\n\n\n\n\nTesting for CSR\nWhether or not a point process is completely spatially random (CSR) depends on two characteristics: points need to be distributed homogeneously and they have to be independent of each other (see definitions above). There are various ways to test for CSR, here we show the use-case of the clark-evans test (Baddeley, Rubak, and Turner 2015, 165–66).\n\n\nShow the code\nclarkevans.test(pp_ls[['0.01']]$`OD Mature`)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  pp_ls[[\"0.01\"]]$`OD Mature`\nR = 0.77286, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "03-imaging-multivar-ppSOD.html#multitype-and-multivariate-viewpoint",
    "href": "03-imaging-multivar-ppSOD.html#multitype-and-multivariate-viewpoint",
    "title": "Multitype point process",
    "section": "Multitype and Multivariate viewpoint",
    "text": "Multitype and Multivariate viewpoint\nA pattern with multiple type of points, e.g. cell types, can be seen in different ways. One the one hand, the multitype approach assumes that the points \\(x\\) were recorded together with with their labels \\(m\\) and that they were generated at the same time. The locations and labels therefore have a joint distribution \\(P(X,M)\\). On the other hand one can assume that the pattern with multiple types of points is a combination of several distinct point patterns, one for each type of point. This is the multivariate approach and the different point patterns \\(A\\) and \\(B\\) form a joint distribution \\(P(A,B)\\). To test if the labels depend on the location one can assume the following null hypotheses (Baddeley, Rubak, and Turner 2015, 565–67):\n\ncomplete spatial randomness and independence (CSRI): the points are distributed at random; the type of each points is randomly allocated; independence between points of different types; allocation of the types independently of the other points and of its location.\nrandom labeling: each point is assigned a type at random independently of its location\nindependence of components: the points of different types are independent of each other.\n\nApart from CSRI is is also important for the analysis if we can assume stationarity, i.e. the statistical properties of the point pattern do not change in the window.\nFor simplicity, we will focus on three cell types of our point pattern: Ependymal, OD Mature and Microglia. \n\n\nShow the code\nmarks(pp) &lt;- factor(marks(pp))\nselection &lt;- c('OD Mature', 'Ependymal', 'Microglia')\nfov_sel &lt;- c('0.01')\n\npp_sel &lt;-  subset(pp, marks %in% selection, drop = TRUE)\nspe_sel &lt;- spe[, spe$sample_id == \"0.01\" &  spe$cluster_id %in% selection]\n\n\nWe select on fov, which corresponds to one cut in the frontal plane.\n\n\nShow the code\npp_sel |&gt; as.data.frame() |&gt; \n  ggplot(aes(x = x, y = y, color = marks)) +\n  geom_point() +\n  theme_minimal() +\n  coord_fixed() +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\nThe summary of pp (point pattern) object returns general properties, plus intensities, combined and per mark type.\n\n\nShow the code\nsummary(pp)\n\n\nMarked planar point pattern:  6111 points\nAverage intensity 0.001906561 points per square unit\n\nCoordinates are given to 4 decimal places\n\nMultitype:\n            frequency  proportion    intensity\nAmbiguous         773 0.126493200 2.411670e-04\nAstrocyte         646 0.105711000 2.015445e-04\nEndothelial       469 0.076746850 1.463225e-04\nEpendymal         268 0.043855340 8.361288e-05\nExcitatory       1180 0.193094400 3.681463e-04\nInhibitory       1965 0.321551300 6.130571e-04\nMicroglia          97 0.015873020 3.026287e-05\nOD Immature       200 0.032727870 6.239767e-05\nOD Mature         457 0.074783180 1.425787e-04\nPericytes          56 0.009163803 1.747135e-05\n\nWindow: rectangle = [1222.5635, 3012.4248] x [-3993.535, -2202.755] units\n                    (1790 x 1791 units)\nWindow area = 3205250 square units\n\n\nTo get the overall intensity the individual intensities can be summed up. Assuming that the the multitype process is first order stationary (i.e. each sub-process is stationary) the individual intensities sum up to the intensity of the unmarked point process (Baddeley, Rubak, and Turner 2015, 574ff.).\n\n\nShow the code\nsum(intensity(pp)) == intensity(unmark(pp))\n\n\n[1] TRUE\n\n\nThe stationarity assumption is not appropriate in all cases. To assess first-order stationarity visually, we can plot the kernel density estimates per type.\n\n\nShow the code\nppls &lt;- split(pp_sel) # split by mark\nplot(density(ppls))\n\n\n\n\n\n\n\n\n\nEpendymal and OD Mature cells are cleary inhomogeneous, while for Microglia cells it is not so clear and we could assume homogeneity, especially because the window is larger than the tissue and there is a tissue border in the bottom middle.\nTo further inverstiagte the spatial arrangement of the different cell types we can calculate the relative risk, i.e., the probability of observing a given celltype at a given location. It is calculated using the function relrisk. The bandwidth for smoothing is calculated with bw.relrisk and might need to be adjusted (Baddeley, Rubak, and Turner 2015, 577–83).\nThe relrisk function further gives us the dominant mark for different regions of the tissue of interest. This could be interesting in the annotation of spatial domains. It indicates at each location, which cell type is most likely to occur.\n\n\nShow the code\nrpd &lt;- relrisk(pp_sel, diggle = TRUE)\ndom &lt;- im.apply(rpd, which.max)\ndom &lt;- eval.im(factor(dom, levels = seq_along(levels(unique(marks(pp_sel)))),\n                      labels = levels(unique(marks(pp_sel)))))\nplot(dom,las=2,main=\"Dominant mark\")",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "03-imaging-multivar-ppSOD.html#nearest-neighbourhood-contingency",
    "href": "03-imaging-multivar-ppSOD.html#nearest-neighbourhood-contingency",
    "title": "Multitype point process",
    "section": "Nearest neighbourhood contingency",
    "text": "Nearest neighbourhood contingency\nTo further investigate the spatial distribution of the marks we can investigate the nearest neighbourhood of each cell type. One possibility is to work with nearest neighborhood contingency tables developed by (Dixon 2002). The statistical tests are implemented in the R package dixon (de la Cruz 2008).\nThe measure of segregation \\(S\\) is defined in (Dixon 2002) as\n\\[S_{i,j}= \\frac{\\log[(N_{i,j}/(N_i−N_{i,j})]}{[(N_i−1)/(N−N_i)]}\\] where \\(N_i\\) is the number of individuals \\(i\\), \\(N_{i,j}\\) is the number of individuals of type \\(i\\) with a nearest neighbor of type \\(j\\), and \\(N\\) is the total number of individuals.\nA value of \\(S=0\\) is consistent with random labeling. A value larger than 0 indicates that the two types are more segregated than expected by chance, the larger the value the more segregated. Note that segregated means that it is more likely to expect a neigbour of type \\(j\\) than by chance. In the case that the neigbour is of the same type this is equivalent to “attraction” of the types. On the other hand if \\(S&lt;0\\) it indicates that type \\(j\\) is less likely to be a neigbour than by chance. The P-values are calculated using expected numbers of nearest neighbors under the null hypothesis of random labeling using a Monte-Carlo simulation and assumes an asymptotic \\(\\chi^2\\) distribution.\n\n\nShow the code\nout &lt;- dixon(as.data.frame(pp_sel), nsim = 99)\n\n\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\n\nShow the code\nout$tablaZ %&gt;% \n  arrange(desc(abs(`Z `))) %&gt;%\n  select(-`  p-val.Nobs`)\n\n\n       From        To     Obs.Count     Exp. Count    S      Z    p-val.Z\n1 Ependymal Ependymal           262          87.16  1.96  20.04    0.0000\n2 Ependymal OD Mature             3         149.18 -2.04 -16.87    0.0000\n3 OD Mature Ependymal             8         149.18 -1.43 -14.26    0.0000\n4 OD Mature OD Mature           380         253.83  0.60  11.43    0.0000\n5 Ependymal Microglia             3          31.66 -1.07  -5.66    0.0000\n6 Microglia Ependymal             9          31.66 -0.68  -4.92    0.0000\n7 Microglia OD Mature            67          53.99  0.25   2.60    0.0094\n8 Microglia Microglia            21          11.34  0.32   2.50    0.0124\n9 OD Mature Microglia            69          53.99  0.12   2.35    0.0190\n\n\nIn this table we see that most Ependymal cells are very clustered, while Microglia are more evenly distributed. Further we see that it is less likely to find a Ependymal cells next to a OD mature cells than by chance.\nOD Mature cells show this interesting characteristic that they are clustered in some parts of the tissue and more evenly distributed in other parts of the tissue. This characteristic is not visible in the table. The statistic also considers only the nearest neighbour and ignores neighbours that are further away.",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "03-imaging-multivar-ppSOD.html#summary-functions-for-pairs-of-types",
    "href": "03-imaging-multivar-ppSOD.html#summary-functions-for-pairs-of-types",
    "title": "Multitype point process",
    "section": "Summary functions for pairs of types",
    "text": "Summary functions for pairs of types\nSimilar to the simple case without marks, it is possible to estimate summary functions. In particular, summary functions between different marks can be calculated. Note that the canonical functions assume that the multi-type process is stationary.\n\nCross K-function\nThe cross K-function is a summary function that measures the average number of points of type j within a distance r of a point of type i. The formula is given by:\n\\[\nK(r) = \\frac{1}{\\lambda_j} \\mathbb{E} [t(u,r,X^{j})|u \\in X^{i}],\n\\]\nwhere \\(X^{i}\\) is the point pattern of type \\(i\\) and \\(t(u,r,X^{j})\\) is the number of points of type \\(j\\) in a circle of radius \\(r\\) around \\(u\\) (Baddeley, Rubak, and Turner 2015, 594–95). It is important to remember that the homogeneous cross K-function assumes that the multitype process is stationary. If this is not the case, there is a risk in misinterpreting the results. The problem is the confounding between clustering and inhomogeneity, c.f. (Baddeley, Rubak, and Turner 2015, 151–52)\nFirst, we plot an overview over the cross K function for the different types. As we have seen before the assumption of stationarity might be not valid. We will therefore use the inhomogeneous version of the cross K function.\n\n\nShow the code\nresCross &lt;- calcCrossMetricPerFov(\n  spe,\n  selection = c(\"OD Mature\", \"Ependymal\", \"Microglia\"),\n  subsetby = 'sample_id',\n  fun = 'Kcross.inhom',\n  marks = 'cluster_id',\n  r_seq = seq(0, 500, length.out = 100),\n  by = c('Animal_ID', 'sample_id')\n)\n\n\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n\n\nShow the code\nresCross &lt;- subset(resCross, sample_id %in% fov_sel)\nplotCrossMetricPerFov(resCross, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\nThe diagonal of the inhomogeneous cross K-function plot shows the K-function for the different marks (indication of Poisson or non-Poisson point processes). Off-diagonal panels give indication of independence of points when the number of points follows the expected K-function but does not imply that the individual marks follow a Poisson process. If the processes of the types are independent, we assume that they are also uncorrelated.\nIn the example above, assuming that the process is inhomogeneous, the Ependymals cells appear to be regularly spaced, which seems counter intuitive. However, this is the result of the pattern being inhomogeneous with spatially varying intensity. When accounting for this, the pattern is more regular than expected under an inhomogeneous point process. The estimation of the inhomogeneous cross functions is not straightforward and results change based on the estimation of the local intensity and the edge correction, c.f. (Baddeley, Rubak, and Turner 2015, 605).\nLet’s focus a bit more on the relationship between Ependymal and the other two cell types. We will also calculate confidence intervals for the different cross K-functions. We have already seen that our dataset most likely does not satisfy the assumption of stationarity. For this reason, we will calculate the inhomogeneous cross K-function. Note that the option to calculate confidence intervals is not yet implemented in spatialFDA.\n\n\n\n\n\n\n\n\n\nRemember that the dashed line represents the assumption of a multitype Poisson process. If the line lies above the dotted line, there is indication of attraction while if the line is below the dotted line there is indication of repulsion. In the plot above we can see that there is indication of attraction between Ependymal and OD Mature cells while there is indication of repulsion between Ependymal and Microglia cells.\n\n\nCross L-function\nAlternatively the L cross function with similar interpretation can be calculated using the Lcross function (Baddeley, Rubak, and Turner 2015, 596ff).\n\n\nShow the code\nresCross &lt;- calcCrossMetricPerFov(\n  spe,\n  selection = c(\"OD Mature\", \"Ependymal\", \"Microglia\"),\n  subsetby = 'sample_id',\n  fun = 'Lcross.inhom',\n  marks = 'cluster_id',\n  r_seq = seq(0, 500, length.out = 100),\n  by = c('Animal_ID', 'sample_id')\n)\n\n\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n&lt;simpleError: Weights in K-function were infinite or NA&gt;\n\n\nShow the code\nresCross &lt;- subset(resCross, sample_id %in% fov_sel)\nplotCrossMetricPerFov(resCross, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\nMark connection function\nThe mark connection function is the cross pair-correlation function, i.e. the generalization of the pair correlation function to a multitype point processes, divided by the unmarked pair-correlation function. It can be interpreted as the conditional probability that two points a distance \\(r\\) apart have labels of type \\(i\\) and of type \\(j\\), given the presence of those points (Baddeley, Rubak, and Turner 2015, 596–97).\n\n\nShow the code\nplotCrossAll(pp_sel, \"markconnect\", \"iso\") + \n  scale_y_continuous(limits = c(0, 1))\n\n\n\n\nShow the code\nresCross &lt;- calcCrossMetricPerFov(\n  spe = spe_sel,\n  selection = c(\"OD Mature\", \"Ependymal\", \"Microglia\"),\n  subsetby = 'sample_id',\n  fun = 'markconnect',\n  marks = 'cluster_id',\n  r_seq = seq(0, 500, length.out = 100),\n  by = c('Animal_ID', 'sample_id')\n)\n\n#resCross &lt;- subset(resCross, sample_id %in% fov_sel)\nplotCrossMetricPerFov(resCross, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\nThe dashed lines indicate expected values under random labeling. The values measure dependence (or association) between the different labelled points. Positive values indicate that nearby points are more likely to have different types than expected by chance. This positive association between different cell types does not necessarily imply dependence, as it could be influenced by a negative association between cells of the same type, as it it could be the case for the Microglia cells. Furthermore, as the calculation is based on the \\(K\\) function, the mark connection function assumes homogenity.\n\n\nCross F-function (empty space function), cross G-function (Nearest-neighbor function) and cross J-function\nThe cross F-function is the cumulative distribution function of the distance from a location to the nearest point of the same type. For each type \\(i\\), it is defined as:\n\\[F_i(r) = \\mathbb{P}\\{d(u,X^{i}\\leq r\\}.\\]\nThe cross G-function is the cumulative distribution function of the distance from a location to the nearest point of another type and is defined as:\n\\[G_{ij}(r) = \\mathbb{P}\\{d(x,X^{(j)} \\setminus u \\leq r \\mid X^{(i)} \\ \\text{has a point at u}).\\]\nIf the points are independent of each other, the G and F function are identical. Both assume that the process is stationary. There are inhomogenous alternatives, in case the intensity is varying. Then we only assume correlation stationarity.\nThere exists a difference in the interpretation of the theoretical values of the K-cross and the G-cross function. For the K-cross, the theoretical value indicates independence between marks while for the G-cross the theoretical value is consistent with the assumption that the points of type j are Poisson in addition to being independent of the points of type \\(i\\) (Baddeley, Rubak, and Turner 2015, 597 ff).\nThe cross J-function is defined as:\n\\[J_{ij}(r) = \\frac{1-G_{ij}(r)}{1-F_{j}(r)}\\]\nand summarizes the interpoint dependence between type \\(i\\) and \\(j\\). Under the hypothesis of independent components, i.e., that the point processes of each type are independent, the G-function is equivalent to the F-function and the J-function is equal to 1 (Baddeley, Rubak, and Turner 2015, 597 ff).\n\n\n\n\n\n\n\n\n\n\nDot functions\nFor each K-, G- and J- function, there also exist dot functions, which measure distances from points of one type to points of any type. These functions allow us to measure the dependence of one mark with all other marks at once. For expample, the K-dot function represents the expected number of an other point within distance \\(r\\) of a typical point of type \\(i\\) (Baddeley, Rubak, and Turner 2015, 600 ff).\n\n\nShow the code\nplotCrossAll(pp_sel, \"Kdot.inhom\", \"iso\")\n\n\n\n\nShow the code\nresCross &lt;- calcCrossMetricPerFov(\n  spe,\n  selection = c(\"OD Mature\", \"Ependymal\", \"Microglia\"),\n  subsetby = 'sample_id',\n  fun = 'Kdot',\n  marks = 'cluster_id',\n  r_seq = seq(0, 500, length.out = 100),\n  by = c('Animal_ID', 'sample_id')\n)\n\n\n[1] \"OD Mature\"\n&lt;simpleWarning in Kdot(X = structure(list(window = structure(list(type = \"rectangle\",     xrange = c(-3035.012264, -1242.450271), yrange = c(2820.324434,     4609.586219), units = structure(list(singular = \"unit\", plural = \"units\",         multiplier = 1), class = \"unitname\")), class = \"owin\"),     n = 330L, x = c(-2948.588648, -2897.57708, -2869.656103,     -2891.24141, -2853.006718, -3010.277574, -2971.954101, -2904.677092,     -2887.791265, -2851.791437, -2849.074748, -2888.740698, -3001.803085,     -2950.421434, -2909.636307, -2891.839974, -2993.495947, -3013.524167,     -2979.043681, -2942.557256, -2916.580302, -2942.573152, -2870.153308,     -3014.760719, -2965.791655, -2997.982094, -2915.058426, -2971.194414,     -2777.493667, -2705.709586, -2700.426346, -2652.577315, -2722.280767,     -2696.287446, -2652.228644, -2647.736406, -2696.29761, -2727.428433,     -2728.429955, -2686.017141, -2673.563985, -2694.412134, -2668.909929,     -2830.438634, -2695.535222, -2745.565611, -2682.19967, -2833.931051,     -2762.727439, -2728.982509, -2676.243835, -2774.560203, -2810.140797,     -2784.815473, -2707.84147, -2667.451079, -2664.998593, -2750.028718,     -2827.729711, -2736.182561, -2696.16138, -2504.201919, -2548.19189,     -2624.044011, -2593.025973, -2532.743363, -2488.007598, -2591.692045,     -2499.152178, -2496.629962, -2526.047305, -2523.765679, -2461.582417,     -2602.590931, -2581.537901, -2516.877432, -2628.696367, -2622.64497,     -2622.246798, -2613.625969, -2609.644597, -2608.181092, -2599.903422,     -2592.779881, -2583.948804, -2583.539748, -2569.169882, -2521.698539,     -2522.350268, -2505.718266, -2503.069553, -2478.307907, -2467.6025,     -2466.025129, -2462.221525, -2450.735643, -2484.995191, -2548.471308,     -2527.003744, -2624.620707, -2387.26222, -2377.046714, -2408.671885,     -2388.248919, -2371.718117, -2400.23381, -2428.068384, -2353.874704,     -2381.315461, -2274.867703, -2390.174816, -2226.145481, -2050.582732,     -2203.809148, -2133.914786, -2212.342478, -2205.192536, -2205.596189,     -2201.984075, -2198.864461, -2188.68064, -2181.834842, -2170.400812,     -2169.690486, -2166.254113, -2160.46512, -2154.268849, -2153.373917,     -2138.725275, -2133.493169, -2113.480705, -2114.05935, -2100.910119,     -2093.056651, -2091.011138, -2081.636, -2080.731905, -2077.984034,     -2075.830594, -2072.56278, -2048.586667, -2113.746816, -2111.550558,     -2086.316319, -2056.815762, -2053.144007, -2191.755348, -2152.649342,     -2144.33852, -2101.243137, -2071.091963, -2193.416918, -1997.291817,     -1927.184001, -1894.825623, -1877.58193, -1965.694727, -1887.452165,     -1881.639719, -1962.893407, -1865.000144, -1930.817334, -1864.038162,     -2015.35057, -1988.84309, -1987.89471, -1978.128122, -1938.633242,     -1889.08222, -1870.046028, -2012.379259, -2006.53979, -1964.164552,     -1932.265108, -1910.782552, -1905.466485, -1873.323675, -1911.294723,     -1724.780357, -1721.007625, -1678.709103, -1678.387408, -1686.465555,     -1765.453122, -1708.799512, -1712.155819, -1663.10485, -1674.102591,     -1700.476631, -1795.004844, -1697.856433, -1668.806815, -1803.098029,     -1792.569437, -1786.286675, -1776.054993, -1755.874682, -1743.991335,     -1726.337292, -1696.10723, -1688.327886, -1674.271414, -1649.46646,     -1830.313555, -1694.881055, -1685.624107, -1727.650791, -1690.405684,     -1812.951339, -1803.781844, -1790.415442, -1784.018361, -1780.136391,     -1780.268901, -1775.885117, -1749.007922, -1745.847979, -1743.063749,     -1726.660223, -1693.600276, -1689.141444, -1675.739132, -1664.511233,     -1659.870135, -1648.112164, -1690.610776, -1793.166854, -1697.788483,     -1676.44659, -1650.296953, -1789.7932, -1706.819991, -1662.406809,     -1615.650595, -1605.177957, -1602.529167, -1592.058585, -1573.057787,     -1569.804767, -1564.214192, -1551.827367, -1511.595991, -1603.712842,     -1590.971353, -1546.159478, -1544.921424, -1525.143847, -1487.659978,     -1574.386694, -1505.388734, -1615.835468, -1581.025504, -1581.462525,     -1576.829273, -1565.313123, -1565.21983, -1611.277761, -1605.427875,     -1599.540292, -1579.82756, -1566.308811, -1509.328217, -1581.126602,     -1532.077601, -1616.556592, -1529.38126, -1478.284952, -1529.979598,     -1517.208185, -1536.40972, -1503.753746, -1632.208867, -1629.323804,     -1619.558297, -1556.804559, -1512.797886, -1498.402708, -1470.052083,     -1459.861512, -1402.276493, -1396.145301, -1314.961563, -1406.221183,     -1272.161465, -1340.028868, -1394.781083, -1357.697515, -1340.224204,     -1292.966101, -1291.968755, -1389.667817, -1404.535662, -1340.309407,     -1416.89511, -1333.905108, -1316.763197, -1295.85602, -1250.712018,     -1292.58811, -1373.066236, -1283.369355, -1271.450575, -1266.981863,     -1395.509992, -1359.589533, -1430.799589, -1281.437757, -1344.877437,     -1276.351606, -1343.149557, -1419.950009, -2841.209074, -2644.259827,     -2643.69724, -2639.769058, -2637.359732, -2635.277076, -2581.88169,     -2416.209518, -2214.633261, -2050.116742, -1641.450665, -1834.650755,     -1727.594083, -1639.475301, -1640.007241, -1577.979884, -1554.816016,     -1439.151853, -1434.588352), y = c(2835.768383, 2875.669847,     2948.229483, 2843.552431, 2855.166397, 3164.341178, 3163.589689,     3206.256229, 3119.59291, 3152.037516, 3079.129589, 3136.041864,     3359.197613, 3275.093089, 3303.010553, 3284.828044, 3226.153905,     3522.723196, 3529.882938, 3600.703083, 3549.700718, 3693.19986,     3676.155387, 4030.151175, 4130.690415, 4313.0572, 4465.901528,     4500.767216, 4440.646041, 4536.866798, 4456.594788, 4545.091597,     4519.838812, 4448.325096, 4603.144283, 4478.351401, 4473.058113,     4597.291869, 4591.912034, 4443.648231, 4606.313836, 4575.335564,     4453.60095, 4078.588959, 4207.565574, 3836.29171, 3679.773345,     3555.017771, 3435.990569, 3498.863633, 3449.436989, 3545.805157,     3244.198876, 3342.16202, 3246.745027, 3402.469467, 3302.340493,     3391.479877, 3203.352345, 3056.727567, 3024.14462, 2891.54081,     2908.026178, 3267.141301, 3278.748286, 3530.591294, 3461.369411,     3726.31803, 3674.495736, 3921.850861, 4373.473106, 4406.869954,     4381.736425, 4235.158056, 4388.333718, 4387.255086, 4420.520191,     4566.340641, 4575.055469, 4469.78641, 4440.323399, 4547.764771,     4508.04966, 4474.9182, 4472.475054, 4597.312847, 4449.857658,     4434.374512, 4504.111755, 4536.325595, 4586.123853, 4464.732421,     4564.902567, 4600.052072, 4512.815431, 4565.600833, 4494.423598,     4441.756616, 4564.44851, 4435.734983, 4509.86677, 4558.178418,     4355.224017, 4357.495516, 4263.549852, 4200.53303, 4105.754506,     4162.514271, 4196.380751, 3826.325709, 3512.282745, 3439.620227,     3662.796772, 4180.678296, 4155.173709, 4339.705654, 4250.440963,     4291.456064, 4276.492436, 4264.710077, 4325.311288, 4322.00383,     4299.989196, 4345.27344, 4334.769063, 4262.122977, 4231.426482,     4333.352374, 4289.159685, 4268.312473, 4292.60158, 4322.26525,     4267.616377, 4264.201252, 4353.534494, 4324.716751, 4284.672823,     4233.788766, 4315.859019, 4291.396787, 4228.866223, 4349.820328,     4235.399399, 4331.398266, 4356.028053, 4266.70718, 4291.559249,     4248.905388, 4232.109364, 4297.501244, 4327.828693, 4339.247729,     4470.757466, 4481.461776, 4536.60647, 4443.20883, 4563.133146,     4511.454778, 4453.436315, 4508.498938, 4588.46565, 4442.970837,     4462.979794, 4302.229293, 4264.182122, 4247.036257, 4278.63612,     4253.038014, 4396.842054, 4291.082779, 4182.015141, 4201.462222,     4205.895258, 4115.78863, 4040.597709, 3769.537019, 2952.121616,     2982.064466, 2968.294008, 2856.142242, 2845.305802, 2956.50451,     2932.266683, 3149.4759, 3055.060419, 3256.318748, 3289.553561,     3281.203782, 3608.616167, 3978.457672, 4089.040147, 4200.543477,     4373.22094, 4340.295201, 4337.945368, 4287.982459, 4320.276062,     4356.900213, 4358.287614, 4352.440736, 4358.53312, 4260.305943,     4372.732153, 4384.356861, 4235.319511, 4329.236487, 4238.609518,     4346.793865, 4470.073025, 4432.745015, 4477.595025, 4457.240233,     4514.699451, 4477.885773, 4453.830857, 4495.541361, 4437.7741,     4582.007973, 4434.900081, 4536.46749, 4518.239437, 4429.185128,     4537.82398, 4485.330097, 4528.331239, 4509.271887, 4514.792449,     4471.367195, 4452.771376, 4545.340296, 4447.432351, 4541.433353,     4450.252368, 4486.47381, 4544.317978, 4573.904384, 4547.850315,     4608.27241, 4537.341946, 4591.899558, 4448.184792, 4555.98108,     4446.71009, 4497.636344, 4505.808874, 4514.294625, 4586.857206,     4597.682458, 4442.396086, 4541.705664, 4583.234706, 4470.846389,     4530.388419, 4456.692326, 4544.021902, 4578.300394, 4314.034808,     4394.325312, 4362.082783, 4341.885911, 4361.914805, 4409.478619,     4193.339064, 4085.75337, 3651.472679, 3445.918756, 3424.976685,     3374.467451, 3399.351568, 3347.002523, 3243.50162, 3189.17197,     3076.263691, 2872.286101, 2894.178291, 2934.592506, 2980.918672,     2905.627809, 3003.508061, 2835.013182, 2854.482881, 2996.671785,     2855.183296, 2967.095426, 2978.217875, 3202.229051, 3155.119982,     3112.528353, 3060.145818, 3020.849459, 3040.192509, 3086.634439,     3123.015574, 3249.282971, 3395.012925, 3351.869929, 3262.627213,     3405.862712, 3237.107675, 3529.319871, 3556.309906, 3583.396021,     3506.982802, 3686.680304, 3923.837035, 3877.275304, 4149.979278,     4353.442328, 4306.131126, 4440.139228, 4565.624204, 3452.244101,     4485.295487, 4559.048569, 4269.735255, 4377.596222, 3404.738948,     4416.37055, 4416.756402, 4208.629329, 4214.600924, 3514.966271,     4248.751093, 4408.22055, 4341.648892, 4568.999682, 4412.646676,     4406.541082, 3248.74563, 4294.518844), markformat = \"vector\",     marks = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,     1L, 1L, 1L, 1L, 1L), levels = \"OD Mature\", class = \"factor\")), class = \"ppp\"),     r = c(0, 5.05050505050505, 10.1010101010101, 15.1515151515152,     20.2020202020202, 25.2525252525253, 30.3030303030303, 35.3535353535353,     40.4040404040404, 45.4545454545455, 50.5050505050505, 55.5555555555556,     60.6060606060606, 65.6565656565656, 70.7070707070707, 75.7575757575758,     80.8080808080808, 85.8585858585859, 90.9090909090909, 95.959595959596,     101.010101010101, 106.060606060606, 111.111111111111, 116.161616161616,     121.212121212121, 126.262626262626, 131.313131313131, 136.363636363636,     141.414141414141, 146.464646464646, 151.515151515152, 156.565656565657,     161.616161616162, 166.666666666667, 171.717171717172, 176.767676767677,     181.818181818182, 186.868686868687, 191.919191919192, 196.969696969697,     202.020202020202, 207.070707070707, 212.121212121212, 217.171717171717,     222.222222222222, 227.272727272727, 232.323232323232, 237.373737373737,     242.424242424242, 247.474747474747, 252.525252525253, 257.575757575758,     262.626262626263, 267.676767676768, 272.727272727273, 277.777777777778,     282.828282828283, 287.878787878788, 292.929292929293, 297.979797979798,     303.030303030303, 308.080808080808, 313.131313131313, 318.181818181818,     323.232323232323, 328.282828282828, 333.333333333333, 338.383838383838,     343.434343434343, 348.484848484848, 353.535353535354, 358.585858585859,     363.636363636364, 368.686868686869, 373.737373737374, 378.787878787879,     383.838383838384, 388.888888888889, 393.939393939394, 398.989898989899,     404.040404040404, 409.090909090909, 414.141414141414, 419.191919191919,     424.242424242424, 429.292929292929, 434.343434343434, 439.393939393939,     444.444444444444, 449.49494949495, 454.545454545455, 459.59595959596,     464.646464646465, 469.69696969697, 474.747474747475, 479.79797979798,     484.848484848485, 489.89898989899, 494.949494949495, 500)): input string '&lt;b7&gt;' cannot be translated to UTF-8, is it valid in 'ANSI_X3.4-1968'?&gt;\n[1] \"Ependymal\"\n[1] \"Microglia\"\n\n\nShow the code\nresCross &lt;- subset(resCross, sample_id %in% fov_sel)\nplotMetricPerFov(resCross, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id', ID = \"ID\")\n\n\n\n\n\n\n\n\n\nThe dot functions are useful summary statistics to analyse the dependence of one mark with all other marks.",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "03-imaging-multivar-ppSOD.html#summary-function-within-and-between-types",
    "href": "03-imaging-multivar-ppSOD.html#summary-function-within-and-between-types",
    "title": "Multitype point process",
    "section": "Summary function within and between types",
    "text": "Summary function within and between types\nIn our original dataset, we have a large number of different marks. We picked three: OD mature, Ependymal and Microglia for illustrative purposes. An alternative to looking at all cross summary function combinations, it is possible to compare between and within types (Baddeley, Rubak, and Turner 2015).\n\nMark equality function\nThe Mark or Type Equality function for a stationary multitype point process measures the correlation between types of two points separated by distance r. It is the sum of the mark connection function of all pairs of points of the same type.\nIf k &lt; 1, points at distance r are less likely than expected to be of the same type. If &gt; 1, they are more likely to be of the same type. The value 1 indicates a lack of correlation (Baddeley, Rubak, and Turner 2015, 603 ff).\n\n\nShow the code\nresCross &lt;- calcMetricPerFov(\n  spe,\n  selection = c(\"OD Mature\", \"Ependymal\", \"Microglia\"),\n  subsetby = 'sample_id',\n  fun = 'markcorr',\n  marks = 'cluster_id',\n  r_seq = seq(0, 500, length.out = 100),\n  by = c('Animal_ID', 'sample_id')\n)\n\nresCross &lt;- subset(resCross, sample_id %in% fov_sel)\nplotMetricPerFov(resCross, theo = TRUE, correction = \"iso\", x = \"r\", image_id = 'sample_id')\n\n\n\n\n\n\n\n\n\nWe can see that in our dataset that it the more likely it is to find points of the same type at shorter distances. The curve never crosses the dashed line at 1, which means that it is generally more likely to find points of the same type at any distance than expected by chance.",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "03-imaging-multivar-ppSOD.html#testing-random-labelling",
    "href": "03-imaging-multivar-ppSOD.html#testing-random-labelling",
    "title": "Multitype point process",
    "section": "Testing random labelling",
    "text": "Testing random labelling\nThe random labeling test is most logical when the marks represents its status, which is not most appropriate assumption when considering cell types. Testing for random labeling can be done using permutation test, in which the labels are randomly permuted. Random labeling can be assumed if the permuted datasets are statistically equivalent to the original dataset (Baddeley, Rubak, and Turner 2015, 609 ff).",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "03-imaging-multivar-ppSOD.html#testing-the-indepenence-of-components-assumption",
    "href": "03-imaging-multivar-ppSOD.html#testing-the-indepenence-of-components-assumption",
    "title": "Multitype point process",
    "section": "Testing the indepenence of components assumption",
    "text": "Testing the indepenence of components assumption\nThe i-to-j functions are useful to test the independence of different subprocesses. If the processes of type i and j are independent, then \\(K_{ij} = \\pi r^2, G_{ij}(r) = F_{j}(r),  J_{ij}(r) \\equiv 1\\). Alternatively, randomization tests can be used in which simulated patterns from the dataset are generated and randomly split into subpatterns. These are then compared to the null hypothesis in which all subpatterns should be statistically equivalent to the original. However, this approach assumes stationarity and there is a need to handle edge effects (Baddeley, Rubak, and Turner 2015, 606 ff).",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "03-imaging-multivar-ppSOD.html#session-info",
    "href": "03-imaging-multivar-ppSOD.html#session-info",
    "title": "Multitype point process",
    "section": "Session info",
    "text": "Session info\n\n\nShow the code\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-16                      reshape2_1.4.4                \n[19] patchwork_1.2.0                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.5.1                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0              spatialFDA_0.99.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.9-1                    rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.3.0                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] fftwtools_0.9-11              spatstat.utils_3.0-5         \n [87] rmarkdown_2.25                XVector_0.40.0               \n [89] base64enc_0.1-3               htmltools_0.5.6.1            \n [91] pkgconfig_2.0.3               sparseMatrixStats_1.12.2     \n [93] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [95] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [97] farver_2.1.1                  jsonlite_1.8.7               \n [99] BiocParallel_1.34.2           R.oo_1.25.0                  \n[101] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[103] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[105] Rhdf5lib_1.22.1               munsell_0.5.0                \n[107] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[109] viridis_0.6.4                 stringi_1.7.12               \n[111] leafsync_0.1.0                zlibbioc_1.46.0              \n[113] plyr_1.8.9                    parallel_4.3.1               \n[115] ggrepel_0.9.4                 deldir_1.0-9                 \n[117] Biostrings_2.68.1             stars_0.6-4                  \n[119] splines_4.3.1                 tensor_1.5                   \n[121] locfit_1.5-9.8                igraph_1.5.1                 \n[123] ScaledMatrix_1.8.1            BiocVersion_3.17.1           \n[125] XML_3.99-0.14                 evaluate_0.22                \n[127] BiocManager_1.30.22           httpuv_1.6.11                \n[129] tidyr_1.3.0                   purrr_1.0.2                  \n[131] polyclip_1.10-6               rsvd_1.0.5                   \n[133] lwgeom_0.2-13                 xtable_1.8-4                 \n[135] e1071_1.7-13                  RSpectra_0.16-1              \n[137] later_1.3.1                   viridisLite_0.4.2            \n[139] class_7.3-22                  tibble_3.2.1                 \n[141] memoise_2.0.1                 beeswarm_0.4.0               \n[143] AnnotationDbi_1.62.2          cluster_2.1.4",
    "crumbs": [
      "Point Pattern-based Methods"
    ]
  },
  {
    "objectID": "04-imaging-multivar-latSOD.html",
    "href": "04-imaging-multivar-latSOD.html",
    "title": "Irregular Lattices",
    "section": "",
    "text": "Show the code\nsource(\"utils.R\")\ntheme_set(theme_minimal())\n\n\nFor this representation of cells, we will rely on the SpatialFeatureExperiment package. For preprocessing of the dataset, we refer the reader to the vignette of the voyager package.\n\n\nShow the code\n#taken from https://pachterlab.github.io/voyager/articles/vig4_cosmx.html\n(sfe &lt;- HeNSCLCData())\n\n\nclass: SpatialFeatureExperiment \ndim: 980 100290 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100290): 1_1 1_2 ... 30_4759 30_4760\ncolData names(17): Area AspectRatio ... nCounts nGenes\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n\nShow the code\n# Empty cells\ncolData(sfe)$is_empty &lt;- colData(sfe)$nCounts &lt; 1\n# Select, sum negative control probes\n(neg_inds &lt;- str_detect(rownames(sfe), \"^NegPrb\")) %&gt;% sum\n\n\n[1] 20\n\n\nShow the code\ncolData(sfe)$prop_neg &lt;- colSums(counts(sfe)[neg_inds,])/colData(sfe)$nCounts\n# Remove low quality cells\nsfe &lt;- sfe[,!sfe$is_empty & sfe$prop_neg &lt; 0.1]\n# Re-calculate stats\nrowData(sfe)$is_neg &lt;- neg_inds\n# log Counts\nsfe &lt;- logNormCounts(sfe)\n\n\n\n\nIn this vignette, we will show the metrics related a ligand-receptor pair, CEACAM6 and EGFR which was identified in the original publication of the CosMx dataset (He et al. 2022).\n\n\nShow the code\nplotSpatialFeature(sfe, c(\"CEACAM6\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nplotSpatialFeature(sfe, c(\"EGFR\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the challenges when working with (irregular) lattice data is the construction of a neighbourhood graph (Pebesma and Bivand 2023). The main question is, what to consider as neighbours, as this will affect downstream analyses. Various methods exist to create neighbours, such as contiguitiy based neighbours (neighbours in direct contact), graph-based neighbours (e.g., \\(k\\)-nearest neighbours), distance based neighbours or higher order neighbours (Getis 2009; Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023). The documentation of the package spdep gives an overview of the different methods.\nSegmentation of individual cells is challenging (Wang 2019) and construction of contiguity-based neighbours based on individual cell segmentation assumes very accurate segmentation results. Furthermore it would neglect the influence of more distant, not directly adjacent neighbours, which based on the feature of interest might not be the correct assumption.\nIn an irregular lattice, the task of finding a spatial weight matrix is more complex, as different options exist. One option is to base the neighbourhood graph on neighbours that are in direct contact with each other (contiguous), as implemented in the poly2nb method. As cell segmentation is notoriously imperfect, we add a snap value, which means that we consider all cells with distance 20 or less as contiguous.\n\n\nShow the code\ncolGraph(sfe, \"poly2nb\") &lt;-\n  findSpatialNeighbors(sfe,\n    type = \"cellSeg\",\n    method = \"poly2nb\", # wraps the spdep function with the same name\n    style = \"W\",\n    snap = 20 # all cells with less distance  apart are considered contiguous\n  )\n\n\n\n\nShow the code\np1 &lt;- plotColGraph(sfe,\n  colGraphName = \"poly2nb\",\n  colGeometryName = \"cellSeg\",\n  bbox =  c(xmin = 3500, xmax = 10000, ymin = 157200, ymax = 162200)\n) + theme_void()\n\n\nAlternatively, we can use a k-nearest neighbours approach. The the number \\(k\\) is somewhat arbitrary.\n\n\nShow the code\ncolGraph(sfe, \"knn5\") &lt;-\n  findSpatialNeighbors(sfe,\n    method = \"knearneigh\", # wraps the spdep function with the same name\n    k = 5,\n    zero.policy = TRUE\n  )\n\n\n\n\nShow the code\np2 &lt;- plotColGraph(sfe,\n  colGraphName = \"knn5\",\n  colGeometryName = \"cellSeg\",\n  bbox = c(xmin = 3500, xmax = 10000, ymin = 157200, ymax = 162200)\n) + theme_void()\n\n\nThe graphs below show noticeable differences. In the contiguous neighbour graph on the left (neighbours in direct contact), we can see the formation of distinct patches that are not connected to the rest of the tissue. In addition some cells don’t have any direct neighbours. In contrast, the k-nearest neighbours (kNN) graph on the right reveals that these patches tend to be connected to the rest of the structure.\n\n\nShow the code\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\nHere we set the arguments for the examples below.\n\n\nShow the code\nfeatures &lt;- c(\"KRT17\", \"TAGLN\")\ncolGraphName &lt;- \"knn5\"\ncolGeometryName &lt;- \"centroids\"\nsegmentation &lt;- \"cellSeg\"\n\n\n\n\n\n\n\nFor two continous observation the global bivariate Moran’s I is defined as (Wartenberg 1985; Bivand 2022)\n\\[I_B = \\frac{\\Sigma_i(\\Sigma_j{w_{ij}y_j\\times x_i})}{\\Sigma_i{x_i^2}}\\]\nwhere \\(x_i\\) and \\(y_i\\) are the two variables of interest and \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\).\nThe global bivariate Moran’s I is a measure of autocorrelation of the variables \\(x\\) and \\(y\\) with the spatial lag of \\(y\\). Therefore the result might overestimate the spatial autocorrelation of the variables due to the inherent (non-spatial) correlation of \\(x\\) and \\(y\\) (Bivand 2022).\n\n\n\n\nShow the code\nres_xy &lt;- spdep::moran_bv(x = logcounts(sfe)[features[1],],\n         y = logcounts(sfe)[features[2],],\n         listw =  colGraph(sfe, colGraphName),\n         nsim = 499)\nboot::boot.ci(res_xy, conf = c(0.99, 0.95, 0.9), type = \"basic\")\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 499 bootstrap replicates\n\nCALL : \nboot::boot.ci(boot.out = res_xy, conf = c(0.99, 0.95, 0.9), type = \"basic\")\n\nIntervals : \nLevel      Basic         \n99%   (-0.3232, -0.3087 )   \n95%   (-0.3213, -0.3101 )   \n90%   (-0.3204, -0.3110 )  \nCalculations and Intervals on Original Scale\nSome basic intervals may be unstable\n\n\nShow the code\nplot(res_xy)\n\n\n\n\n\n\n\n\n\nFrom the result of the global measure, the overall spatial autocorrelation of the two genes is not significant.\n\n\n\n\nLee’s L is a bivariate measure that combines non-spatial pearson correlation with spatial autocorrelation via Moran’s I (Lee 2001). This enables us to asses the spatial dependence of two continuous variables in a single measure. The measure is defined as\n\\[L(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\]\nwhere \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\), \\(x\\) and \\(y\\) the two variables and \\(\\bar{x}\\) and \\(\\bar{y}\\) their means.\n\n\n\n\nShow the code\nres_lee &lt;- calculateBivariate(sfe, type = \"lee.mc\", \n                   feature1 = features[1], feature2 = features[2],\n                   colGraphName = colGraphName,\n                   nsim = 499)\nres_lee$lee.mc_statistic\n\n\n statistic \n-0.1528025 \n\n\nShow the code\nres_lee$ lee.mc_p.value\n\n\n[1] 0.998\n\n\n\n\n\n\n\n\n\nSimilar to the global variant of Lee’s L the local variant (Lee 2001) is defined as\n\\[L_i(x,y) = \\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\] Local Lee’s L is a measure of spatial co-expression, when the variables of interest are gene expression measurements and can also be a metric of co-localization. Unlike the gobal version, the variables are not averaged and show the local contribution to the metric. Positive values indicate colocalization, negative values indicate segregation.\nThis can be interesting in the context of detection of coexpressed ligand-receptor pairs. A method that is based on bivariate Moran’s I and tries to detect such pairs is SpatialDM (Li et al. 2023).\n\n\n\n\n\n\n\nShow the code\nsfe_tissue &lt;- runBivariate(sfe, type = \"locallee\",\n                    feature1 = features[1], feature2 = features[2],\n                    colGraphName = colGraphName)\n\nplotLocalResult(sfe_tissue, \"locallee\", \n                 features = localResultFeatures(sfe_tissue, \"locallee\"),\n                ncol = 2, divergent = TRUE, diverge_center = 0,\n                colGeometryName = colGeometryName) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeary’s C is a measure of spatial autocorrelation that is based on the difference between a variable and its neighbours. (Anselin 2019) defines it as\n\\[C_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2,\\]\nand can be generalized to \\(k\\) parameters by expanding\n\\[c_{k,i} = \\sum_{v=1}^k c_{v,i}\\]\nwhere \\(c_{v,i}\\) is the local Geary’s C for the \\(v\\)th variable at location \\(i\\). The number of variables that can be used is not fixed, which makes the interpretation a bit more difficult. In general, the metric summarizes similarity in the “multivariate attribute space” (i.e. the gene expression) to its geographic neighbours. The common difficulty in these analyses is the interpretation of the mixture of similarity in the geographic space and similarity in the attribute space.\n\n\n\nTo speed up computation we will use highly variable genes.\n\n\nShow the code\nhvgs &lt;- getTopHVGs(sfe, fdr.threshold = 0.01)\n\n# Subset of the tissue\nsfe_tissue &lt;- runMultivariate(sfe, type = \"localC_multi\",\n                    subset_row = hvgs,\n                    colGraphName = colGraphName)\n\n# Local C mutli is stored in colData so this is a workaround to plot it\nplotSpatialFeature(sfe_tissue, \"localC_multi\")\n\n\n\n\n\n\n\n\n\nWe can further plot the results of the permutation test. Significant values indicate interesting regions, but should be interpreted with care for various reasons. For example, we are looking for similarity in a combination of multiple values but the exact combination is not known. Anselin (2019) write “Overall, however, the statistic indicates a combination of the notion of distance in multi-attribute space with that of geographic neighbors. This is the essence of any spatial autocorrelation statistic. It is also the trade-off encountered in spatially constrained multivariate clustering methods (for a recent discussion, see, e.g., Grubesic, Wei, and Murray 2014).”. Multi-attribute space refers here to the highly variable genes. The problem comes down to where the similarity comes from, the gene expression or the physical space. The same problem is common in spatial domain detection methods.\n\n\nShow the code\nsfe &lt;- runMultivariate(sfe, type = \"localC_perm_multi\",\n                    subset_row = hvgs,\n                    nsim = 100,\n                    colGraphName= colGraphName)\n\n# stored as spatially reduced dim; plot it in this way\nspatialReducedDim(sfe, \"localC_perm_multi\",  c(1, 11))\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis test is useful to assess the overlap of the k-nearest neighbours from physical distances (tissue space) with the k-nearest neighbours from the gene expression measurements (attribute space). For both physical and attribute space k-nearest neighbor matrix is computed. In a second step the probability of an overlap between the two matrices have in common (Anselin and Li 2020).\n\n\nShow the code\nsf &lt;- colGeometries(sfe)[[segmentation]]\nsf &lt;- cbind(sf,  t(as.matrix(logcounts(sfe)[hvgs,])))\n\nnbr_test &lt;- neighbor_match_test(sf[c(hvgs)], k = 20)\n\nsf$Probability &lt;- nbr_test$Probability\nsf$Cardinality &lt;- nbr_test$Cardinality\n\ntm_shape(sf) + tm_fill(col = 'Cardinality')  \n\n\n\n\n\n\n\n\n\nShow the code\ntm_shape(sf) + tm_fill(col = 'Probability')  \n\n\n\n\n\n\n\n\n\nCardinality is a measure of how many neighbours of the two matrices are in common. Some regions show high cardinality with low probability therefore share similarity on both attribute and physical space. In contrast to multivariate local Geary’s C this metric focuses directly on the distances and not on a weighted average. A problem of this approach is called the empty space problem which states that as the number of dimensions of the feature sets increase, the empty space between observations also increases (Anselin and Li 2020).\n\n\n\nIn addition to measures of spatial autocorrelation of continuous data as seen above, there exist a method that apply the same concept to binary and categorical data, joint count statistics. In essence the joint count statistic compares the distribution of categorical marks in a lattice with frequencies that would occur randomly. These random occurrences can be computed using a theoretical approximation or random permutations. The same concept was also extended in a multivariate setting with more than two categories. The corresponding spdep function are called joincount.test and joincount.multi Bivand (2022).\n\n\n\nThe local methods presented above should always be interpreted with care, since we face the problem of multiple testing when calculating them for each cell. Moreover, the presented methods should mainly serve as exploratory measures to identify interesting regions in the data. Multiple processes can lead to the same pattern, thus from identifying the pattern we cannot infer the underlying process. Indication of clustering does not explain why this occurs. On the one hand, clustering can be the result of spatial interaction between the variables of interest. We have an accumulation of a gene of interest in one region of the tissue. On the other hand clustering can be the result spatial heterogeneity, when local similarity is created by structural heterogeneity in the tissue, e.g., that cells with uniform expression of a gene of interest are grouped together which then creates the apparent clustering of the gene expression measurement.\n\n\n\n\n\nShow the code\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-16                      reshape2_1.4.4                \n[19] patchwork_1.2.0                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.5.1                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.9-1                    rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.3.0                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] spatstat.utils_3.0-5          rmarkdown_2.25               \n [87] XVector_0.40.0                htmltools_0.5.6.1            \n [89] pkgconfig_2.0.3               base64enc_0.1-3              \n [91] sparseMatrixStats_1.12.2      fastmap_1.1.1                \n [93] htmlwidgets_1.6.2             shiny_1.7.5.1                \n [95] DelayedMatrixStats_1.22.6     farver_2.1.1                 \n [97] jsonlite_1.8.7                BiocParallel_1.34.2          \n [99] R.oo_1.25.0                   BiocSingular_1.16.0          \n[101] RCurl_1.98-1.12               GenomeInfoDbData_1.2.10      \n[103] s2_1.1.4                      Rhdf5lib_1.22.1              \n[105] munsell_0.5.0                 Rcpp_1.0.11                  \n[107] ggnewscale_0.4.9              viridis_0.6.4                \n[109] stringi_1.7.12                leafsync_0.1.0               \n[111] zlibbioc_1.46.0               plyr_1.8.9                   \n[113] parallel_4.3.1                ggrepel_0.9.4                \n[115] deldir_1.0-9                  Biostrings_2.68.1            \n[117] stars_0.6-4                   splines_4.3.1                \n[119] tensor_1.5                    locfit_1.5-9.8               \n[121] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[123] BiocVersion_3.17.1            XML_3.99-0.14                \n[125] evaluate_0.22                 BiocManager_1.30.22          \n[127] httpuv_1.6.11                 purrr_1.0.2                  \n[129] polyclip_1.10-6               scattermore_1.2              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4\n©2024 The pasta authors. Content is published under Creative Commons CC-BY-4.0 License for the text and GPL-3 License for any code.",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "04-imaging-multivar-latSOD.html#dependencies",
    "href": "04-imaging-multivar-latSOD.html#dependencies",
    "title": "Irregular Lattices",
    "section": "",
    "text": "Show the code\nsource(\"utils.R\")\ntheme_set(theme_minimal())\n\n\nFor this representation of cells, we will rely on the SpatialFeatureExperiment package. For preprocessing of the dataset, we refer the reader to the vignette of the voyager package.\n\n\nShow the code\n#taken from https://pachterlab.github.io/voyager/articles/vig4_cosmx.html\n(sfe &lt;- HeNSCLCData())\n\n\nclass: SpatialFeatureExperiment \ndim: 980 100290 \nmetadata(0):\nassays(1): counts\nrownames(980): AATK ABL1 ... NegPrb22 NegPrb23\nrowData names(3): means vars cv2\ncolnames(100290): 1_1 1_2 ... 30_4759 30_4760\ncolData names(17): Area AspectRatio ... nCounts nGenes\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : CenterX_global_px CenterY_global_px\nimgData names(1): sample_id\n\nunit: full_res_image_pixels\nGeometries:\ncolGeometries: centroids (POINT), cellSeg (POLYGON) \n\nGraphs:\nsample01: \n\n\nShow the code\n# Empty cells\ncolData(sfe)$is_empty &lt;- colData(sfe)$nCounts &lt; 1\n# Select, sum negative control probes\n(neg_inds &lt;- str_detect(rownames(sfe), \"^NegPrb\")) %&gt;% sum\n\n\n[1] 20\n\n\nShow the code\ncolData(sfe)$prop_neg &lt;- colSums(counts(sfe)[neg_inds,])/colData(sfe)$nCounts\n# Remove low quality cells\nsfe &lt;- sfe[,!sfe$is_empty & sfe$prop_neg &lt; 0.1]\n# Re-calculate stats\nrowData(sfe)$is_neg &lt;- neg_inds\n# log Counts\nsfe &lt;- logNormCounts(sfe)\n\n\n\n\nIn this vignette, we will show the metrics related a ligand-receptor pair, CEACAM6 and EGFR which was identified in the original publication of the CosMx dataset (He et al. 2022).\n\n\nShow the code\nplotSpatialFeature(sfe, c(\"CEACAM6\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nplotSpatialFeature(sfe, c(\"EGFR\"),\n                   colGeometryName = \"centroids\", \n                   ncol = 2, scattermore = TRUE) + \n  theme_void()",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "04-imaging-multivar-latSOD.html#spatial-weight-matrix",
    "href": "04-imaging-multivar-latSOD.html#spatial-weight-matrix",
    "title": "Irregular Lattices",
    "section": "",
    "text": "One of the challenges when working with (irregular) lattice data is the construction of a neighbourhood graph (Pebesma and Bivand 2023). The main question is, what to consider as neighbours, as this will affect downstream analyses. Various methods exist to create neighbours, such as contiguitiy based neighbours (neighbours in direct contact), graph-based neighbours (e.g., \\(k\\)-nearest neighbours), distance based neighbours or higher order neighbours (Getis 2009; Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023). The documentation of the package spdep gives an overview of the different methods.\nSegmentation of individual cells is challenging (Wang 2019) and construction of contiguity-based neighbours based on individual cell segmentation assumes very accurate segmentation results. Furthermore it would neglect the influence of more distant, not directly adjacent neighbours, which based on the feature of interest might not be the correct assumption.\nIn an irregular lattice, the task of finding a spatial weight matrix is more complex, as different options exist. One option is to base the neighbourhood graph on neighbours that are in direct contact with each other (contiguous), as implemented in the poly2nb method. As cell segmentation is notoriously imperfect, we add a snap value, which means that we consider all cells with distance 20 or less as contiguous.\n\n\nShow the code\ncolGraph(sfe, \"poly2nb\") &lt;-\n  findSpatialNeighbors(sfe,\n    type = \"cellSeg\",\n    method = \"poly2nb\", # wraps the spdep function with the same name\n    style = \"W\",\n    snap = 20 # all cells with less distance  apart are considered contiguous\n  )\n\n\n\n\nShow the code\np1 &lt;- plotColGraph(sfe,\n  colGraphName = \"poly2nb\",\n  colGeometryName = \"cellSeg\",\n  bbox =  c(xmin = 3500, xmax = 10000, ymin = 157200, ymax = 162200)\n) + theme_void()\n\n\nAlternatively, we can use a k-nearest neighbours approach. The the number \\(k\\) is somewhat arbitrary.\n\n\nShow the code\ncolGraph(sfe, \"knn5\") &lt;-\n  findSpatialNeighbors(sfe,\n    method = \"knearneigh\", # wraps the spdep function with the same name\n    k = 5,\n    zero.policy = TRUE\n  )\n\n\n\n\nShow the code\np2 &lt;- plotColGraph(sfe,\n  colGraphName = \"knn5\",\n  colGeometryName = \"cellSeg\",\n  bbox = c(xmin = 3500, xmax = 10000, ymin = 157200, ymax = 162200)\n) + theme_void()\n\n\nThe graphs below show noticeable differences. In the contiguous neighbour graph on the left (neighbours in direct contact), we can see the formation of distinct patches that are not connected to the rest of the tissue. In addition some cells don’t have any direct neighbours. In contrast, the k-nearest neighbours (kNN) graph on the right reveals that these patches tend to be connected to the rest of the structure.\n\n\nShow the code\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\nHere we set the arguments for the examples below.\n\n\nShow the code\nfeatures &lt;- c(\"KRT17\", \"TAGLN\")\ncolGraphName &lt;- \"knn5\"\ncolGeometryName &lt;- \"centroids\"\nsegmentation &lt;- \"cellSeg\"",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "04-imaging-multivar-latSOD.html#global-measures-for-bivariate-data",
    "href": "04-imaging-multivar-latSOD.html#global-measures-for-bivariate-data",
    "title": "Irregular Lattices",
    "section": "",
    "text": "For two continous observation the global bivariate Moran’s I is defined as (Wartenberg 1985; Bivand 2022)\n\\[I_B = \\frac{\\Sigma_i(\\Sigma_j{w_{ij}y_j\\times x_i})}{\\Sigma_i{x_i^2}}\\]\nwhere \\(x_i\\) and \\(y_i\\) are the two variables of interest and \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\).\nThe global bivariate Moran’s I is a measure of autocorrelation of the variables \\(x\\) and \\(y\\) with the spatial lag of \\(y\\). Therefore the result might overestimate the spatial autocorrelation of the variables due to the inherent (non-spatial) correlation of \\(x\\) and \\(y\\) (Bivand 2022).\n\n\n\n\nShow the code\nres_xy &lt;- spdep::moran_bv(x = logcounts(sfe)[features[1],],\n         y = logcounts(sfe)[features[2],],\n         listw =  colGraph(sfe, colGraphName),\n         nsim = 499)\nboot::boot.ci(res_xy, conf = c(0.99, 0.95, 0.9), type = \"basic\")\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 499 bootstrap replicates\n\nCALL : \nboot::boot.ci(boot.out = res_xy, conf = c(0.99, 0.95, 0.9), type = \"basic\")\n\nIntervals : \nLevel      Basic         \n99%   (-0.3232, -0.3087 )   \n95%   (-0.3213, -0.3101 )   \n90%   (-0.3204, -0.3110 )  \nCalculations and Intervals on Original Scale\nSome basic intervals may be unstable\n\n\nShow the code\nplot(res_xy)\n\n\n\n\n\n\n\n\n\nFrom the result of the global measure, the overall spatial autocorrelation of the two genes is not significant.\n\n\n\n\nLee’s L is a bivariate measure that combines non-spatial pearson correlation with spatial autocorrelation via Moran’s I (Lee 2001). This enables us to asses the spatial dependence of two continuous variables in a single measure. The measure is defined as\n\\[L(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\]\nwhere \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\), \\(x\\) and \\(y\\) the two variables and \\(\\bar{x}\\) and \\(\\bar{y}\\) their means.\n\n\n\n\nShow the code\nres_lee &lt;- calculateBivariate(sfe, type = \"lee.mc\", \n                   feature1 = features[1], feature2 = features[2],\n                   colGraphName = colGraphName,\n                   nsim = 499)\nres_lee$lee.mc_statistic\n\n\n statistic \n-0.1528025 \n\n\nShow the code\nres_lee$ lee.mc_p.value\n\n\n[1] 0.998",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "04-imaging-multivar-latSOD.html#local-measures-for-bivariate-data",
    "href": "04-imaging-multivar-latSOD.html#local-measures-for-bivariate-data",
    "title": "Irregular Lattices",
    "section": "",
    "text": "Similar to the global variant of Lee’s L the local variant (Lee 2001) is defined as\n\\[L_i(x,y) = \\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\] Local Lee’s L is a measure of spatial co-expression, when the variables of interest are gene expression measurements and can also be a metric of co-localization. Unlike the gobal version, the variables are not averaged and show the local contribution to the metric. Positive values indicate colocalization, negative values indicate segregation.\nThis can be interesting in the context of detection of coexpressed ligand-receptor pairs. A method that is based on bivariate Moran’s I and tries to detect such pairs is SpatialDM (Li et al. 2023).\n\n\n\n\n\n\n\nShow the code\nsfe_tissue &lt;- runBivariate(sfe, type = \"locallee\",\n                    feature1 = features[1], feature2 = features[2],\n                    colGraphName = colGraphName)\n\nplotLocalResult(sfe_tissue, \"locallee\", \n                 features = localResultFeatures(sfe_tissue, \"locallee\"),\n                ncol = 2, divergent = TRUE, diverge_center = 0,\n                colGeometryName = colGeometryName)",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "04-imaging-multivar-latSOD.html#local-measures-for-multivariate-data",
    "href": "04-imaging-multivar-latSOD.html#local-measures-for-multivariate-data",
    "title": "Irregular Lattices",
    "section": "",
    "text": "Geary’s C is a measure of spatial autocorrelation that is based on the difference between a variable and its neighbours. (Anselin 2019) defines it as\n\\[C_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2,\\]\nand can be generalized to \\(k\\) parameters by expanding\n\\[c_{k,i} = \\sum_{v=1}^k c_{v,i}\\]\nwhere \\(c_{v,i}\\) is the local Geary’s C for the \\(v\\)th variable at location \\(i\\). The number of variables that can be used is not fixed, which makes the interpretation a bit more difficult. In general, the metric summarizes similarity in the “multivariate attribute space” (i.e. the gene expression) to its geographic neighbours. The common difficulty in these analyses is the interpretation of the mixture of similarity in the geographic space and similarity in the attribute space.\n\n\n\nTo speed up computation we will use highly variable genes.\n\n\nShow the code\nhvgs &lt;- getTopHVGs(sfe, fdr.threshold = 0.01)\n\n# Subset of the tissue\nsfe_tissue &lt;- runMultivariate(sfe, type = \"localC_multi\",\n                    subset_row = hvgs,\n                    colGraphName = colGraphName)\n\n# Local C mutli is stored in colData so this is a workaround to plot it\nplotSpatialFeature(sfe_tissue, \"localC_multi\")\n\n\n\n\n\n\n\n\n\nWe can further plot the results of the permutation test. Significant values indicate interesting regions, but should be interpreted with care for various reasons. For example, we are looking for similarity in a combination of multiple values but the exact combination is not known. Anselin (2019) write “Overall, however, the statistic indicates a combination of the notion of distance in multi-attribute space with that of geographic neighbors. This is the essence of any spatial autocorrelation statistic. It is also the trade-off encountered in spatially constrained multivariate clustering methods (for a recent discussion, see, e.g., Grubesic, Wei, and Murray 2014).”. Multi-attribute space refers here to the highly variable genes. The problem comes down to where the similarity comes from, the gene expression or the physical space. The same problem is common in spatial domain detection methods.\n\n\nShow the code\nsfe &lt;- runMultivariate(sfe, type = \"localC_perm_multi\",\n                    subset_row = hvgs,\n                    nsim = 100,\n                    colGraphName= colGraphName)\n\n# stored as spatially reduced dim; plot it in this way\nspatialReducedDim(sfe, \"localC_perm_multi\",  c(1, 11))",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "04-imaging-multivar-latSOD.html#local-neighbor-match-test",
    "href": "04-imaging-multivar-latSOD.html#local-neighbor-match-test",
    "title": "Irregular Lattices",
    "section": "",
    "text": "This test is useful to assess the overlap of the k-nearest neighbours from physical distances (tissue space) with the k-nearest neighbours from the gene expression measurements (attribute space). For both physical and attribute space k-nearest neighbor matrix is computed. In a second step the probability of an overlap between the two matrices have in common (Anselin and Li 2020).\n\n\nShow the code\nsf &lt;- colGeometries(sfe)[[segmentation]]\nsf &lt;- cbind(sf,  t(as.matrix(logcounts(sfe)[hvgs,])))\n\nnbr_test &lt;- neighbor_match_test(sf[c(hvgs)], k = 20)\n\nsf$Probability &lt;- nbr_test$Probability\nsf$Cardinality &lt;- nbr_test$Cardinality\n\ntm_shape(sf) + tm_fill(col = 'Cardinality')  \n\n\n\n\n\n\n\n\n\nShow the code\ntm_shape(sf) + tm_fill(col = 'Probability')  \n\n\n\n\n\n\n\n\n\nCardinality is a measure of how many neighbours of the two matrices are in common. Some regions show high cardinality with low probability therefore share similarity on both attribute and physical space. In contrast to multivariate local Geary’s C this metric focuses directly on the distances and not on a weighted average. A problem of this approach is called the empty space problem which states that as the number of dimensions of the feature sets increase, the empty space between observations also increases (Anselin and Li 2020).",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "04-imaging-multivar-latSOD.html#measures-for-binary-and-categorical-data",
    "href": "04-imaging-multivar-latSOD.html#measures-for-binary-and-categorical-data",
    "title": "Irregular Lattices",
    "section": "",
    "text": "In addition to measures of spatial autocorrelation of continuous data as seen above, there exist a method that apply the same concept to binary and categorical data, joint count statistics. In essence the joint count statistic compares the distribution of categorical marks in a lattice with frequencies that would occur randomly. These random occurrences can be computed using a theoretical approximation or random permutations. The same concept was also extended in a multivariate setting with more than two categories. The corresponding spdep function are called joincount.test and joincount.multi Bivand (2022).",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "04-imaging-multivar-latSOD.html#a-note-of-caution",
    "href": "04-imaging-multivar-latSOD.html#a-note-of-caution",
    "title": "Irregular Lattices",
    "section": "",
    "text": "The local methods presented above should always be interpreted with care, since we face the problem of multiple testing when calculating them for each cell. Moreover, the presented methods should mainly serve as exploratory measures to identify interesting regions in the data. Multiple processes can lead to the same pattern, thus from identifying the pattern we cannot infer the underlying process. Indication of clustering does not explain why this occurs. On the one hand, clustering can be the result of spatial interaction between the variables of interest. We have an accumulation of a gene of interest in one region of the tissue. On the other hand clustering can be the result spatial heterogeneity, when local similarity is created by structural heterogeneity in the tissue, e.g., that cells with uniform expression of a gene of interest are grouped together which then creates the apparent clustering of the gene expression measurement.",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "04-imaging-multivar-latSOD.html#session-info",
    "href": "04-imaging-multivar-latSOD.html#session-info",
    "title": "Irregular Lattices",
    "section": "",
    "text": "Show the code\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-16                      reshape2_1.4.4                \n[19] patchwork_1.2.0                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.5.1                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.9-1                    rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  R.utils_2.12.2               \n [19] dichromat_2.0-0.1             scico_1.5.0                  \n [21] limma_3.56.2                  rstudioapi_0.15.0            \n [23] RSQLite_2.3.1                 generics_0.1.3               \n [25] crosstalk_1.2.0               Matrix_1.5-4.1               \n [27] ggbeeswarm_0.7.2              fansi_1.0.5                  \n [29] abind_1.4-5                   R.methodsS3_1.8.2            \n [31] terra_1.7-55                  lifecycle_1.0.3              \n [33] yaml_2.3.7                    edgeR_3.42.4                 \n [35] rhdf5_2.44.0                  tmaptools_3.1-1              \n [37] grid_4.3.1                    blob_1.2.4                   \n [39] promises_1.2.1                dqrng_0.3.1                  \n [41] crayon_1.5.2                  lattice_0.21-8               \n [43] beachmat_2.16.0               KEGGREST_1.40.1              \n [45] magick_2.8.0                  pillar_1.9.0                 \n [47] knitr_1.44                    metapod_1.7.0                \n [49] rjson_0.2.21                  boot_1.3-28.1                \n [51] codetools_0.2-19              wk_0.8.0                     \n [53] glue_1.6.2                    vctrs_0.6.4                  \n [55] png_0.1-8                     gtable_0.3.4                 \n [57] cachem_1.0.8                  xfun_0.40                    \n [59] S4Arrays_1.0.6                mime_0.12                    \n [61] DropletUtils_1.20.0           units_0.8-4                  \n [63] statmod_1.5.0                 bluster_1.10.0               \n [65] interactiveDisplayBase_1.38.0 ellipsis_0.3.2               \n [67] bit64_4.0.5                   filelock_1.0.2               \n [69] irlba_2.3.5.1                 vipor_0.4.5                  \n [71] KernSmooth_2.23-21            colorspace_2.1-0             \n [73] DBI_1.1.3                     raster_3.6-26                \n [75] tidyselect_1.2.0              bit_4.0.5                    \n [77] compiler_4.3.1                curl_5.1.0                   \n [79] BiocNeighbors_1.18.0          DelayedArray_0.26.7          \n [81] scales_1.3.0                  classInt_0.4-10              \n [83] rappdirs_0.3.3                goftest_1.2-3                \n [85] spatstat.utils_3.0-5          rmarkdown_2.25               \n [87] XVector_0.40.0                htmltools_0.5.6.1            \n [89] pkgconfig_2.0.3               base64enc_0.1-3              \n [91] sparseMatrixStats_1.12.2      fastmap_1.1.1                \n [93] htmlwidgets_1.6.2             shiny_1.7.5.1                \n [95] DelayedMatrixStats_1.22.6     farver_2.1.1                 \n [97] jsonlite_1.8.7                BiocParallel_1.34.2          \n [99] R.oo_1.25.0                   BiocSingular_1.16.0          \n[101] RCurl_1.98-1.12               GenomeInfoDbData_1.2.10      \n[103] s2_1.1.4                      Rhdf5lib_1.22.1              \n[105] munsell_0.5.0                 Rcpp_1.0.11                  \n[107] ggnewscale_0.4.9              viridis_0.6.4                \n[109] stringi_1.7.12                leafsync_0.1.0               \n[111] zlibbioc_1.46.0               plyr_1.8.9                   \n[113] parallel_4.3.1                ggrepel_0.9.4                \n[115] deldir_1.0-9                  Biostrings_2.68.1            \n[117] stars_0.6-4                   splines_4.3.1                \n[119] tensor_1.5                    locfit_1.5-9.8               \n[121] igraph_1.5.1                  ScaledMatrix_1.8.1           \n[123] BiocVersion_3.17.1            XML_3.99-0.14                \n[125] evaluate_0.22                 BiocManager_1.30.22          \n[127] httpuv_1.6.11                 purrr_1.0.2                  \n[129] polyclip_1.10-6               scattermore_1.2              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "05-HTS-univar-latSOD.html",
    "href": "05-HTS-univar-latSOD.html",
    "title": "Preamble",
    "section": "",
    "text": "Show the code\nsource(\"utils.R\")\ntheme_set(theme_light())\n\n\n\n\n\n\n\nShow the code\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe_full &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe_full &lt;- mirrorImg(sfe_full, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe &lt;- sfe_full[,colData(sfe_full)$in_tissue]\nsfe &lt;- sfe[rowSums(counts(sfe)) &gt; 0,]\n\n#perform normalisation \nsfe &lt;- scater::logNormCounts(sfe)\n\n# construct the weight matrix using the Voyager function\ncolGraph(sfe, \"visium\") &lt;- findVisiumGraph(sfe)\n\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, named Mdk (ENSMUSG00000027239) and Ncl (ENSMUSG00000026234) (McKellar et al. 2021).\nHere we set the arguments for the examples below.\n\n\nShow the code\nfeatures &lt;- c(\"ENSMUSG00000027239\", \"ENSMUSG00000026234\") # MdK, Ncl\ncolGraphName &lt;- \"visium\"\ncolGeometryName &lt;- \"spotPoly\"\n\n\n\n\nShow the code\nrowData(sfe)[rowData(sfe)$symbol == features,]\n\n\nDataFrame with 0 rows and 6 columns\n\n\n\n\n\nSpot based data is collected along a regular spaced grid where all sample areas have the same size. Such a grid is also called a regular lattice. In more rigorous terms the data \\(Y\\) is the product of a random process but the sampling locations are fixed along a lattice \\(D\\). The lattice \\(D\\) does not have to regular but in the scope of spot based data it is. The main difference of this type of data in comparison to point patterns is, that the locations of the data are then not results of a stochastic process but rather due to a defined sampling strategy (Zuur, Ieno, and Smith 2007).\nThe lattice is composed of individual spatial units\n\\[D = \\{A_1, A_2,...,A_n\\}\\]\nwhere these units are not supposed to overlap\n\\[A_i \\cap A_j = \\emptyset \\forall i \\neq j\\]\nThe data is then a random variable of the spatial unit along the lattice\n\\[Y_i = Y(A_i)\\]\nMost lattice data analysis technique build on the concept of neighbours. Therefore, the spatial relationship has to be modelled with e.g. a spatial weigth matrix \\(W\\). There are a lot of ways to define a spatial weigth matrix \\(W\\). Here, the units that are adjacent are specified with a one and the ones that are not adjacent with a zero (binary coniguity matrix)\n\\[w_{ij} = \\begin{cases} 1 \\text{ if } A_i \\text{ and } A_j \\text{ are adjacent}\\\\ 0 \\text{ otw} \\end{cases}\\]\nother options to specify the weight matrix \\(W\\) are mentioned in Zuur, Ieno, and Smith (2007).\nVoyager has a special function for the construction of the weight matrix in Visium data findVisiumGraph.\n\n\n\nGlobal methods give us an overview over the entire field-of-view and summarize the spatial autocorrelation metric to a single value. The metrics are a function of the weight matrix and the variables of interest. The variables of interest can be gene expression, intensity of a marker or the area of the cell. The global measures can be seen as a weighted average of the local metric, as explained below.\nIn general, a global spatial autocorrelation measure has the form of a double sum over all locations \\(i,j\\)\n\\[\\sum_i \\sum_j f(x_i,x_j) w_{ij}\\]\nwhere \\(f(x_i,x_j)\\) is the measure of association between features of interest and \\(w_{ij}\\) scales the relationship by a spatial weight as defined in the weight matrix \\(W\\). If \\(i\\) and \\(j\\) are not neighbours, i.e. we assume they do not have any spatial association, the corresponding element of the weights matrix is 0 (i.e., \\(w_{ij} = 0\\)). In the following we will see that the function \\(f\\) varies between the different spatial autocorrelation measures (Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023).\n\n\nThe global Moran’s I (Moran 1950) coefficient is a measure of spatial autocorrelation, defined as:\n\\[I = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(x_i - \\bar{x})(x_j - \\bar{x})}{\\sum_i (x_i - \\bar{x})^2}.\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\) and \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\). The expected value is close to \\(0\\) for large \\(n\\) (\\(\\mathbb{E}(I) = -1/(n-1)\\)), whereas a value higher than indicates spatial auto-correlation. Negative values indicate negative auto-correlation.\n\n\n\n\nShow the code\ncalculateMoransI(\n  sfe,\n  features = features,\n  colGraphName = colGraphName,\n  exprs_values = \"logcounts\"\n)\n\n\nDataFrame with 2 rows and 2 columns\n                       moran         K\n                   &lt;numeric&gt; &lt;numeric&gt;\nENSMUSG00000027239  0.025309  77.87974\nENSMUSG00000026234  0.115698   2.50434\n\n\nWe can also use the moran.mc function to calculate the Moran’s I coefficient. This function uses a Monte Carlo simulation to calculate the p-value.\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     colGraphName = colGraphName,\n                     exprs_values = \"logcounts\",\n                     type = \"moran.mc\",\n                     nsim = 200)\n\nres &lt;- rowData(sfe)[features,]\nres\n\n\nDataFrame with 2 rows and 12 columns\n                              Ensembl      symbol            type      means\n                          &lt;character&gt; &lt;character&gt;     &lt;character&gt;  &lt;numeric&gt;\nENSMUSG00000027239 ENSMUSG00000027239         Mdk Gene Expression 0.00500801\nENSMUSG00000026234 ENSMUSG00000026234         Ncl Gene Expression 0.22095353\n                         vars       cv2 moran.mc_statistic_Vis5A\n                    &lt;numeric&gt; &lt;numeric&gt;                &lt;numeric&gt;\nENSMUSG00000027239 0.00698754  278.6078                 0.025309\nENSMUSG00000026234 0.62578406   12.8181                 0.115698\n                   moran.mc_parameter_Vis5A moran.mc_p.value_Vis5A\n                                  &lt;numeric&gt;              &lt;numeric&gt;\nENSMUSG00000027239                      177             0.11940299\nENSMUSG00000026234                      201             0.00497512\n                   moran.mc_alternative_Vis5A  moran.mc_method_Vis5A\n                                  &lt;character&gt;            &lt;character&gt;\nENSMUSG00000027239                    greater Monte-Carlo simulati..\nENSMUSG00000026234                    greater Monte-Carlo simulati..\n                                        moran.mc_res_Vis5A\n                                                    &lt;list&gt;\nENSMUSG00000027239       0.0049342,0.0144482,0.0103339,...\nENSMUSG00000026234  0.00985937,-0.01687232,-0.02470626,...\n\n\nShow the code\n#value of the metric\nres[,7]\n\n\n[1] 0.02530897 0.11569815\n\n\nShow the code\n#p-value\nres[,9]\n\n\n[1] 0.119402985 0.004975124\n\n\nWe can see both genes have a positive Moran’s I coefficient and a highly significant p-value. The expected value is \\(\\mathbb{E}(I) = -1/(n-1)\\) which is for large \\(N\\) close to 0. Positive and significant values indicate that areas with similar values are clustered. It is important to note that this could be both at the high or low end of the values of interest. Negative values indicate clustering of alternating values, i.e., gives a measure of spatial heterogeneity. Moreover, one should note that the result is dependent on the weight matrix. Different weight matrices will give different results. To compare Moran’s I coefficients between different values, we need to use the same weight matrix.\n\n\n\n\nGeary’s \\(C\\) (Geary 1954) is a different measure of global autocorrelation and is very closely related to Moran’s \\(I\\). However, it focuses on spatial dissimilarity. Geary’s \\(C\\) is defined by\n\\[C = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(x_i-x_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(x_i-\\bar{x})^2}\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\), \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\) and \\(n\\) the total numer of locations. The interpretation is opposite to Moran’s \\(I\\): a value smaller than \\(1\\) indicates positive auto-correlation whereas a value greater than \\(1\\) represents negative auto-correlation.\n\n\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     colGraphName = colGraphName,\n                     nsim = 200,\n                     type = \"geary.mc\")\n\nres &lt;- rowData(sfe)[features,]\nres\n\n\nDataFrame with 2 rows and 18 columns\n                              Ensembl      symbol            type      means\n                          &lt;character&gt; &lt;character&gt;     &lt;character&gt;  &lt;numeric&gt;\nENSMUSG00000027239 ENSMUSG00000027239         Mdk Gene Expression 0.00500801\nENSMUSG00000026234 ENSMUSG00000026234         Ncl Gene Expression 0.22095353\n                         vars       cv2 moran.mc_statistic_Vis5A\n                    &lt;numeric&gt; &lt;numeric&gt;                &lt;numeric&gt;\nENSMUSG00000027239 0.00698754  278.6078                 0.025309\nENSMUSG00000026234 0.62578406   12.8181                 0.115698\n                   moran.mc_parameter_Vis5A moran.mc_p.value_Vis5A\n                                  &lt;numeric&gt;              &lt;numeric&gt;\nENSMUSG00000027239                      177             0.11940299\nENSMUSG00000026234                      201             0.00497512\n                   moran.mc_alternative_Vis5A  moran.mc_method_Vis5A\n                                  &lt;character&gt;            &lt;character&gt;\nENSMUSG00000027239                    greater Monte-Carlo simulati..\nENSMUSG00000026234                    greater Monte-Carlo simulati..\n                                        moran.mc_res_Vis5A\n                                                    &lt;list&gt;\nENSMUSG00000027239       0.0049342,0.0144482,0.0103339,...\nENSMUSG00000026234  0.00985937,-0.01687232,-0.02470626,...\n                   geary.mc_statistic_Vis5A geary.mc_parameter_Vis5A\n                                  &lt;numeric&gt;                &lt;numeric&gt;\nENSMUSG00000027239                 0.960884                       21\nENSMUSG00000026234                 0.881768                        1\n                   geary.mc_p.value_Vis5A geary.mc_alternative_Vis5A\n                                &lt;numeric&gt;                &lt;character&gt;\nENSMUSG00000027239             0.10447761                    greater\nENSMUSG00000026234             0.00497512                    greater\n                    geary.mc_method_Vis5A             geary.mc_res_Vis5A\n                              &lt;character&gt;                         &lt;list&gt;\nENSMUSG00000027239 Monte-Carlo simulati.. 1.034019,0.992434,0.982648,...\nENSMUSG00000026234 Monte-Carlo simulati..    0.99592,1.01737,1.02285,...\n\n\nShow the code\n#value of the metric\nres[,7]\n\n\n[1] 0.02530897 0.11569815\n\n\nShow the code\n#p-value\nres[,9]\n\n\n[1] 0.119402985 0.004975124\n\n\nAgain, the value of Geary’s \\(C\\) indicates that the genes are spatially auto-correlated.\n\n\n\n\nThe global \\(G\\) (Getis and Ord 1992) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in the dataset. Formally that is\n\\[G(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j} \\text{s.t } j \\neq i.\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather consider both.\nIt is recommended to use binary weights for this calculation. We will use the spdep package directly to calculate the global \\(G\\) statistic.\n\n\nShow the code\n# Get the weight matrix from sfe object\nweights_neighbourhoods_binary &lt;- colGraph(sfe, colGraphName)\n# Change it to binary weights\nweights_neighbourhoods_binary$style &lt;- \"B\" \n# Calculate the global G statistic\nspdep::globalG.test(x = counts(sfe)[features[1],], \n                    listw = weights_neighbourhoods_binary)\n\n\n\n    Getis-Ord global G statistic\n\ndata:  counts(sfe)[features[1], ] \nweights: weights_neighbourhoods_binary \n\nstandard deviate = 0.4597, p-value = 0.3229\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.659292e-03       1.074114e-03       1.620386e-06 \n\n\n\n\n\n\nUnlike global measures that give an overview over the entire field of view, local measures report information about the statistic at each location (cell). There exist local analogs of Moran’s I and Geary’s C for which the global statistic can be represented as a weighted sum of the local statistics. As above, the local coefficients are based on both the spatial weights matrix and the values of the measurement of interest.\n\n\nThe local Moran’s I coefficient (Anselin 1995) is a measure of spatial autocorrelation on each location of interest. It is defined as:\n\\[I_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\\]\nwhere the index \\(i\\) refers to the location for which the measure is calculated. The interpretation is analogous to the global Moran’s I where a value of \\(I_i\\) higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation; smaller values indicate negative auto-correlation. It is important to note that, as for the global counterpart, the value of local Moran’s I could be a result from both the high or low end of the values. Since we measure and test a large number of locations simultaneously, we need to correct for multiple testing (e.g., using the Benjamini-Hochberg procedure).\n\n\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     colGraphName = colGraphName,\n                     type = \"localmoran\")\n\nplotLocalResult(sfe, \"localmoran\",\n                features = features, ncol = 2,\n                colGeometryName = colGeometryName)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimilar to local Moran’s I, there is a local Geary’s C (Anselin 1995) coefficient. It is defined as\n\\[C_i = \\sum_{j=1}^n w_{ij}(x_i-x_j)^2\\]\nThe interpretation is analogous to the global Geary’s C (value less than \\(1\\) indicates positive auto-correlation, a value greater than \\(1\\) highlights negative auto-correlation).\nIn this example, we will not plot the local Geary’s C coefficient for gene expression but for features that are associated with an individual cell, e.g., the number of counts or the number of genes expressed. For this, the colDataUnivariate function is used to calculate the local Geary’s C coefficient for such features.\n\n\n\n\nShow the code\nsfe &lt;- colDataUnivariate(sfe, \"localC_perm\",\n                         features = c(\"nCounts\", \"nGenes\"),\n                         colGraphName = colGraphName)\n\nplotLocalResult(\n  sfe,\n  \"localC_perm\",\n  features = c(\"nCounts\", \"nGenes\"),\n  ncol = 2,\n  colGeometryName = colGeometryName,\n  divergent = TRUE,\n  diverge_center = 0\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe local Getis-Ord \\(G_i\\) (J. K. Ord and Getis 1995; Getis and Ord 1992) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\), according to:\n\\[G_i(d) = \\frac{\\sum_{j \\neq i } w_{ij}(d)x_j}{\\sum_{j \\neq i} x_j}\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\), which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term.\n\n\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     #include_self = TRUE, # this would specify G_i^*(d),\n                     colGraphName = colGraphName,\n                     type = \"localG\")\n\nplotLocalResult(sfe, \"localG\",\n                features = features,\n                ncol = 2,\n                colGeometryName = colGeometryName)\n\n\n\n\n\n\n\n\n\nThe results above gives an estimate of the local Getis-Ord statistic for each cell, but no significance value. This can be done by using a permutation approach using the localG_perm argument.\nPositive values indicate clustering of high values, i.e., hot spots, and negative values indicate clustering of low values, i.e., cold spots. The method does not detect outlier values because, unlike in local Moran’s I, there is no cross-product between \\(i\\) and \\(j\\). But unlike local Moran’s I, we know the type of interaction (high-high or low-low) between \\(i\\) and \\(j\\).\n\n\n\n\n\nThe local spatial heteroscedasticity (LOSH) is a measure of spatial autocorrelation that is based on the variance of the local neighbourhood. Unlike the other measures, this method does not assume homoscedastic variance over the whole tissue region. LOSH is defined as:\n\\[H_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_i(d), j \\in N(i,d)\\) are the local residuals that are subtracted from the local mean. The power \\(a\\) modulates the interpretation of the residuals (\\(a=1\\): residuals are interpreted as absolute deviations from the local mean; \\(a=2\\): residuals are interpreted as deviations from the local variance).\nThe LOSH should be interpreted in combination with the local Getis-Ord \\(G_i^*\\) statistic. The \\(G_i^*\\) quantifies the local mean of the variable of interest, while \\(H_i\\) quantifies the local variance. This table provided by Ord and Getis (J. Keith Ord and Getis 2012) summarizes the interpretation of the combination of \\(G_i^*\\) and \\(H_i\\).\n\n\n\n\n\n\n\n\n\nhigh \\(H_i\\)\nlow \\(H_i\\)\n\n\n\n\nlarge \\(\\|G_i^*\\|\\)\nA hot spot with heterogeneous local conditions\nA hot spot with similar surrounding areas; the map would indicate whether the affected region is larger than the single “cell”\n\n\nsmall $ |G_i^*| $\nHeterogeneous local conditions but at a low average level (an unlikely event)\nHomogeneous local conditions and a low average level\n\n\n\n\n\n\n\nShow the code\n# run localG with permutation test\nsfe &lt;- runUnivariate(sfe,\n                     features = features[1],\n                     colGraphName = colGraphName,\n                     type = \"LOSH\")\n\n\nplotLocalResult(sfe, \"LOSH\",\n                features = features[1],\n                colGeometryName = colGeometryName)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe local methods presented above should always be interpreted with care, since we face the problem of multiple testing when calculating them for each cell. Moreover, the presented methods should mainly serve as exploratory measures to identify interesting regions in the data. Multiple processes can lead to the same pattern, thus from identifying the pattern we cannot infer the underlying process. Indication of clustering does not explain why this occurs. On the one hand, clustering can be the result of spatial interaction between the variables of interest. We have an accumulation of a gene of interest in one region of the tissue. On the other hand clustering can be the result spatial heterogeneity, when local similarity is created by structural heterogeneity in the tissue, e.g., that cells with uniform expression of a gene of interest are grouped together which then creates the apparent clustering of the gene expression measurement.\n©2024 The pasta authors. Content is published under Creative Commons CC-BY-4.0 License for the text and GPL-3 License for any code.",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "05-HTS-univar-latSOD.html#dependencies",
    "href": "05-HTS-univar-latSOD.html#dependencies",
    "title": "Preamble",
    "section": "",
    "text": "Show the code\nsource(\"utils.R\")\ntheme_set(theme_light())",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "05-HTS-univar-latSOD.html#setup-and-preprocessing",
    "href": "05-HTS-univar-latSOD.html#setup-and-preprocessing",
    "title": "Preamble",
    "section": "",
    "text": "Show the code\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe_full &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe_full &lt;- mirrorImg(sfe_full, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe &lt;- sfe_full[,colData(sfe_full)$in_tissue]\nsfe &lt;- sfe[rowSums(counts(sfe)) &gt; 0,]\n\n#perform normalisation \nsfe &lt;- scater::logNormCounts(sfe)\n\n# construct the weight matrix using the Voyager function\ncolGraph(sfe, \"visium\") &lt;- findVisiumGraph(sfe)\n\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, named Mdk (ENSMUSG00000027239) and Ncl (ENSMUSG00000026234) (McKellar et al. 2021).\nHere we set the arguments for the examples below.\n\n\nShow the code\nfeatures &lt;- c(\"ENSMUSG00000027239\", \"ENSMUSG00000026234\") # MdK, Ncl\ncolGraphName &lt;- \"visium\"\ncolGeometryName &lt;- \"spotPoly\"\n\n\n\n\nShow the code\nrowData(sfe)[rowData(sfe)$symbol == features,]\n\n\nDataFrame with 0 rows and 6 columns",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "05-HTS-univar-latSOD.html#regular-lattice-and-neighbourhood-matrix",
    "href": "05-HTS-univar-latSOD.html#regular-lattice-and-neighbourhood-matrix",
    "title": "Preamble",
    "section": "",
    "text": "Spot based data is collected along a regular spaced grid where all sample areas have the same size. Such a grid is also called a regular lattice. In more rigorous terms the data \\(Y\\) is the product of a random process but the sampling locations are fixed along a lattice \\(D\\). The lattice \\(D\\) does not have to regular but in the scope of spot based data it is. The main difference of this type of data in comparison to point patterns is, that the locations of the data are then not results of a stochastic process but rather due to a defined sampling strategy (Zuur, Ieno, and Smith 2007).\nThe lattice is composed of individual spatial units\n\\[D = \\{A_1, A_2,...,A_n\\}\\]\nwhere these units are not supposed to overlap\n\\[A_i \\cap A_j = \\emptyset \\forall i \\neq j\\]\nThe data is then a random variable of the spatial unit along the lattice\n\\[Y_i = Y(A_i)\\]\nMost lattice data analysis technique build on the concept of neighbours. Therefore, the spatial relationship has to be modelled with e.g. a spatial weigth matrix \\(W\\). There are a lot of ways to define a spatial weigth matrix \\(W\\). Here, the units that are adjacent are specified with a one and the ones that are not adjacent with a zero (binary coniguity matrix)\n\\[w_{ij} = \\begin{cases} 1 \\text{ if } A_i \\text{ and } A_j \\text{ are adjacent}\\\\ 0 \\text{ otw} \\end{cases}\\]\nother options to specify the weight matrix \\(W\\) are mentioned in Zuur, Ieno, and Smith (2007).\nVoyager has a special function for the construction of the weight matrix in Visium data findVisiumGraph.",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "05-HTS-univar-latSOD.html#global-measures",
    "href": "05-HTS-univar-latSOD.html#global-measures",
    "title": "Preamble",
    "section": "",
    "text": "Global methods give us an overview over the entire field-of-view and summarize the spatial autocorrelation metric to a single value. The metrics are a function of the weight matrix and the variables of interest. The variables of interest can be gene expression, intensity of a marker or the area of the cell. The global measures can be seen as a weighted average of the local metric, as explained below.\nIn general, a global spatial autocorrelation measure has the form of a double sum over all locations \\(i,j\\)\n\\[\\sum_i \\sum_j f(x_i,x_j) w_{ij}\\]\nwhere \\(f(x_i,x_j)\\) is the measure of association between features of interest and \\(w_{ij}\\) scales the relationship by a spatial weight as defined in the weight matrix \\(W\\). If \\(i\\) and \\(j\\) are not neighbours, i.e. we assume they do not have any spatial association, the corresponding element of the weights matrix is 0 (i.e., \\(w_{ij} = 0\\)). In the following we will see that the function \\(f\\) varies between the different spatial autocorrelation measures (Zuur, Ieno, and Smith 2007; Pebesma and Bivand 2023).\n\n\nThe global Moran’s I (Moran 1950) coefficient is a measure of spatial autocorrelation, defined as:\n\\[I = \\frac{n}{\\sum_i\\sum_j w_{ij}} \\frac{\\sum_i\\sum_j w_{ij}(x_i - \\bar{x})(x_j - \\bar{x})}{\\sum_i (x_i - \\bar{x})^2}.\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\) and \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\). The expected value is close to \\(0\\) for large \\(n\\) (\\(\\mathbb{E}(I) = -1/(n-1)\\)), whereas a value higher than indicates spatial auto-correlation. Negative values indicate negative auto-correlation.\n\n\n\n\nShow the code\ncalculateMoransI(\n  sfe,\n  features = features,\n  colGraphName = colGraphName,\n  exprs_values = \"logcounts\"\n)\n\n\nDataFrame with 2 rows and 2 columns\n                       moran         K\n                   &lt;numeric&gt; &lt;numeric&gt;\nENSMUSG00000027239  0.025309  77.87974\nENSMUSG00000026234  0.115698   2.50434\n\n\nWe can also use the moran.mc function to calculate the Moran’s I coefficient. This function uses a Monte Carlo simulation to calculate the p-value.\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     colGraphName = colGraphName,\n                     exprs_values = \"logcounts\",\n                     type = \"moran.mc\",\n                     nsim = 200)\n\nres &lt;- rowData(sfe)[features,]\nres\n\n\nDataFrame with 2 rows and 12 columns\n                              Ensembl      symbol            type      means\n                          &lt;character&gt; &lt;character&gt;     &lt;character&gt;  &lt;numeric&gt;\nENSMUSG00000027239 ENSMUSG00000027239         Mdk Gene Expression 0.00500801\nENSMUSG00000026234 ENSMUSG00000026234         Ncl Gene Expression 0.22095353\n                         vars       cv2 moran.mc_statistic_Vis5A\n                    &lt;numeric&gt; &lt;numeric&gt;                &lt;numeric&gt;\nENSMUSG00000027239 0.00698754  278.6078                 0.025309\nENSMUSG00000026234 0.62578406   12.8181                 0.115698\n                   moran.mc_parameter_Vis5A moran.mc_p.value_Vis5A\n                                  &lt;numeric&gt;              &lt;numeric&gt;\nENSMUSG00000027239                      177             0.11940299\nENSMUSG00000026234                      201             0.00497512\n                   moran.mc_alternative_Vis5A  moran.mc_method_Vis5A\n                                  &lt;character&gt;            &lt;character&gt;\nENSMUSG00000027239                    greater Monte-Carlo simulati..\nENSMUSG00000026234                    greater Monte-Carlo simulati..\n                                        moran.mc_res_Vis5A\n                                                    &lt;list&gt;\nENSMUSG00000027239       0.0049342,0.0144482,0.0103339,...\nENSMUSG00000026234  0.00985937,-0.01687232,-0.02470626,...\n\n\nShow the code\n#value of the metric\nres[,7]\n\n\n[1] 0.02530897 0.11569815\n\n\nShow the code\n#p-value\nres[,9]\n\n\n[1] 0.119402985 0.004975124\n\n\nWe can see both genes have a positive Moran’s I coefficient and a highly significant p-value. The expected value is \\(\\mathbb{E}(I) = -1/(n-1)\\) which is for large \\(N\\) close to 0. Positive and significant values indicate that areas with similar values are clustered. It is important to note that this could be both at the high or low end of the values of interest. Negative values indicate clustering of alternating values, i.e., gives a measure of spatial heterogeneity. Moreover, one should note that the result is dependent on the weight matrix. Different weight matrices will give different results. To compare Moran’s I coefficients between different values, we need to use the same weight matrix.\n\n\n\n\nGeary’s \\(C\\) (Geary 1954) is a different measure of global autocorrelation and is very closely related to Moran’s \\(I\\). However, it focuses on spatial dissimilarity. Geary’s \\(C\\) is defined by\n\\[C = \\frac{(n-1) \\sum_i \\sum_j w_{ij}(x_i-x_j)^2}{2\\sum_i \\sum_j w_{ij}\\sum_i(x_i-\\bar{x})^2}\\]\nwhere \\(x_i\\) and \\(x_j\\) represent the values of the variable of interest at locations \\(i\\) and \\(j\\), \\(\\hat{x}\\) is the mean of all \\(x\\), \\(w_{ij}\\) is the spatial weight between the locations of \\(i\\) and \\(j\\) and \\(n\\) the total numer of locations. The interpretation is opposite to Moran’s \\(I\\): a value smaller than \\(1\\) indicates positive auto-correlation whereas a value greater than \\(1\\) represents negative auto-correlation.\n\n\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     colGraphName = colGraphName,\n                     nsim = 200,\n                     type = \"geary.mc\")\n\nres &lt;- rowData(sfe)[features,]\nres\n\n\nDataFrame with 2 rows and 18 columns\n                              Ensembl      symbol            type      means\n                          &lt;character&gt; &lt;character&gt;     &lt;character&gt;  &lt;numeric&gt;\nENSMUSG00000027239 ENSMUSG00000027239         Mdk Gene Expression 0.00500801\nENSMUSG00000026234 ENSMUSG00000026234         Ncl Gene Expression 0.22095353\n                         vars       cv2 moran.mc_statistic_Vis5A\n                    &lt;numeric&gt; &lt;numeric&gt;                &lt;numeric&gt;\nENSMUSG00000027239 0.00698754  278.6078                 0.025309\nENSMUSG00000026234 0.62578406   12.8181                 0.115698\n                   moran.mc_parameter_Vis5A moran.mc_p.value_Vis5A\n                                  &lt;numeric&gt;              &lt;numeric&gt;\nENSMUSG00000027239                      177             0.11940299\nENSMUSG00000026234                      201             0.00497512\n                   moran.mc_alternative_Vis5A  moran.mc_method_Vis5A\n                                  &lt;character&gt;            &lt;character&gt;\nENSMUSG00000027239                    greater Monte-Carlo simulati..\nENSMUSG00000026234                    greater Monte-Carlo simulati..\n                                        moran.mc_res_Vis5A\n                                                    &lt;list&gt;\nENSMUSG00000027239       0.0049342,0.0144482,0.0103339,...\nENSMUSG00000026234  0.00985937,-0.01687232,-0.02470626,...\n                   geary.mc_statistic_Vis5A geary.mc_parameter_Vis5A\n                                  &lt;numeric&gt;                &lt;numeric&gt;\nENSMUSG00000027239                 0.960884                       21\nENSMUSG00000026234                 0.881768                        1\n                   geary.mc_p.value_Vis5A geary.mc_alternative_Vis5A\n                                &lt;numeric&gt;                &lt;character&gt;\nENSMUSG00000027239             0.10447761                    greater\nENSMUSG00000026234             0.00497512                    greater\n                    geary.mc_method_Vis5A             geary.mc_res_Vis5A\n                              &lt;character&gt;                         &lt;list&gt;\nENSMUSG00000027239 Monte-Carlo simulati.. 1.034019,0.992434,0.982648,...\nENSMUSG00000026234 Monte-Carlo simulati..    0.99592,1.01737,1.02285,...\n\n\nShow the code\n#value of the metric\nres[,7]\n\n\n[1] 0.02530897 0.11569815\n\n\nShow the code\n#p-value\nres[,9]\n\n\n[1] 0.119402985 0.004975124\n\n\nAgain, the value of Geary’s \\(C\\) indicates that the genes are spatially auto-correlated.\n\n\n\n\nThe global \\(G\\) (Getis and Ord 1992) statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values \\((x_i, x_j)\\) in the dataset. Formally that is\n\\[G(d) = \\frac{\\sum_{i = 1}^n \\sum_{j=1}^n w_{ij}(d)x_ix_j}{\\sum_{i = 1}^n \\sum_{j=1}^n x_i x_j} \\text{s.t } j \\neq i.\\]\nThe global \\(G(d)\\) statistic is very similar to global Moran’s \\(I\\). The global \\(G(d)\\) statistic is based on the sum of the products of the datapoints whereas global Moran’s \\(I\\) is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather consider both.\nIt is recommended to use binary weights for this calculation. We will use the spdep package directly to calculate the global \\(G\\) statistic.\n\n\nShow the code\n# Get the weight matrix from sfe object\nweights_neighbourhoods_binary &lt;- colGraph(sfe, colGraphName)\n# Change it to binary weights\nweights_neighbourhoods_binary$style &lt;- \"B\" \n# Calculate the global G statistic\nspdep::globalG.test(x = counts(sfe)[features[1],], \n                    listw = weights_neighbourhoods_binary)\n\n\n\n    Getis-Ord global G statistic\n\ndata:  counts(sfe)[features[1], ] \nweights: weights_neighbourhoods_binary \n\nstandard deviate = 0.4597, p-value = 0.3229\nalternative hypothesis: greater\nsample estimates:\nGlobal G statistic        Expectation           Variance \n      1.659292e-03       1.074114e-03       1.620386e-06",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "05-HTS-univar-latSOD.html#local-measures",
    "href": "05-HTS-univar-latSOD.html#local-measures",
    "title": "Preamble",
    "section": "",
    "text": "Unlike global measures that give an overview over the entire field of view, local measures report information about the statistic at each location (cell). There exist local analogs of Moran’s I and Geary’s C for which the global statistic can be represented as a weighted sum of the local statistics. As above, the local coefficients are based on both the spatial weights matrix and the values of the measurement of interest.\n\n\nThe local Moran’s I coefficient (Anselin 1995) is a measure of spatial autocorrelation on each location of interest. It is defined as:\n\\[I_i = \\frac{x_i - \\bar{x}}{\\sum_{k=1}^n(x_k-\\bar{x})^2/(n-1)} \\sum_{j=1}^n w_{ij}(x_j - \\bar{x})\\]\nwhere the index \\(i\\) refers to the location for which the measure is calculated. The interpretation is analogous to the global Moran’s I where a value of \\(I_i\\) higher than \\(\\mathbb{E}(I) = -1/(n-1)\\) indicates spatial auto-correlation; smaller values indicate negative auto-correlation. It is important to note that, as for the global counterpart, the value of local Moran’s I could be a result from both the high or low end of the values. Since we measure and test a large number of locations simultaneously, we need to correct for multiple testing (e.g., using the Benjamini-Hochberg procedure).\n\n\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     colGraphName = colGraphName,\n                     type = \"localmoran\")\n\nplotLocalResult(sfe, \"localmoran\",\n                features = features, ncol = 2,\n                colGeometryName = colGeometryName)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimilar to local Moran’s I, there is a local Geary’s C (Anselin 1995) coefficient. It is defined as\n\\[C_i = \\sum_{j=1}^n w_{ij}(x_i-x_j)^2\\]\nThe interpretation is analogous to the global Geary’s C (value less than \\(1\\) indicates positive auto-correlation, a value greater than \\(1\\) highlights negative auto-correlation).\nIn this example, we will not plot the local Geary’s C coefficient for gene expression but for features that are associated with an individual cell, e.g., the number of counts or the number of genes expressed. For this, the colDataUnivariate function is used to calculate the local Geary’s C coefficient for such features.\n\n\n\n\nShow the code\nsfe &lt;- colDataUnivariate(sfe, \"localC_perm\",\n                         features = c(\"nCounts\", \"nGenes\"),\n                         colGraphName = colGraphName)\n\nplotLocalResult(\n  sfe,\n  \"localC_perm\",\n  features = c(\"nCounts\", \"nGenes\"),\n  ncol = 2,\n  colGeometryName = colGeometryName,\n  divergent = TRUE,\n  diverge_center = 0\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe local Getis-Ord \\(G_i\\) (J. K. Ord and Getis 1995; Getis and Ord 1992) statistic quantifies the weighted concentration of points within a radius \\(d\\) and in a local region \\(i\\), according to:\n\\[G_i(d) = \\frac{\\sum_{j \\neq i } w_{ij}(d)x_j}{\\sum_{j \\neq i} x_j}\\]\nThere is a variant of this statistic, \\(G_i^*(d)\\), which is the same as \\(G_i(d)\\) except that the contribution when \\(j=i\\) is included in the term.\n\n\n\n\nShow the code\nsfe &lt;- runUnivariate(sfe,\n                     features = features,\n                     #include_self = TRUE, # this would specify G_i^*(d),\n                     colGraphName = colGraphName,\n                     type = \"localG\")\n\nplotLocalResult(sfe, \"localG\",\n                features = features,\n                ncol = 2,\n                colGeometryName = colGeometryName)\n\n\n\n\n\n\n\n\n\nThe results above gives an estimate of the local Getis-Ord statistic for each cell, but no significance value. This can be done by using a permutation approach using the localG_perm argument.\nPositive values indicate clustering of high values, i.e., hot spots, and negative values indicate clustering of low values, i.e., cold spots. The method does not detect outlier values because, unlike in local Moran’s I, there is no cross-product between \\(i\\) and \\(j\\). But unlike local Moran’s I, we know the type of interaction (high-high or low-low) between \\(i\\) and \\(j\\).\n\n\n\n\n\nThe local spatial heteroscedasticity (LOSH) is a measure of spatial autocorrelation that is based on the variance of the local neighbourhood. Unlike the other measures, this method does not assume homoscedastic variance over the whole tissue region. LOSH is defined as:\n\\[H_i(d) = \\frac{\\sum_j w_{ij}(d)|e_j(d)|^a}{\\sum_j w_{ij}(d)}\\]\nwhere \\(e_j(d) = x_j - \\bar{x}_i(d), j \\in N(i,d)\\) are the local residuals that are subtracted from the local mean. The power \\(a\\) modulates the interpretation of the residuals (\\(a=1\\): residuals are interpreted as absolute deviations from the local mean; \\(a=2\\): residuals are interpreted as deviations from the local variance).\nThe LOSH should be interpreted in combination with the local Getis-Ord \\(G_i^*\\) statistic. The \\(G_i^*\\) quantifies the local mean of the variable of interest, while \\(H_i\\) quantifies the local variance. This table provided by Ord and Getis (J. Keith Ord and Getis 2012) summarizes the interpretation of the combination of \\(G_i^*\\) and \\(H_i\\).\n\n\n\n\n\n\n\n\n\nhigh \\(H_i\\)\nlow \\(H_i\\)\n\n\n\n\nlarge \\(\\|G_i^*\\|\\)\nA hot spot with heterogeneous local conditions\nA hot spot with similar surrounding areas; the map would indicate whether the affected region is larger than the single “cell”\n\n\nsmall $ |G_i^*| $\nHeterogeneous local conditions but at a low average level (an unlikely event)\nHomogeneous local conditions and a low average level\n\n\n\n\n\n\n\nShow the code\n# run localG with permutation test\nsfe &lt;- runUnivariate(sfe,\n                     features = features[1],\n                     colGraphName = colGraphName,\n                     type = \"LOSH\")\n\n\nplotLocalResult(sfe, \"LOSH\",\n                features = features[1],\n                colGeometryName = colGeometryName)",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "05-HTS-univar-latSOD.html#a-note-of-caution",
    "href": "05-HTS-univar-latSOD.html#a-note-of-caution",
    "title": "Preamble",
    "section": "",
    "text": "The local methods presented above should always be interpreted with care, since we face the problem of multiple testing when calculating them for each cell. Moreover, the presented methods should mainly serve as exploratory measures to identify interesting regions in the data. Multiple processes can lead to the same pattern, thus from identifying the pattern we cannot infer the underlying process. Indication of clustering does not explain why this occurs. On the one hand, clustering can be the result of spatial interaction between the variables of interest. We have an accumulation of a gene of interest in one region of the tissue. On the other hand clustering can be the result spatial heterogeneity, when local similarity is created by structural heterogeneity in the tissue, e.g., that cells with uniform expression of a gene of interest are grouped together which then creates the apparent clustering of the gene expression measurement.",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "05-HTS-univar-latSOD.html#session-info",
    "href": "05-HTS-univar-latSOD.html#session-info",
    "title": "Preamble",
    "section": "Session info",
    "text": "Session info\n\n\nShow the code\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-16                      reshape2_1.4.4                \n[19] patchwork_1.2.0                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.5.1                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.9-1                    rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  dbscan_1.1-11                \n [19] R.utils_2.12.2                dichromat_2.0-0.1            \n [21] scico_1.5.0                   limma_3.56.2                 \n [23] rstudioapi_0.15.0             RSQLite_2.3.1                \n [25] generics_0.1.3                crosstalk_1.2.0              \n [27] Matrix_1.5-4.1                ggbeeswarm_0.7.2             \n [29] fansi_1.0.5                   abind_1.4-5                  \n [31] R.methodsS3_1.8.2             terra_1.7-55                 \n [33] lifecycle_1.0.3               yaml_2.3.7                   \n [35] edgeR_3.42.4                  rhdf5_2.44.0                 \n [37] tmaptools_3.1-1               grid_4.3.1                   \n [39] blob_1.2.4                    promises_1.2.1               \n [41] dqrng_0.3.1                   crayon_1.5.2                 \n [43] lattice_0.21-8                beachmat_2.16.0              \n [45] KEGGREST_1.40.1               magick_2.8.0                 \n [47] pillar_1.9.0                  knitr_1.44                   \n [49] metapod_1.7.0                 rjson_0.2.21                 \n [51] boot_1.3-28.1                 codetools_0.2-19             \n [53] wk_0.8.0                      glue_1.6.2                   \n [55] vctrs_0.6.4                   png_0.1-8                    \n [57] gtable_0.3.4                  cachem_1.0.8                 \n [59] xfun_0.40                     S4Arrays_1.0.6               \n [61] mime_0.12                     DropletUtils_1.20.0          \n [63] units_0.8-4                   statmod_1.5.0                \n [65] bluster_1.10.0                interactiveDisplayBase_1.38.0\n [67] ellipsis_0.3.2                bit64_4.0.5                  \n [69] filelock_1.0.2                irlba_2.3.5.1                \n [71] vipor_0.4.5                   KernSmooth_2.23-21           \n [73] colorspace_2.1-0              DBI_1.1.3                    \n [75] raster_3.6-26                 tidyselect_1.2.0             \n [77] bit_4.0.5                     compiler_4.3.1               \n [79] curl_5.1.0                    BiocNeighbors_1.18.0         \n [81] DelayedArray_0.26.7           scales_1.3.0                 \n [83] classInt_0.4-10               rappdirs_0.3.3               \n [85] goftest_1.2-3                 spatstat.utils_3.0-5         \n [87] rmarkdown_2.25                XVector_0.40.0               \n [89] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [91] base64enc_0.1-3               sparseMatrixStats_1.12.2     \n [93] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [95] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [97] farver_2.1.1                  jsonlite_1.8.7               \n [99] BiocParallel_1.34.2           R.oo_1.25.0                  \n[101] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[103] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[105] Rhdf5lib_1.22.1               munsell_0.5.0                \n[107] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[109] viridis_0.6.4                 stringi_1.7.12               \n[111] leafsync_0.1.0                zlibbioc_1.46.0              \n[113] plyr_1.8.9                    parallel_4.3.1               \n[115] ggrepel_0.9.4                 deldir_1.0-9                 \n[117] Biostrings_2.68.1             stars_0.6-4                  \n[119] splines_4.3.1                 tensor_1.5                   \n[121] locfit_1.5-9.8                igraph_1.5.1                 \n[123] ScaledMatrix_1.8.1            BiocVersion_3.17.1           \n[125] XML_3.99-0.14                 evaluate_0.22                \n[127] BiocManager_1.30.22           httpuv_1.6.11                \n[129] purrr_1.0.2                   polyclip_1.10-6              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "06-HTS-multivar-latSOD.html",
    "href": "06-HTS-multivar-latSOD.html",
    "title": "Preamble",
    "section": "",
    "text": "Show the code\nsource(\"utils.R\")\ntheme_set(theme_light())\n\n\n\n\n\n\n\nShow the code\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe_full &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe_full &lt;- mirrorImg(sfe_full, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe &lt;- sfe_full[,colData(sfe_full)$in_tissue]\nsfe &lt;- sfe[rowSums(counts(sfe)) &gt; 0,]\n\n#perform normalisation \nsfe &lt;- scater::logNormCounts(sfe)\n\ncolGraph(sfe, \"visium\") &lt;- findVisiumGraph(sfe)\n\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, named Mdk (ENSMUSG00000027239) and Ncl (ENSMUSG00000026234) (McKellar et al. 2021).\n\n\nShow the code\nMdK &lt;- \"ENSMUSG00000027239\"\nNcI &lt;- \"ENSMUSG00000026234\"\n\n\n\n\nShow the code\nfeatures &lt;- c(\"ENSMUSG00000027239\", \"ENSMUSG00000026234\") # MdK, Ncl\ncolGraphName &lt;- \"visium\"\ncolGeometryName &lt;- \"spotPoly\"\nsegmentation &lt;- \"spotPoly\"\n\n\n\n\n\nSpot based data is collected along a regular spaced grid where all sample areas have the same size. Such a grid is also called a regular lattice. In more rigorous terms the data \\(Y\\) is the product of a random process but the sampling locations are fixed along a lattice \\(D\\). The lattice \\(D\\) does not have to regular but in the scope of spot based data it is. The main difference of this type of data in comparison to point patterns is, that the locations of the data are then not results of a stochastic process but rather due to a defined sampling strategy (Zuur, Ieno, and Smith 2007).\nThe lattice is composed of individual spatial units\n\\[D = \\{A_1, A_2,...,A_n\\}\\]\nwhere these units are not supposed to overlap\n\\[A_i \\cap A_j = \\emptyset \\forall i \\neq j\\]\nThe data is then a random variable of the spatial unit along the lattice\n\\[Y_i = Y(A_i)\\]\nMost lattice data analysis technique build on the concept of neighbours. Therefore, the spatial relationship has to be modelled with e.g. a spatial weigth matrix \\(W\\). There are a lot of ways to define a spatial weigth matrix \\(W\\). Here, the units that are adjacent are specified with a one and the ones that are not adjacent with a zero (binary coniguity matrix)\n\\[w_{ij} = \\begin{cases} 1 \\text{ if } A_i \\text{ and } A_j \\text{ are adjacent}\\\\ 0 \\text{ otw} \\end{cases}\\]\nother options to specify the weight matrix \\(W\\) are mentioned in Zuur, Ieno, and Smith (2007).\nVoyager has a special function for the construction of the weight matrix in Visium data findVisiumGraph.\n\n\n\n\n\nFor two continous observation the global bivariate Moran’s I is defined as (Wartenberg 1985; Bivand 2022)\n\\[I_B = \\frac{\\Sigma_i(\\Sigma_j{w_{ij}y_j\\times x_i})}{\\Sigma_i{x_i^2}}\\]\nwhere \\(x_i\\) and \\(y_i\\) are the two variables of interest and \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\).\nThe global bivariate Moran’s I is a measure of autocorrelation of the variables \\(x\\) and \\(y\\) with the spatial lag of \\(y\\). Therefore the result might overestimate the spatial autocorrelation of the variables due to the inherent (non-spatial) correlation of \\(x\\) and \\(y\\) (Bivand 2022).\n\n\n\n\nShow the code\nres_xy &lt;- spdep::moran_bv(x = logcounts(sfe)[features[1],],\n         y = logcounts(sfe)[features[2],],\n         listw =  colGraph(sfe, colGraphName),\n         nsim = 499)\nboot::boot.ci(res_xy, conf = c(0.99, 0.95, 0.9), type = \"basic\")\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 499 bootstrap replicates\n\nCALL : \nboot::boot.ci(boot.out = res_xy, conf = c(0.99, 0.95, 0.9), type = \"basic\")\n\nIntervals : \nLevel      Basic         \n99%   (-0.0057,  0.0674 )   \n95%   ( 0.0034,  0.0602 )   \n90%   ( 0.0084,  0.0556 )  \nCalculations and Intervals on Original Scale\nSome basic intervals may be unstable\n\n\nShow the code\nplot(res_xy)\n\n\n\n\n\n\n\n\n\nFrom the result of the global measure, the overall spatial autocorrelation of the two genes is not significant.\n\n\n\n\nLee’s L is a bivariate measure that combines non-spatial pearson correlation with spatial autocorrelation via Moran’s I (Lee 2001). This enables us to asses the spatial dependence of two continuous variables in a single measure. The measure is defined as\n\\[L(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\]\nwhere \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\), \\(x\\) and \\(y\\) the two variables and \\(\\bar{x}\\) and \\(\\bar{y}\\) their means.\n\n\n\n\nShow the code\nres_lee &lt;- calculateBivariate(sfe, type = \"lee.mc\", \n                   feature1 = features[1], feature2 = features[2],\n                   colGraphName = colGraphName,\n                   nsim = 499)\nres_lee$lee.mc_statistic\n\n\nstatistic \n0.0213312 \n\n\nShow the code\nres_lee$ lee.mc_p.value\n\n\n[1] 0.008\n\n\n\n\n\n\n\n\n\nSimilar to the global variant of Lee’s L the local variant (Lee 2001) is defined as\n\\[L_i(x,y) = \\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\] Local Lee’s L is a measure of spatial co-expression, when the variables of interest are gene expression measurements and can also be a metric of co-localization. Unlike the gobal version, the variables are not averaged and show the local contribution to the metric. Positive values indicate colocalization, negative values indicate segregation.\nThis can be interesting in the context of detection of coexpressed ligand-receptor pairs. A method that is based on bivariate Moran’s I and tries to detect such pairs is SpatialDM (Li et al. 2023).\n\n\n\n\n\n\n\nShow the code\nsfe_tissue &lt;- runBivariate(sfe, type = \"locallee\",\n                    feature1 = features[1], feature2 = features[2],\n                    colGraphName = colGraphName)\n\nplotLocalResult(sfe_tissue, \"locallee\", \n                 features = localResultFeatures(sfe_tissue, \"locallee\"),\n                ncol = 2, divergent = TRUE, diverge_center = 0,\n                colGeometryName = colGeometryName) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeary’s C is a measure of spatial autocorrelation that is based on the difference between a variable and its neighbours. (Anselin 2019) defines it as\n\\[C_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2,\\]\nand can be generalized to \\(k\\) parameters by expanding\n\\[c_{k,i} = \\sum_{v=1}^k c_{v,i}\\]\nwhere \\(c_{v,i}\\) is the local Geary’s C for the \\(v\\)th variable at location \\(i\\). The number of variables that can be used is not fixed, which makes the interpretation a bit more difficult. In general, the metric summarizes similarity in the “multivariate attribute space” (i.e. the gene expression) to its geographic neighbours. The common difficulty in these analyses is the interpretation of the mixture of similarity in the geographic space and similarity in the attribute space.\n\n\n\nTo speed up computation we will use highly variable genes.\n\n\nShow the code\nhvgs &lt;- getTopHVGs(sfe, fdr.threshold = 0.01)\n\n# Subset of the tissue\nsfe_tissue &lt;- runMultivariate(sfe, type = \"localC_multi\",\n                    subset_row = hvgs,\n                    colGraphName = colGraphName)\n\n# Local C mutli is stored in colData so this is a workaround to plot it\nplotSpatialFeature(sfe_tissue, \"localC_multi\")\n\n\n\n\n\n\n\n\n\nWe can further plot the results of the permutation test. Significant values indicate interesting regions, but should be interpreted with care for various reasons. For example, we are looking for similarity in a combination of multiple values but the exact combination is not known. Anselin (2019) write “Overall, however, the statistic indicates a combination of the notion of distance in multi-attribute space with that of geographic neighbors. This is the essence of any spatial autocorrelation statistic. It is also the trade-off encountered in spatially constrained multivariate clustering methods (for a recent discussion, see, e.g., Grubesic, Wei, and Murray 2014).”. Multi-attribute space refers here to the highly variable genes. The problem comes down to where the similarity comes from, the gene expression or the physical space. The same problem is common in spatial domain detection methods.\n\n\nShow the code\nsfe &lt;- runMultivariate(sfe, type = \"localC_perm_multi\",\n                    subset_row = hvgs,\n                    nsim = 100,\n                    colGraphName= colGraphName)\n\n# stored as spatially reduced dim; plot it in this way\nspatialReducedDim(sfe, \"localC_perm_multi\",  c(1, 11))\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis test is useful to assess the overlap of the k-nearest neighbours from physical distances (tissue space) with the k-nearest neighbours from the gene expression measurements (attribute space). For both physical and attribute space k-nearest neighbor matrix is computed. In a second step the probability of an overlap between the two matrices have in common (Anselin and Li 2020).\n\n\nShow the code\nsf &lt;- colGeometries(sfe)[[segmentation]]\nsf &lt;- cbind(sf,  t(as.matrix(logcounts(sfe)[hvgs,])))\n\nnbr_test &lt;- neighbor_match_test(sf[c(hvgs)], k = 20)\n\nsf$Probability &lt;- nbr_test$Probability\nsf$Cardinality &lt;- nbr_test$Cardinality\n\ntm_shape(sf) + tm_fill(col = 'Cardinality')  \n\n\n\n\n\n\n\n\n\nShow the code\ntm_shape(sf) + tm_fill(col = 'Probability')  \n\n\n\n\n\n\n\n\n\nCardinality is a measure of how many neighbours of the two matrices are in common. Some regions show high cardinality with low probability therefore share similarity on both attribute and physical space. In contrast to multivariate local Geary’s C this metric focuses directly on the distances and not on a weighted average. A problem of this approach is called the empty space problem which states that as the number of dimensions of the feature sets increase, the empty space between observations also increases (Anselin and Li 2020).\n\n\n\nIn addition to measures of spatial autocorrelation of continuous data as seen above, there exist a method that apply the same concept to binary and categorical data, joint count statistics. In essence the joint count statistic compares the distribution of categorical marks in a lattice with frequencies that would occur randomly. These random occurrences can be computed using a theoretical approximation or random permutations. The same concept was also extended in a multivariate setting with more than two categories. The corresponding spdep function are called joincount.test and joincount.multi Bivand (2022).\n\n\n\nThe local methods presented above should always be interpreted with care, since we face the problem of multiple testing when calculating them for each cell. Moreover, the presented methods should mainly serve as exploratory measures to identify interesting regions in the data. Multiple processes can lead to the same pattern, thus from identifying the pattern we cannot infer the underlying process. Indication of clustering does not explain why this occurs. On the one hand, clustering can be the result of spatial interaction between the variables of interest. We have an accumulation of a gene of interest in one region of the tissue. On the other hand clustering can be the result spatial heterogeneity, when local similarity is created by structural heterogeneity in the tissue, e.g., that cells with uniform expression of a gene of interest are grouped together which then creates the apparent clustering of the gene expression measurement.\n\n\n\n\n\nShow the code\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-16                      reshape2_1.4.4                \n[19] patchwork_1.2.0                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.5.1                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.9-1                    rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  dbscan_1.1-11                \n [19] R.utils_2.12.2                dichromat_2.0-0.1            \n [21] scico_1.5.0                   limma_3.56.2                 \n [23] rstudioapi_0.15.0             RSQLite_2.3.1                \n [25] generics_0.1.3                crosstalk_1.2.0              \n [27] Matrix_1.5-4.1                ggbeeswarm_0.7.2             \n [29] fansi_1.0.5                   abind_1.4-5                  \n [31] R.methodsS3_1.8.2             terra_1.7-55                 \n [33] lifecycle_1.0.3               yaml_2.3.7                   \n [35] edgeR_3.42.4                  rhdf5_2.44.0                 \n [37] tmaptools_3.1-1               grid_4.3.1                   \n [39] blob_1.2.4                    promises_1.2.1               \n [41] dqrng_0.3.1                   crayon_1.5.2                 \n [43] lattice_0.21-8                beachmat_2.16.0              \n [45] KEGGREST_1.40.1               magick_2.8.0                 \n [47] pillar_1.9.0                  knitr_1.44                   \n [49] metapod_1.7.0                 rjson_0.2.21                 \n [51] boot_1.3-28.1                 codetools_0.2-19             \n [53] wk_0.8.0                      glue_1.6.2                   \n [55] vctrs_0.6.4                   png_0.1-8                    \n [57] gtable_0.3.4                  cachem_1.0.8                 \n [59] xfun_0.40                     S4Arrays_1.0.6               \n [61] mime_0.12                     DropletUtils_1.20.0          \n [63] units_0.8-4                   statmod_1.5.0                \n [65] bluster_1.10.0                interactiveDisplayBase_1.38.0\n [67] ellipsis_0.3.2                bit64_4.0.5                  \n [69] filelock_1.0.2                irlba_2.3.5.1                \n [71] vipor_0.4.5                   KernSmooth_2.23-21           \n [73] colorspace_2.1-0              DBI_1.1.3                    \n [75] raster_3.6-26                 tidyselect_1.2.0             \n [77] bit_4.0.5                     compiler_4.3.1               \n [79] curl_5.1.0                    BiocNeighbors_1.18.0         \n [81] DelayedArray_0.26.7           scales_1.3.0                 \n [83] classInt_0.4-10               rappdirs_0.3.3               \n [85] goftest_1.2-3                 spatstat.utils_3.0-5         \n [87] rmarkdown_2.25                XVector_0.40.0               \n [89] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [91] base64enc_0.1-3               sparseMatrixStats_1.12.2     \n [93] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [95] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [97] farver_2.1.1                  jsonlite_1.8.7               \n [99] BiocParallel_1.34.2           R.oo_1.25.0                  \n[101] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[103] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[105] Rhdf5lib_1.22.1               munsell_0.5.0                \n[107] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[109] viridis_0.6.4                 stringi_1.7.12               \n[111] leafsync_0.1.0                zlibbioc_1.46.0              \n[113] plyr_1.8.9                    parallel_4.3.1               \n[115] ggrepel_0.9.4                 deldir_1.0-9                 \n[117] Biostrings_2.68.1             stars_0.6-4                  \n[119] splines_4.3.1                 tensor_1.5                   \n[121] locfit_1.5-9.8                igraph_1.5.1                 \n[123] ScaledMatrix_1.8.1            BiocVersion_3.17.1           \n[125] XML_3.99-0.14                 evaluate_0.22                \n[127] BiocManager_1.30.22           httpuv_1.6.11                \n[129] purrr_1.0.2                   polyclip_1.10-6              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4\n©2024 The pasta authors. Content is published under Creative Commons CC-BY-4.0 License for the text and GPL-3 License for any code.",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "06-HTS-multivar-latSOD.html#dependencies",
    "href": "06-HTS-multivar-latSOD.html#dependencies",
    "title": "Preamble",
    "section": "",
    "text": "Show the code\nsource(\"utils.R\")\ntheme_set(theme_light())",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "06-HTS-multivar-latSOD.html#setup-and-preprocessing",
    "href": "06-HTS-multivar-latSOD.html#setup-and-preprocessing",
    "title": "Preamble",
    "section": "",
    "text": "Show the code\n# taken from https://pachterlab.github.io/voyager/articles/visium_10x.html\n#spe_vis &lt;- readRDS(\"../data/spe_spot.rds\")\n#spe_vis\n\nsfe_full &lt;- SFEData::McKellarMuscleData(dataset = \"full\")\n\nsfe_full &lt;- mirrorImg(sfe_full, sample_id = \"Vis5A\", image_id = \"lowres\")\nsfe &lt;- sfe_full[,colData(sfe_full)$in_tissue]\nsfe &lt;- sfe[rowSums(counts(sfe)) &gt; 0,]\n\n#perform normalisation \nsfe &lt;- scater::logNormCounts(sfe)\n\ncolGraph(sfe, \"visium\") &lt;- findVisiumGraph(sfe)\n\n\nGiven this data from McKellar et al. we choose two genes to analyse henceforth, named Mdk (ENSMUSG00000027239) and Ncl (ENSMUSG00000026234) (McKellar et al. 2021).\n\n\nShow the code\nMdK &lt;- \"ENSMUSG00000027239\"\nNcI &lt;- \"ENSMUSG00000026234\"\n\n\n\n\nShow the code\nfeatures &lt;- c(\"ENSMUSG00000027239\", \"ENSMUSG00000026234\") # MdK, Ncl\ncolGraphName &lt;- \"visium\"\ncolGeometryName &lt;- \"spotPoly\"\nsegmentation &lt;- \"spotPoly\"",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "06-HTS-multivar-latSOD.html#regular-lattice-and-neighbourhood-matrix",
    "href": "06-HTS-multivar-latSOD.html#regular-lattice-and-neighbourhood-matrix",
    "title": "Preamble",
    "section": "",
    "text": "Spot based data is collected along a regular spaced grid where all sample areas have the same size. Such a grid is also called a regular lattice. In more rigorous terms the data \\(Y\\) is the product of a random process but the sampling locations are fixed along a lattice \\(D\\). The lattice \\(D\\) does not have to regular but in the scope of spot based data it is. The main difference of this type of data in comparison to point patterns is, that the locations of the data are then not results of a stochastic process but rather due to a defined sampling strategy (Zuur, Ieno, and Smith 2007).\nThe lattice is composed of individual spatial units\n\\[D = \\{A_1, A_2,...,A_n\\}\\]\nwhere these units are not supposed to overlap\n\\[A_i \\cap A_j = \\emptyset \\forall i \\neq j\\]\nThe data is then a random variable of the spatial unit along the lattice\n\\[Y_i = Y(A_i)\\]\nMost lattice data analysis technique build on the concept of neighbours. Therefore, the spatial relationship has to be modelled with e.g. a spatial weigth matrix \\(W\\). There are a lot of ways to define a spatial weigth matrix \\(W\\). Here, the units that are adjacent are specified with a one and the ones that are not adjacent with a zero (binary coniguity matrix)\n\\[w_{ij} = \\begin{cases} 1 \\text{ if } A_i \\text{ and } A_j \\text{ are adjacent}\\\\ 0 \\text{ otw} \\end{cases}\\]\nother options to specify the weight matrix \\(W\\) are mentioned in Zuur, Ieno, and Smith (2007).\nVoyager has a special function for the construction of the weight matrix in Visium data findVisiumGraph.",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "06-HTS-multivar-latSOD.html#global-measures-for-bivariate-data",
    "href": "06-HTS-multivar-latSOD.html#global-measures-for-bivariate-data",
    "title": "Preamble",
    "section": "",
    "text": "For two continous observation the global bivariate Moran’s I is defined as (Wartenberg 1985; Bivand 2022)\n\\[I_B = \\frac{\\Sigma_i(\\Sigma_j{w_{ij}y_j\\times x_i})}{\\Sigma_i{x_i^2}}\\]\nwhere \\(x_i\\) and \\(y_i\\) are the two variables of interest and \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\).\nThe global bivariate Moran’s I is a measure of autocorrelation of the variables \\(x\\) and \\(y\\) with the spatial lag of \\(y\\). Therefore the result might overestimate the spatial autocorrelation of the variables due to the inherent (non-spatial) correlation of \\(x\\) and \\(y\\) (Bivand 2022).\n\n\n\n\nShow the code\nres_xy &lt;- spdep::moran_bv(x = logcounts(sfe)[features[1],],\n         y = logcounts(sfe)[features[2],],\n         listw =  colGraph(sfe, colGraphName),\n         nsim = 499)\nboot::boot.ci(res_xy, conf = c(0.99, 0.95, 0.9), type = \"basic\")\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 499 bootstrap replicates\n\nCALL : \nboot::boot.ci(boot.out = res_xy, conf = c(0.99, 0.95, 0.9), type = \"basic\")\n\nIntervals : \nLevel      Basic         \n99%   (-0.0057,  0.0674 )   \n95%   ( 0.0034,  0.0602 )   \n90%   ( 0.0084,  0.0556 )  \nCalculations and Intervals on Original Scale\nSome basic intervals may be unstable\n\n\nShow the code\nplot(res_xy)\n\n\n\n\n\n\n\n\n\nFrom the result of the global measure, the overall spatial autocorrelation of the two genes is not significant.\n\n\n\n\nLee’s L is a bivariate measure that combines non-spatial pearson correlation with spatial autocorrelation via Moran’s I (Lee 2001). This enables us to asses the spatial dependence of two continuous variables in a single measure. The measure is defined as\n\\[L(x,y) = \\frac{n}{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij})^2}\\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\]\nwhere \\(w_{ij}\\) is the value of the spatial weights matrix for positions \\(i\\) and \\(j\\), \\(x\\) and \\(y\\) the two variables and \\(\\bar{x}\\) and \\(\\bar{y}\\) their means.\n\n\n\n\nShow the code\nres_lee &lt;- calculateBivariate(sfe, type = \"lee.mc\", \n                   feature1 = features[1], feature2 = features[2],\n                   colGraphName = colGraphName,\n                   nsim = 499)\nres_lee$lee.mc_statistic\n\n\nstatistic \n0.0213312 \n\n\nShow the code\nres_lee$ lee.mc_p.value\n\n\n[1] 0.008",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "06-HTS-multivar-latSOD.html#local-measures-for-bivariate-data",
    "href": "06-HTS-multivar-latSOD.html#local-measures-for-bivariate-data",
    "title": "Preamble",
    "section": "",
    "text": "Similar to the global variant of Lee’s L the local variant (Lee 2001) is defined as\n\\[L_i(x,y) = \\frac{\\sum_{i=1}^n(\\sum_{j=1}^nw_{ij}(x_i-\\bar{x}))(\\sum_{j=1}^nw_{ij}(y_j-\\bar{y}))}{\\sqrt{\\sum_{i=1}^nw_{ij}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^nw_{ij}(y_i-\\bar{y})^2}},\\] Local Lee’s L is a measure of spatial co-expression, when the variables of interest are gene expression measurements and can also be a metric of co-localization. Unlike the gobal version, the variables are not averaged and show the local contribution to the metric. Positive values indicate colocalization, negative values indicate segregation.\nThis can be interesting in the context of detection of coexpressed ligand-receptor pairs. A method that is based on bivariate Moran’s I and tries to detect such pairs is SpatialDM (Li et al. 2023).\n\n\n\n\n\n\n\nShow the code\nsfe_tissue &lt;- runBivariate(sfe, type = \"locallee\",\n                    feature1 = features[1], feature2 = features[2],\n                    colGraphName = colGraphName)\n\nplotLocalResult(sfe_tissue, \"locallee\", \n                 features = localResultFeatures(sfe_tissue, \"locallee\"),\n                ncol = 2, divergent = TRUE, diverge_center = 0,\n                colGeometryName = colGeometryName)",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "06-HTS-multivar-latSOD.html#local-measures-for-multivariate-data",
    "href": "06-HTS-multivar-latSOD.html#local-measures-for-multivariate-data",
    "title": "Preamble",
    "section": "",
    "text": "Geary’s C is a measure of spatial autocorrelation that is based on the difference between a variable and its neighbours. (Anselin 2019) defines it as\n\\[C_i = \\sum_{j=1}^n w_{ij}(z_i-z_j)^2,\\]\nand can be generalized to \\(k\\) parameters by expanding\n\\[c_{k,i} = \\sum_{v=1}^k c_{v,i}\\]\nwhere \\(c_{v,i}\\) is the local Geary’s C for the \\(v\\)th variable at location \\(i\\). The number of variables that can be used is not fixed, which makes the interpretation a bit more difficult. In general, the metric summarizes similarity in the “multivariate attribute space” (i.e. the gene expression) to its geographic neighbours. The common difficulty in these analyses is the interpretation of the mixture of similarity in the geographic space and similarity in the attribute space.\n\n\n\nTo speed up computation we will use highly variable genes.\n\n\nShow the code\nhvgs &lt;- getTopHVGs(sfe, fdr.threshold = 0.01)\n\n# Subset of the tissue\nsfe_tissue &lt;- runMultivariate(sfe, type = \"localC_multi\",\n                    subset_row = hvgs,\n                    colGraphName = colGraphName)\n\n# Local C mutli is stored in colData so this is a workaround to plot it\nplotSpatialFeature(sfe_tissue, \"localC_multi\")\n\n\n\n\n\n\n\n\n\nWe can further plot the results of the permutation test. Significant values indicate interesting regions, but should be interpreted with care for various reasons. For example, we are looking for similarity in a combination of multiple values but the exact combination is not known. Anselin (2019) write “Overall, however, the statistic indicates a combination of the notion of distance in multi-attribute space with that of geographic neighbors. This is the essence of any spatial autocorrelation statistic. It is also the trade-off encountered in spatially constrained multivariate clustering methods (for a recent discussion, see, e.g., Grubesic, Wei, and Murray 2014).”. Multi-attribute space refers here to the highly variable genes. The problem comes down to where the similarity comes from, the gene expression or the physical space. The same problem is common in spatial domain detection methods.\n\n\nShow the code\nsfe &lt;- runMultivariate(sfe, type = \"localC_perm_multi\",\n                    subset_row = hvgs,\n                    nsim = 100,\n                    colGraphName= colGraphName)\n\n# stored as spatially reduced dim; plot it in this way\nspatialReducedDim(sfe, \"localC_perm_multi\",  c(1, 11))",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "06-HTS-multivar-latSOD.html#local-neighbor-match-test",
    "href": "06-HTS-multivar-latSOD.html#local-neighbor-match-test",
    "title": "Preamble",
    "section": "",
    "text": "This test is useful to assess the overlap of the k-nearest neighbours from physical distances (tissue space) with the k-nearest neighbours from the gene expression measurements (attribute space). For both physical and attribute space k-nearest neighbor matrix is computed. In a second step the probability of an overlap between the two matrices have in common (Anselin and Li 2020).\n\n\nShow the code\nsf &lt;- colGeometries(sfe)[[segmentation]]\nsf &lt;- cbind(sf,  t(as.matrix(logcounts(sfe)[hvgs,])))\n\nnbr_test &lt;- neighbor_match_test(sf[c(hvgs)], k = 20)\n\nsf$Probability &lt;- nbr_test$Probability\nsf$Cardinality &lt;- nbr_test$Cardinality\n\ntm_shape(sf) + tm_fill(col = 'Cardinality')  \n\n\n\n\n\n\n\n\n\nShow the code\ntm_shape(sf) + tm_fill(col = 'Probability')  \n\n\n\n\n\n\n\n\n\nCardinality is a measure of how many neighbours of the two matrices are in common. Some regions show high cardinality with low probability therefore share similarity on both attribute and physical space. In contrast to multivariate local Geary’s C this metric focuses directly on the distances and not on a weighted average. A problem of this approach is called the empty space problem which states that as the number of dimensions of the feature sets increase, the empty space between observations also increases (Anselin and Li 2020).",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "06-HTS-multivar-latSOD.html#measures-for-binary-and-categorical-data",
    "href": "06-HTS-multivar-latSOD.html#measures-for-binary-and-categorical-data",
    "title": "Preamble",
    "section": "",
    "text": "In addition to measures of spatial autocorrelation of continuous data as seen above, there exist a method that apply the same concept to binary and categorical data, joint count statistics. In essence the joint count statistic compares the distribution of categorical marks in a lattice with frequencies that would occur randomly. These random occurrences can be computed using a theoretical approximation or random permutations. The same concept was also extended in a multivariate setting with more than two categories. The corresponding spdep function are called joincount.test and joincount.multi Bivand (2022).",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "06-HTS-multivar-latSOD.html#a-note-of-caution",
    "href": "06-HTS-multivar-latSOD.html#a-note-of-caution",
    "title": "Preamble",
    "section": "",
    "text": "The local methods presented above should always be interpreted with care, since we face the problem of multiple testing when calculating them for each cell. Moreover, the presented methods should mainly serve as exploratory measures to identify interesting regions in the data. Multiple processes can lead to the same pattern, thus from identifying the pattern we cannot infer the underlying process. Indication of clustering does not explain why this occurs. On the one hand, clustering can be the result of spatial interaction between the variables of interest. We have an accumulation of a gene of interest in one region of the tissue. On the other hand clustering can be the result spatial heterogeneity, when local similarity is created by structural heterogeneity in the tissue, e.g., that cells with uniform expression of a gene of interest are grouped together which then creates the apparent clustering of the gene expression measurement.",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "06-HTS-multivar-latSOD.html#session-info",
    "href": "06-HTS-multivar-latSOD.html#session-info",
    "title": "Preamble",
    "section": "",
    "text": "Show the code\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magrittr_2.0.3                 stringr_1.5.0                 \n [3] dixon_0.0-8                    splancs_2.01-44               \n [5] spdep_1.2-8                    spData_2.3.0                  \n [7] tmap_3.3-4                     scater_1.28.0                 \n [9] scran_1.28.2                   scuttle_1.10.3                \n[11] SFEData_1.2.0                  SpatialFeatureExperiment_1.2.3\n[13] Voyager_1.2.7                  rgeoda_0.0.10-4               \n[15] digest_0.6.33                  ncf_1.3-2                     \n[17] sf_1.0-16                      reshape2_1.4.4                \n[19] patchwork_1.2.0                STexampleData_1.8.0           \n[21] ExperimentHub_2.8.1            AnnotationHub_3.8.0           \n[23] BiocFileCache_2.8.0            dbplyr_2.3.4                  \n[25] RANN_2.6.1                     seg_0.5-7                     \n[27] sp_2.1-1                       rlang_1.1.1                   \n[29] ggplot2_3.5.1                  dplyr_1.1.3                   \n[31] mixR_0.2.0                     spatstat_3.0-6                \n[33] spatstat.linnet_3.1-1          spatstat.model_3.2-6          \n[35] rpart_4.1.19                   spatstat.explore_3.2-3        \n[37] nlme_3.1-162                   spatstat.random_3.1-6         \n[39] spatstat.geom_3.2-5            spatstat.data_3.0-1           \n[41] SpatialExperiment_1.10.0       SingleCellExperiment_1.22.0   \n[43] SummarizedExperiment_1.30.2    Biobase_2.60.0                \n[45] GenomicRanges_1.52.1           GenomeInfoDb_1.36.4           \n[47] IRanges_2.34.1                 S4Vectors_0.38.2              \n[49] BiocGenerics_0.46.0            MatrixGenerics_1.12.3         \n[51] matrixStats_1.0.0             \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-2         bitops_1.0-7                 \n  [3] httr_1.4.7                    RColorBrewer_1.1-3           \n  [5] tools_4.3.1                   utf8_1.2.3                   \n  [7] R6_2.5.1                      HDF5Array_1.28.1             \n  [9] mgcv_1.9-1                    rhdf5filters_1.12.1          \n [11] withr_2.5.1                   gridExtra_2.3                \n [13] leaflet_2.2.0                 leafem_0.2.3                 \n [15] cli_3.6.1                     labeling_0.4.3               \n [17] proxy_0.4-27                  dbscan_1.1-11                \n [19] R.utils_2.12.2                dichromat_2.0-0.1            \n [21] scico_1.5.0                   limma_3.56.2                 \n [23] rstudioapi_0.15.0             RSQLite_2.3.1                \n [25] generics_0.1.3                crosstalk_1.2.0              \n [27] Matrix_1.5-4.1                ggbeeswarm_0.7.2             \n [29] fansi_1.0.5                   abind_1.4-5                  \n [31] R.methodsS3_1.8.2             terra_1.7-55                 \n [33] lifecycle_1.0.3               yaml_2.3.7                   \n [35] edgeR_3.42.4                  rhdf5_2.44.0                 \n [37] tmaptools_3.1-1               grid_4.3.1                   \n [39] blob_1.2.4                    promises_1.2.1               \n [41] dqrng_0.3.1                   crayon_1.5.2                 \n [43] lattice_0.21-8                beachmat_2.16.0              \n [45] KEGGREST_1.40.1               magick_2.8.0                 \n [47] pillar_1.9.0                  knitr_1.44                   \n [49] metapod_1.7.0                 rjson_0.2.21                 \n [51] boot_1.3-28.1                 codetools_0.2-19             \n [53] wk_0.8.0                      glue_1.6.2                   \n [55] vctrs_0.6.4                   png_0.1-8                    \n [57] gtable_0.3.4                  cachem_1.0.8                 \n [59] xfun_0.40                     S4Arrays_1.0.6               \n [61] mime_0.12                     DropletUtils_1.20.0          \n [63] units_0.8-4                   statmod_1.5.0                \n [65] bluster_1.10.0                interactiveDisplayBase_1.38.0\n [67] ellipsis_0.3.2                bit64_4.0.5                  \n [69] filelock_1.0.2                irlba_2.3.5.1                \n [71] vipor_0.4.5                   KernSmooth_2.23-21           \n [73] colorspace_2.1-0              DBI_1.1.3                    \n [75] raster_3.6-26                 tidyselect_1.2.0             \n [77] bit_4.0.5                     compiler_4.3.1               \n [79] curl_5.1.0                    BiocNeighbors_1.18.0         \n [81] DelayedArray_0.26.7           scales_1.3.0                 \n [83] classInt_0.4-10               rappdirs_0.3.3               \n [85] goftest_1.2-3                 spatstat.utils_3.0-5         \n [87] rmarkdown_2.25                XVector_0.40.0               \n [89] htmltools_0.5.6.1             pkgconfig_2.0.3              \n [91] base64enc_0.1-3               sparseMatrixStats_1.12.2     \n [93] fastmap_1.1.1                 htmlwidgets_1.6.2            \n [95] shiny_1.7.5.1                 DelayedMatrixStats_1.22.6    \n [97] farver_2.1.1                  jsonlite_1.8.7               \n [99] BiocParallel_1.34.2           R.oo_1.25.0                  \n[101] BiocSingular_1.16.0           RCurl_1.98-1.12              \n[103] GenomeInfoDbData_1.2.10       s2_1.1.4                     \n[105] Rhdf5lib_1.22.1               munsell_0.5.0                \n[107] Rcpp_1.0.11                   ggnewscale_0.4.9             \n[109] viridis_0.6.4                 stringi_1.7.12               \n[111] leafsync_0.1.0                zlibbioc_1.46.0              \n[113] plyr_1.8.9                    parallel_4.3.1               \n[115] ggrepel_0.9.4                 deldir_1.0-9                 \n[117] Biostrings_2.68.1             stars_0.6-4                  \n[119] splines_4.3.1                 tensor_1.5                   \n[121] locfit_1.5-9.8                igraph_1.5.1                 \n[123] ScaledMatrix_1.8.1            BiocVersion_3.17.1           \n[125] XML_3.99-0.14                 evaluate_0.22                \n[127] BiocManager_1.30.22           httpuv_1.6.11                \n[129] purrr_1.0.2                   polyclip_1.10-6              \n[131] rsvd_1.0.5                    lwgeom_0.2-13                \n[133] xtable_1.8-4                  e1071_1.7-13                 \n[135] RSpectra_0.16-1               later_1.3.1                  \n[137] viridisLite_0.4.2             class_7.3-22                 \n[139] tibble_3.2.1                  memoise_2.0.1                \n[141] beeswarm_0.4.0                AnnotationDbi_1.62.2         \n[143] cluster_2.1.4",
    "crumbs": [
      "Lattice-based Methods"
    ]
  },
  {
    "objectID": "00-overview-latSOD.html",
    "href": "00-overview-latSOD.html",
    "title": "Lattice data analysis – Summary",
    "section": "",
    "text": "©2024 The pasta authors. Content is published under Creative Commons CC-BY-4.0 License for the text and GPL-3 License for any code.",
    "crumbs": [
      "Overview Lattice-based Methods"
    ]
  }
]